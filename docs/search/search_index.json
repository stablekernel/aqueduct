{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Aqueduct Aqueduct is an HTTP web server framework for building REST applications written in Dart. How to Use this Documentation The menu on the left contains a hierarchy documents. Those documents - and how you should use them - are described in the following table: Location Description Recommended Usage Top-Level (e.g. Tour, Core Concepts) Introductory and quick reference documents Read these documents when you are new to Aqueduct Snippets Example code snippets of common behaviors Read these documents for examples and inspiration Tutorial A linear, guided tutorial to building your first application A 1-3 hour long tutorial to learn Aqueduct Guides A hierarchy of in-depth guides for the many facets of Aqueduct Refer to these documents often to understand concepts and usage of Aqueduct In addition to these guides, be sure to use the API Reference to look up classes, methods, functions and other elements of the framework. Getting Started Tips The best way to get started is to read the Core Concepts guide while working through the tutorial . Then, add new features to the application created during the tutorial by looking up the classes you are using in the API Reference , and implementing behavior not found in the tutorial. It's a good idea to install a tool like Dash for viewing the API Reference. Once you have the basic concepts down, start reading the guides in the left hand menu to take advantage of the many features of the framework. Check out the repository of examples here . Import this file into IntelliJ IDEA for Aqueduct file and code templates. Aqueduct is catered towards test-driven development - the best way to write an application is to write tests using a test harness and run those tests after implementing an endpoint. You may also run the command aqueduct document client in your project directory to generate a web client for your application. This client can be opened in any browser and will execute requests against your locally running application.","title":"Home"},{"location":"#aqueduct","text":"Aqueduct is an HTTP web server framework for building REST applications written in Dart.","title":"Aqueduct"},{"location":"#how-to-use-this-documentation","text":"The menu on the left contains a hierarchy documents. Those documents - and how you should use them - are described in the following table: Location Description Recommended Usage Top-Level (e.g. Tour, Core Concepts) Introductory and quick reference documents Read these documents when you are new to Aqueduct Snippets Example code snippets of common behaviors Read these documents for examples and inspiration Tutorial A linear, guided tutorial to building your first application A 1-3 hour long tutorial to learn Aqueduct Guides A hierarchy of in-depth guides for the many facets of Aqueduct Refer to these documents often to understand concepts and usage of Aqueduct In addition to these guides, be sure to use the API Reference to look up classes, methods, functions and other elements of the framework.","title":"How to Use this Documentation"},{"location":"#getting-started-tips","text":"The best way to get started is to read the Core Concepts guide while working through the tutorial . Then, add new features to the application created during the tutorial by looking up the classes you are using in the API Reference , and implementing behavior not found in the tutorial. It's a good idea to install a tool like Dash for viewing the API Reference. Once you have the basic concepts down, start reading the guides in the left hand menu to take advantage of the many features of the framework. Check out the repository of examples here . Import this file into IntelliJ IDEA for Aqueduct file and code templates. Aqueduct is catered towards test-driven development - the best way to write an application is to write tests using a test harness and run those tests after implementing an endpoint. You may also run the command aqueduct document client in your project directory to generate a web client for your application. This client can be opened in any browser and will execute requests against your locally running application.","title":"Getting Started Tips"},{"location":"best_practices/","text":"Best Practices for Developing Aqueduct Applications Keep Dart Projects Separate Because Dart is cross-platform, developers should avoid combining client application projects with Aqueduct projects. Instead, use a single repository with an independent project for each facet of the system. When there are opportunities for code sharing between platforms (typically between Flutter and AngularDart), shared code can live in a dependency project in the same repository. A typical directory structure for an multi-faceted application looks like this: application_name/ aqueduct/ flutter/ angular/ shared/ Project Definition A project is a directory that contain a pubspec.yaml file and lib directory. It is tempting to share your data model types between your server and client applications, but this falls apart for anything but the most simple of applications. There are enough behavioral differences between the four representations of your data model - in the database, on the server, on the wire (JSON), and on the client - that a single type will have a hard time encompassing. Instead, generate an OpenAPI specification with aqueduct document and use one of the many open-source tools for generating client data model types. Use Test Driven Development (or something close to it) In Aqueduct, testing is a first-class citizen. The aqueduct_test package has classes and methods for initializing and running an application for testing, making requests to that application, and verifying the responses. There is value to using tools like Postman or CURL to test proof of concept code, but the aqueduct_test package is geared specifically for replacing these tools while retaining automated tests as the project grows. An example test suite looks like this: void main () { final harness = new Harness ().. install (); test ( GET /endpoint returns 200 and a simple object , () async { final response = await harness . agent . get ( /endpoint ); expectResponse ( response , 200 , body: { key : value }); }); } Use a bin Script to Verify Assumptions Keep a simple Dart script file in the bin/ directory that imports your project. Use this file as a scratchpad to test exploratory code before committing to a test suite. Don't check this file into source control. import package:myapp/myapp.dart ; Future main () async { var whatIsThis = await someYetToBeNamedUsefullyMethod (); print ( $ whatIsThis ); } Create New Projects from a Template Use aqueduct create to create applications with the appropriate structure and boilerplate. There are templates for different kinds of applications; view these templates with aqueduct create list-templates . Use a Debugger A debugger allows you to stop execution of a running application at a particular line of code to verify variable values, and then continue to step through that code line by line. It can be used when running test suites or when running the application through the bin/main.dart script. In IntelliJ IDEA, right-click on any file with a main function (which includes test suites) and select Debug option. Use breakpoints (by clicking on the gutter area to the left of the text editing area) to stop execution at a particular line before it is executed. Use the Suggested Project Directory Structure See Aqueduct Project Structure . Pass Services to Controllers in entryPoint Pass service objects to controllers in entryPoint and only pass the services the controller will use. class AppChannel extends ApplicationChannel { GitHub githubService ; PostgreSQLConnection databaseConnection ; @ override Future prepare () async { databaseConnection = new PostgreSQLConnection (); githubService = new GitHub (); } @ override Controller get entryPoint { final router = new Router (); router . route ( /data ) . link (() = new DBController ( databaseConnection )); router . route ( /github ) . link (() = new GitHubController ( githubService )); return router ; } } Passing references like this allows for injecting dependencies that depend on the environment; e.g. in production, development or during tests. It also avoids tight coupling between the objects in your application. Minimize the access a controller has to its dependencies; e.g. don't pass it a StreamController when it only needs Sink or a Stream . Use a Test Harness A test harness initializes your application in a test suite. It has built in behavior that you can add to for things that are specific to your application. Documentation for using a test harness in your application is located here . Use config.src.yaml Use the convention of config.src.yaml file to prevent configuration errors and inject test dependencies. Understand how Aqueduct Uses Isolates See more in Application Structure . Use ResourceController Subclasses Subclassing ResourceController provides significant conveniences, safeties and behaviors used by the majority of an application's request handling logic. Prefer to use this class for non-middleware controllers. Keep ApplicationChannel Tidy A ApplicationChannel should handle initialization, routing and nothing more. Consider moving non-initialization behavior into a service object in a separate file. Avoid Raw SQL Queries Prefer to use the Aqueduct ORM. It sends appropriate HTTP responses for different kinds of errors, validates input data and is ensures the queries match up with your data model. Use API Reference Aqueduct is an object oriented framework - behaviors are implemented by instances of some type. The types of objects, their properties and their behaviors all follow similar naming conventions to make the API more discoverable. Many types in Aqueduct have a prefix in common with related types. For example, types like AuthServer , AuthServerDelegate and AuthCode are all related because they deal with authentication and authorization. Methods are named consistently across classes (e.g, asMap is a common method name). When looking for a solution, look at the API reference for the objects you have access to. These objects may already have the behavior you wish to implement or have a reference to an object with that behavior. Use try-catch Sparingly All request handling code is wrapped in a try-catch block that will interpret exceptions and errors and return meaningful HTTP responses. Unknown exceptions will yield a 500 Server Error response. In general, you do not need to use try-catch unless you want a different HTTP response than the one being returned for the exception. Code that throws an exception during initialization should not be caught if the error is fatal to the application launching successfully.","title":"Best Practices"},{"location":"best_practices/#best-practices-for-developing-aqueduct-applications","text":"","title":"Best Practices for Developing Aqueduct Applications"},{"location":"best_practices/#keep-dart-projects-separate","text":"Because Dart is cross-platform, developers should avoid combining client application projects with Aqueduct projects. Instead, use a single repository with an independent project for each facet of the system. When there are opportunities for code sharing between platforms (typically between Flutter and AngularDart), shared code can live in a dependency project in the same repository. A typical directory structure for an multi-faceted application looks like this: application_name/ aqueduct/ flutter/ angular/ shared/ Project Definition A project is a directory that contain a pubspec.yaml file and lib directory. It is tempting to share your data model types between your server and client applications, but this falls apart for anything but the most simple of applications. There are enough behavioral differences between the four representations of your data model - in the database, on the server, on the wire (JSON), and on the client - that a single type will have a hard time encompassing. Instead, generate an OpenAPI specification with aqueduct document and use one of the many open-source tools for generating client data model types.","title":"Keep Dart Projects Separate"},{"location":"best_practices/#use-test-driven-development-or-something-close-to-it","text":"In Aqueduct, testing is a first-class citizen. The aqueduct_test package has classes and methods for initializing and running an application for testing, making requests to that application, and verifying the responses. There is value to using tools like Postman or CURL to test proof of concept code, but the aqueduct_test package is geared specifically for replacing these tools while retaining automated tests as the project grows. An example test suite looks like this: void main () { final harness = new Harness ().. install (); test ( GET /endpoint returns 200 and a simple object , () async { final response = await harness . agent . get ( /endpoint ); expectResponse ( response , 200 , body: { key : value }); }); }","title":"Use Test Driven Development (or something close to it)"},{"location":"best_practices/#use-a-bin-script-to-verify-assumptions","text":"Keep a simple Dart script file in the bin/ directory that imports your project. Use this file as a scratchpad to test exploratory code before committing to a test suite. Don't check this file into source control. import package:myapp/myapp.dart ; Future main () async { var whatIsThis = await someYetToBeNamedUsefullyMethod (); print ( $ whatIsThis ); }","title":"Use a bin Script to Verify Assumptions"},{"location":"best_practices/#create-new-projects-from-a-template","text":"Use aqueduct create to create applications with the appropriate structure and boilerplate. There are templates for different kinds of applications; view these templates with aqueduct create list-templates .","title":"Create New Projects from a Template"},{"location":"best_practices/#use-a-debugger","text":"A debugger allows you to stop execution of a running application at a particular line of code to verify variable values, and then continue to step through that code line by line. It can be used when running test suites or when running the application through the bin/main.dart script. In IntelliJ IDEA, right-click on any file with a main function (which includes test suites) and select Debug option. Use breakpoints (by clicking on the gutter area to the left of the text editing area) to stop execution at a particular line before it is executed.","title":"Use a Debugger"},{"location":"best_practices/#use-the-suggested-project-directory-structure","text":"See Aqueduct Project Structure .","title":"Use the Suggested Project Directory Structure"},{"location":"best_practices/#pass-services-to-controllers-in-entrypoint","text":"Pass service objects to controllers in entryPoint and only pass the services the controller will use. class AppChannel extends ApplicationChannel { GitHub githubService ; PostgreSQLConnection databaseConnection ; @ override Future prepare () async { databaseConnection = new PostgreSQLConnection (); githubService = new GitHub (); } @ override Controller get entryPoint { final router = new Router (); router . route ( /data ) . link (() = new DBController ( databaseConnection )); router . route ( /github ) . link (() = new GitHubController ( githubService )); return router ; } } Passing references like this allows for injecting dependencies that depend on the environment; e.g. in production, development or during tests. It also avoids tight coupling between the objects in your application. Minimize the access a controller has to its dependencies; e.g. don't pass it a StreamController when it only needs Sink or a Stream .","title":"Pass Services to Controllers in entryPoint"},{"location":"best_practices/#use-a-test-harness","text":"A test harness initializes your application in a test suite. It has built in behavior that you can add to for things that are specific to your application. Documentation for using a test harness in your application is located here .","title":"Use a Test Harness"},{"location":"best_practices/#use-configsrcyaml","text":"Use the convention of config.src.yaml file to prevent configuration errors and inject test dependencies.","title":"Use config.src.yaml"},{"location":"best_practices/#understand-how-aqueduct-uses-isolates","text":"See more in Application Structure .","title":"Understand how Aqueduct Uses Isolates"},{"location":"best_practices/#use-resourcecontroller-subclasses","text":"Subclassing ResourceController provides significant conveniences, safeties and behaviors used by the majority of an application's request handling logic. Prefer to use this class for non-middleware controllers.","title":"Use ResourceController Subclasses"},{"location":"best_practices/#keep-applicationchannel-tidy","text":"A ApplicationChannel should handle initialization, routing and nothing more. Consider moving non-initialization behavior into a service object in a separate file.","title":"Keep ApplicationChannel Tidy"},{"location":"best_practices/#avoid-raw-sql-queries","text":"Prefer to use the Aqueduct ORM. It sends appropriate HTTP responses for different kinds of errors, validates input data and is ensures the queries match up with your data model.","title":"Avoid Raw SQL Queries"},{"location":"best_practices/#use-api-reference","text":"Aqueduct is an object oriented framework - behaviors are implemented by instances of some type. The types of objects, their properties and their behaviors all follow similar naming conventions to make the API more discoverable. Many types in Aqueduct have a prefix in common with related types. For example, types like AuthServer , AuthServerDelegate and AuthCode are all related because they deal with authentication and authorization. Methods are named consistently across classes (e.g, asMap is a common method name). When looking for a solution, look at the API reference for the objects you have access to. These objects may already have the behavior you wish to implement or have a reference to an object with that behavior.","title":"Use API Reference"},{"location":"best_practices/#use-try-catch-sparingly","text":"All request handling code is wrapped in a try-catch block that will interpret exceptions and errors and return meaningful HTTP responses. Unknown exceptions will yield a 500 Server Error response. In general, you do not need to use try-catch unless you want a different HTTP response than the one being returned for the exception. Code that throws an exception during initialization should not be caught if the error is fatal to the application launching successfully.","title":"Use try-catch Sparingly"},{"location":"core_concepts/","text":"Resources Resources are the things your application exposes through its HTTP API. A resource can be anything - a user profile in an application, a temperature sensor in Antarctica, or a high score for a game. For example, the GitHub API exposes organization, repository, issue and pull request resources; a social network API has profiles, posts, and user relationships. Resources are organized into collections (e.g., all of the posts), for which individual resources within that collection can be uniquely identified (e.g., a single post). Requests are made to an application to retrieve the state of a resource or to provide the desired state of a resource. Most often, resources are represented as JSON arrays and objects. When retrieving a resource, its JSON representation is encoded into the response body. When providing the desired state of a resource, a client sends the JSON representation of the desired resource state in the request body. For more details on the concept of a resource, see the RFC Specification for HTTP/1.1 . Routing Resources are identified by the path of an HTTP request. For example, the URL http://example.com/organizations identifies the collection of organization resources on the server http://example.com . The URL http://example.com/organizations/1 identifies a single organization. An application exposes routes for each resource it manages. A route is a string that matches the path of a request. When a request's path matches a route, the associated handler is invoked to handle the request. Routes look like paths, but have some additional syntax. For example, the route /organizations will match requests with the path /organizations . The route /organizations/:id will match the paths /organizations/1 , /organizations/2 , and so on. Complex routes can be formed with additional syntax. See the guide on routing for usage details. Controllers Controllers are objects that handle requests. For example, a controller might fetch rows from a database and send them to the client in the response body. Another controller might verify the username and password of a request's Authorization header are valid. Controllers are linked together to form a series of actions to take for a request. These linked together controllers are called a channel . If the above examples were linked together, the channel would check if a request were authorized before it sent a response containing database rows. There are two flavors of controllers. An endpoint controller performs operations on a resource or resource collection, and always sends a response. Endpoint controllers fulfill requests by returning the state of a resource or by changing the state of a resource. You write most of your application-specific logic endpoint controllers. A middleware controller takes an action for a request, but isn't responsible for fulfilling the request. Middleware controllers can do many different things and are often reusable in many channels. Most often, a middleware controller validates something about a request before it reaches an endpoint controller. Middleware controllers can send a response for a request, and doing so prevents any other controller in that channel from handling the request. A channel must have exactly one endpoint controller. It can be preceded by zero or more middleware controllers. See the guides on Controllers and ResourceControllers for usage details. The Application Channel The application channel is an object that contains all of the controllers in an application. It designates one controller as the first controller to receive every request called its entry point . Controllers are linked to the entry point (directly or transitively) to form the entire application channel. In nearly every application, the entry point is a router; this controller splits the channel into sub-channels for a given route. The application channel is also responsible for initializing the application's services, reading configuration files and other startup related tasks. See the guide on the Application Channel for more details. Services A service is an object that encapsulates complex tasks or algorithms, external communication or tasks that will be reused across an application. The purpose of a service object is to provide a simple interface to more detailed behavior. For example, a database connection is a service object; a user of a database connection doesn't know the details of how the connection is made or how to encode the query onto the wire, but it can still execute queries. The primary user of service objects are controllers. Services are injected into controllers by passing them as arguments to the controller's constructor. The controller keeps a reference to the service, so that it can use it when handling a request. For more details on injecting services, see the guide on the Application Channel . Isolates Isolates are memory-isolated threads; an object created on one isolate can't be referenced by another isolate. When an application starts, one or more isolates containing replicas of your application code are spawned. This behavior effectively 'load balances' your application across multiple threads. A benefit to this structure is that each isolate has its own set of services, like database connections. This eliminates the need for techniques like 'database connection pooling', because the entire application is effectively 'pooled'. Bindings A request might contain headers, query parameters, a body and path parameters that need to be parsed, validated and used in controller code. Bindings are annotations added to variables that perform this parsing and validation automatically. Appropriate error responses are sent when a bound value can't be parsed into expected type or validation fails. Bindings cut down on boiler plate code and reduce testing surface, making development faster and code easier to reason about. For more information on bindings, see the guide on Resource Controllers . Queries and Data Models Application store information in databases for persistence. Writing database queries by hand is error-prone and doesn't leverage static analysis tools that are so valuable in a Dart application. Aqueduct's ORM (Object-Relational Mapping) provides statically-typed queries that are easy to write and test. Your application's data model is defined by creating Dart classes. Each class is mapped to a database table, and each property of that class is mapped to a column in that table. Aqueduct's command-line tool generates database migration files that detect changes in your data model that can be applied to a live, versioned database. A data model can also be represented as a JSON object to build tools on top of your application. For more details, see the guide on Authorization . Authorization OAuth 2.0 is a standardized authorization framework. Aqueduct contains a specification-compliant implementation of an OAuth 2.0 server that can be integrated directly into your application, or stood up alone to provide an authorization server for federated services. This implementation is easily customizable - it can store authorization artifacts - like tokens and client identifiers - in different types of databases or use stateless authorization mechanisms like JWT. The default implementation leverages the Aqueduct ORM to store artifacts in PostgreSQL. For more details, see the guide on Databases . Documentation OpenAPI 3.0 is a standardized documentation format for HTTP APIs. Many built-in Aqueduct objects support 'automatic' documentation. Objects that are specific to your application can build on top of this to immediately document your application for every change you make. For more details, see the guide on OpenAPI Documentation .","title":"Core Concepts"},{"location":"core_concepts/#resources","text":"Resources are the things your application exposes through its HTTP API. A resource can be anything - a user profile in an application, a temperature sensor in Antarctica, or a high score for a game. For example, the GitHub API exposes organization, repository, issue and pull request resources; a social network API has profiles, posts, and user relationships. Resources are organized into collections (e.g., all of the posts), for which individual resources within that collection can be uniquely identified (e.g., a single post). Requests are made to an application to retrieve the state of a resource or to provide the desired state of a resource. Most often, resources are represented as JSON arrays and objects. When retrieving a resource, its JSON representation is encoded into the response body. When providing the desired state of a resource, a client sends the JSON representation of the desired resource state in the request body. For more details on the concept of a resource, see the RFC Specification for HTTP/1.1 .","title":"Resources"},{"location":"core_concepts/#routing","text":"Resources are identified by the path of an HTTP request. For example, the URL http://example.com/organizations identifies the collection of organization resources on the server http://example.com . The URL http://example.com/organizations/1 identifies a single organization. An application exposes routes for each resource it manages. A route is a string that matches the path of a request. When a request's path matches a route, the associated handler is invoked to handle the request. Routes look like paths, but have some additional syntax. For example, the route /organizations will match requests with the path /organizations . The route /organizations/:id will match the paths /organizations/1 , /organizations/2 , and so on. Complex routes can be formed with additional syntax. See the guide on routing for usage details.","title":"Routing"},{"location":"core_concepts/#controllers","text":"Controllers are objects that handle requests. For example, a controller might fetch rows from a database and send them to the client in the response body. Another controller might verify the username and password of a request's Authorization header are valid. Controllers are linked together to form a series of actions to take for a request. These linked together controllers are called a channel . If the above examples were linked together, the channel would check if a request were authorized before it sent a response containing database rows. There are two flavors of controllers. An endpoint controller performs operations on a resource or resource collection, and always sends a response. Endpoint controllers fulfill requests by returning the state of a resource or by changing the state of a resource. You write most of your application-specific logic endpoint controllers. A middleware controller takes an action for a request, but isn't responsible for fulfilling the request. Middleware controllers can do many different things and are often reusable in many channels. Most often, a middleware controller validates something about a request before it reaches an endpoint controller. Middleware controllers can send a response for a request, and doing so prevents any other controller in that channel from handling the request. A channel must have exactly one endpoint controller. It can be preceded by zero or more middleware controllers. See the guides on Controllers and ResourceControllers for usage details.","title":"Controllers"},{"location":"core_concepts/#the-application-channel","text":"The application channel is an object that contains all of the controllers in an application. It designates one controller as the first controller to receive every request called its entry point . Controllers are linked to the entry point (directly or transitively) to form the entire application channel. In nearly every application, the entry point is a router; this controller splits the channel into sub-channels for a given route. The application channel is also responsible for initializing the application's services, reading configuration files and other startup related tasks. See the guide on the Application Channel for more details.","title":"The Application Channel"},{"location":"core_concepts/#services","text":"A service is an object that encapsulates complex tasks or algorithms, external communication or tasks that will be reused across an application. The purpose of a service object is to provide a simple interface to more detailed behavior. For example, a database connection is a service object; a user of a database connection doesn't know the details of how the connection is made or how to encode the query onto the wire, but it can still execute queries. The primary user of service objects are controllers. Services are injected into controllers by passing them as arguments to the controller's constructor. The controller keeps a reference to the service, so that it can use it when handling a request. For more details on injecting services, see the guide on the Application Channel .","title":"Services"},{"location":"core_concepts/#isolates","text":"Isolates are memory-isolated threads; an object created on one isolate can't be referenced by another isolate. When an application starts, one or more isolates containing replicas of your application code are spawned. This behavior effectively 'load balances' your application across multiple threads. A benefit to this structure is that each isolate has its own set of services, like database connections. This eliminates the need for techniques like 'database connection pooling', because the entire application is effectively 'pooled'.","title":"Isolates"},{"location":"core_concepts/#bindings","text":"A request might contain headers, query parameters, a body and path parameters that need to be parsed, validated and used in controller code. Bindings are annotations added to variables that perform this parsing and validation automatically. Appropriate error responses are sent when a bound value can't be parsed into expected type or validation fails. Bindings cut down on boiler plate code and reduce testing surface, making development faster and code easier to reason about. For more information on bindings, see the guide on Resource Controllers .","title":"Bindings"},{"location":"core_concepts/#queries-and-data-models","text":"Application store information in databases for persistence. Writing database queries by hand is error-prone and doesn't leverage static analysis tools that are so valuable in a Dart application. Aqueduct's ORM (Object-Relational Mapping) provides statically-typed queries that are easy to write and test. Your application's data model is defined by creating Dart classes. Each class is mapped to a database table, and each property of that class is mapped to a column in that table. Aqueduct's command-line tool generates database migration files that detect changes in your data model that can be applied to a live, versioned database. A data model can also be represented as a JSON object to build tools on top of your application. For more details, see the guide on Authorization .","title":"Queries and Data Models"},{"location":"core_concepts/#authorization","text":"OAuth 2.0 is a standardized authorization framework. Aqueduct contains a specification-compliant implementation of an OAuth 2.0 server that can be integrated directly into your application, or stood up alone to provide an authorization server for federated services. This implementation is easily customizable - it can store authorization artifacts - like tokens and client identifiers - in different types of databases or use stateless authorization mechanisms like JWT. The default implementation leverages the Aqueduct ORM to store artifacts in PostgreSQL. For more details, see the guide on Databases .","title":"Authorization"},{"location":"core_concepts/#documentation","text":"OpenAPI 3.0 is a standardized documentation format for HTTP APIs. Many built-in Aqueduct objects support 'automatic' documentation. Objects that are specific to your application can build on top of this to immediately document your application for every change you make. For more details, see the guide on OpenAPI Documentation .","title":"Documentation"},{"location":"getting_started/","text":"Getting Started with Aqueduct Installation Install Dart . Activate the Aqueduct CLI pub global activate aqueduct Create a new project. aqueduct create my_project Open the project directory in an IntelliJ IDE , Atom or Visual Studio Code . All three IDEs have a Dart plugin. How to Learn Aqueduct There are different approaches depending on how you prefer to learn. The guided tutorial is a hands-on walkthrough where you build an application while learning basic Aqueduct concepts. The example repository contains a few deployable applications that you may review or tinker with. The guides (located in the menu on this website) dive deeply into the concepts of Aqueduct and show example code. Creating a new project and using the API reference to jump right in. It is best to first understand how HTTP requests are responded to - the foundation of Aqueduct - before moving on to topics such as the ORM and OAuth 2.0. Both the tutorial and the HTTP guides are the primary source of this information. A project created by the aqueduct tool has example routes connected for modification, too. Creating a Project The aqueduct create command-line tool creates new Aqueduct project directories. The default template contains the minimal project structure for running an Aqueduct application. A project name must be snake_case. aqueduct create my_project_name Other templates exist that contain foundational code for using Aqueduct's ORM and OAuth 2.0 implementation. These templates can be listed: aqueduct create list-templates You may provide the name of a template when creating a project to use that template: aqueduct create -t db my_project_name Using the Aqueduct ORM Aqueduct's ORM uses PostgreSQL. During development, you will need a locally running instance of PostgreSQL. On macOS, installing Postgres.app is a very convenient way to run PostgreSQL locally. For other platforms, see PostgreSQL's downloads page . When creating a project, use the db template. If adding to an existing project, see this guide . To create a database, make sure PostgreSQL is running and open the command-line utility to connect to it. psql Location of psql with Postgres.app If you installed Postgres.app, psql is inside the application bundle. You can run this tool by selecting Open psql from the status bar item in the Finder. Then, create a database that your application will connect to and a user that it will connect with: CREATE DATABASE my_database_name ; CREATE USER dart_app WITH PASSWORD dart ; GRANT ALL ON DATABASE my_database_name TO dart_app ; An application must create a ManagedContext that handles the connection to this database: class MyChannel extends ApplicationChannel { ManagedContext context ; @ override Future prepare () async { var dataModel = new ManagedDataModel . fromCurrentMirrorSystem (); var store = new PostgreSQLPersistentStore . fromConnectionInfo ( dart_app , dart , localhost , 5432 , my_database_name ); context = new ManagedContext ( dataModel , store ); } ... } Once you have declared ManagedObject s in your application, generate the database schema by generating and executing migrations from your project's directory: aqueduct db generate aqueduct db upgrade --connect postgres://dart_app:dart@localhost:5432/my_database_name See the guides on connecting to a database and testing with a database for more details on configuring a database connection.","title":"Getting Started"},{"location":"getting_started/#getting-started-with-aqueduct","text":"","title":"Getting Started with Aqueduct"},{"location":"getting_started/#installation","text":"Install Dart . Activate the Aqueduct CLI pub global activate aqueduct Create a new project. aqueduct create my_project Open the project directory in an IntelliJ IDE , Atom or Visual Studio Code . All three IDEs have a Dart plugin.","title":"Installation"},{"location":"getting_started/#how-to-learn-aqueduct","text":"There are different approaches depending on how you prefer to learn. The guided tutorial is a hands-on walkthrough where you build an application while learning basic Aqueduct concepts. The example repository contains a few deployable applications that you may review or tinker with. The guides (located in the menu on this website) dive deeply into the concepts of Aqueduct and show example code. Creating a new project and using the API reference to jump right in. It is best to first understand how HTTP requests are responded to - the foundation of Aqueduct - before moving on to topics such as the ORM and OAuth 2.0. Both the tutorial and the HTTP guides are the primary source of this information. A project created by the aqueduct tool has example routes connected for modification, too.","title":"How to Learn Aqueduct"},{"location":"getting_started/#creating-a-project","text":"The aqueduct create command-line tool creates new Aqueduct project directories. The default template contains the minimal project structure for running an Aqueduct application. A project name must be snake_case. aqueduct create my_project_name Other templates exist that contain foundational code for using Aqueduct's ORM and OAuth 2.0 implementation. These templates can be listed: aqueduct create list-templates You may provide the name of a template when creating a project to use that template: aqueduct create -t db my_project_name","title":"Creating a Project"},{"location":"getting_started/#using-the-aqueduct-orm","text":"Aqueduct's ORM uses PostgreSQL. During development, you will need a locally running instance of PostgreSQL. On macOS, installing Postgres.app is a very convenient way to run PostgreSQL locally. For other platforms, see PostgreSQL's downloads page . When creating a project, use the db template. If adding to an existing project, see this guide . To create a database, make sure PostgreSQL is running and open the command-line utility to connect to it. psql Location of psql with Postgres.app If you installed Postgres.app, psql is inside the application bundle. You can run this tool by selecting Open psql from the status bar item in the Finder. Then, create a database that your application will connect to and a user that it will connect with: CREATE DATABASE my_database_name ; CREATE USER dart_app WITH PASSWORD dart ; GRANT ALL ON DATABASE my_database_name TO dart_app ; An application must create a ManagedContext that handles the connection to this database: class MyChannel extends ApplicationChannel { ManagedContext context ; @ override Future prepare () async { var dataModel = new ManagedDataModel . fromCurrentMirrorSystem (); var store = new PostgreSQLPersistentStore . fromConnectionInfo ( dart_app , dart , localhost , 5432 , my_database_name ); context = new ManagedContext ( dataModel , store ); } ... } Once you have declared ManagedObject s in your application, generate the database schema by generating and executing migrations from your project's directory: aqueduct db generate aqueduct db upgrade --connect postgres://dart_app:dart@localhost:5432/my_database_name See the guides on connecting to a database and testing with a database for more details on configuring a database connection.","title":"Using the Aqueduct ORM"},{"location":"intellij/","text":"Aqueduct IntellIJ IDEA Templates This document describes how to install file and code templates for Aqueduct when using an IntelliJ IDE (e.g., IDEA, IDEA CE, Webstorm). Installation Download the this file and import it into IntelliJ by selecting Import Settings... from the File menu. File Templates File templates are created by selecting New from the File menu or by right-clicking a directory in the project navigator. The following templates exists: Template Name Behavior Aqueduct ResourceController Creates a new file with the skeleton of an ResourceController . Aqueduct ManagedObject Creates a new file with the skeleton of a ManagedObject subclass Aqueduct Test Creates a new file that creates and installs a TestHarness subclass from your project. Live Templates Live templates are keywords that expand into a larger code block. Typing the keyword in a Dart file and hitting return will enter common Aqueduct code. Live templates often have placeholders that can by jumped between by using the return key. Live Templates: HTTP Shortcut Behavior operation Creates a new operation method in a ResourceController . bindbody Adds a body binding to an operation method. bindheader Adds a header binding to an operation method. bindquery Adds a query binding to an operation method. bindpath Adds a path binding to an operation method. Live Templates: ORM Shortcut Behavior ps Enters the property selector syntax for Query.where , Query.join and other query configuration methods. column Adds a column annotated field to a ManagedObject . relate Adds a relationship annotated field to a ManagedObject . Live Templates: Testing Shortcut Behavior test Creates a test closure in a test file.","title":"IntelliJ IDEA Templates"},{"location":"intellij/#aqueduct-intellij-idea-templates","text":"This document describes how to install file and code templates for Aqueduct when using an IntelliJ IDE (e.g., IDEA, IDEA CE, Webstorm).","title":"Aqueduct IntellIJ IDEA Templates"},{"location":"intellij/#installation","text":"Download the this file and import it into IntelliJ by selecting Import Settings... from the File menu.","title":"Installation"},{"location":"intellij/#file-templates","text":"File templates are created by selecting New from the File menu or by right-clicking a directory in the project navigator. The following templates exists: Template Name Behavior Aqueduct ResourceController Creates a new file with the skeleton of an ResourceController . Aqueduct ManagedObject Creates a new file with the skeleton of a ManagedObject subclass Aqueduct Test Creates a new file that creates and installs a TestHarness subclass from your project.","title":"File Templates"},{"location":"intellij/#live-templates","text":"Live templates are keywords that expand into a larger code block. Typing the keyword in a Dart file and hitting return will enter common Aqueduct code. Live templates often have placeholders that can by jumped between by using the return key.","title":"Live Templates"},{"location":"intellij/#live-templates-http","text":"Shortcut Behavior operation Creates a new operation method in a ResourceController . bindbody Adds a body binding to an operation method. bindheader Adds a header binding to an operation method. bindquery Adds a query binding to an operation method. bindpath Adds a path binding to an operation method.","title":"Live Templates: HTTP"},{"location":"intellij/#live-templates-orm","text":"Shortcut Behavior ps Enters the property selector syntax for Query.where , Query.join and other query configuration methods. column Adds a column annotated field to a ManagedObject . relate Adds a relationship annotated field to a ManagedObject .","title":"Live Templates: ORM"},{"location":"intellij/#live-templates-testing","text":"Shortcut Behavior test Creates a test closure in a test file.","title":"Live Templates: Testing"},{"location":"migration/","text":"Migration from Aqueduct 2 to Aqueduct 3.0 Aqueduct 3 makes a number of breaking changes from Aqueduct 2. Some of these changes are changes to behavior, and others are simple API renaming. This guide demonstrates the changes required for commonly used code. RequestSink is now ApplicationChannel This type has been renamed to ApplicationChannel and its methods for initializing an application have changed. The method setupRouter has been replaced by the getter entryPoint . All controller creating code should be located in this getter, and you must now create the Router yourself if you choose to. Additionally, the methods to link together controllers (e.g., generate , pipe ) have been replaced with the link method, which always takes a closure. class Channel extends ApplicationChannel { Service service ; @ override Future prepare () async { service = Service ( options . context [ service ]); } @ override Controller get entryPoint { final router = Router (); router . link (() = MyController ( service )); return router ; } } The object returned by this getter is the first controller to receive a request, and does not have to be a router (e.g., it could be global middleware). By default, the closure provided to link is invoked once at startup and the same controller instance is reused for all requests. If a Controller implements Recyclable T , the closure is invoke for each new request and a new controller is created to handle the request. You are no longer required to implement a constructor for ApplicationChannel . All of your initialization should be provided by overriding prepare in your channel. You will have access to configuration data through an options property in both prepare and entryPoint . HTTPController is now ResourceController The name of this type has changed, and the syntax for identifying operation methods and binding values has improved. class MyController extends ResourceController { @ Operation . get () Future Response getAll ({ @ Bind . query ( filter ) String filter }) async { ... } @ Operation . put ( id ) Future Response updateThing ( @ Bind . path ( id ) int id , @ Bind . body () Thing thing ) async { ... } } Operation methods must now be decorated an Operation annotation; this replaces metadata like @httpGet . For an operation method to match a request with path variables, the names of those path variables must be arguments to the Operation constructor. In previous versions, path variable methods were selected if the method's arguments bound a path variable. This is no longer the case - binding a path variable has no impact on the selection of a method, the path variable must be identified in the Operation . You no longer have to bind a path variable and can retrieve it through the request.path . Bound parameters are identified by the Bind annotation, and the type of binding is identified by the constructor used. This syntax replaces HTTPQuery.bind() , etc. Query.where syntax has changed Previously, query filters were applied by assigning expressions like whereEqualTo to properties of Query.where . This has been replaced with the property selector syntax that is used when joining, sorting or paging by a property. final query = Query User () .. where (( u ) = u . id ). equalTo ( 1 ); Methods like whereEqualTo no longer exist - all expressions to apply to a selected property are instance methods of the object returned by where . Test library is now aqueduct_test The test library is now a separate library named aqueduct_test and must be added to your pubspec.yaml . Much of its behavior has changed to make writing tests more effective. See the documentation for more details. Swagger - OpenAPI Aqueduct had experimental support for Swagger documentation generation. It now has full, tested support for OpenAPI 3 documentation generation. See the documentation for more details. Renames The following common signatures are a non-exhaustive list of simple API renaming: Authorization.resourceOwnerIdentifier - Authorization.ownerID Request.innerRequest - Request.raw AuthStorage - AuthServerDelegate AuthServer.storage - AuthServer.delegate ApplicationConfiguration - ApplicationOptions Application.configuration - Application.options ServiceRegistry - ServiceRegistry ManagedTableAttributes - Table ManagedRelationshipDeleteRule - DeleteRule ManagedRelationship - Relate ManagedColumnAttributes - Column managedPrimaryKey - primaryKey ManagedTransientAttribute - Serialize Serialize now replaces managedTransientAttribute, managedTransientInputAttribute, and managedTransientOutputAttribute. RequestController - Controller RequestController.processRequest - Controller.handle HTTPController - ResourceController Router.unhandledRequestController - Router.unmatchedController","title":"3.0 Migration Guide"},{"location":"migration/#migration-from-aqueduct-2-to-aqueduct-30","text":"Aqueduct 3 makes a number of breaking changes from Aqueduct 2. Some of these changes are changes to behavior, and others are simple API renaming. This guide demonstrates the changes required for commonly used code.","title":"Migration from Aqueduct 2 to Aqueduct 3.0"},{"location":"migration/#requestsink-is-now-applicationchannel","text":"This type has been renamed to ApplicationChannel and its methods for initializing an application have changed. The method setupRouter has been replaced by the getter entryPoint . All controller creating code should be located in this getter, and you must now create the Router yourself if you choose to. Additionally, the methods to link together controllers (e.g., generate , pipe ) have been replaced with the link method, which always takes a closure. class Channel extends ApplicationChannel { Service service ; @ override Future prepare () async { service = Service ( options . context [ service ]); } @ override Controller get entryPoint { final router = Router (); router . link (() = MyController ( service )); return router ; } } The object returned by this getter is the first controller to receive a request, and does not have to be a router (e.g., it could be global middleware). By default, the closure provided to link is invoked once at startup and the same controller instance is reused for all requests. If a Controller implements Recyclable T , the closure is invoke for each new request and a new controller is created to handle the request. You are no longer required to implement a constructor for ApplicationChannel . All of your initialization should be provided by overriding prepare in your channel. You will have access to configuration data through an options property in both prepare and entryPoint .","title":"RequestSink is now ApplicationChannel"},{"location":"migration/#httpcontroller-is-now-resourcecontroller","text":"The name of this type has changed, and the syntax for identifying operation methods and binding values has improved. class MyController extends ResourceController { @ Operation . get () Future Response getAll ({ @ Bind . query ( filter ) String filter }) async { ... } @ Operation . put ( id ) Future Response updateThing ( @ Bind . path ( id ) int id , @ Bind . body () Thing thing ) async { ... } } Operation methods must now be decorated an Operation annotation; this replaces metadata like @httpGet . For an operation method to match a request with path variables, the names of those path variables must be arguments to the Operation constructor. In previous versions, path variable methods were selected if the method's arguments bound a path variable. This is no longer the case - binding a path variable has no impact on the selection of a method, the path variable must be identified in the Operation . You no longer have to bind a path variable and can retrieve it through the request.path . Bound parameters are identified by the Bind annotation, and the type of binding is identified by the constructor used. This syntax replaces HTTPQuery.bind() , etc.","title":"HTTPController is now ResourceController"},{"location":"migration/#querywhere-syntax-has-changed","text":"Previously, query filters were applied by assigning expressions like whereEqualTo to properties of Query.where . This has been replaced with the property selector syntax that is used when joining, sorting or paging by a property. final query = Query User () .. where (( u ) = u . id ). equalTo ( 1 ); Methods like whereEqualTo no longer exist - all expressions to apply to a selected property are instance methods of the object returned by where .","title":"Query.where syntax has changed"},{"location":"migration/#test-library-is-now-aqueduct_test","text":"The test library is now a separate library named aqueduct_test and must be added to your pubspec.yaml . Much of its behavior has changed to make writing tests more effective. See the documentation for more details.","title":"Test library is now aqueduct_test"},{"location":"migration/#swagger-openapi","text":"Aqueduct had experimental support for Swagger documentation generation. It now has full, tested support for OpenAPI 3 documentation generation. See the documentation for more details.","title":"Swagger -&gt; OpenAPI"},{"location":"migration/#renames","text":"The following common signatures are a non-exhaustive list of simple API renaming: Authorization.resourceOwnerIdentifier - Authorization.ownerID Request.innerRequest - Request.raw AuthStorage - AuthServerDelegate AuthServer.storage - AuthServer.delegate ApplicationConfiguration - ApplicationOptions Application.configuration - Application.options ServiceRegistry - ServiceRegistry ManagedTableAttributes - Table ManagedRelationshipDeleteRule - DeleteRule ManagedRelationship - Relate ManagedColumnAttributes - Column managedPrimaryKey - primaryKey ManagedTransientAttribute - Serialize Serialize now replaces managedTransientAttribute, managedTransientInputAttribute, and managedTransientOutputAttribute. RequestController - Controller RequestController.processRequest - Controller.handle HTTPController - ResourceController Router.unhandledRequestController - Router.unmatchedController","title":"Renames"},{"location":"tour/","text":"Aqueduct: A Tour The tour demonstrates many of Aqueduct's features. Command-Line Interface (CLI) The aqueduct command line tool creates, runs and documents Aqueduct applications; manages database migrations; and manages OAuth client identifiers. Install by running pub global activate aqueduct on a machine with Dart installed. Create and run an application: aqueduct create my_app cd my_app/ aqueduct serve Initialization An Aqueduct application starts at an ApplicationChannel . You subclass it once per application to handle initialization tasks like setting up routes and database connections. An example application looks like this: import package:aqueduct/aqueduct.dart ; class TodoApp extends ApplicationChannel { ManagedContext context ; @ override Future prepare () async { context = ManagedContext (...); } @ override Controller get entryPoint { final router = Router (); router . route ( /projects/[:id] ) . link (() = ProjectController ( context )); return router ; } } Routing A router determines which controller object should handle a request. The route specification syntax is a concise syntax to construct routes with variables and optional segments in a single statement. @ override Controller get entryPoint { final router = Router (); // Handles /users, /users/1, /users/2, etc. router . route ( /projects/[:id] ) . link (() = ProjectController ()); // Handles any route that starts with /file/ router . route ( /file/* ) . link (() = FileController ()); // Handles the specific route /health router . route ( /health ) . linkFunction (( req ) async = Response . ok ( null )); return router ; } Controllers Controllers handle requests. A controller handles a request by overriding its handle method. This method either returns a response or a request. If a response is returned, that response is sent to the client. If the request is returned, the linked controller handles the request. class SecretKeyAuthorizer extends Controller { @ override Future RequestOrResponse handle ( Request request ) async { if ( request . raw . headers . value ( x-secret-key ) == secret! ) { return request ; } return Response . badRequest (); } } This behavior allows for middleware controllers to be linked together, such that a request goes through a number of steps before it is finally handled. All controllers execute their code in an exception handler. If an exception is thrown in your controller code, a response with an appropriate error code is returned. You subclass HandlerException to provide error response customization for application-specific exceptions. ResourceControllers ResourceControllers are the most often used controller. Each operation - e.g. POST /projects , GET /projects and GET /projects/1 - is mapped to methods in a subclass. Parameters of those methods are annotated to bind the values of the request when the method is invoked. import package:aqueduct/aqueduct.dart class ProjectController extends ResourceController { @ Operation . get ( id ) Future Response getProjectById (@ Bind . path ( id ) int id ) async { // GET / projects /: id return Response . ok (...) ; } @ Operation . post () Future Response createProject ( @ Bind . body () Project project ) async { // POST /project final inserted = await insertProject ( project ); return Response . ok ( inserted ); } @ Operation . get () Future Response getAllProjects ( @ Bind . header ( x-client-id ) String clientId , { @ Bind . query ( limit ) int limit: 10 }) async { // GET /projects return Response . ok (...); } } ManagedObjectControllers ManagedObjectController T s are ResourceController s that automatically map a REST interface to database queries; e.g. POST inserts a row, GET gets all row of a type. They do not need to be subclassed, but can be to provide customization. router . route ( /users/[:id] ) . link (() = ManagedObjectController Project ( context )); Configuration An application's configuration is written in a YAML file. Each environment your application runs in (e.g., locally, under test, production, development) has different values for things like the port to listen on and database connection credentials. The format of a configuration file is defined by your application. An example looks like: // config.yaml database: host: api.projects.com port: 5432 databaseName: project port: 8000 Subclass Configuration and declare a property for each key in your configuration file: class TodoConfig extends Configuration { TodoConfig ( String path ) : super . fromFile ( File ( path )); DatabaseConfiguration database ; int port ; } The default name of your configuration file is config.yaml , but can be changed at the command-line. You create an instance of your configuration from the configuration file path from your application options: import package:aqueduct/aqueduct.dart ; class TodoApp extends ApplicationChannel { @ override Future prepare () async { var options = TodoConfig ( options . configurationFilePath ); ... } } Running and Concurrency Aqueduct applications are run with the aqueduct serve command line tool. You can attach debugging and instrumentation tools and specify how many threads the application should run on: aqueduct serve --observe --isolates 5 --port 8888 Aqueduct applications are multi-isolate (multi-threaded). Each isolate runs a replica of the same web server with its own set of services like database connections. This makes behavior like database connection pooling implicit. PostgreSQL ORM The Query T class configures and executes database queries. Its type argument determines what table is to be queried and the type of object you will work with in your code. import package:aqueduct/aqueduct.dart class ProjectController extends ResourceController { ProjectController ( this . context ) ; final ManagedContext context ; @ Operation . get () Future Response getAllProjects () async { final query = Query Project ( context ); final results = await query . fetch (); return Response . ok ( results ); } } Configuration of the query - like its WHERE clause - are configured through a fluent, type-safe syntax. A property selector identifies which column of the table to apply an expression to. The following query fetches all project's due in the next week and includes their tasks by joining the related table. final nextWeek = DateTime . now (). add ( Duration ( days: 7 )); final query = Query Project ( context ) .. where (( project ) = project . dueDate ). isLessThan ( nextWeek ) .. join ( set : ( project ) = project . tasks ); final projects = await query . fetch (); Rows are inserted or updated by setting the statically-typed values of a query. final insertQuery = Query Project ( context ) .. values . name = Build an aqueduct .. values . dueDate = DateTime ( year , month ); var newProject = await insertQuery . insert (); final updateQuery = Query Project ( context ) .. where (( project ) = project . id ). equalTo ( newProject . id ) .. values . name = Build a miniature aqueduct ; newProject = await updateQuery . updateOne (); Query T s can perform sorting, joining and paging queries. final overdueQuery = Query Project ( context ) .. where (( project ) = project . dueDate ). lessThan ( DateTime (). now ()) .. sortBy (( project ) = project . dueDate , QuerySortOrder . ascending ) .. join ( object: ( project ) = project . owner ); final overdueProjectsAndTheirOwners = await query . fetch (); Controllers will interpret exceptions thrown by queries to return an appropriate error response to the client. For example, unique constraint conflicts return 409, missing required properties return 400 and database connection failure returns 503. Defining a Data Model To use the ORM, you declare your tables as Dart types and create a subclass of ManagedObject T . A subclass maps to a table in the database, each instance maps to a row, and each property is a column. The following declaration will map to a table named _project with columns id , name and dueDate . class Project extends ManagedObject _Project implements _Project { bool get isPastDue = dueDate . difference ( DateTime . now ()). inSeconds 0 ; } class _Project { @ primaryKey int id ; @ Column ( indexed: true ) String name ; DateTime dueDate ; } Managed objects have relationships to other managed objects. Relationships can be has-one, has-many and many-to-many. A relationship is always two-sided - the related types must declare a property that references each other. class Project extends ManagedObject _Project implements _Project {} class _Project { ... // Project has-many Tasks ManagedSet Task tasks ; } class Task extends ManagedObject _Task implements _Task {} class _Task { ... // Task belongs to a project, maps to project_id foreign key column @ Relate ( # tasks ) Project project ; } ManagedObject T s are serializable and can be directly read from a request body, or encoded as a response body. class ProjectController extends ResourceController { @ Operation . put ( id ) Future Response updateProject ( @ Bind . path ( id ) int projectId , @ Bind . body () Project project ) async { final query = Query Project ( context ) .. where (( project ) = project . id ). equalTo ( projectId ) .. values = project ; return Response . ok ( await query . updateOne ()); } } Database Migrations The CLI will automatically generate database migration scripts by detecting changes to your managed objects. The following, when ran in a project directory, will generate and execute a database migration. aqueduct db generate aqueduct db upgrade --connect postgres://user:password@host:5432/database You can edit migration files by hand to alter any assumptions or enter required values, and run aqueduct db validate to ensure the changes still yield the same schema. Be sure to keep generated files in version control. OAuth 2.0 An OAuth 2.0 server implementation handles authentication and authorization for Aqueduct applications. You create an AuthServer and its delegate as services in your application. The delegate is configurable and manages how tokens are generated and stored. By default, access tokens are a random 32-byte string and client identifiers, tokens and access codes are stored in your database using the ORM. import package:aqueduct/aqueduct.dart ; import package:aqueduct/managed_auth.dart ; class AppApplicationChannel extends ApplicationChannel { AuthServer authServer ; ManagedContext context ; @ override Future prepare () async { context = ManagedContext (...); final delegate = ManagedAuthDelegate User ( context ); authServer = AuthServer ( delegate ); } } Built-in authentication controllers for exchanging user credentials for access tokens are named AuthController and AuthCodeController . Authorizer s are middleware that require a valid access token to access their linked controller. Controller get entryPoint { final router = Router (); // POST /auth/token with username and password (or access code) to get access token router . route ( /auth/token ) . link (() = AuthController ( authServer )); // GET /auth/code returns login form, POST /auth/code grants access code router . route ( /auth/code ) . link (() = AuthCodeController ( authServer )); // ProjectController requires request to include access token router . route ( /projects/[:id] ) . link (() = Authorizer . bearer ( authServer )) . link (() = ProjectController ( context )); return router ; } The CLI has tools to manage OAuth 2.0 client identifiers and access scopes. aqueduct auth add-client \\ --id com.app.mobile \\ --secret foobar \\ --redirect-uri https://somewhereoutthere.com \\ --allowed-scopes users projects admin.readonly Logging All requests are logged to an application-wide logger. Set up a listener for the logger in ApplicationChannel to write log messages to the console or another medium. class WildfireChannel extends ApplicationChannel { @ override Future prepare () async { logger . onRecord . listen (( record ) { print ( $ record ); }); } } Testing Aqueduct tests start a local version of your application and execute requests. You write expectations on the responses. A TestHarness manages the starting and stopping of an application, and exposes a default Agent for executing requests. An Agent can be configured to have default headers, and multiple agents can be used within the same test. import harness/app.dart ; void main () { final harness = TestHarness TodoApp ().. install (); test ( GET /projects returns all projects , () async { var response = await harness . agent . get ( /projects ); expectResponse ( response , 200 , body: every ( partial ({ id : greaterThan ( 0 ), name : isNotNull , dueDate : isNotNull }))); }); } Testing with a Database Aqueduct's ORM uses PostgreSQL as its database. Before your tests run, Aqueduct will create your application's database tables in a local PostgreSQL database. After the tests complete, it will delete those tables. This allows you to start with an empty database for each test suite as well as control exactly which records are in your database while testing, but without having to manage database schemas or use an mock implementation (e.g., SQLite). This behavior, and behavior for managing applications with an OAuth 2.0 provider, are available as harness mixins . Documentation OpenAPI documents describe your application's interface. These documents can be used to generate documentation and client code. A document can be generated by reflecting on your application's codebase, just run the aqueduct document command. The aqueduct document client command creates a web page that can be used to configure issue requests specific to your application.","title":"Tour"},{"location":"tour/#aqueduct-a-tour","text":"The tour demonstrates many of Aqueduct's features.","title":"Aqueduct: A Tour"},{"location":"tour/#command-line-interface-cli","text":"The aqueduct command line tool creates, runs and documents Aqueduct applications; manages database migrations; and manages OAuth client identifiers. Install by running pub global activate aqueduct on a machine with Dart installed. Create and run an application: aqueduct create my_app cd my_app/ aqueduct serve","title":"Command-Line Interface (CLI)"},{"location":"tour/#initialization","text":"An Aqueduct application starts at an ApplicationChannel . You subclass it once per application to handle initialization tasks like setting up routes and database connections. An example application looks like this: import package:aqueduct/aqueduct.dart ; class TodoApp extends ApplicationChannel { ManagedContext context ; @ override Future prepare () async { context = ManagedContext (...); } @ override Controller get entryPoint { final router = Router (); router . route ( /projects/[:id] ) . link (() = ProjectController ( context )); return router ; } }","title":"Initialization"},{"location":"tour/#routing","text":"A router determines which controller object should handle a request. The route specification syntax is a concise syntax to construct routes with variables and optional segments in a single statement. @ override Controller get entryPoint { final router = Router (); // Handles /users, /users/1, /users/2, etc. router . route ( /projects/[:id] ) . link (() = ProjectController ()); // Handles any route that starts with /file/ router . route ( /file/* ) . link (() = FileController ()); // Handles the specific route /health router . route ( /health ) . linkFunction (( req ) async = Response . ok ( null )); return router ; }","title":"Routing"},{"location":"tour/#controllers","text":"Controllers handle requests. A controller handles a request by overriding its handle method. This method either returns a response or a request. If a response is returned, that response is sent to the client. If the request is returned, the linked controller handles the request. class SecretKeyAuthorizer extends Controller { @ override Future RequestOrResponse handle ( Request request ) async { if ( request . raw . headers . value ( x-secret-key ) == secret! ) { return request ; } return Response . badRequest (); } } This behavior allows for middleware controllers to be linked together, such that a request goes through a number of steps before it is finally handled. All controllers execute their code in an exception handler. If an exception is thrown in your controller code, a response with an appropriate error code is returned. You subclass HandlerException to provide error response customization for application-specific exceptions.","title":"Controllers"},{"location":"tour/#resourcecontrollers","text":"ResourceControllers are the most often used controller. Each operation - e.g. POST /projects , GET /projects and GET /projects/1 - is mapped to methods in a subclass. Parameters of those methods are annotated to bind the values of the request when the method is invoked. import package:aqueduct/aqueduct.dart class ProjectController extends ResourceController { @ Operation . get ( id ) Future Response getProjectById (@ Bind . path ( id ) int id ) async { // GET / projects /: id return Response . ok (...) ; } @ Operation . post () Future Response createProject ( @ Bind . body () Project project ) async { // POST /project final inserted = await insertProject ( project ); return Response . ok ( inserted ); } @ Operation . get () Future Response getAllProjects ( @ Bind . header ( x-client-id ) String clientId , { @ Bind . query ( limit ) int limit: 10 }) async { // GET /projects return Response . ok (...); } }","title":"ResourceControllers"},{"location":"tour/#managedobjectcontrollers","text":"ManagedObjectController T s are ResourceController s that automatically map a REST interface to database queries; e.g. POST inserts a row, GET gets all row of a type. They do not need to be subclassed, but can be to provide customization. router . route ( /users/[:id] ) . link (() = ManagedObjectController Project ( context ));","title":"ManagedObjectControllers"},{"location":"tour/#configuration","text":"An application's configuration is written in a YAML file. Each environment your application runs in (e.g., locally, under test, production, development) has different values for things like the port to listen on and database connection credentials. The format of a configuration file is defined by your application. An example looks like: // config.yaml database: host: api.projects.com port: 5432 databaseName: project port: 8000 Subclass Configuration and declare a property for each key in your configuration file: class TodoConfig extends Configuration { TodoConfig ( String path ) : super . fromFile ( File ( path )); DatabaseConfiguration database ; int port ; } The default name of your configuration file is config.yaml , but can be changed at the command-line. You create an instance of your configuration from the configuration file path from your application options: import package:aqueduct/aqueduct.dart ; class TodoApp extends ApplicationChannel { @ override Future prepare () async { var options = TodoConfig ( options . configurationFilePath ); ... } }","title":"Configuration"},{"location":"tour/#running-and-concurrency","text":"Aqueduct applications are run with the aqueduct serve command line tool. You can attach debugging and instrumentation tools and specify how many threads the application should run on: aqueduct serve --observe --isolates 5 --port 8888 Aqueduct applications are multi-isolate (multi-threaded). Each isolate runs a replica of the same web server with its own set of services like database connections. This makes behavior like database connection pooling implicit.","title":"Running and Concurrency"},{"location":"tour/#postgresql-orm","text":"The Query T class configures and executes database queries. Its type argument determines what table is to be queried and the type of object you will work with in your code. import package:aqueduct/aqueduct.dart class ProjectController extends ResourceController { ProjectController ( this . context ) ; final ManagedContext context ; @ Operation . get () Future Response getAllProjects () async { final query = Query Project ( context ); final results = await query . fetch (); return Response . ok ( results ); } } Configuration of the query - like its WHERE clause - are configured through a fluent, type-safe syntax. A property selector identifies which column of the table to apply an expression to. The following query fetches all project's due in the next week and includes their tasks by joining the related table. final nextWeek = DateTime . now (). add ( Duration ( days: 7 )); final query = Query Project ( context ) .. where (( project ) = project . dueDate ). isLessThan ( nextWeek ) .. join ( set : ( project ) = project . tasks ); final projects = await query . fetch (); Rows are inserted or updated by setting the statically-typed values of a query. final insertQuery = Query Project ( context ) .. values . name = Build an aqueduct .. values . dueDate = DateTime ( year , month ); var newProject = await insertQuery . insert (); final updateQuery = Query Project ( context ) .. where (( project ) = project . id ). equalTo ( newProject . id ) .. values . name = Build a miniature aqueduct ; newProject = await updateQuery . updateOne (); Query T s can perform sorting, joining and paging queries. final overdueQuery = Query Project ( context ) .. where (( project ) = project . dueDate ). lessThan ( DateTime (). now ()) .. sortBy (( project ) = project . dueDate , QuerySortOrder . ascending ) .. join ( object: ( project ) = project . owner ); final overdueProjectsAndTheirOwners = await query . fetch (); Controllers will interpret exceptions thrown by queries to return an appropriate error response to the client. For example, unique constraint conflicts return 409, missing required properties return 400 and database connection failure returns 503.","title":"PostgreSQL ORM"},{"location":"tour/#defining-a-data-model","text":"To use the ORM, you declare your tables as Dart types and create a subclass of ManagedObject T . A subclass maps to a table in the database, each instance maps to a row, and each property is a column. The following declaration will map to a table named _project with columns id , name and dueDate . class Project extends ManagedObject _Project implements _Project { bool get isPastDue = dueDate . difference ( DateTime . now ()). inSeconds 0 ; } class _Project { @ primaryKey int id ; @ Column ( indexed: true ) String name ; DateTime dueDate ; } Managed objects have relationships to other managed objects. Relationships can be has-one, has-many and many-to-many. A relationship is always two-sided - the related types must declare a property that references each other. class Project extends ManagedObject _Project implements _Project {} class _Project { ... // Project has-many Tasks ManagedSet Task tasks ; } class Task extends ManagedObject _Task implements _Task {} class _Task { ... // Task belongs to a project, maps to project_id foreign key column @ Relate ( # tasks ) Project project ; } ManagedObject T s are serializable and can be directly read from a request body, or encoded as a response body. class ProjectController extends ResourceController { @ Operation . put ( id ) Future Response updateProject ( @ Bind . path ( id ) int projectId , @ Bind . body () Project project ) async { final query = Query Project ( context ) .. where (( project ) = project . id ). equalTo ( projectId ) .. values = project ; return Response . ok ( await query . updateOne ()); } }","title":"Defining a Data Model"},{"location":"tour/#database-migrations","text":"The CLI will automatically generate database migration scripts by detecting changes to your managed objects. The following, when ran in a project directory, will generate and execute a database migration. aqueduct db generate aqueduct db upgrade --connect postgres://user:password@host:5432/database You can edit migration files by hand to alter any assumptions or enter required values, and run aqueduct db validate to ensure the changes still yield the same schema. Be sure to keep generated files in version control.","title":"Database Migrations"},{"location":"tour/#oauth-20","text":"An OAuth 2.0 server implementation handles authentication and authorization for Aqueduct applications. You create an AuthServer and its delegate as services in your application. The delegate is configurable and manages how tokens are generated and stored. By default, access tokens are a random 32-byte string and client identifiers, tokens and access codes are stored in your database using the ORM. import package:aqueduct/aqueduct.dart ; import package:aqueduct/managed_auth.dart ; class AppApplicationChannel extends ApplicationChannel { AuthServer authServer ; ManagedContext context ; @ override Future prepare () async { context = ManagedContext (...); final delegate = ManagedAuthDelegate User ( context ); authServer = AuthServer ( delegate ); } } Built-in authentication controllers for exchanging user credentials for access tokens are named AuthController and AuthCodeController . Authorizer s are middleware that require a valid access token to access their linked controller. Controller get entryPoint { final router = Router (); // POST /auth/token with username and password (or access code) to get access token router . route ( /auth/token ) . link (() = AuthController ( authServer )); // GET /auth/code returns login form, POST /auth/code grants access code router . route ( /auth/code ) . link (() = AuthCodeController ( authServer )); // ProjectController requires request to include access token router . route ( /projects/[:id] ) . link (() = Authorizer . bearer ( authServer )) . link (() = ProjectController ( context )); return router ; } The CLI has tools to manage OAuth 2.0 client identifiers and access scopes. aqueduct auth add-client \\ --id com.app.mobile \\ --secret foobar \\ --redirect-uri https://somewhereoutthere.com \\ --allowed-scopes users projects admin.readonly","title":"OAuth 2.0"},{"location":"tour/#logging","text":"All requests are logged to an application-wide logger. Set up a listener for the logger in ApplicationChannel to write log messages to the console or another medium. class WildfireChannel extends ApplicationChannel { @ override Future prepare () async { logger . onRecord . listen (( record ) { print ( $ record ); }); } }","title":"Logging"},{"location":"tour/#testing","text":"Aqueduct tests start a local version of your application and execute requests. You write expectations on the responses. A TestHarness manages the starting and stopping of an application, and exposes a default Agent for executing requests. An Agent can be configured to have default headers, and multiple agents can be used within the same test. import harness/app.dart ; void main () { final harness = TestHarness TodoApp ().. install (); test ( GET /projects returns all projects , () async { var response = await harness . agent . get ( /projects ); expectResponse ( response , 200 , body: every ( partial ({ id : greaterThan ( 0 ), name : isNotNull , dueDate : isNotNull }))); }); }","title":"Testing"},{"location":"tour/#testing-with-a-database","text":"Aqueduct's ORM uses PostgreSQL as its database. Before your tests run, Aqueduct will create your application's database tables in a local PostgreSQL database. After the tests complete, it will delete those tables. This allows you to start with an empty database for each test suite as well as control exactly which records are in your database while testing, but without having to manage database schemas or use an mock implementation (e.g., SQLite). This behavior, and behavior for managing applications with an OAuth 2.0 provider, are available as harness mixins .","title":"Testing with a Database"},{"location":"tour/#documentation","text":"OpenAPI documents describe your application's interface. These documents can be used to generate documentation and client code. A document can be generated by reflecting on your application's codebase, just run the aqueduct document command. The aqueduct document client command creates a web page that can be used to configure issue requests specific to your application.","title":"Documentation"},{"location":"application/","text":"Tasks An Aqueduct application is centered around an application channel ; an object that handles initialization tasks. For every application that you write, you create exactly one subclass of ApplicationChannel and implement its required methods. These methods prepare any service objects (like database connections) and controllers (objects that handle requests) that your application will use. You manage loading and reading configuration data - such as development vs. production environment options - from within an application channel. An application channel is instantiated for each thread your application executes on. Guides The Application Channel Configuring an Application Aqueduct Application Structure Performance: Multi-threading","title":"Overview"},{"location":"application/#tasks","text":"An Aqueduct application is centered around an application channel ; an object that handles initialization tasks. For every application that you write, you create exactly one subclass of ApplicationChannel and implement its required methods. These methods prepare any service objects (like database connections) and controllers (objects that handle requests) that your application will use. You manage loading and reading configuration data - such as development vs. production environment options - from within an application channel. An application channel is instantiated for each thread your application executes on.","title":"Tasks"},{"location":"application/#guides","text":"The Application Channel Configuring an Application Aqueduct Application Structure Performance: Multi-threading","title":"Guides"},{"location":"application/channel/","text":"Understanding Application Initialization and the ApplicationChannel Learn how an application is initialized so it can serve requests. Overview Applications fulfill HTTP requests using controllers . A controller is an object that can handle a request in some way. In general, there are two types of controllers: Endpoint controllers fulfill a request (e.g., insert a row into a database and send a 200 OK response). Middleware controllers verify something about a request (e.g., verifying the Authorization header has valid credentials) or modify the response created by an endpoint controller (e.g., add a response header). Controllers are linked together - starting with zero or more middleware and ending with an endpoint controller - to form a series of steps a request will go through. Every controller can either pass the request on to its linked controller, or respond to the request itself (in which case, the linked controller never sees the request). For example, an authorizer middleware will let a request pass if it has valid credentials, but will respond with a 401 Unauthorized response if the credentials are invalid. Some controllers, like Router , can have multiple controllers linked to it. These linked controllers are called channels . You create and link channels in a subclass of ApplicationChannel . There is one ApplicationChannel subclass per application. Building the ApplicationChannel You must override ApplicationChannel.entryPoint to return the first controller of your application's channel. In the implementation of this method, every controller that will be used in the application is linked to either the entry point in some way. Here's an example: class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = new Router (); router . route ( /users ) . link (() = Authorizer ()) . link (() = UserController ()); return router ; } } This method links together a Router , Authorizer and UserController in that order. A request is first handled by the Router , and if its path matches '/users', it will be sent to an Authorizer . If the Authorizer verifies the request, the request is passed to a UserController for fulfillment. By contrast, if the request's path doesn't match '/users', the Router sends a 404 Not Found response and doesn't pass it to the Authorizer . Likewise, if the request isn't authorized, the Authorizer will send a 401 Unauthorized response and prevent it from being passed to the UserController . In other words, a request 'falls out' of the channel once a controller responds to it, so that no further controllers will receive it. Linking Controllers The link() method takes a closure that creates a new controller. Some controllers get instantiated for each request, and others get reused for every request. See the chapter on controllers for more information. Providing Services for Controllers Controllers often need to get (or create) information from outside the application. The most common example is database access, but it could be anything: another REST API, a connected device, etc. A service object encapsulates the information and behavior needed to work with an external system. This separation of concerns between controllers and service objects allows for better structured and more testable code. Service objects are passed to controllers through their constructor. A controller that needs a database connection, for example, would take a database connection object in its constructor and store it in a property. Services are created by overriding prepare() in an ApplicationChannel . Here's an example: class AppChannel extends ApplicationChannel { PostgreSQLConnection database ; @ override Future prepare () async { database = new PostgreSQLConnection (); } @ override Controller get entryPoint { final router = new Router (); router . route ( /users ) . link (() = new Authorizer ()) . link (() = new UserController ( database )); return router ; } } Notice that database is created in prepare() , stored in a property and passed to each new instance of UserController . The prepare() method is always executed before entryPoint is called. Application Channel Configuration A benefit to using service objects is that they can be altered depending on the environment the application is running in without requiring changes to our controller code. For example, the database an application will connect to will be different when running in production than when running tests. Besides service configuration, there may be other types of initialization an application wants to take. Common tasks include adding codecs to CodecRegistry or setting the default CORSPolicy . All of this initialization is done in prepare() . Some of the information needed to configure an application will come from a configuration file or environment variables. This information is available through the options property of an application channel. For more information on using a configuration file and environment variables to guide initialization, see this guide . Multi-threaded Aqueduct Applications Aqueduct applications can - and should - be spread across a number of threads. This allows an application to take advantage of multiple CPUs and serve requests faster. In Dart, threads are called isolates . An instance of your ApplicationChannel is created for each isolate. When your application receives an HTTP request, one of these instances receives the request and processes it. These instances are replicas of one another and it doesn't matter which instance processes the request. This isolate-channel architecture is very similar to running multiple servers that run the same application. The number of isolates an application will use is configurable at startup when using the aqueduct serve command. An isolate can't share memory with another isolate. If an object is created on one isolate, it cannot be referenced by another. Therefore, each ApplicationChannel instance has its own set of services that are configured in the same way. This behavior also makes design patterns like connection pooling implicit; instead of a pool of database connections, there is a pool of application channels that each have their own database connection. This architecture intentionally prevents you from keeping state in your application. When you scale to multiple servers, you can trust that your cluster works correctly because you are already effectively clustering on a single server node. For further reading on writing multi-threaded applications, see this guide . Initialization Callbacks Both prepare() and entryPoint are part of the initialization process of an application channel. Most applications only ever need these two methods. Another method, that is rarely used, is willStartReceivingRequests() . This method is called after prepare() and entryPoint have been executed, and right before your application will start receiving requests. These three initialization callbacks are called once per isolate to initialize the channel running on that isolate. For initialization that should only occur once per application start (regardless of how many isolates are running), an ApplicationChannel subclass can implement a static method named initializeApplication() . class AppChannel extends ApplicationChannel { static Future initializeApplication ( ApplicationOptions options ) async { ... do one time setup ... } ... } This method is invoked before any ApplicationChannel instances are created. Any changes made to options will be available in each ApplicationChannel 's options property. For example: class AppChannel extends ApplicationChannel { static Future initializeApplication ( ApplicationOptions options ) async { options . context [ special item ] = xyz ; } Future prepare () async { var parsedConfigValues = options . context [ special item ]; // == xyz ... } } It is important to note the behavior of isolates as it relates to Aqueduct and the initialization process. Each isolate has its own heap. initializeApplication is executed in the main isolate, whereas each ApplicationChannel is instantiated in its own isolate. This means that any values stored in ApplicationOptions must be safe to pass across isolates - i.e., they can't contain references to closures. Additionally, any global variables or static properties that are set in the main isolate will not be set in other isolates. Configuration types like CodecRegistry do not share values across isolates, because they use a static property to hold a reference to the repository of codecs. Therefore, they must be set up in ApplicationChannel.prepare() . Also, because static methods cannot be overridden in Dart, it is important that you ensure the name and signature of initializeApplication exactly matches what is shown in these code samples. The analyzer can't help you here, unfortunately. Application Channel File An ApplicationChannel subclass is most often declared in its own file named lib/channel.dart . This file must be exported from the application library file. For example, if the application is named wildfire , the application library file is lib/wildfire.dart . Here is a sample directory structure: wildfire/ lib/ wildfire.dart channel.dart controllers/ user_controller.dart ... See this guide for more details on how an Aqueduct application's files are structured. Lazy Services Many service objects will establish a persistent network connection. A network connection can sometimes be interrupted and have to re-establish itself. If these connections are only opened when the application first starts, the application will not be able to reopen these connections without restarting the application. This would be very bad. For that reason, services should manage their own connectivity behavior. For example, a database connection should connect it when it is asked to execute a query. If it already has a valid connection, it will go ahead and execute the query. Otherwise, it will establish the connection and then execute the query. The caller doesn't care - it gets a Future with the desired result. The pseudo-code looks something like this: Future execute ( String sql ) async { if ( connection == null || ! connection . isAvailable ) { connection = new Connection (...); await connection . open (); } return connection . executeSQL ( sql ); } The Application Object Hidden in all of this discussion is the Application T object. Because the aqueduct serve command manages creating an Application T instance, your code rarely concerns itself with this type. An Application T is the top-level object in an Aqueduct application; it sets up HTTP listeners and directs requests to ApplicationChannel s. The Application T itself is just a generic container for ApplicationChannel s; it doesn't do much other than kick everything off. The application's start method will initialize at least one instance of the application's ApplicationChannel . If something goes wrong during this initialization process, the application will throw an exception and halt starting the server. For example, setting up an invalid route in a ApplicationChannel subclass would trigger this type of startup exception. An Application T has a number of options that determine how it will listen for HTTP requests, such as which port it is listening on or the SSL certificate it will use. These values are available in the channel's options property, an instance of ApplicationOptions .","title":"Startup & Initialization"},{"location":"application/channel/#understanding-application-initialization-and-the-applicationchannel","text":"Learn how an application is initialized so it can serve requests.","title":"Understanding Application Initialization and the ApplicationChannel"},{"location":"application/channel/#overview","text":"Applications fulfill HTTP requests using controllers . A controller is an object that can handle a request in some way. In general, there are two types of controllers: Endpoint controllers fulfill a request (e.g., insert a row into a database and send a 200 OK response). Middleware controllers verify something about a request (e.g., verifying the Authorization header has valid credentials) or modify the response created by an endpoint controller (e.g., add a response header). Controllers are linked together - starting with zero or more middleware and ending with an endpoint controller - to form a series of steps a request will go through. Every controller can either pass the request on to its linked controller, or respond to the request itself (in which case, the linked controller never sees the request). For example, an authorizer middleware will let a request pass if it has valid credentials, but will respond with a 401 Unauthorized response if the credentials are invalid. Some controllers, like Router , can have multiple controllers linked to it. These linked controllers are called channels . You create and link channels in a subclass of ApplicationChannel . There is one ApplicationChannel subclass per application.","title":"Overview"},{"location":"application/channel/#building-the-applicationchannel","text":"You must override ApplicationChannel.entryPoint to return the first controller of your application's channel. In the implementation of this method, every controller that will be used in the application is linked to either the entry point in some way. Here's an example: class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = new Router (); router . route ( /users ) . link (() = Authorizer ()) . link (() = UserController ()); return router ; } } This method links together a Router , Authorizer and UserController in that order. A request is first handled by the Router , and if its path matches '/users', it will be sent to an Authorizer . If the Authorizer verifies the request, the request is passed to a UserController for fulfillment. By contrast, if the request's path doesn't match '/users', the Router sends a 404 Not Found response and doesn't pass it to the Authorizer . Likewise, if the request isn't authorized, the Authorizer will send a 401 Unauthorized response and prevent it from being passed to the UserController . In other words, a request 'falls out' of the channel once a controller responds to it, so that no further controllers will receive it. Linking Controllers The link() method takes a closure that creates a new controller. Some controllers get instantiated for each request, and others get reused for every request. See the chapter on controllers for more information.","title":"Building the ApplicationChannel"},{"location":"application/channel/#providing-services-for-controllers","text":"Controllers often need to get (or create) information from outside the application. The most common example is database access, but it could be anything: another REST API, a connected device, etc. A service object encapsulates the information and behavior needed to work with an external system. This separation of concerns between controllers and service objects allows for better structured and more testable code. Service objects are passed to controllers through their constructor. A controller that needs a database connection, for example, would take a database connection object in its constructor and store it in a property. Services are created by overriding prepare() in an ApplicationChannel . Here's an example: class AppChannel extends ApplicationChannel { PostgreSQLConnection database ; @ override Future prepare () async { database = new PostgreSQLConnection (); } @ override Controller get entryPoint { final router = new Router (); router . route ( /users ) . link (() = new Authorizer ()) . link (() = new UserController ( database )); return router ; } } Notice that database is created in prepare() , stored in a property and passed to each new instance of UserController . The prepare() method is always executed before entryPoint is called.","title":"Providing Services for Controllers"},{"location":"application/channel/#application-channel-configuration","text":"A benefit to using service objects is that they can be altered depending on the environment the application is running in without requiring changes to our controller code. For example, the database an application will connect to will be different when running in production than when running tests. Besides service configuration, there may be other types of initialization an application wants to take. Common tasks include adding codecs to CodecRegistry or setting the default CORSPolicy . All of this initialization is done in prepare() . Some of the information needed to configure an application will come from a configuration file or environment variables. This information is available through the options property of an application channel. For more information on using a configuration file and environment variables to guide initialization, see this guide .","title":"Application Channel Configuration"},{"location":"application/channel/#multi-threaded-aqueduct-applications","text":"Aqueduct applications can - and should - be spread across a number of threads. This allows an application to take advantage of multiple CPUs and serve requests faster. In Dart, threads are called isolates . An instance of your ApplicationChannel is created for each isolate. When your application receives an HTTP request, one of these instances receives the request and processes it. These instances are replicas of one another and it doesn't matter which instance processes the request. This isolate-channel architecture is very similar to running multiple servers that run the same application. The number of isolates an application will use is configurable at startup when using the aqueduct serve command. An isolate can't share memory with another isolate. If an object is created on one isolate, it cannot be referenced by another. Therefore, each ApplicationChannel instance has its own set of services that are configured in the same way. This behavior also makes design patterns like connection pooling implicit; instead of a pool of database connections, there is a pool of application channels that each have their own database connection. This architecture intentionally prevents you from keeping state in your application. When you scale to multiple servers, you can trust that your cluster works correctly because you are already effectively clustering on a single server node. For further reading on writing multi-threaded applications, see this guide .","title":"Multi-threaded Aqueduct Applications"},{"location":"application/channel/#initialization-callbacks","text":"Both prepare() and entryPoint are part of the initialization process of an application channel. Most applications only ever need these two methods. Another method, that is rarely used, is willStartReceivingRequests() . This method is called after prepare() and entryPoint have been executed, and right before your application will start receiving requests. These three initialization callbacks are called once per isolate to initialize the channel running on that isolate. For initialization that should only occur once per application start (regardless of how many isolates are running), an ApplicationChannel subclass can implement a static method named initializeApplication() . class AppChannel extends ApplicationChannel { static Future initializeApplication ( ApplicationOptions options ) async { ... do one time setup ... } ... } This method is invoked before any ApplicationChannel instances are created. Any changes made to options will be available in each ApplicationChannel 's options property. For example: class AppChannel extends ApplicationChannel { static Future initializeApplication ( ApplicationOptions options ) async { options . context [ special item ] = xyz ; } Future prepare () async { var parsedConfigValues = options . context [ special item ]; // == xyz ... } } It is important to note the behavior of isolates as it relates to Aqueduct and the initialization process. Each isolate has its own heap. initializeApplication is executed in the main isolate, whereas each ApplicationChannel is instantiated in its own isolate. This means that any values stored in ApplicationOptions must be safe to pass across isolates - i.e., they can't contain references to closures. Additionally, any global variables or static properties that are set in the main isolate will not be set in other isolates. Configuration types like CodecRegistry do not share values across isolates, because they use a static property to hold a reference to the repository of codecs. Therefore, they must be set up in ApplicationChannel.prepare() . Also, because static methods cannot be overridden in Dart, it is important that you ensure the name and signature of initializeApplication exactly matches what is shown in these code samples. The analyzer can't help you here, unfortunately.","title":"Initialization Callbacks"},{"location":"application/channel/#application-channel-file","text":"An ApplicationChannel subclass is most often declared in its own file named lib/channel.dart . This file must be exported from the application library file. For example, if the application is named wildfire , the application library file is lib/wildfire.dart . Here is a sample directory structure: wildfire/ lib/ wildfire.dart channel.dart controllers/ user_controller.dart ... See this guide for more details on how an Aqueduct application's files are structured.","title":"Application Channel File"},{"location":"application/channel/#lazy-services","text":"Many service objects will establish a persistent network connection. A network connection can sometimes be interrupted and have to re-establish itself. If these connections are only opened when the application first starts, the application will not be able to reopen these connections without restarting the application. This would be very bad. For that reason, services should manage their own connectivity behavior. For example, a database connection should connect it when it is asked to execute a query. If it already has a valid connection, it will go ahead and execute the query. Otherwise, it will establish the connection and then execute the query. The caller doesn't care - it gets a Future with the desired result. The pseudo-code looks something like this: Future execute ( String sql ) async { if ( connection == null || ! connection . isAvailable ) { connection = new Connection (...); await connection . open (); } return connection . executeSQL ( sql ); }","title":"Lazy Services"},{"location":"application/channel/#the-application-object","text":"Hidden in all of this discussion is the Application T object. Because the aqueduct serve command manages creating an Application T instance, your code rarely concerns itself with this type. An Application T is the top-level object in an Aqueduct application; it sets up HTTP listeners and directs requests to ApplicationChannel s. The Application T itself is just a generic container for ApplicationChannel s; it doesn't do much other than kick everything off. The application's start method will initialize at least one instance of the application's ApplicationChannel . If something goes wrong during this initialization process, the application will throw an exception and halt starting the server. For example, setting up an invalid route in a ApplicationChannel subclass would trigger this type of startup exception. An Application T has a number of options that determine how it will listen for HTTP requests, such as which port it is listening on or the SSL certificate it will use. These values are available in the channel's options property, an instance of ApplicationOptions .","title":"The Application Object"},{"location":"application/configure/","text":"Configuring an Aqueduct Application This guide covers configuring an Aqueduct application. Configuration Files Aqueduct applications use YAML configuration files to provide environment-specific values like database connection information. Use separate configuration files for testing and different deployment environments. The path of a configuration file is available to an ApplicationChannel through its options property. class TodoAppChannel extends ApplicationChannel { @ override Future prepare () async { var config = new TodoConfiguration ( options . configurationFilePath ); ... } } The default value is config.yaml . The best practice for reading a configuration file is to subclass Configuration . A Configuration declares a property for each key in a configuration file. For example, see the following Configuration subclass: class TodoConfiguration extends Configuration { TodoConfiguration ( String fileName ) : super . fromFile ( fileName ); DatabaseConnectionConfiguration database ; String apiBaseURL ; @ optionalConfiguration int identifier ; } This would read a YAML file like this: database : username : fred password : fredspassword host : db . myapp . com port : 5432 databaseName : fredsdb apiBaseURL : / api identifier : 2 If required properties are omitted from the YAML file being read, application startup will fail and throw an informative error. You may use Configuration s to read values from environment variables. In config.yaml , use a $ -prefixed environment variable name instead of a value: database: $DATABASE_CONNECTION_URL apiBaseURL: /api If the environment variable DATABASE_CONNECTION_URL 's value were \"postgres://user:password@localhost:5432/test\" , the value of TodoConfiguration.database will be that string at runtime. (Note that DatabaseConnectionConfiguration may either have a YAML object for each connection attribute, or a database connection string.) The safe_config package has instructions for more additional usages. Configuration Conventions and Deployment Options Aqueduct uses two configuration files for a project: config.yaml and config.src.yaml . The latter is the configuration source file . The configuration source file declares key-value pairs that will be used when running the application tests. Deployed instances use config.yaml . This pattern is used for two reasons: It is the template for the config.yaml that will be read on deployed applications, providing documentation for your application's configuration. It has the configuration values used during testing to inject mock dependencies. For example, a production API instance might have the following config.yaml file with connection info for a production database: database : postgres :// app_user : $ % 4 jlkn # an * @ mOZkea2 @ somedns . name . com : 5432 / production_db Whereas config.src.yaml would have connection info for a local, test database: database : postgres :// test : test @ localhost : 5432 / temporary_db The source configuration file should be checked into version control. Whether or not config.yaml is checked in depends on how you are deploying your code. If you are using environment variables to control application configuration, you should check config.yaml into source control and provide $ -prefixed environment variable values. If you are using managing configuration files on each deployed instance, do not check config.yaml into source control because it'll be a different file for each instance. It can sometimes makes sense to have a local.yaml with values for running the application locally, e.g. when doing client testing. Use --config-path with aqueduct serve to use a non-default name. Preventing Resource Leaks When an Aqueduct application starts, the application and its ApplicationChannel s will likely create services that they use to respond to requests. In order for application tests to complete successfully, these services must be \"closed\" when the application stops. For built-in services, like PostgreSQLPersistentStore , this happens automatically when Application.stop() is invoked. A ServiceRegistry automatically stops registered services. Registration looks like this: var connection = new ConnectionOfSomeKind (); await connection . open (); ServiceRegistry . defaultInstance . register ConnectionOfSomeKind ( connection , ( c ) = c . close ()); This method takes the service to be closed and a closure that closes it. The service is passed as an argument to the closure. If the closure returns a Future , ServiceRegistry.close will not complete until the Future completes. ServiceRegistry.defaultInstance is closed in Application.stop() , any registries created by the programmer must be closed manually. The return type of ServiceRegistry.register is the object being registered. This makes registration syntax a bit more palatable: var connection = ServiceRegistry . defaultInstance . register ConnectionOfSomeKind ( new ConnectionOfSomeKind (), ( c ) = c . close ()); await connection . open (); Configuring CORS Headers All controllers have built-in behavior for handling CORS requests from a browser. When a preflight request is received from a browser (an OPTIONS request with Access-Control-Request-Method header and Origin headers), the response is created by evaluating the policy of the Controller that will respond to the real request. In practice, this means that the policy of the last controller in a channel is used. For example, the policy of FooController generates the preflight response: router . route ( /foo ) . link (() = new Authorizer (...)) . link (() = new FooController ()); Every Controller has a policy property (a CORSPolicy instance). The policy has properties for configuring CORS options for that particular endpoint. By having a policy , every Controller automatically implements logic to respond to preflight requests without any additional code. Policies can be set at the controller level or at the application level. The static property CORSPolicy.defaultPolicy can be modified at initialization time to set the CORS options for every controller. class MyApplicationChannel extends ApplicationChannel { @ override Future prepare () async { CORSPolicy . defaultPolicy . allowedOrigins = [ http://mywebsite.com/ ]; } } The default policy is very permissive: POST, PUT, DELETE and GET are allowed methods. All origins are valid (*). Each individual controller can override or replace the default policy by modifying its own policy in its constructor. class MyResourceController extends ResourceController { MyResourceController () { policy . allowedMethods = [ POST ]; } } Configuring HTTPS By default, an Aqueduct application does not use HTTPS. In many cases, an Aqueduct application sits behind an SSL-enabled load balancer or some other proxy. The traffic from the load balancer is sent to the Aqueduct application unencrypted over HTTP. However, Aqueduct may be configured to manage HTTPS connections itself. By passing the value private key and SSL certificate paths as options to --ssl-key-path and --ssl-certificate-path in aqueduct serve , an Aqueduct application will configure itself to only allow HTTPS connections. aqueduct serve --ssl-key-path server.key.pem --ssl-certificate-path server.cert.pem Both the key and certificate file must be unencrypted PEM files, and both must be provided to this command. These files are typically issued by a \"Certificate Authority\", such as letsencrypt.org . When an application is started with these options, the certificateFilePath and keyFilePath are set on the ApplicationOptions your application is being run with. (If you are not using aqueduct serve , you can set these values directly when instantiating ApplicationOptions .) For more granular control over setting up an HTTPS server, you may override securityContext in ApplicationChannel . By default, this property will create a SecurityContext from the certificateFilePath and keyFilePath in the channels's options . A SecurityContext allows for password-encrypted credential files, configuring client certificates and other less used HTTPS schemes. class MyApplicationChannel extends ApplicationChannel { @ override SecurityContext get securityContext { return new SecurityContext () .. usePrivateKey ( server.key , password: 1234 ) .. useCertificateChain ( server.crt , password: 1234 ); } }","title":"Environment Configuration"},{"location":"application/configure/#configuring-an-aqueduct-application","text":"This guide covers configuring an Aqueduct application.","title":"Configuring an Aqueduct Application"},{"location":"application/configure/#configuration-files","text":"Aqueduct applications use YAML configuration files to provide environment-specific values like database connection information. Use separate configuration files for testing and different deployment environments. The path of a configuration file is available to an ApplicationChannel through its options property. class TodoAppChannel extends ApplicationChannel { @ override Future prepare () async { var config = new TodoConfiguration ( options . configurationFilePath ); ... } } The default value is config.yaml . The best practice for reading a configuration file is to subclass Configuration . A Configuration declares a property for each key in a configuration file. For example, see the following Configuration subclass: class TodoConfiguration extends Configuration { TodoConfiguration ( String fileName ) : super . fromFile ( fileName ); DatabaseConnectionConfiguration database ; String apiBaseURL ; @ optionalConfiguration int identifier ; } This would read a YAML file like this: database : username : fred password : fredspassword host : db . myapp . com port : 5432 databaseName : fredsdb apiBaseURL : / api identifier : 2 If required properties are omitted from the YAML file being read, application startup will fail and throw an informative error. You may use Configuration s to read values from environment variables. In config.yaml , use a $ -prefixed environment variable name instead of a value: database: $DATABASE_CONNECTION_URL apiBaseURL: /api If the environment variable DATABASE_CONNECTION_URL 's value were \"postgres://user:password@localhost:5432/test\" , the value of TodoConfiguration.database will be that string at runtime. (Note that DatabaseConnectionConfiguration may either have a YAML object for each connection attribute, or a database connection string.) The safe_config package has instructions for more additional usages.","title":"Configuration Files"},{"location":"application/configure/#configuration-conventions-and-deployment-options","text":"Aqueduct uses two configuration files for a project: config.yaml and config.src.yaml . The latter is the configuration source file . The configuration source file declares key-value pairs that will be used when running the application tests. Deployed instances use config.yaml . This pattern is used for two reasons: It is the template for the config.yaml that will be read on deployed applications, providing documentation for your application's configuration. It has the configuration values used during testing to inject mock dependencies. For example, a production API instance might have the following config.yaml file with connection info for a production database: database : postgres :// app_user : $ % 4 jlkn # an * @ mOZkea2 @ somedns . name . com : 5432 / production_db Whereas config.src.yaml would have connection info for a local, test database: database : postgres :// test : test @ localhost : 5432 / temporary_db The source configuration file should be checked into version control. Whether or not config.yaml is checked in depends on how you are deploying your code. If you are using environment variables to control application configuration, you should check config.yaml into source control and provide $ -prefixed environment variable values. If you are using managing configuration files on each deployed instance, do not check config.yaml into source control because it'll be a different file for each instance. It can sometimes makes sense to have a local.yaml with values for running the application locally, e.g. when doing client testing. Use --config-path with aqueduct serve to use a non-default name.","title":"Configuration Conventions and Deployment Options"},{"location":"application/configure/#preventing-resource-leaks","text":"When an Aqueduct application starts, the application and its ApplicationChannel s will likely create services that they use to respond to requests. In order for application tests to complete successfully, these services must be \"closed\" when the application stops. For built-in services, like PostgreSQLPersistentStore , this happens automatically when Application.stop() is invoked. A ServiceRegistry automatically stops registered services. Registration looks like this: var connection = new ConnectionOfSomeKind (); await connection . open (); ServiceRegistry . defaultInstance . register ConnectionOfSomeKind ( connection , ( c ) = c . close ()); This method takes the service to be closed and a closure that closes it. The service is passed as an argument to the closure. If the closure returns a Future , ServiceRegistry.close will not complete until the Future completes. ServiceRegistry.defaultInstance is closed in Application.stop() , any registries created by the programmer must be closed manually. The return type of ServiceRegistry.register is the object being registered. This makes registration syntax a bit more palatable: var connection = ServiceRegistry . defaultInstance . register ConnectionOfSomeKind ( new ConnectionOfSomeKind (), ( c ) = c . close ()); await connection . open ();","title":"Preventing Resource Leaks"},{"location":"application/configure/#configuring-cors-headers","text":"All controllers have built-in behavior for handling CORS requests from a browser. When a preflight request is received from a browser (an OPTIONS request with Access-Control-Request-Method header and Origin headers), the response is created by evaluating the policy of the Controller that will respond to the real request. In practice, this means that the policy of the last controller in a channel is used. For example, the policy of FooController generates the preflight response: router . route ( /foo ) . link (() = new Authorizer (...)) . link (() = new FooController ()); Every Controller has a policy property (a CORSPolicy instance). The policy has properties for configuring CORS options for that particular endpoint. By having a policy , every Controller automatically implements logic to respond to preflight requests without any additional code. Policies can be set at the controller level or at the application level. The static property CORSPolicy.defaultPolicy can be modified at initialization time to set the CORS options for every controller. class MyApplicationChannel extends ApplicationChannel { @ override Future prepare () async { CORSPolicy . defaultPolicy . allowedOrigins = [ http://mywebsite.com/ ]; } } The default policy is very permissive: POST, PUT, DELETE and GET are allowed methods. All origins are valid (*). Each individual controller can override or replace the default policy by modifying its own policy in its constructor. class MyResourceController extends ResourceController { MyResourceController () { policy . allowedMethods = [ POST ]; } }","title":"Configuring CORS Headers"},{"location":"application/configure/#configuring-https","text":"By default, an Aqueduct application does not use HTTPS. In many cases, an Aqueduct application sits behind an SSL-enabled load balancer or some other proxy. The traffic from the load balancer is sent to the Aqueduct application unencrypted over HTTP. However, Aqueduct may be configured to manage HTTPS connections itself. By passing the value private key and SSL certificate paths as options to --ssl-key-path and --ssl-certificate-path in aqueduct serve , an Aqueduct application will configure itself to only allow HTTPS connections. aqueduct serve --ssl-key-path server.key.pem --ssl-certificate-path server.cert.pem Both the key and certificate file must be unencrypted PEM files, and both must be provided to this command. These files are typically issued by a \"Certificate Authority\", such as letsencrypt.org . When an application is started with these options, the certificateFilePath and keyFilePath are set on the ApplicationOptions your application is being run with. (If you are not using aqueduct serve , you can set these values directly when instantiating ApplicationOptions .) For more granular control over setting up an HTTPS server, you may override securityContext in ApplicationChannel . By default, this property will create a SecurityContext from the certificateFilePath and keyFilePath in the channels's options . A SecurityContext allows for password-encrypted credential files, configuring client certificates and other less used HTTPS schemes. class MyApplicationChannel extends ApplicationChannel { @ override SecurityContext get securityContext { return new SecurityContext () .. usePrivateKey ( server.key , password: 1234 ) .. useCertificateChain ( server.crt , password: 1234 ); } }","title":"Configuring HTTPS"},{"location":"application/structure/","text":"Aqueduct Application Architecture The purpose of this document is to understand the objects that comprise an Aqueduct application, and how they work with one another to serve HTTP requests. It also discusses the project structure on the filesystem. Controllers are Building Blocks The building blocks of an Aqueduct application are Controllers . Each controller type has logic to handle an HTTP request in some way. Controllers are linked together to form a channel ; an ordered series of controllers. A channel is a composition of its controllers' behaviors. For example, consider an Authorizer controller that verifies the request's authorization credentials are correct, and a SecretController that sends a response with secret information. By composing these two controllers together, we have a channel that verifies credentials before sending a secret. The benefit of controllers and channels is that controllers can be reused in multiple channels; the Authorizer can protect other types of controllers without any change to its logic. The last controller in a channel must always respond to a request. These types of controllers are called endpoint controllers and implement the business logic for your application's endpoints. For example, an endpoint controller might fetch a list of books from a database and send them in a response. The other controllers in a channel are called middleware controllers . These types of controllers typically verify something about a request before letting the next controller in the channel handle it. Middleware controllers can respond to a request, but doing so prevents the rest of the controllers in the channel from handling the request. For example, an \"authorization\" controller could send a 401 Unauthorized response protecting the endpoint controller from unauthorized requests. A \"caching\" controller could send a response with information from a cache, preventing the endpoint controller from performing an expensive query. Both middleware and endpoint controllers are instances of Controller (or a subclass). Middleware controllers are typically reusable, while endpoint controllers are typically not. If a middleware controller is not reusable, its logic might be better suited for the endpoint controller it precedes in the channel. Most endpoint controllers are created by subclassing ResourceController (itself a subclass of Controller ). This class allows you to implement methods for each HTTP method (like GET or POST) for a given endpoint. The Application Channel and Entry Point Each application designates one controller as the entry point of the application. This controller is the first to receive a new request and is the head of the application's channel. In most applications, the entry point is a Router ; this controller allows multiple channels to be linked, effectively splitting the channel into sub-channels. The diagram above looks like this in code: class AppChannel extends ApplicationChannel { @ override Controller get entry { final router = new Router (); router . route ( /a ) . link (() = new AController ()); router . route ( /b ) . link (() = new Authorizer (...)) . link (() = new BController ()); router . route ( /c ) . link (() = new Authorizer (...)) . link (() = new CController ()); return router ; } } See this guide for more details on the application channel and entry point. Aqueduct Project Structure and Organization An Aqueduct project is a directory that contains, at minimum, the following file structure: pubspec.yaml lib/ application_name.dart The name of any Dart application is defined by the name key in pubspec.yaml . In order for aqueduct serve to run your application, there must be a .dart file in lib/ with that same name. This is your application library file and it must declare a ApplicationChannel subclass or import a file that does. This is the bare minimum requirement to run an Aqueduct application. (See Deploying for more details on running applications.) For organizing applications of reasonable size, we recommend the following structure: pubspec.yaml config.src.yaml config.yaml lib/ application_name.dart channel.dart controller/ user_controller.dart model/ user.dart test/ user_controller_test.dart harness/ app.dart The required pubspec.yaml and lib/application_name.dart files are present alongside a few others: config.yaml : A configuration file for the running application. config.src.yaml : A template for config.yaml . channel.dart : A file solely for the ApplicationChannel of an application. This file should be exported from application_name.dart . controller/ : A directory for Controller subclass files. model/ : A directory for ManagedObject T subclass files. test/harness/app.dart : A test harness ) for automated testing. Feel free to create other subdirectories in lib/ for organizing other types of files. Aqueduct and dart:io Aqueduct runs on top of dart:io and relies on its HttpServer implementation. When an Aqueduct application is started, one or more HttpServer instances are bound to the port specified by aqueduct serve . For each HTTP request, an instance of Request is created to wrap the HttpRequest from dart:io . The Request is added to a ApplicationChannel , sending it through the channel of Controller s until it is responded to. In rare circumstances, you may choose to remove a Request from the application channel and manipulate the request with dart:io only. Once removed, it is your responsibility to respond to the request by setting properties on and closing the HttpRequest.response . To take a request out of the channel, simply return null from a Controller : @ override Controller get entryPoint { final router = new Router (); router . route ( /bypass_aqueduct ) . linkFunction (( req ) async { req . response . statusCode = 200 ; req . response . close (); return null ; }); return router ; } This technique is valuable when Aqueduct can't do something you want it to do or when using websockets .","title":"Application Structure"},{"location":"application/structure/#aqueduct-application-architecture","text":"The purpose of this document is to understand the objects that comprise an Aqueduct application, and how they work with one another to serve HTTP requests. It also discusses the project structure on the filesystem.","title":"Aqueduct Application Architecture"},{"location":"application/structure/#controllers-are-building-blocks","text":"The building blocks of an Aqueduct application are Controllers . Each controller type has logic to handle an HTTP request in some way. Controllers are linked together to form a channel ; an ordered series of controllers. A channel is a composition of its controllers' behaviors. For example, consider an Authorizer controller that verifies the request's authorization credentials are correct, and a SecretController that sends a response with secret information. By composing these two controllers together, we have a channel that verifies credentials before sending a secret. The benefit of controllers and channels is that controllers can be reused in multiple channels; the Authorizer can protect other types of controllers without any change to its logic. The last controller in a channel must always respond to a request. These types of controllers are called endpoint controllers and implement the business logic for your application's endpoints. For example, an endpoint controller might fetch a list of books from a database and send them in a response. The other controllers in a channel are called middleware controllers . These types of controllers typically verify something about a request before letting the next controller in the channel handle it. Middleware controllers can respond to a request, but doing so prevents the rest of the controllers in the channel from handling the request. For example, an \"authorization\" controller could send a 401 Unauthorized response protecting the endpoint controller from unauthorized requests. A \"caching\" controller could send a response with information from a cache, preventing the endpoint controller from performing an expensive query. Both middleware and endpoint controllers are instances of Controller (or a subclass). Middleware controllers are typically reusable, while endpoint controllers are typically not. If a middleware controller is not reusable, its logic might be better suited for the endpoint controller it precedes in the channel. Most endpoint controllers are created by subclassing ResourceController (itself a subclass of Controller ). This class allows you to implement methods for each HTTP method (like GET or POST) for a given endpoint.","title":"Controllers are Building Blocks"},{"location":"application/structure/#the-application-channel-and-entry-point","text":"Each application designates one controller as the entry point of the application. This controller is the first to receive a new request and is the head of the application's channel. In most applications, the entry point is a Router ; this controller allows multiple channels to be linked, effectively splitting the channel into sub-channels. The diagram above looks like this in code: class AppChannel extends ApplicationChannel { @ override Controller get entry { final router = new Router (); router . route ( /a ) . link (() = new AController ()); router . route ( /b ) . link (() = new Authorizer (...)) . link (() = new BController ()); router . route ( /c ) . link (() = new Authorizer (...)) . link (() = new CController ()); return router ; } } See this guide for more details on the application channel and entry point.","title":"The Application Channel and Entry Point"},{"location":"application/structure/#aqueduct-project-structure-and-organization","text":"An Aqueduct project is a directory that contains, at minimum, the following file structure: pubspec.yaml lib/ application_name.dart The name of any Dart application is defined by the name key in pubspec.yaml . In order for aqueduct serve to run your application, there must be a .dart file in lib/ with that same name. This is your application library file and it must declare a ApplicationChannel subclass or import a file that does. This is the bare minimum requirement to run an Aqueduct application. (See Deploying for more details on running applications.) For organizing applications of reasonable size, we recommend the following structure: pubspec.yaml config.src.yaml config.yaml lib/ application_name.dart channel.dart controller/ user_controller.dart model/ user.dart test/ user_controller_test.dart harness/ app.dart The required pubspec.yaml and lib/application_name.dart files are present alongside a few others: config.yaml : A configuration file for the running application. config.src.yaml : A template for config.yaml . channel.dart : A file solely for the ApplicationChannel of an application. This file should be exported from application_name.dart . controller/ : A directory for Controller subclass files. model/ : A directory for ManagedObject T subclass files. test/harness/app.dart : A test harness ) for automated testing. Feel free to create other subdirectories in lib/ for organizing other types of files.","title":"Aqueduct Project Structure and Organization"},{"location":"application/structure/#aqueduct-and-dartio","text":"Aqueduct runs on top of dart:io and relies on its HttpServer implementation. When an Aqueduct application is started, one or more HttpServer instances are bound to the port specified by aqueduct serve . For each HTTP request, an instance of Request is created to wrap the HttpRequest from dart:io . The Request is added to a ApplicationChannel , sending it through the channel of Controller s until it is responded to. In rare circumstances, you may choose to remove a Request from the application channel and manipulate the request with dart:io only. Once removed, it is your responsibility to respond to the request by setting properties on and closing the HttpRequest.response . To take a request out of the channel, simply return null from a Controller : @ override Controller get entryPoint { final router = new Router (); router . route ( /bypass_aqueduct ) . linkFunction (( req ) async { req . response . statusCode = 200 ; req . response . close (); return null ; }); return router ; } This technique is valuable when Aqueduct can't do something you want it to do or when using websockets .","title":"Aqueduct and dart:io"},{"location":"application/threading/","text":"Multi-threading in Aqueduct One of the primary differentiators between Aqueduct and other server frameworks is its multi-threaded behavior. When an Aqueduct application starts, it replicates the application logic across a number of threads. In Dart, threads are called isolates . The difference in naming isn't just to be cute - an isolate is a little bit different than a thread in that memory is not shared between isolates. Each isolate has its own heap (this is where memory for objects is allocated from) that other isolates can't access. An isolated thread is very valuable. Many multi-threaded applications share memory across threads, which require difficult design patterns and can easily introduce hard to track bugs that even the most experienced programmer will have a hard time avoiding. How Aqueduct Uses Isolates An application is initialized by invoking a series of initialization methods in a ApplicationChannel . Once these methods are finished executing, the application starts sending HTTP requests through the channel created by the ApplicationChannel . Because an ApplicationChannel is a type - and can be instantiated - Aqueduct simply creates a number of isolates and instantiates ApplicationChannel for each. The initialization code is therefore identical for each isolate, which means that the ongoing behavior of each isolate is also identical. More importantly, you - the programmer - have to do absolutely nothing to take advantage of Aqueduct's multi-threaded behavior. You simply have to pick the number of isolates you want to run the application on (see this section ). While you don't have to do anything in an Aqueduct application to take advantage of multiple processors, there are things you shouldn't do or should do in another way. First, you must be careful of keeping any state in your application. After initialization, any objects created while handling a request should be destroyed once the request is fulfilled. Any data that needs to be persisted must be stored in a database or other data store. This is just good practice for a REST API anyhow, so nothing is really lost here. However, there are times where you do need to track state. For example, if you are managing websocket connections, you do need to store some state after initialization - a reference to the websocket. This guide covers this topic in detail; the simple explanation is to use the ApplicationMessageHub . Another thing that is important to consider is initialization. The methods prepare() and entryPoint in an application channel will be invoked on each isolate. This behavior is guaranteed to occur for each isolate and there is often little to worry about. However, when implementing ApplicationChannel.initializeApplication , code runs on the main isolate. Any changes to static variables or singletons will not be replicated to the isolates running the application logic. The use case for this method is rather minimal, but it is very important that types like CodecRegistry aren't configured in this method. How Many Isolates Should I Use To give you a starting point, the default number of isolates for an application is 3 when started with aqueduct serve . While less than 3 isolates will most certainly degrade performance, more than 3 doesn't necessarily improve performance. (And many more will certainly degrade performance.) There are a number of variables that factor into the isolate count decision. First, recall a computer essentially does two things: it executes instructions and transmits data. Both of these tasks take time, especially when that data is transmitted to another computer thousands of miles away. (It is a modern marvel that these tasks occur as fast as they do - one that we often take for granted.) While a few milliseconds difference in speed to handle a single request isn't all that meaningful, when you start receiving thousands of requests at a time, these milliseconds add up. When your application is struggling to keep up with executing instructions, it is said to be CPU-bound . (When your application is struggling to transmit data, it is said to be IO-bound .) A CPU-bound application has two choices: execute less instructions or have more processors (or cores) to execute instructions with. Most computers these days have multiple processors. When only using a single isolate, an Aqueduct application can only use one of those processors at a time. As the number of isolates increases, so too do the number of processors that can be used at a time. Thus, more isolates means more processors means more instructions and your application bound less by the CPU. However, there is a limit - creating 100 isolates when there are only two processors doesn't yield any greater performance, because 50 isolates will fight over a single processor. In fact, the amount of work to schedule these instructions and the amount of memory this many isolates will consume will hurt performance. For example, when running benchmarks with wrk on my four-core machine, I get significantly better results as I add isolates 1 through 4, but then I get marginal gains and finally less or equal performance as I increase the number of isolates past 4. The blue bar represents the number of requests per second for each isolate count when making a simple HTTP call to Aqueduct. (Note that benchmarks are a good way of measuring relative performance of an application and identifying bottlenecks, but real world usability performance across a network is the only measurement that matters. The absolute value of these benchmarks should not be taken seriously, as they entirely remove the network portion of the transmission.) But this isn't the whole story. Server applications are rarely CPU-bound, but instead IO-bound. The red bar represents the number of requests per second when making a database query and returning the results of that query as JSON in the response body. When using Observatory, the measurements indicate that the overwhelming majority of the time is spent transmitting data to and from the database. This is an example of being bound by IO (and the speed of the query). Recall that each isolate has its own database connection. A database connection is a serial queue - it can only handle one query at a time. Increasing the number of database connections means handling more queries at a time. This is no more apparent than when looking at the following graph, which measures the latency of requests with and without a database call. When there is only one database connection (one isolate), the latency is significantly higher per request - the application is entirely bound by the speed of the database serial queue. Adding a second isolate, and therefore a second database connection, drops the latency by more than half. There are diminishing returns as more database connections are added. That's because the same thing about the number of threads per processor also applies to the number of database connections. Adding more database connections doesn't magically make the database server run any faster. As a general rule, start with N-1 isolates, where N is the number of processors on the machine. Use wrk and Observatory to profile your application and tune accordingly. In a multi-instance environment, remember that the total number of database connections is MxN, where M is the number of machines and N is the number of isolates. If you find yourself in a jam where IO would be better served by less isolates, but CPU would be better served by more isolates, you may consider using a database connection pool isolate.","title":"Multi-threading"},{"location":"application/threading/#multi-threading-in-aqueduct","text":"One of the primary differentiators between Aqueduct and other server frameworks is its multi-threaded behavior. When an Aqueduct application starts, it replicates the application logic across a number of threads. In Dart, threads are called isolates . The difference in naming isn't just to be cute - an isolate is a little bit different than a thread in that memory is not shared between isolates. Each isolate has its own heap (this is where memory for objects is allocated from) that other isolates can't access. An isolated thread is very valuable. Many multi-threaded applications share memory across threads, which require difficult design patterns and can easily introduce hard to track bugs that even the most experienced programmer will have a hard time avoiding.","title":"Multi-threading in Aqueduct"},{"location":"application/threading/#how-aqueduct-uses-isolates","text":"An application is initialized by invoking a series of initialization methods in a ApplicationChannel . Once these methods are finished executing, the application starts sending HTTP requests through the channel created by the ApplicationChannel . Because an ApplicationChannel is a type - and can be instantiated - Aqueduct simply creates a number of isolates and instantiates ApplicationChannel for each. The initialization code is therefore identical for each isolate, which means that the ongoing behavior of each isolate is also identical. More importantly, you - the programmer - have to do absolutely nothing to take advantage of Aqueduct's multi-threaded behavior. You simply have to pick the number of isolates you want to run the application on (see this section ). While you don't have to do anything in an Aqueduct application to take advantage of multiple processors, there are things you shouldn't do or should do in another way. First, you must be careful of keeping any state in your application. After initialization, any objects created while handling a request should be destroyed once the request is fulfilled. Any data that needs to be persisted must be stored in a database or other data store. This is just good practice for a REST API anyhow, so nothing is really lost here. However, there are times where you do need to track state. For example, if you are managing websocket connections, you do need to store some state after initialization - a reference to the websocket. This guide covers this topic in detail; the simple explanation is to use the ApplicationMessageHub . Another thing that is important to consider is initialization. The methods prepare() and entryPoint in an application channel will be invoked on each isolate. This behavior is guaranteed to occur for each isolate and there is often little to worry about. However, when implementing ApplicationChannel.initializeApplication , code runs on the main isolate. Any changes to static variables or singletons will not be replicated to the isolates running the application logic. The use case for this method is rather minimal, but it is very important that types like CodecRegistry aren't configured in this method.","title":"How Aqueduct Uses Isolates"},{"location":"application/threading/#how-many-isolates-should-i-use","text":"To give you a starting point, the default number of isolates for an application is 3 when started with aqueduct serve . While less than 3 isolates will most certainly degrade performance, more than 3 doesn't necessarily improve performance. (And many more will certainly degrade performance.) There are a number of variables that factor into the isolate count decision. First, recall a computer essentially does two things: it executes instructions and transmits data. Both of these tasks take time, especially when that data is transmitted to another computer thousands of miles away. (It is a modern marvel that these tasks occur as fast as they do - one that we often take for granted.) While a few milliseconds difference in speed to handle a single request isn't all that meaningful, when you start receiving thousands of requests at a time, these milliseconds add up. When your application is struggling to keep up with executing instructions, it is said to be CPU-bound . (When your application is struggling to transmit data, it is said to be IO-bound .) A CPU-bound application has two choices: execute less instructions or have more processors (or cores) to execute instructions with. Most computers these days have multiple processors. When only using a single isolate, an Aqueduct application can only use one of those processors at a time. As the number of isolates increases, so too do the number of processors that can be used at a time. Thus, more isolates means more processors means more instructions and your application bound less by the CPU. However, there is a limit - creating 100 isolates when there are only two processors doesn't yield any greater performance, because 50 isolates will fight over a single processor. In fact, the amount of work to schedule these instructions and the amount of memory this many isolates will consume will hurt performance. For example, when running benchmarks with wrk on my four-core machine, I get significantly better results as I add isolates 1 through 4, but then I get marginal gains and finally less or equal performance as I increase the number of isolates past 4. The blue bar represents the number of requests per second for each isolate count when making a simple HTTP call to Aqueduct. (Note that benchmarks are a good way of measuring relative performance of an application and identifying bottlenecks, but real world usability performance across a network is the only measurement that matters. The absolute value of these benchmarks should not be taken seriously, as they entirely remove the network portion of the transmission.) But this isn't the whole story. Server applications are rarely CPU-bound, but instead IO-bound. The red bar represents the number of requests per second when making a database query and returning the results of that query as JSON in the response body. When using Observatory, the measurements indicate that the overwhelming majority of the time is spent transmitting data to and from the database. This is an example of being bound by IO (and the speed of the query). Recall that each isolate has its own database connection. A database connection is a serial queue - it can only handle one query at a time. Increasing the number of database connections means handling more queries at a time. This is no more apparent than when looking at the following graph, which measures the latency of requests with and without a database call. When there is only one database connection (one isolate), the latency is significantly higher per request - the application is entirely bound by the speed of the database serial queue. Adding a second isolate, and therefore a second database connection, drops the latency by more than half. There are diminishing returns as more database connections are added. That's because the same thing about the number of threads per processor also applies to the number of database connections. Adding more database connections doesn't magically make the database server run any faster. As a general rule, start with N-1 isolates, where N is the number of processors on the machine. Use wrk and Observatory to profile your application and tune accordingly. In a multi-instance environment, remember that the total number of database connections is MxN, where M is the number of machines and N is the number of isolates. If you find yourself in a jam where IO would be better served by less isolates, but CPU would be better served by more isolates, you may consider using a database connection pool isolate.","title":"How Many Isolates Should I Use"},{"location":"auth/","text":"Tasks Aqueduct has types to manage authentication and authorization according to the OAuth 2.0 specification . You create an AuthServer service object for your application that manages authentication and authorization logic. An AuthServer requires a helper object that implements AuthServerDelegate to handle configuration and required data storage. Most often, this object is a ManagedAuthDelegate T that uses the Aqueduct ORM to manage this storage. An AuthServer service object is injected into Authorizer controllers that protect access to controller channels. An AuthServer is also injected into AuthCodeController and AuthController to provide HTTP APIs for authentication. The aqueduct auth command-line tool manages configuration - such as client identifier management - for live applications. Guides What is OAuth 2.0? Creating and Using AuthServers Securing Routes with Authorizer Adding Authentication Endpoints Using Scopes to Control Access Managing OAuth 2.0 Clients","title":"Overview"},{"location":"auth/#tasks","text":"Aqueduct has types to manage authentication and authorization according to the OAuth 2.0 specification . You create an AuthServer service object for your application that manages authentication and authorization logic. An AuthServer requires a helper object that implements AuthServerDelegate to handle configuration and required data storage. Most often, this object is a ManagedAuthDelegate T that uses the Aqueduct ORM to manage this storage. An AuthServer service object is injected into Authorizer controllers that protect access to controller channels. An AuthServer is also injected into AuthCodeController and AuthController to provide HTTP APIs for authentication. The aqueduct auth command-line tool manages configuration - such as client identifier management - for live applications.","title":"Tasks"},{"location":"auth/#guides","text":"What is OAuth 2.0? Creating and Using AuthServers Securing Routes with Authorizer Adding Authentication Endpoints Using Scopes to Control Access Managing OAuth 2.0 Clients","title":"Guides"},{"location":"auth/auth_scopes/","text":"Granular Authorization with OAuth 2.0 Scopes In many applications, operations have varying levels of access control. For example, a user may need special permission to create 'notes', but every user can read notes. In OAuth 2.0, permissions for operations are determined by an access token's scope . Operations can be defined to require certain scopes, and a request may only invoke those operations if its access token was granted with those scopes. A scope is a string identifier, like notes or notes.readonly . When a client application authenticates on behalf of a user, it requests one or more of these scope identifiers to be granted to the access token. Valid scopes will be stored with the access token, so that the scope can be referenced by subsequent uses of the access token. Scope Usage in Aqueduct An access token's scope is determined when a user authenticates. During authentication, a client application indicates the requested scope, and the Aqueduct application determines if that scope is permissible for the client application and the user. This scope information is attached to the access token. When a request is made with an access token, an Authorizer retrieves the token's scope. After the request is validated, the Authorizer stores scope information in Request.authorization . Linked controllers can use this information to determine how the request is handled. In general, a controller will reject a request and send a 403 Forbidden response when an access token has insufficient scope for an operation. Therefore, adding scopes to an application consists of three steps: Adding scope restrictions to operations. Adding permissible scopes for OAuth2 client identifiers (and optionally users). Updating client applications to request scope when authenticating. Adding Scope Restrictions to Operations When an Authorizer handles a request, it creates an Authorization object that is attached to the request. An Authorization object has a scopes property that contains every scope granted for the access token. This object also has a convenience method for checking if a particular scope is valid for that list of scopes: class NoteController extends Controller { @ override Future RequestOrResponse handle ( Request request ) async { if ( ! request . authorization . isAuthorizedForScope ( notes )) { return Response . forbidden (); } return Response . ok ( await getAllNotes ()); } } Use an Authorizer The authorization property of Request is only valid after the request is handled by an Authorizer . It is null otherwise. An Authorizer may also validate the scope of a request before letting it pass to its linked controller. router . route ( /notes ) . link (() = Authorizer . bearer ( authServer , scopes: [ notes ])) . link (() = NoteController ()); In the above, the NoteController will only be reached if the request's bearer token has 'notes' scope. If there is insufficient scope, a 403 Forbidden response is sent. This applies to all operations of the NoteController . It often makes sense to have separate scope for different operations on the same resource. The Scope annotation may be added to ResourceController operation methods for this purpose. class NoteController extends ResourceController { @ Scope ([ notes.readonly ]) @ Operation . get () Future Response getNotes () async = ...; @ Scope ([ notes ]) @ Operation . post () Future Response createNote ( @ Bind . body () Note note ) async = ...; } If a request does not have sufficient scope for the intended operation method, a 403 Forbidden response is sent. When using Scope annotations, you must link an Authorizer prior to the ResourceController , but it is not necessary to specify Authorizer scopes. If a Scope annotation or Authorizer contains multiple scope entries, an access token must have scope for each of those entries. For example, the annotation @Scope(['notes', 'user']) requires an access token to have both 'notes' and 'user' scope. Defining Permissible Scope When a client application authenticates on behalf of a user, it includes a list of request scopes for the access token. An Aqueduct application will grant the requested scopes to the token if the scopes are permissible for both the authenticating client identifier and the authenticating user. To add permissible scopes to an authenticating client, you use the aqueduct auth command-line tool. When creating a new client identifier, include the --allowed-scopes options: aqueduct auth add-client \\ --id com.app.mobile \\ --secret myspecialsecret \\ --allowed-scopes notes users \\ --connect postgres://user:password@dbhost:5432/db_name When modifying an existing client identifier, use the command aqueduct auth set-scope : aqueduct auth set-scope \\ --id com.app.mobile \\ --scopes notes users \\ --connect postgres://user:password@dbhost:5432/db_name Each scope is a space-delimited string; the above examples allow clients authenticating with the com.app.mobile client ID to grant access tokens with 'notes' and 'users' scope. If a client application requests scopes that are not available for that client application, the granted access token will not contain that scope. If none of the request scopes are available for the client identifier, no access token is granted. When adding scope restrictions to your application, you must ensure that all of the client applications that have access to those operations are able to grant that scope. Scopes may also be limited by some attribute of your application's concept of a 'user'. This user-level filtering is done by overriding getAllowedScopes in AuthServerDelegate . By default, this method returns AuthScope.Any - which means there are no restrictions. If the client application allows the scope, then any user that logs in with that application can request that scope. This method may return a list of AuthScope s that are valid for the authenticating user. The following example shows a ManagedAuthDelegate T subclass that allows any scope for @stablekernel.com usernames, no scopes for @hotmail.com addresses and some limited scope for everyone else: class DomainBasedAuthDelegate extends ManagedAuthDelegate User { DomainBasedAuthDelegate ( ManagedContext context , { int tokenLimit: 40 }) : super ( context , tokenLimit: tokenLimit ); @ override List AuthScope getAllowedScopes ( covariant User user ) { if ( user . username . endsWith ( @stablekernel.com )) { return AuthScope . Any ; } else if ( user . username . endsWith ( @hotmail.com )) { return []; } else { return [ AuthScope ( user )]; } } } The user passed to getAllowedScopes is the user being authenticated. It will have previously been fetched by the AuthServer . The AuthServer fetches this object by invoking AuthDelegate.getResourceOwner . The default implementation of this method for ManagedAuthDelegate T only fetches the id , username , salt and hashedPassword of the user. When using some other attribute of an application's user object to restrict allowed scopes, you must also override getResourceOwner to fetch these attributes. For example, if your application's user has a role attribute, you must fetch it and the other four required properties. Here's an example implementation: class RoleBasedAuthDelegate extends ManagedAuthDelegate User { RoleBasedAuthDelegate ( ManagedContext context , { int tokenLimit: 40 }) : super ( context , tokenLimit: tokenLimit ); @ override Future User getResourceOwner ( AuthServer server , String username ) { final query = Query User ( context ) .. where (( u ) = u . username ). equalTo ( username ) .. returningProperties (( t ) = [ t . id , t . username , t . hashedPassword , t . salt , t . role ]); return query . fetchOne (); } @ override List AuthScope getAllowedScopes ( covariant User user ) { var scopeStrings = []; if ( user . role == admin ) { scopeStrings = [ admin , user ]; } else if ( user . role == user ) { scopeStrings = [ user:email ]; } return scopeStrings . map (( str ) = AuthScope ( str )). toList (); } } Client Application Integration Client applications that integrate with your scoped Aqueduct application must include a list of requested scopes when performing authentication. When authenticating through AuthController , a scope parameter must be added to the form data body. This parameter's value must be a space-delimited, URL-encoded list of requested scopes. username=bob password=foo grant_type=password scope=notes%20users When authenticating via an AuthCodeController , this same query parameter is added to the initial GET request to render the login form. When authentication is complete, the list of granted scopes will be available in the JSON response body as a space-delimited string. { access_token : ... , refresh_token : ... , token_type : bearer , expires_in : 3600 , scopes : notes users } Scope Format and Hierarchy There is no definitive guide on what a scope string should look like, other than being restricted to alphanumeric characters and some symbols. Aqueduct, however, provides a simple scoping structure - there are two special symbols, : and . . Hierarchy is specified by the : character. For example, the following is a hierarchy of scopes related to a user and its sub-resources: user (can read/write everything a user has) user:email (can read/write a user's email) user:documents (can read/write a user's documents) user:documents:spreadsheets (can read/write a user's spreadsheet documents) Notice how these scopes form a hierarchy. Each segment makes the scope more restrictive. For example, if an access token has user:email scope, it only allows access to a user's email. However, if the access token has user scope, it allows access to everything a user has, including their email. As another example, an access token with user:documents scope can access all of a user's documents, but the scope user:documents:spreadsheets is limited to only spreadsheet documents. Scope is often used to indicate read vs. write access. At first glance, it might sound like a good idea to use the hierarchy operator, e.g. user:email:read and user:email:write . However, an access token with user:email:write does not have permission to read email and this is likely unintended. This is where scope modifiers come in. A scope modifier is added after a . at the end of a scope string. For example, user:email.readonly grants readonly access to a user's email whereas user:email grants read and write access. An access token without a modifier has permission any modifier. Thus, user and user:email can both access user:email.readonly protected resources and actions, but user:email.readonly cannot access resources protected by user:email . A scope modifier is only valid for the last segment of a scope string. That is, user:documents.readonly:spreadsheets is not valid, but user:documents:spreadsheets.readonly is.","title":"OAuth 2.0 Scoping"},{"location":"auth/auth_scopes/#granular-authorization-with-oauth-20-scopes","text":"In many applications, operations have varying levels of access control. For example, a user may need special permission to create 'notes', but every user can read notes. In OAuth 2.0, permissions for operations are determined by an access token's scope . Operations can be defined to require certain scopes, and a request may only invoke those operations if its access token was granted with those scopes. A scope is a string identifier, like notes or notes.readonly . When a client application authenticates on behalf of a user, it requests one or more of these scope identifiers to be granted to the access token. Valid scopes will be stored with the access token, so that the scope can be referenced by subsequent uses of the access token.","title":"Granular Authorization with OAuth 2.0 Scopes"},{"location":"auth/auth_scopes/#scope-usage-in-aqueduct","text":"An access token's scope is determined when a user authenticates. During authentication, a client application indicates the requested scope, and the Aqueduct application determines if that scope is permissible for the client application and the user. This scope information is attached to the access token. When a request is made with an access token, an Authorizer retrieves the token's scope. After the request is validated, the Authorizer stores scope information in Request.authorization . Linked controllers can use this information to determine how the request is handled. In general, a controller will reject a request and send a 403 Forbidden response when an access token has insufficient scope for an operation. Therefore, adding scopes to an application consists of three steps: Adding scope restrictions to operations. Adding permissible scopes for OAuth2 client identifiers (and optionally users). Updating client applications to request scope when authenticating.","title":"Scope Usage in Aqueduct"},{"location":"auth/auth_scopes/#adding-scope-restrictions-to-operations","text":"When an Authorizer handles a request, it creates an Authorization object that is attached to the request. An Authorization object has a scopes property that contains every scope granted for the access token. This object also has a convenience method for checking if a particular scope is valid for that list of scopes: class NoteController extends Controller { @ override Future RequestOrResponse handle ( Request request ) async { if ( ! request . authorization . isAuthorizedForScope ( notes )) { return Response . forbidden (); } return Response . ok ( await getAllNotes ()); } } Use an Authorizer The authorization property of Request is only valid after the request is handled by an Authorizer . It is null otherwise. An Authorizer may also validate the scope of a request before letting it pass to its linked controller. router . route ( /notes ) . link (() = Authorizer . bearer ( authServer , scopes: [ notes ])) . link (() = NoteController ()); In the above, the NoteController will only be reached if the request's bearer token has 'notes' scope. If there is insufficient scope, a 403 Forbidden response is sent. This applies to all operations of the NoteController . It often makes sense to have separate scope for different operations on the same resource. The Scope annotation may be added to ResourceController operation methods for this purpose. class NoteController extends ResourceController { @ Scope ([ notes.readonly ]) @ Operation . get () Future Response getNotes () async = ...; @ Scope ([ notes ]) @ Operation . post () Future Response createNote ( @ Bind . body () Note note ) async = ...; } If a request does not have sufficient scope for the intended operation method, a 403 Forbidden response is sent. When using Scope annotations, you must link an Authorizer prior to the ResourceController , but it is not necessary to specify Authorizer scopes. If a Scope annotation or Authorizer contains multiple scope entries, an access token must have scope for each of those entries. For example, the annotation @Scope(['notes', 'user']) requires an access token to have both 'notes' and 'user' scope.","title":"Adding Scope Restrictions to Operations"},{"location":"auth/auth_scopes/#defining-permissible-scope","text":"When a client application authenticates on behalf of a user, it includes a list of request scopes for the access token. An Aqueduct application will grant the requested scopes to the token if the scopes are permissible for both the authenticating client identifier and the authenticating user. To add permissible scopes to an authenticating client, you use the aqueduct auth command-line tool. When creating a new client identifier, include the --allowed-scopes options: aqueduct auth add-client \\ --id com.app.mobile \\ --secret myspecialsecret \\ --allowed-scopes notes users \\ --connect postgres://user:password@dbhost:5432/db_name When modifying an existing client identifier, use the command aqueduct auth set-scope : aqueduct auth set-scope \\ --id com.app.mobile \\ --scopes notes users \\ --connect postgres://user:password@dbhost:5432/db_name Each scope is a space-delimited string; the above examples allow clients authenticating with the com.app.mobile client ID to grant access tokens with 'notes' and 'users' scope. If a client application requests scopes that are not available for that client application, the granted access token will not contain that scope. If none of the request scopes are available for the client identifier, no access token is granted. When adding scope restrictions to your application, you must ensure that all of the client applications that have access to those operations are able to grant that scope. Scopes may also be limited by some attribute of your application's concept of a 'user'. This user-level filtering is done by overriding getAllowedScopes in AuthServerDelegate . By default, this method returns AuthScope.Any - which means there are no restrictions. If the client application allows the scope, then any user that logs in with that application can request that scope. This method may return a list of AuthScope s that are valid for the authenticating user. The following example shows a ManagedAuthDelegate T subclass that allows any scope for @stablekernel.com usernames, no scopes for @hotmail.com addresses and some limited scope for everyone else: class DomainBasedAuthDelegate extends ManagedAuthDelegate User { DomainBasedAuthDelegate ( ManagedContext context , { int tokenLimit: 40 }) : super ( context , tokenLimit: tokenLimit ); @ override List AuthScope getAllowedScopes ( covariant User user ) { if ( user . username . endsWith ( @stablekernel.com )) { return AuthScope . Any ; } else if ( user . username . endsWith ( @hotmail.com )) { return []; } else { return [ AuthScope ( user )]; } } } The user passed to getAllowedScopes is the user being authenticated. It will have previously been fetched by the AuthServer . The AuthServer fetches this object by invoking AuthDelegate.getResourceOwner . The default implementation of this method for ManagedAuthDelegate T only fetches the id , username , salt and hashedPassword of the user. When using some other attribute of an application's user object to restrict allowed scopes, you must also override getResourceOwner to fetch these attributes. For example, if your application's user has a role attribute, you must fetch it and the other four required properties. Here's an example implementation: class RoleBasedAuthDelegate extends ManagedAuthDelegate User { RoleBasedAuthDelegate ( ManagedContext context , { int tokenLimit: 40 }) : super ( context , tokenLimit: tokenLimit ); @ override Future User getResourceOwner ( AuthServer server , String username ) { final query = Query User ( context ) .. where (( u ) = u . username ). equalTo ( username ) .. returningProperties (( t ) = [ t . id , t . username , t . hashedPassword , t . salt , t . role ]); return query . fetchOne (); } @ override List AuthScope getAllowedScopes ( covariant User user ) { var scopeStrings = []; if ( user . role == admin ) { scopeStrings = [ admin , user ]; } else if ( user . role == user ) { scopeStrings = [ user:email ]; } return scopeStrings . map (( str ) = AuthScope ( str )). toList (); } }","title":"Defining Permissible Scope"},{"location":"auth/auth_scopes/#client-application-integration","text":"Client applications that integrate with your scoped Aqueduct application must include a list of requested scopes when performing authentication. When authenticating through AuthController , a scope parameter must be added to the form data body. This parameter's value must be a space-delimited, URL-encoded list of requested scopes. username=bob password=foo grant_type=password scope=notes%20users When authenticating via an AuthCodeController , this same query parameter is added to the initial GET request to render the login form. When authentication is complete, the list of granted scopes will be available in the JSON response body as a space-delimited string. { access_token : ... , refresh_token : ... , token_type : bearer , expires_in : 3600 , scopes : notes users }","title":"Client Application Integration"},{"location":"auth/auth_scopes/#scope-format-and-hierarchy","text":"There is no definitive guide on what a scope string should look like, other than being restricted to alphanumeric characters and some symbols. Aqueduct, however, provides a simple scoping structure - there are two special symbols, : and . . Hierarchy is specified by the : character. For example, the following is a hierarchy of scopes related to a user and its sub-resources: user (can read/write everything a user has) user:email (can read/write a user's email) user:documents (can read/write a user's documents) user:documents:spreadsheets (can read/write a user's spreadsheet documents) Notice how these scopes form a hierarchy. Each segment makes the scope more restrictive. For example, if an access token has user:email scope, it only allows access to a user's email. However, if the access token has user scope, it allows access to everything a user has, including their email. As another example, an access token with user:documents scope can access all of a user's documents, but the scope user:documents:spreadsheets is limited to only spreadsheet documents. Scope is often used to indicate read vs. write access. At first glance, it might sound like a good idea to use the hierarchy operator, e.g. user:email:read and user:email:write . However, an access token with user:email:write does not have permission to read email and this is likely unintended. This is where scope modifiers come in. A scope modifier is added after a . at the end of a scope string. For example, user:email.readonly grants readonly access to a user's email whereas user:email grants read and write access. An access token without a modifier has permission any modifier. Thus, user and user:email can both access user:email.readonly protected resources and actions, but user:email.readonly cannot access resources protected by user:email . A scope modifier is only valid for the last segment of a scope string. That is, user:documents.readonly:spreadsheets is not valid, but user:documents:spreadsheets.readonly is.","title":"Scope Format and Hierarchy"},{"location":"auth/authorizer/","text":"Securing Routes with Authorizer Instances of Authorizer are added to an application channel to verify HTTP request's authorization information before passing the request onwards. They protect channel access and typically come right after route . Here's an example: @ override Controller get entryPoint { final router = Router (); router . route ( /protected ) . link (() = Authorizer . bearer ( authServer )) . link (() = ProtectedController ()); router . route ( /other ) . link (() = Authorizer . basic ( authServer )) . link (() = OtherProtectedController ()); return router ; } An Authorizer parses the Authorization header of an HTTP request. The named constructors of Authorizer indicate the required format of Authorization header. The Authorization.bearer() constructor expects an OAuth 2.0 bearer token in the header, which has the following format: Authorization : Bearer 768 iuzjkx82jkasjkd9z9 Authorizer.basic expects HTTP Basic Authentication, where the username and password are joined with the colon character ( : ) and Base 64-encoded: // dXNlcjpwYXNzd29yZA== is user:password Authorization: Basic dXNlcjpwYXNzd29yZA== If the header can't be parsed, doesn't exist or is in the wrong format, an Authorizer responds to the request with a 401 status code and prevents the next controller from receiving the request. Once parsed, an Authorizer sends the information - either the bearer token, or the username and password - to its AuthServer for verification. If the AuthServer rejects the authorization info, the Authorizer responds to the request with a 401 status code and prevents the next controller from receiving the request. Otherwise, the request continues to the next controller. For Authorizer.bearer , the value in a request's header must be a valid, unexpired access token. These types of authorizers are used when an endpoint requires a logged in user. For Authorizer.basic authorizers, credentials are verified by finding an OAuth 2.0 client identifier and ensuring its client secret matches. Routes with this type of authorizer are known as client authenticated routes. These types of authorizers are used when an endpoint requires a valid client application, but not a logged in user. Authorizer and OAuth 2.0 Scope An Authorizer may restrict access to controllers based on the scope of the request's bearer token. By default, an Authorizer.bearer allows any valid bearer token to pass through it. If desired, an Authorizer is initialized with a list of required scopes. A request may only pass the Authorizer if it has access to all scopes listed in the Authorizer . For example, the following requires at least user:posts and location scope: router . route ( /checkin ) . link (() = Authorizer . bearer ( authServer , scopes: [ user:posts , location ])) . link (() = CheckInController ()); Note that you don't have to use an Authorizer to restrict access based on scope. A controller has access to scope information after the request has passed through an Authorizer , so it can use the scope to make more granular authorization decisions. Authorization Objects A bearer token represents a granted authorization - at some point in the past, a user provided their credentials and the token is the proof of that. When a bearer token is sent in the authorization header of an HTTP request, the application can look up which user the token is for and the client application it was issued for. This information is stored in an instance of Authorization after the token has been verified and is assigned to Request.authorization . Controllers protected by an Authorizer can access this information to further determine their behavior. For example, a social networking application might have a /news_feed endpoint protected by an Authorizer . When an authenticated user makes a request for /news_feed , the controller will return that user's news feed. It can determine this by using the Authorization : class NewsFeedController extends ResourceController { NewsFeedController ( this . context ); ManagedContext context ; @ Operation . get () Future Response getNewsFeed () async { var forUserID = request . authorization . ownerID ; var query = Query Post ( context ) .. where (( p ) = p . author ). identifiedBy ( forUserID ); return Response . ok ( await query . fetch ()); } } In the above controller, it's impossible for a user to access another user's posts. Authorization objects also retain the scope of an access token so that a controller can make more granular decisions about the information/action in the endpoint. Checking whether an Authorization has access to a particular scope is accomplished by either looking at the list of its scopes or using authorizedForScope : class NewsFeedController extends ResourceController { NewsFeedController ( this . context ); ManagedContext context ; @ Operation . get () Future Response getNewsFeed () async { if ( ! request . authorization . authorizedForScope ( user:feed )) { return Response . unauthorized (); } var forUserID = request . authorization . ownerID ; var query = Query Post ( context ) .. where (( p ) = p . author ). identifiedBy ( forUserID ); return Response . ok ( await query . fetch ()); } } Using Authorizers Without AuthServer Throughout this guide, the argument to an instance of Authorizer has been referred to as an AuthServer . This is true - but only because AuthServer implements AuthValidator . AuthValidator is an interface for verifying bearer tokens and username/password credentials. You may use Authorizer without using AuthServer . For example, an application that doesn't use OAuth 2.0 could provide its own AuthValidator interface to simply verify the username and password of every request: class BasicValidator implements AuthValidator { @ override FutureOr Authorization validate T ( AuthorizationParser T parser , T authorizationData , { List AuthScope requiredScope }) {} var user = await userForName ( usernameAndPassword . username ); if ( user . password == hash ( usernameAndPassword . password , user . salt )) { return Authorization (...); } // Will end up creating a 401 Not Authorized Response return null ; } } The validate method must return an Authorization if the credentials are valid, or null if they are not. The parser lets the validator know the format of the Authorization header (e.g., 'Basic' or 'Bearer') and authorizationData is the meaningful information in that header. There are two concrete types of AuthorizationParser T : AuthorizationBasicParser and AuthorizationBearerParser . The authorization data for a basic parser is an instance of AuthBasicCredentials that contain the username and password, while the bearer parser's authorization data is the bearer token string.","title":"Protecting Routes"},{"location":"auth/authorizer/#securing-routes-with-authorizer","text":"Instances of Authorizer are added to an application channel to verify HTTP request's authorization information before passing the request onwards. They protect channel access and typically come right after route . Here's an example: @ override Controller get entryPoint { final router = Router (); router . route ( /protected ) . link (() = Authorizer . bearer ( authServer )) . link (() = ProtectedController ()); router . route ( /other ) . link (() = Authorizer . basic ( authServer )) . link (() = OtherProtectedController ()); return router ; } An Authorizer parses the Authorization header of an HTTP request. The named constructors of Authorizer indicate the required format of Authorization header. The Authorization.bearer() constructor expects an OAuth 2.0 bearer token in the header, which has the following format: Authorization : Bearer 768 iuzjkx82jkasjkd9z9 Authorizer.basic expects HTTP Basic Authentication, where the username and password are joined with the colon character ( : ) and Base 64-encoded: // dXNlcjpwYXNzd29yZA== is user:password Authorization: Basic dXNlcjpwYXNzd29yZA== If the header can't be parsed, doesn't exist or is in the wrong format, an Authorizer responds to the request with a 401 status code and prevents the next controller from receiving the request. Once parsed, an Authorizer sends the information - either the bearer token, or the username and password - to its AuthServer for verification. If the AuthServer rejects the authorization info, the Authorizer responds to the request with a 401 status code and prevents the next controller from receiving the request. Otherwise, the request continues to the next controller. For Authorizer.bearer , the value in a request's header must be a valid, unexpired access token. These types of authorizers are used when an endpoint requires a logged in user. For Authorizer.basic authorizers, credentials are verified by finding an OAuth 2.0 client identifier and ensuring its client secret matches. Routes with this type of authorizer are known as client authenticated routes. These types of authorizers are used when an endpoint requires a valid client application, but not a logged in user.","title":"Securing Routes with Authorizer"},{"location":"auth/authorizer/#authorizer-and-oauth-20-scope","text":"An Authorizer may restrict access to controllers based on the scope of the request's bearer token. By default, an Authorizer.bearer allows any valid bearer token to pass through it. If desired, an Authorizer is initialized with a list of required scopes. A request may only pass the Authorizer if it has access to all scopes listed in the Authorizer . For example, the following requires at least user:posts and location scope: router . route ( /checkin ) . link (() = Authorizer . bearer ( authServer , scopes: [ user:posts , location ])) . link (() = CheckInController ()); Note that you don't have to use an Authorizer to restrict access based on scope. A controller has access to scope information after the request has passed through an Authorizer , so it can use the scope to make more granular authorization decisions.","title":"Authorizer and OAuth 2.0 Scope"},{"location":"auth/authorizer/#authorization-objects","text":"A bearer token represents a granted authorization - at some point in the past, a user provided their credentials and the token is the proof of that. When a bearer token is sent in the authorization header of an HTTP request, the application can look up which user the token is for and the client application it was issued for. This information is stored in an instance of Authorization after the token has been verified and is assigned to Request.authorization . Controllers protected by an Authorizer can access this information to further determine their behavior. For example, a social networking application might have a /news_feed endpoint protected by an Authorizer . When an authenticated user makes a request for /news_feed , the controller will return that user's news feed. It can determine this by using the Authorization : class NewsFeedController extends ResourceController { NewsFeedController ( this . context ); ManagedContext context ; @ Operation . get () Future Response getNewsFeed () async { var forUserID = request . authorization . ownerID ; var query = Query Post ( context ) .. where (( p ) = p . author ). identifiedBy ( forUserID ); return Response . ok ( await query . fetch ()); } } In the above controller, it's impossible for a user to access another user's posts. Authorization objects also retain the scope of an access token so that a controller can make more granular decisions about the information/action in the endpoint. Checking whether an Authorization has access to a particular scope is accomplished by either looking at the list of its scopes or using authorizedForScope : class NewsFeedController extends ResourceController { NewsFeedController ( this . context ); ManagedContext context ; @ Operation . get () Future Response getNewsFeed () async { if ( ! request . authorization . authorizedForScope ( user:feed )) { return Response . unauthorized (); } var forUserID = request . authorization . ownerID ; var query = Query Post ( context ) .. where (( p ) = p . author ). identifiedBy ( forUserID ); return Response . ok ( await query . fetch ()); } }","title":"Authorization Objects"},{"location":"auth/authorizer/#using-authorizers-without-authserver","text":"Throughout this guide, the argument to an instance of Authorizer has been referred to as an AuthServer . This is true - but only because AuthServer implements AuthValidator . AuthValidator is an interface for verifying bearer tokens and username/password credentials. You may use Authorizer without using AuthServer . For example, an application that doesn't use OAuth 2.0 could provide its own AuthValidator interface to simply verify the username and password of every request: class BasicValidator implements AuthValidator { @ override FutureOr Authorization validate T ( AuthorizationParser T parser , T authorizationData , { List AuthScope requiredScope }) {} var user = await userForName ( usernameAndPassword . username ); if ( user . password == hash ( usernameAndPassword . password , user . salt )) { return Authorization (...); } // Will end up creating a 401 Not Authorized Response return null ; } } The validate method must return an Authorization if the credentials are valid, or null if they are not. The parser lets the validator know the format of the Authorization header (e.g., 'Basic' or 'Bearer') and authorizationData is the meaningful information in that header. There are two concrete types of AuthorizationParser T : AuthorizationBasicParser and AuthorizationBearerParser . The authorization data for a basic parser is an instance of AuthBasicCredentials that contain the username and password, while the bearer parser's authorization data is the bearer token string.","title":"Using Authorizers Without AuthServer"},{"location":"auth/cli/","text":"Manage OAuth 2.0 Clients The aqueduct auth command line tool creates OAuth 2.0 client application identifiers and inserts them into an application's database. To use this tool, you must use ManagedAuthDelegate T and your database must be contain the tables to support it (see this guide for more details). Exchanging a username and password for an authorization token requires a registered client identifier. A token belongs to both the authenticating user and the client application. Clients are represented by instances of ManagedAuthClient from aqueduct/managed_auth . Authenticating clients must provide their client ID (and client secret, if applicable) in the Authorization header when requesting access tokens. An OAuth 2.0 client must have a string identifier that uniquely identifies the client. For example, com.food_app.mobile may be a client identifier for the mobile applications for some 'Food App'. To create a simple OAuth 2.0 client, the following command line utility can be run: aqueduct auth add-client \\ --id com.food_app.mobile \\ --connect postgres://user:password@dbhost:5432/food_app The connect option identifies the database for the application, which this tool will connect to and insert a record into the ManagedAuthClient database table. The identifier is provided through the id option. An OAuth 2.0 client created in this way is a public client; there is no client secret. An OAuth 2.0 client that uses the resource owner grant flow, but cannot secure its client secret, should use this type of client. An application can't secure its client secret if its source code is viewable - like any JavaScript application. It is suggested that native mobile applications also use public clients because their source code could potentially disassembled to reveal a client secret, but isn't necessarily required. When making requests to client authenticated endpoints (those protected with Authorizer.basic ), the client secret is omitted from the authorization header. The string to base64 encode is clientID: , where the colon ( : ) is required. For example, to generate an authorization header in Dart for a public client: var clientID = com.foobar.xyz ; var clientCredentials = Base64Encoder () . convert ( $clientID: . codeUnits ); var header = Basic $clientCredentials ; Confidential Clients An OAuth 2.0 client is confidential if it has a client secret. Client secrets can be provided with the auth tool: aqueduct auth add-client \\ --id com.food_app.mobile \\ --secret myspecialsecret \\ --connect postgres://user:password@dbhost:5432/food_app Client secrets are hashed (many times) with a randomly generated salt before they are stored. Therefore, their actual value must be stored securely elsewhere. (We use LastPass, for example.) Redirect URIs To allow the authorization code flow (provided by AuthCodeController ), a client must have a redirect URI. This is the URI that an authenticating user's browser will be redirected to after entering their username and password. A client must be a confidential client to have a redirect URI. aqueduct auth add-client \\ --id com.food_app.mobile \\ --secret myspecialsecret \\ --redirect-uri https://someapp.com/callback \\ --connect postgres://user:password@dbhost:5432/food_app Scopes If an application is using OAuth 2.0 scopes, a client can have scopes that it allows tokens to have access to. This allows scopes to be restricted by the client they are authenticating with. aqueduct auth add-client \\ --id com.food_app.mobile \\ --secret myspecialsecret \\ --allowed-scopes scopeA scopeB scopeC.readonly \\ --connect postgres://user:password@dbhost:5432/food_app Scopes are space-delimited and must be enclosed in quotes so that your shell will treat the entire string as one value. Scope may be set after a client has already been created with aqueduct auth set-scope : aqueduct auth set-scope \\ --id com.food_app.mobile \\ --scopes scopeA scopeC \\ --connect postgres://user:password@dbhost:5432/food_app Other Info Like all aqueduct commands that send commands to a database, the connect option can be replaced by a database.yaml file in the project directory with the following format: username: user password: password host: host port: 5432 databaseName: my_app","title":"Managing OAuth 2.0 Clients"},{"location":"auth/cli/#manage-oauth-20-clients","text":"The aqueduct auth command line tool creates OAuth 2.0 client application identifiers and inserts them into an application's database. To use this tool, you must use ManagedAuthDelegate T and your database must be contain the tables to support it (see this guide for more details). Exchanging a username and password for an authorization token requires a registered client identifier. A token belongs to both the authenticating user and the client application. Clients are represented by instances of ManagedAuthClient from aqueduct/managed_auth . Authenticating clients must provide their client ID (and client secret, if applicable) in the Authorization header when requesting access tokens. An OAuth 2.0 client must have a string identifier that uniquely identifies the client. For example, com.food_app.mobile may be a client identifier for the mobile applications for some 'Food App'. To create a simple OAuth 2.0 client, the following command line utility can be run: aqueduct auth add-client \\ --id com.food_app.mobile \\ --connect postgres://user:password@dbhost:5432/food_app The connect option identifies the database for the application, which this tool will connect to and insert a record into the ManagedAuthClient database table. The identifier is provided through the id option. An OAuth 2.0 client created in this way is a public client; there is no client secret. An OAuth 2.0 client that uses the resource owner grant flow, but cannot secure its client secret, should use this type of client. An application can't secure its client secret if its source code is viewable - like any JavaScript application. It is suggested that native mobile applications also use public clients because their source code could potentially disassembled to reveal a client secret, but isn't necessarily required. When making requests to client authenticated endpoints (those protected with Authorizer.basic ), the client secret is omitted from the authorization header. The string to base64 encode is clientID: , where the colon ( : ) is required. For example, to generate an authorization header in Dart for a public client: var clientID = com.foobar.xyz ; var clientCredentials = Base64Encoder () . convert ( $clientID: . codeUnits ); var header = Basic $clientCredentials ;","title":"Manage OAuth 2.0 Clients"},{"location":"auth/cli/#confidential-clients","text":"An OAuth 2.0 client is confidential if it has a client secret. Client secrets can be provided with the auth tool: aqueduct auth add-client \\ --id com.food_app.mobile \\ --secret myspecialsecret \\ --connect postgres://user:password@dbhost:5432/food_app Client secrets are hashed (many times) with a randomly generated salt before they are stored. Therefore, their actual value must be stored securely elsewhere. (We use LastPass, for example.)","title":"Confidential Clients"},{"location":"auth/cli/#redirect-uris","text":"To allow the authorization code flow (provided by AuthCodeController ), a client must have a redirect URI. This is the URI that an authenticating user's browser will be redirected to after entering their username and password. A client must be a confidential client to have a redirect URI. aqueduct auth add-client \\ --id com.food_app.mobile \\ --secret myspecialsecret \\ --redirect-uri https://someapp.com/callback \\ --connect postgres://user:password@dbhost:5432/food_app","title":"Redirect URIs"},{"location":"auth/cli/#scopes","text":"If an application is using OAuth 2.0 scopes, a client can have scopes that it allows tokens to have access to. This allows scopes to be restricted by the client they are authenticating with. aqueduct auth add-client \\ --id com.food_app.mobile \\ --secret myspecialsecret \\ --allowed-scopes scopeA scopeB scopeC.readonly \\ --connect postgres://user:password@dbhost:5432/food_app Scopes are space-delimited and must be enclosed in quotes so that your shell will treat the entire string as one value. Scope may be set after a client has already been created with aqueduct auth set-scope : aqueduct auth set-scope \\ --id com.food_app.mobile \\ --scopes scopeA scopeC \\ --connect postgres://user:password@dbhost:5432/food_app","title":"Scopes"},{"location":"auth/cli/#other-info","text":"Like all aqueduct commands that send commands to a database, the connect option can be replaced by a database.yaml file in the project directory with the following format: username: user password: password host: host port: 5432 databaseName: my_app","title":"Other Info"},{"location":"auth/controllers/","text":"Issue Access Tokens with AuthController An application using Aqueduct's Auth framework must have endpoints to exchange credentials for access tokens. While a developer could implement these endpoints themselves and talk directly to an AuthServer , the OAuth 2.0 specification is where happiness goes to die. Therefore, there exist two Controller s in Aqueduct that handle granting and refreshing authorization tokens - AuthController and AuthCodeController . Issue, Refresh and Exchange Tokens with AuthController An AuthController grants access tokens and refreshes them. It also exchanges authorization codes obtained from AuthCodeController for access tokens. Using an AuthController in an application is straightforward - hook it up to a Router and pass it an AuthServer . @ override Controller get entryPoint { final router = Router (); router . route ( /auth/token ) . link (() = AuthController ( authServer )); return router ; } To grant an access token, a client application sends a HTTP POST to the controller. The request must have: an Authorization header with the Client ID and Client Secret (if one exists) and, a x-www-form-urlencoded body with the username and password of the authenticating user. The body must also contain the key-value pair grant_type=password . For example, the following Dart code will initiate successful authentication: var clientID = com.app.demo ; var clientSecret = mySecret ; var body = username=bob@stablekernel.com password=foobar grant_type=password ; var clientCredentials = Base64Encoder (). convert ( $ clientID : $ clientSecret . codeUnits ); var response = await http . post ( https://stablekernel.com/auth/token , headers: { Content-Type : application/x-www-form-urlencoded , Authorization : Basic $ clientCredentials }, body: body ); If the OAuth 2.0 client ID is public - that is, it does not have a client secret - the secret is omitted from the authorization header: // Notice that the separating colon (:) is still present. var clientCredentials = Base64Encoder (). convert ( $ clientID : . codeUnits ); The response to a password token request is a JSON body that follows the OAuth 2.0 specification: { access_token : ... refresh_token : ... , expires_in : 3600, token_type : bearer } The expires_in field is a computed property based on the delta of the issue date and expiration date. You should avoid manually editing the values for the columns issuedate and expirationdate Tokens are refreshed through the same endpoint, but with a payload that only contains the refresh token and grant_type=refresh_token . grant_type=refresh_token refresh_token=kjasdiuz9u3namnsd See Aqueduct Auth CLI for more details on creating OAuth 2.0 client identifier and secrets. If an Aqueduct application is using scope, an additional scope parameter can contain a space-delimited list of requested authorization scope. Only allowed scopes are returned and granted, and if no scopes are allowed then the request fails. If scope is provided, granted scope will be available in the response body. It is important that an Authorizer must not protect instances of AuthController . The Authorization header is parsed and verified by AuthController . Once granted, an access token can be used to pass Authorizer.bearer() s in the application channel. Issue Authorization Codes with AuthCodeController An AuthCodeController manages the OAuth 2.0 authorization code flow. The authorization code flow is used when an Aqueduct application allows third party applications access to authorized resources. Let's say you've built an Aqueduct application that allows people to store notes for themselves. Now, a friend approaches you with their application that is a to-do list. Instead of building their own note-taking feature, your friend wants users of their application to access the notes the user has stored in your application. While trustworthy, you don't want your friend to have access to the username and passwords of your subscribers. Your friend adds a link to their application that takes the user to an HTML page hosted by your server. The user enters their credentials in this page, which sends a POST request to your server. Your server responds by redirecting the user's browser back into your friend's application. An authorization code is included in the query string of the redirect URL. Your friend's application parses the code from the URL and sends it to their server. Behind the scenes, their server exchanges this code with your server for an access token. An AuthCodeController responds to both GET and POST requests. When issued a GET , it serves up a HTML page with a login form. This login form's submit action sends a POST to the same endpoint with the username and password of the user. Upon success, the response from the POST is a 302 redirect with an authorization code. Setting up an AuthCodeController is nearly as simple as setting up an AuthController , but requires a function that renders the HTML login form. Here's an example: @ override Controller get entryPoint { final router = Router (); router . route ( /auth/code ) . link (() = AuthCodeController ( authServer , renderAuthorizationPageHTML: renderLogin )); return router ; } Future String renderLogin ( AuthCodeController requestingController , URI requestURI , Map String , String queryParameters ) { var html = HTMLRenderer . templateWithSubstitutions ( web/login.html , requestURI , queryParameters ); return html ; } It is important that all values passed to HTML rendering function are sent in the form's query parameters - they contain necessary security components and scope information. When your friend's application links to your login page - GET /auth/code - they must include three query parameters: state , client_id , response_type . They may optionally include scope . https://stablekernel.com/auth/code?client_id=friend.app response_type=code state=87uijn3rkja The value of client_id must be created specifically for your friend's application and stored in your database. (See more on generating client identifiers with aqueduct auth in Aqueduct Auth CLI .) The response_type must always be code . The state must be a value your friend's application creates - it is often some random value like a session cookie. When a user of your friend's application goes through this process, they are redirected back into your friend's application. Both the generated authorization code and the value for state will be query parameters in the URL. That redirect URL will look like: https://friends.app/code_callback?code=abcd672kk state=87uijn3rkja The redirect URL is pre-determined when generating the client identifier with aqueduct auth . Your friend's application verifies that state matches the state they sent in GET /auth/code . They then send the code to their server. The server then exchanges this code with your server by issuing a POST to an AuthController - NOT the AuthCodeController - with the following application/x-www-form-urlencoded body: grant_type=authorization_code code=abcd672kk An access token will be returned to the server which your friend then stores in their database. Whenever one of their users makes a request that requires accessing your application's data, they will execute requests with that access token.","title":"Issuing Access Tokens"},{"location":"auth/controllers/#issue-access-tokens-with-authcontroller","text":"An application using Aqueduct's Auth framework must have endpoints to exchange credentials for access tokens. While a developer could implement these endpoints themselves and talk directly to an AuthServer , the OAuth 2.0 specification is where happiness goes to die. Therefore, there exist two Controller s in Aqueduct that handle granting and refreshing authorization tokens - AuthController and AuthCodeController .","title":"Issue Access Tokens with AuthController"},{"location":"auth/controllers/#issue-refresh-and-exchange-tokens-with-authcontroller","text":"An AuthController grants access tokens and refreshes them. It also exchanges authorization codes obtained from AuthCodeController for access tokens. Using an AuthController in an application is straightforward - hook it up to a Router and pass it an AuthServer . @ override Controller get entryPoint { final router = Router (); router . route ( /auth/token ) . link (() = AuthController ( authServer )); return router ; } To grant an access token, a client application sends a HTTP POST to the controller. The request must have: an Authorization header with the Client ID and Client Secret (if one exists) and, a x-www-form-urlencoded body with the username and password of the authenticating user. The body must also contain the key-value pair grant_type=password . For example, the following Dart code will initiate successful authentication: var clientID = com.app.demo ; var clientSecret = mySecret ; var body = username=bob@stablekernel.com password=foobar grant_type=password ; var clientCredentials = Base64Encoder (). convert ( $ clientID : $ clientSecret . codeUnits ); var response = await http . post ( https://stablekernel.com/auth/token , headers: { Content-Type : application/x-www-form-urlencoded , Authorization : Basic $ clientCredentials }, body: body ); If the OAuth 2.0 client ID is public - that is, it does not have a client secret - the secret is omitted from the authorization header: // Notice that the separating colon (:) is still present. var clientCredentials = Base64Encoder (). convert ( $ clientID : . codeUnits ); The response to a password token request is a JSON body that follows the OAuth 2.0 specification: { access_token : ... refresh_token : ... , expires_in : 3600, token_type : bearer } The expires_in field is a computed property based on the delta of the issue date and expiration date. You should avoid manually editing the values for the columns issuedate and expirationdate Tokens are refreshed through the same endpoint, but with a payload that only contains the refresh token and grant_type=refresh_token . grant_type=refresh_token refresh_token=kjasdiuz9u3namnsd See Aqueduct Auth CLI for more details on creating OAuth 2.0 client identifier and secrets. If an Aqueduct application is using scope, an additional scope parameter can contain a space-delimited list of requested authorization scope. Only allowed scopes are returned and granted, and if no scopes are allowed then the request fails. If scope is provided, granted scope will be available in the response body. It is important that an Authorizer must not protect instances of AuthController . The Authorization header is parsed and verified by AuthController . Once granted, an access token can be used to pass Authorizer.bearer() s in the application channel.","title":"Issue, Refresh and Exchange Tokens with AuthController"},{"location":"auth/controllers/#issue-authorization-codes-with-authcodecontroller","text":"An AuthCodeController manages the OAuth 2.0 authorization code flow. The authorization code flow is used when an Aqueduct application allows third party applications access to authorized resources. Let's say you've built an Aqueduct application that allows people to store notes for themselves. Now, a friend approaches you with their application that is a to-do list. Instead of building their own note-taking feature, your friend wants users of their application to access the notes the user has stored in your application. While trustworthy, you don't want your friend to have access to the username and passwords of your subscribers. Your friend adds a link to their application that takes the user to an HTML page hosted by your server. The user enters their credentials in this page, which sends a POST request to your server. Your server responds by redirecting the user's browser back into your friend's application. An authorization code is included in the query string of the redirect URL. Your friend's application parses the code from the URL and sends it to their server. Behind the scenes, their server exchanges this code with your server for an access token. An AuthCodeController responds to both GET and POST requests. When issued a GET , it serves up a HTML page with a login form. This login form's submit action sends a POST to the same endpoint with the username and password of the user. Upon success, the response from the POST is a 302 redirect with an authorization code. Setting up an AuthCodeController is nearly as simple as setting up an AuthController , but requires a function that renders the HTML login form. Here's an example: @ override Controller get entryPoint { final router = Router (); router . route ( /auth/code ) . link (() = AuthCodeController ( authServer , renderAuthorizationPageHTML: renderLogin )); return router ; } Future String renderLogin ( AuthCodeController requestingController , URI requestURI , Map String , String queryParameters ) { var html = HTMLRenderer . templateWithSubstitutions ( web/login.html , requestURI , queryParameters ); return html ; } It is important that all values passed to HTML rendering function are sent in the form's query parameters - they contain necessary security components and scope information. When your friend's application links to your login page - GET /auth/code - they must include three query parameters: state , client_id , response_type . They may optionally include scope . https://stablekernel.com/auth/code?client_id=friend.app response_type=code state=87uijn3rkja The value of client_id must be created specifically for your friend's application and stored in your database. (See more on generating client identifiers with aqueduct auth in Aqueduct Auth CLI .) The response_type must always be code . The state must be a value your friend's application creates - it is often some random value like a session cookie. When a user of your friend's application goes through this process, they are redirected back into your friend's application. Both the generated authorization code and the value for state will be query parameters in the URL. That redirect URL will look like: https://friends.app/code_callback?code=abcd672kk state=87uijn3rkja The redirect URL is pre-determined when generating the client identifier with aqueduct auth . Your friend's application verifies that state matches the state they sent in GET /auth/code . They then send the code to their server. The server then exchanges this code with your server by issuing a POST to an AuthController - NOT the AuthCodeController - with the following application/x-www-form-urlencoded body: grant_type=authorization_code code=abcd672kk An access token will be returned to the server which your friend then stores in their database. Whenever one of their users makes a request that requires accessing your application's data, they will execute requests with that access token.","title":"Issue Authorization Codes with AuthCodeController"},{"location":"auth/server/","text":"Creating AuthServers to Authenticate and Authorize An AuthServer is a service that handles creating, verifying and refreshing authorization tokens. You create an AuthServer in your application channel and inject into types that deal with authorization. This types include: Authorizer : middleware controller that protects endpoint controllers from unauthorized access AuthController : endpoint controller that grants access tokens AuthCodeController : endpoint controller that grants authorization codes to be exchanged for access tokens An AuthServer must persist the data it uses and creates - like client identifiers and access tokens. Storage is often performed by a database, but it can be in memory, a cache or some other medium. Because of the many different storage mediums, an AuthServer doesn't perform any storage itself - it relies on an instance of AuthServerDelegate specific to your application. This allows storage to be independent of verification logic. Creating Instances of AuthServer and AuthServerDelegate AuthServerDelegate is an interface that an AuthServer uses to handle storage of client identifiers, tokens and other authorization artifacts. An AuthServer must be created with a concrete implementation of AuthServerDelegate . Aqueduct contains a concrete implementation of AuthServerDelegate that uses the ORM. It is highly recommended to use this implementation instead of implementing your own storage because it has been thoroughly tested and handles cleaning up expired data correctly. This concrete implementation is named ManagedAuthDelegate T . It exists in a sub-package of Aqueduct and must be explicitly imported. Here's an example of creating an AuthServer and ManagedAuthDelegate T : import package:aqueduct/aqueduct.dart ; import package:aqueduct/managed_auth.dart ; class MyApplicationChannel extends ApplicationChannel { AuthServer authServer ; @ override Future prepare () async { final context = ManagedContext (...); final delegate = ManagedAuthDelegate User ( context ); authServer = AuthServer ( delegate ); } ... } (Notice that ManagedAuthDelegate has a type argument - this will be covered in the next section.) While AuthServer has methods for handling authorization tasks, it is rarely used directly. Instead, AuthCodeController and AuthController are hooked up to routes to grant authorization tokens through your application's HTTP API. Instances of Authorizer secure routes in channels. All of these types invoke the appropriate methods on the AuthServer . Here's an example ApplicationChannel subclass that sets up and uses authorization: import package:aqueduct/aqueduct.dart ; import package:aqueduct/managed_auth.dart ; class MyApplicationChannel extends ApplicationChannel { AuthServer authServer ; ManagedContext context ; @ override Future prepare () async { context = ManagedContext (...); final delegate = ManagedAuthDelegate User ( context ); authServer = AuthServer ( delegate ); } @ override Controller get entryPoint { final router = Router (); // Set up auth token route- this grants and refresh tokens router . route ( /auth/token ). link (() = AuthController ( authServer )); // Set up auth code route- this grants temporary access codes that can be exchanged for token router . route ( /auth/code ). link (() = AuthCodeController ( authServer )); // Set up protected route router . route ( /protected ) . link (() = Authorizer . bearer ( authServer )) . link (() = ProtectedController ()); return router ; } } For more details on authorization controllers like AuthController , see Authorization Controllers . For more details on securing routes, see Authorizers . Using ManagedAuthDelegate ManagedAuthDelegate T is a concrete implementation of AuthServerDelegate , providing storage of authorization tokens and clients for an AuthServer . Storage is accomplished by Aqueduct's ORM. ManagedAuthDelegate T , by default, is not part of the standard aqueduct library. To use this class, an application must import package:aqueduct/managed_auth.dart . The type argument to ManagedAuthDelegate T represents the application's concept of a 'user' or 'account' - OAuth 2.0 terminology would refer to this type as a resource owner . A resource owner must be a ManagedObject T subclass that is specific to your application. Its table definition must extend ResourceOwnerTableDefinition and the instance type must implement ManagedAuthResourceOwner T , where T is the table definition. A basic definition may look like this: class User extends ManagedObject _User implements _User , ManagedAuthResourceOwner _User { } class _User extends ResourceOwnerTableDefinition { @ Column ( unique: true ) String email ; } By extending ResourceOwnerTableDefinition in the table definition, the database table has the following four columns: an integer primary key named id a unique string username a password hash a salt used to generate the password hash A ResourceOwnerTableDefinition also has a ManagedSet of tokens for each token that has been granted on its behalf. The interface ManagedAuthResourceOwner T is a requirement that ensures the type argument is both a ManagedObject T and ResourceOwnerTableDefinition , and serves no other purpose than to restrict ManagedAuthDelegate T 's type parameter. This structure allows an application to declare its own 'user' type while still enforcing the needs of Aqueduct's OAuth 2.0 implementation. The managed_auth library also declares two ManagedObject T subclasses. ManagedAuthToken represents instances of authorization tokens and codes, and ManagedAuthClient represents instances of OAuth 2.0 clients. This means that an Aqueduct application that uses ManagedAuthDelegate T has a minimum of three database tables: users, tokens and clients. ManagedAuthDelegate T will delete authorization tokens and codes when they are no longer in use. This is determined by how many tokens a resource owner has and the tokens expiration dates. Once a resource owner acquires more than 40 tokens/codes, the oldest tokens/codes (determined by expiration date) are deleted. Effectively, the resource owner is limited to 40 tokens. This number can be changed when instantiating ManagedAuthDelegate T : final delegate = ManagedAuthDelegate ( context , tokenLimit: 20 ); Configuring the Database ManagedAuthDelegate T requires database tables for its users, tokens and clients. Use the database command-line tool on your project to generate migration scripts and execute them against a database. This tool will see the declarations for your user type, ManagedAuthToken and ManagedAuthClient and create the appropriate tables.","title":"Setting up Authorization"},{"location":"auth/server/#creating-authservers-to-authenticate-and-authorize","text":"An AuthServer is a service that handles creating, verifying and refreshing authorization tokens. You create an AuthServer in your application channel and inject into types that deal with authorization. This types include: Authorizer : middleware controller that protects endpoint controllers from unauthorized access AuthController : endpoint controller that grants access tokens AuthCodeController : endpoint controller that grants authorization codes to be exchanged for access tokens An AuthServer must persist the data it uses and creates - like client identifiers and access tokens. Storage is often performed by a database, but it can be in memory, a cache or some other medium. Because of the many different storage mediums, an AuthServer doesn't perform any storage itself - it relies on an instance of AuthServerDelegate specific to your application. This allows storage to be independent of verification logic.","title":"Creating AuthServers to Authenticate and Authorize"},{"location":"auth/server/#creating-instances-of-authserver-and-authserverdelegate","text":"AuthServerDelegate is an interface that an AuthServer uses to handle storage of client identifiers, tokens and other authorization artifacts. An AuthServer must be created with a concrete implementation of AuthServerDelegate . Aqueduct contains a concrete implementation of AuthServerDelegate that uses the ORM. It is highly recommended to use this implementation instead of implementing your own storage because it has been thoroughly tested and handles cleaning up expired data correctly. This concrete implementation is named ManagedAuthDelegate T . It exists in a sub-package of Aqueduct and must be explicitly imported. Here's an example of creating an AuthServer and ManagedAuthDelegate T : import package:aqueduct/aqueduct.dart ; import package:aqueduct/managed_auth.dart ; class MyApplicationChannel extends ApplicationChannel { AuthServer authServer ; @ override Future prepare () async { final context = ManagedContext (...); final delegate = ManagedAuthDelegate User ( context ); authServer = AuthServer ( delegate ); } ... } (Notice that ManagedAuthDelegate has a type argument - this will be covered in the next section.) While AuthServer has methods for handling authorization tasks, it is rarely used directly. Instead, AuthCodeController and AuthController are hooked up to routes to grant authorization tokens through your application's HTTP API. Instances of Authorizer secure routes in channels. All of these types invoke the appropriate methods on the AuthServer . Here's an example ApplicationChannel subclass that sets up and uses authorization: import package:aqueduct/aqueduct.dart ; import package:aqueduct/managed_auth.dart ; class MyApplicationChannel extends ApplicationChannel { AuthServer authServer ; ManagedContext context ; @ override Future prepare () async { context = ManagedContext (...); final delegate = ManagedAuthDelegate User ( context ); authServer = AuthServer ( delegate ); } @ override Controller get entryPoint { final router = Router (); // Set up auth token route- this grants and refresh tokens router . route ( /auth/token ). link (() = AuthController ( authServer )); // Set up auth code route- this grants temporary access codes that can be exchanged for token router . route ( /auth/code ). link (() = AuthCodeController ( authServer )); // Set up protected route router . route ( /protected ) . link (() = Authorizer . bearer ( authServer )) . link (() = ProtectedController ()); return router ; } } For more details on authorization controllers like AuthController , see Authorization Controllers . For more details on securing routes, see Authorizers .","title":"Creating Instances of AuthServer and AuthServerDelegate"},{"location":"auth/server/#using-managedauthdelegate","text":"ManagedAuthDelegate T is a concrete implementation of AuthServerDelegate , providing storage of authorization tokens and clients for an AuthServer . Storage is accomplished by Aqueduct's ORM. ManagedAuthDelegate T , by default, is not part of the standard aqueduct library. To use this class, an application must import package:aqueduct/managed_auth.dart . The type argument to ManagedAuthDelegate T represents the application's concept of a 'user' or 'account' - OAuth 2.0 terminology would refer to this type as a resource owner . A resource owner must be a ManagedObject T subclass that is specific to your application. Its table definition must extend ResourceOwnerTableDefinition and the instance type must implement ManagedAuthResourceOwner T , where T is the table definition. A basic definition may look like this: class User extends ManagedObject _User implements _User , ManagedAuthResourceOwner _User { } class _User extends ResourceOwnerTableDefinition { @ Column ( unique: true ) String email ; } By extending ResourceOwnerTableDefinition in the table definition, the database table has the following four columns: an integer primary key named id a unique string username a password hash a salt used to generate the password hash A ResourceOwnerTableDefinition also has a ManagedSet of tokens for each token that has been granted on its behalf. The interface ManagedAuthResourceOwner T is a requirement that ensures the type argument is both a ManagedObject T and ResourceOwnerTableDefinition , and serves no other purpose than to restrict ManagedAuthDelegate T 's type parameter. This structure allows an application to declare its own 'user' type while still enforcing the needs of Aqueduct's OAuth 2.0 implementation. The managed_auth library also declares two ManagedObject T subclasses. ManagedAuthToken represents instances of authorization tokens and codes, and ManagedAuthClient represents instances of OAuth 2.0 clients. This means that an Aqueduct application that uses ManagedAuthDelegate T has a minimum of three database tables: users, tokens and clients. ManagedAuthDelegate T will delete authorization tokens and codes when they are no longer in use. This is determined by how many tokens a resource owner has and the tokens expiration dates. Once a resource owner acquires more than 40 tokens/codes, the oldest tokens/codes (determined by expiration date) are deleted. Effectively, the resource owner is limited to 40 tokens. This number can be changed when instantiating ManagedAuthDelegate T : final delegate = ManagedAuthDelegate ( context , tokenLimit: 20 );","title":"Using ManagedAuthDelegate"},{"location":"auth/server/#configuring-the-database","text":"ManagedAuthDelegate T requires database tables for its users, tokens and clients. Use the database command-line tool on your project to generate migration scripts and execute them against a database. This tool will see the declarations for your user type, ManagedAuthToken and ManagedAuthClient and create the appropriate tables.","title":"Configuring the Database"},{"location":"auth/what_is_oauth/","text":"What is OAuth 2.0? Most applications have the concept of a user. To prevent just anyone from saying they are this user, the user has a password. When a user wants to use your application, they send their username and password to the server so it can ensure they are who they say they are. The simple way to do this is to send the username and password in an Authorization header for every request. Two reasons this is bad: first, every time the user wants to do something, their password is sent in every request and that can be unsafe. Second, any application that wants to keep the user logged in has to store that password - and that is unsafe. In OAuth 2.0, the user gives their username and password to a client application once. The application sends those credentials to a server, and the server gives the application back an access token. A access token is a long, random string that no one can guess. When the user wants to do more stuff, the application sends the token with every request, instead of the user's password. The server checks the token, makes sure its not expired, and then lets the application's request go through. The application doesn't have to store the password and doesn't have to ask the user for their password again. This credential-for-token exchange happens by sending a POST request to some endpoint, where the username and password are sent in the request body. Typically, an Aqueduct application's route for this is /auth/token and handled by an instance of AuthController . OAuth 2.0 makes a subtle distinction: a user and the application they are using are not the same thing. It's intuitive to think of a user as \"making a request to the server\", but in reality, the user makes a request to an application and the application makes the request to the server. The server grants the application access on behalf of the user. In other words, when a user enters their credentials into an application, the application goes to the server and says \"Hey, this user said I can do stuff for them. Look, this is their secret password!\" This is an important distinction, because an OAuth 2.0 server doesn't just verify users: it also verifies applications. An application has a identifier that has been registered with the server. So, for an ecosystem that has a web client, an Android and an iOS app there would likely be three identifiers - one for each. The client application usually stores that identifier in a database. This identifier is called a client identifier . Client identifiers are added to Aqueduct applications with the aqueduct auth tool (see Aqueduct Auth CLI ). When the user is logging in through an application, they submit their username and password. The user doesn't provide the client identifier - in fact, the user doesn't know it. The application sends a request with the user's username and password in the request body, and the client identifier in the Authorization header. All three have to check out for the server to give the application back a token. The full request in pseudo-code looks something like: var request = HTTPRequest ( /auth/token ); request . method = POST ; request . contentType = application/x-www-form-urlencoded ; request . authorization = Base64 . encode ( $ clientID : ); request . body = { username : bob@stablekernel.com , password : supersecretstuff , grant_type : password }; An access token can expire. How long it takes to expire is up to the server - Aqueduct defaults to 24 hours. At first glance, this means that the application would have to ask the user for a password again. But, tokens can also be refreshed. Refreshing a token grants a brand new access token, but without having to ask for the password. This is possible because an access token comes with a refresh token . The refresh token is another long, random string. So, the JSON the server sends back when granting a token looks like this: { access_token : Abca09zzzza2o2kelmzlli3ijlka , token_type : bearer , refresh_token : lkmLIAmooa898nm20jannnnnxaww , expire_in : 3600 } The application hangs on to both an access token and a refresh token. When the token expires, it will send the refresh token back to the server to get a replacement access token. This is done through the same route that the access token came from - /auth/token - except the parameters are a bit different: var request = HTTPRequest ( /auth/token ); request . method = POST ; request . contentType = application/x-www-form-urlencoded ; request . authorization = Base64 . encode ( $ clientID : ); request . body = { refresh_token : lkmLIAmooa898nm20jannnnnxaww , grant_type : refresh_token }; Exchanging a refresh token has the same response as the initial exchange for username and password - except a few values will have changed. The verification and storage of authorization and authentication information is managed by an AuthServer . Other Methods for Obtaining Authorization The method of getting a token above - sending a username and password to /auth/token - is just one of four possible methods OAuth 2.0 uses to authenticate a user. This particular one is called the resource owner password credentials grant . A resource owner is a fancy word for a 'user'. We can shorten it up to just the 'password flow'. It's probably the most common flow - mobiles applications and front-end web applications often use this flow. When you enter your credentials, the client application sends them directly to the server. The other commonly used flow prevents the client application from ever seeing the user's credentials. For example, you might sign into Pivotal Tracker with your Google account. Your account on Pivotal Tracker doesn't have a password. Instead, it is linked to your Google account - which does. Pivotal Tracker never sees your Google password. When you login to Pivotal Tracker in this way, it takes you to Google's authentication page - owned and operated by Google. When you login successfully, Google gives Pivotal Tracker your token. Pivotal Tracker is now an application that can do things on your behalf. This is called the authorization code grant - or just 'auth code flow'. An instance of AuthCodeController handles granting authorization codes. Once a code is received, it can be exchanged for a token via an AuthController .","title":"What is OAuth 2.0?"},{"location":"auth/what_is_oauth/#what-is-oauth-20","text":"Most applications have the concept of a user. To prevent just anyone from saying they are this user, the user has a password. When a user wants to use your application, they send their username and password to the server so it can ensure they are who they say they are. The simple way to do this is to send the username and password in an Authorization header for every request. Two reasons this is bad: first, every time the user wants to do something, their password is sent in every request and that can be unsafe. Second, any application that wants to keep the user logged in has to store that password - and that is unsafe. In OAuth 2.0, the user gives their username and password to a client application once. The application sends those credentials to a server, and the server gives the application back an access token. A access token is a long, random string that no one can guess. When the user wants to do more stuff, the application sends the token with every request, instead of the user's password. The server checks the token, makes sure its not expired, and then lets the application's request go through. The application doesn't have to store the password and doesn't have to ask the user for their password again. This credential-for-token exchange happens by sending a POST request to some endpoint, where the username and password are sent in the request body. Typically, an Aqueduct application's route for this is /auth/token and handled by an instance of AuthController . OAuth 2.0 makes a subtle distinction: a user and the application they are using are not the same thing. It's intuitive to think of a user as \"making a request to the server\", but in reality, the user makes a request to an application and the application makes the request to the server. The server grants the application access on behalf of the user. In other words, when a user enters their credentials into an application, the application goes to the server and says \"Hey, this user said I can do stuff for them. Look, this is their secret password!\" This is an important distinction, because an OAuth 2.0 server doesn't just verify users: it also verifies applications. An application has a identifier that has been registered with the server. So, for an ecosystem that has a web client, an Android and an iOS app there would likely be three identifiers - one for each. The client application usually stores that identifier in a database. This identifier is called a client identifier . Client identifiers are added to Aqueduct applications with the aqueduct auth tool (see Aqueduct Auth CLI ). When the user is logging in through an application, they submit their username and password. The user doesn't provide the client identifier - in fact, the user doesn't know it. The application sends a request with the user's username and password in the request body, and the client identifier in the Authorization header. All three have to check out for the server to give the application back a token. The full request in pseudo-code looks something like: var request = HTTPRequest ( /auth/token ); request . method = POST ; request . contentType = application/x-www-form-urlencoded ; request . authorization = Base64 . encode ( $ clientID : ); request . body = { username : bob@stablekernel.com , password : supersecretstuff , grant_type : password }; An access token can expire. How long it takes to expire is up to the server - Aqueduct defaults to 24 hours. At first glance, this means that the application would have to ask the user for a password again. But, tokens can also be refreshed. Refreshing a token grants a brand new access token, but without having to ask for the password. This is possible because an access token comes with a refresh token . The refresh token is another long, random string. So, the JSON the server sends back when granting a token looks like this: { access_token : Abca09zzzza2o2kelmzlli3ijlka , token_type : bearer , refresh_token : lkmLIAmooa898nm20jannnnnxaww , expire_in : 3600 } The application hangs on to both an access token and a refresh token. When the token expires, it will send the refresh token back to the server to get a replacement access token. This is done through the same route that the access token came from - /auth/token - except the parameters are a bit different: var request = HTTPRequest ( /auth/token ); request . method = POST ; request . contentType = application/x-www-form-urlencoded ; request . authorization = Base64 . encode ( $ clientID : ); request . body = { refresh_token : lkmLIAmooa898nm20jannnnnxaww , grant_type : refresh_token }; Exchanging a refresh token has the same response as the initial exchange for username and password - except a few values will have changed. The verification and storage of authorization and authentication information is managed by an AuthServer .","title":"What is OAuth 2.0?"},{"location":"auth/what_is_oauth/#other-methods-for-obtaining-authorization","text":"The method of getting a token above - sending a username and password to /auth/token - is just one of four possible methods OAuth 2.0 uses to authenticate a user. This particular one is called the resource owner password credentials grant . A resource owner is a fancy word for a 'user'. We can shorten it up to just the 'password flow'. It's probably the most common flow - mobiles applications and front-end web applications often use this flow. When you enter your credentials, the client application sends them directly to the server. The other commonly used flow prevents the client application from ever seeing the user's credentials. For example, you might sign into Pivotal Tracker with your Google account. Your account on Pivotal Tracker doesn't have a password. Instead, it is linked to your Google account - which does. Pivotal Tracker never sees your Google password. When you login to Pivotal Tracker in this way, it takes you to Google's authentication page - owned and operated by Google. When you login successfully, Google gives Pivotal Tracker your token. Pivotal Tracker is now an application that can do things on your behalf. This is called the authorization code grant - or just 'auth code flow'. An instance of AuthCodeController handles granting authorization codes. Once a code is received, it can be exchanged for a token via an AuthController .","title":"Other Methods for Obtaining Authorization"},{"location":"cli/","text":"Tasks The Aqueduct command-line utility creates projects, runs applications, manages database schemas and other tasks. This tool is installed through pub : pub global activate aqueduct The above command updates the tool if a new version is available. You should ensure that aqueduct and your application use the same version of Aqueduct. All command-line tools have a --help option to show their options. Guides Creating Applications Running Applications Managing a Database Managing OAuth 2.0 Clients and Scopes Documenting an API","title":"Overview"},{"location":"cli/#tasks","text":"The Aqueduct command-line utility creates projects, runs applications, manages database schemas and other tasks. This tool is installed through pub : pub global activate aqueduct The above command updates the tool if a new version is available. You should ensure that aqueduct and your application use the same version of Aqueduct. All command-line tools have a --help option to show their options.","title":"Tasks"},{"location":"cli/#guides","text":"Creating Applications Running Applications Managing a Database Managing OAuth 2.0 Clients and Scopes Documenting an API","title":"Guides"},{"location":"cli/create/","text":"Creating Aqueduct Applications The aqueduct create command-line tool creates applications from a template. The usage is: aqueduct create app_name The application name must be snake_case - all lower case, no spaces, no symbols other than _ . By default, a generated project is fairly empty - it has the minimal content, but the structure of a complete application. For applications that use Aqueduct's ORM or OAuth 2.0 behavior, extended templates exist. These can be listed with the following: aqueduct create list-templates To pick a template, add the -t option to aqueduct create . For example, the following uses the db template: aqueduct create -t db app_name The templates are located in the Aqueduct package under examples/templates . When creating a new project from a template, the tool copies the contents of one of the template directories into your current working directory and substitutes some names with your project name.","title":"Creating Applications"},{"location":"cli/create/#creating-aqueduct-applications","text":"The aqueduct create command-line tool creates applications from a template. The usage is: aqueduct create app_name The application name must be snake_case - all lower case, no spaces, no symbols other than _ . By default, a generated project is fairly empty - it has the minimal content, but the structure of a complete application. For applications that use Aqueduct's ORM or OAuth 2.0 behavior, extended templates exist. These can be listed with the following: aqueduct create list-templates To pick a template, add the -t option to aqueduct create . For example, the following uses the db template: aqueduct create -t db app_name The templates are located in the Aqueduct package under examples/templates . When creating a new project from a template, the tool copies the contents of one of the template directories into your current working directory and substitutes some names with your project name.","title":"Creating Aqueduct Applications"},{"location":"cli/document/","text":"Documenting Aqueduct Applications The aqueduct document tool generates an OpenAPI (formerly Swagger) specification by reflecting on your application's code. This command is run in a project directory and will emit the JSON specification to stdout. You can redirect this to a file: aqueduct document swagger.json The file config.src.yaml must exist in your project directory so that the application can be initialized in 'test' mode for the documentation to be generated.","title":"Generating an OpenAPI/Swagger Specification"},{"location":"cli/document/#documenting-aqueduct-applications","text":"The aqueduct document tool generates an OpenAPI (formerly Swagger) specification by reflecting on your application's code. This command is run in a project directory and will emit the JSON specification to stdout. You can redirect this to a file: aqueduct document swagger.json The file config.src.yaml must exist in your project directory so that the application can be initialized in 'test' mode for the documentation to be generated.","title":"Documenting Aqueduct Applications"},{"location":"cli/running/","text":"Running Applications with Aqueduct Serve The aqueduct serve command-line tool runs applications. This tool is run in a project directory and it generates a Dart script that bootstraps your application. The structure of the project does matter - if you are creating a project from the template, the appropriate structure already exists. Otherwise, you must ensure you have a library file with the same name as your application (as defined in pubspec.yaml ). For example, an application named todo must have a lib/todo.dart file. This file must import the file that declares your application's ApplicationChannel . You may specify options like the number of isolates to run the application on and which port to listen for requests on. See more details with aqueduct serve --help .","title":"Running Applications"},{"location":"cli/running/#running-applications-with-aqueduct-serve","text":"The aqueduct serve command-line tool runs applications. This tool is run in a project directory and it generates a Dart script that bootstraps your application. The structure of the project does matter - if you are creating a project from the template, the appropriate structure already exists. Otherwise, you must ensure you have a library file with the same name as your application (as defined in pubspec.yaml ). For example, an application named todo must have a lib/todo.dart file. This file must import the file that declares your application's ApplicationChannel . You may specify options like the number of isolates to run the application on and which port to listen for requests on. See more details with aqueduct serve --help .","title":"Running Applications with Aqueduct Serve"},{"location":"db/","text":"Tasks Aqueduct's ORM stores data in a database and maps database data to Dart objects. You create subclasses of ManagedObject T in your application code to define the database tables your application uses. The properties of these types have annotations like Column and Validate to customize the behavior of tables in your database. Your application creates a ManagedContext service object during initialization that manages database access for your application. This service is injected into controllers that make database queries. Instances of Query T are created to insert, update, read and delete data from a database. A Query T has many configurable options for filtering, joining, paging, sorting and performing aggregate functions on database rows. The aqueduct db command-line tool manages databases that your application connects. This tool creates and executes migration scripts that update the schema of a database to match the requirements of your application. The minimum version of PostgreSQL needed to work with Aqueduct is 9.6. Guides Connecting to a Database Modeling Data Storage, Serialization and Deserialization Executing Queries Joins, Filtering and Paging Executing Queries in a Transaction Adding Validations and Callbacks to ManagedObject Aqueduct Database Tool JSON Document Columns and Operations","title":"Overview"},{"location":"db/#tasks","text":"Aqueduct's ORM stores data in a database and maps database data to Dart objects. You create subclasses of ManagedObject T in your application code to define the database tables your application uses. The properties of these types have annotations like Column and Validate to customize the behavior of tables in your database. Your application creates a ManagedContext service object during initialization that manages database access for your application. This service is injected into controllers that make database queries. Instances of Query T are created to insert, update, read and delete data from a database. A Query T has many configurable options for filtering, joining, paging, sorting and performing aggregate functions on database rows. The aqueduct db command-line tool manages databases that your application connects. This tool creates and executes migration scripts that update the schema of a database to match the requirements of your application. The minimum version of PostgreSQL needed to work with Aqueduct is 9.6.","title":"Tasks"},{"location":"db/#guides","text":"Connecting to a Database Modeling Data Storage, Serialization and Deserialization Executing Queries Joins, Filtering and Paging Executing Queries in a Transaction Adding Validations and Callbacks to ManagedObject Aqueduct Database Tool JSON Document Columns and Operations","title":"Guides"},{"location":"db/advanced_queries/","text":"Advanced Queries: Filtering, Joins, Paging and Reduce Paging Fetched Result Sets In larger data sets, it may make sense to only return a portion of rows from a database. For example, in a social media application, a user could have thousands of pieces of content they had created over many years. The likely use case for fetching their content would be to grab only the most recent content, and only grab earlier content as necessary. Aqueduct has two mechanisms in Query T for building queries that can fetch a subset of rows within a certain range. Naive paging can be accomplished using the fetchLimit and offset properties of a Query T . For example, if a table contains 100 rows, and you would like to grab 10 at a time, each query would have a value of 10 for its fetchLimit . The first query would have an offset of 0, then 10, then 20, and so on. Especially when using sortBy , this type of paging can be effective. One of the drawbacks to this type of paging is that it can skip or duplicate rows if rows are being added or deleted between fetches. For example, consider the seven objects above that are ordered by time. If we page by two objects at a time ( fetchLimit=2 ) starting at the first item ( offset=0 ), our first result set is the first two objects. The next page is the original offset plus the same limit - we grab the next two rows. But before the next page is fetched, a new object is inserted and its at an index that we already fetched. The next page would return 3:00pm again. A similar problem occurs if a row is deleted when paging in this way. It is really annoying for client applications to have to check for and merge duplicates. Another paging technique that doesn't suffer from this problem relies on the client sending a value from the last object in the previous page, instead of an offset. So in the above example, instead of asking for offset 2 in the second query, it'd send the value 1:30pm . The query filters out rows with a value less than the one it was sent, orders the remaining rows and then fetches the newest from the top. Query.pageBy uses this technique. Its usage is similar to sortBy : var firstQuery = Query Post ( context ) .. pageBy (( p ) = p . dateCreated , QuerySortOrder . descending ) .. fetchLimit = 10 ; var firstQueryResults = await firstQuery . fetch (); var oldestPostWeGot = firstQueryResults . last . dateCreated ; var nextQuery = Query Post ( context ) .. pageBy (( p ) = p . dateCreated , QuerySortOrder . descending , boundingValue: oldestPostWeGot ) .. fetchLimit = 10 ; This query would fetch the newest 10 posts. Then, it fetches the next 10 after skipping past all of the ones newer than the oldest post it got in the first result set. When paging, the query must have a fetchLimit - otherwise you're just sorting and returning every row. You identify which property to page on by using a property selector. The second argument to pageBy defines the order the rows will be sorted in. When you first start paging, you don't have any results yet, so you can't specify a value from the last result set. In this case, the boundingValue of pageBy is null - meaning start from the beginning. Once the first set has been fetched, the boundingValue is the value of the paging property in the last object returned. This is often accomplished by adding a query parameter to an endpoint that takes in a bounding value. (See ManagedObjectController T as an example.) A pageBy query will return an empty list of objects when no more values are left. If the number of objects remaining in the last page are less than the fetchLimit , only those objects will be returned. For example, if there four more objects left and the fetchLimit is 10, the number of objects returned will be four. You should index properties that will be paged by: @ Column ( indexed: true ) int pageableProperty ; Filtering Results of a Fetch Operation Fetching every row of a table usually doesn't make sense. Instead, we want a specific object or a set of objects matching some criteria. A Query 's where method is a safe and elegant way to add this criteria to a query. This method allows you to assign boolean expressions to the properties of the object being queried. Each expression is added to the WHERE clause of the generated SQL query. Here's an example of a query that finds a User with an id equal to 1: var query = Query User ( context ) .. where (( u ) = u . id ). equalTo ( 1 ); (The generated SQL here would be 'SELECT _user.id, _user.name, ... FROM _user WHERE _user.id = 1'.) There are many expression methods like equalTo - see the documentation for QueryExpression T for a complete list. You may add multiple criteria to a query by invoking where multiple times. Each criteria is combined together with a logical 'and'. For example, the following query will find all users whose name is \"Bob\" and email is not null: final query = Query User ( context ) .. where (( u ) = u . name ). equalTo ( Bob ) .. where (( u ) = u . email ). isNotNull (); You may apply criteria to relationship properties, too. For nullable relationships, you can apply null/not null checks: var employedQuery = Query Person ( context ) .. where (( c ) = c . company ). isNotNull (); More often, you use the identifiedBy expression for finding objects that belong to a specific object. For example, when finding all employees for a given company: var preferredQuery = Query Employee ( context ) .. where (( c ) = c . company ). identifiedBy ( 23 ); The above will only return employees who work for company with a primary key value of 23. It is equivalent to the following, and both are acceptable: var sameQuery = Query Employee ( context ) .. where (( c ) = c . company . id ). equalTo ( 23 ); Notice in the above that you may select properties of relationships when building a query. Since an employee 'belongs-to' a company, the employee table has a column to store the primary key of a company. This is called a foreign key column. When building a query that selects the primary key of a belongs-to relationship, Aqueduct can interpret this to use the foreign key column value. For selecting properties that are not backed by a foreign key column in the table being queried, see the next section on Joins. Including Relationships in a Fetch (aka, Joins) A Query T can also fetch relationship properties. This allows queries to fetch entire model graphs and reduces the number of round-trips to a database. By default, relationship properties are not fetched in a query and therefore aren't included in an object's asMap() . For example, consider the following definitions, where a User has-many Task s: class User extends ManagedObject _User implements _User {} class _User { @ primaryKey int id ; String name ; ManagedSet Task tasks ; } class Task extends ManagedObject _Task implements _Task {} class _Task { @ primaryKey int id ; @ Column ( # tasks ) User user ; String contents ; } A Query User will fetch the name and id of each User . A User 's tasks are not fetched, so the data returned looks like this: var q = Query User ( context ); var users = await q . fetch (); users . first . asMap () == { id : 1 , name : Bob }; // yup The join() method will tell a query to also include related objects. The following shows a fetch that gets users and their tasks: var q = Query User ( context ) .. join ( set : ( u ) = u . tasks ); var users = await q . fetch (); users . first . asMap () == { id : 1 , name : Bob , tasks : [ { id : 1 , contents : Take out trash , user : { id : 1 }}, ... ] }; // yup When joining a has-many relationship, the set: argument takes a property selector that must select a ManagedSet . (When fetching a has-one or belongs-to relationship, use the object: argument.) The method join() returns a new Query T , where T is the type of the joined object. That is, the above code could also be written as such: var q = Query User ( context ); // type annotation added for clarity Query Task taskSubQuery = q . join ( set : ( u ) = u . tasks ); Configuring Join Queries You do not execute a query created by a join, but you do configure it like any other query. (The parent query keeps track of the joined query and you execute the parent query.) For example, you may modify the properties that are returned for the joined objects: var q = Query User ( context ); q . join ( set : ( u ) = u . tasks ) .. returningProperties (( t ) = [ t . id , t . contents ]); final usersAndTasks = await q . fetch (); You may also apply filtering criteria to a join query. Consider a Parent that has-many Children . When fetching parents and joining their children, a where expression on the join query impacts which children are returned, but does not impact which parents are returned. For example, the following query would fetch every parent, but would only include children who are greater than 1 years old: final q = Query Parent ( context ); q . join ( set : ( p ) = p . children ) .. where (( c ) = c . age ). greaterThan ( 1 ); final parentsAndTheirChildren = await q . fetch (); Filtering Objects by Their Relationships However, consider if we applied a similar expression to the parent query - it would only return parents who have children that are greater than 1 years old . final q = Query Parent ( context ) .. where (( c ) = c . children . haveAtLeastOneWhere . age ). greaterThan ( 1 ); .. join ( set : ( p ) = p . children ); final parentsWithOlderChildren = await q . fetch (); The difference is where the expression is applied. When applying it to the child query, it removes child objects that don't meet the criteria. When applying it to the parent query, it removes parents that don't meet the criteria. The property haveAtLeastOneWhere is specific to has-many relationships. When selecting properties of a has-one or belongs-to relationship, you access the property directly: final q = Query Child ( context ) .. where (( p ) = p . parent . age ). greaterThan ( 30 ) .. join ( object: ( p ) = e . parent ); final childrenWithParentsOver30 = await q . fetch (); Note that you may use relationship properties without explicitly joining the property. A SQL JOIN is still performed, but the related object is not included in the result set. final q = Query Child ( context ) .. where (( p ) = p . parent . age ). greaterThan ( 30 ); final employeesWithManagersOver30YearsOld = await q . fetch (); Multiple Joins More than one join can be applied to a query, and subqueries can be nested. So, this is all valid, assuming the relationship properties exist: var q = Query User ( context ) .. join ( object: ( u ) = u . address ); q . join ( set : ( u ) = u . tasks ) .. join ( object: ( u ) = u . location ); This would fetch all users, their addresses, all of their tasks, and the location for each of their tasks. You'd get a nice sized tree of objects here. Reduce Functions (aka, Aggregate Functions) Queries can also be used to perform functions like count , sum , average , min and max . Here's an example: var query = Query User ( context ); var numberOfUsers = await query . reduce . count (); For reduce functions that use the value of some property, a property selector is used to identify that property. var averageSalary = await query . reduce . sum (( u ) = u . salary ); Any values configured in a Query T also impact the reduce function. For example, applying a Query.where and then executing a sum function will only sum the rows that meet the criteria of the where clause: var query = Query User ( context ) .. where (( u ) = u . name . equalTo ( Bob ); var averageSalaryOfPeopleNamedBob = await query . reduce . sum (( u ) = u . salary ); Fallbacks You may always execute arbitrary SQL with PersistentStore.execute . Note that the objects returned will be a List List dynamic - a list of rows, for each a list of columns. You may also provide raw WHERE clauses with Query.predicate . A QueryPredicate is a String that is set as the query's where clause. A QueryPredicate has two properties, a format string and a Map String, dynamic of parameter values. The format string can (and should) parameterize any input values. Parameters are indicated in the format string using the @ token: // Creates a predicate that would only include instances where some column id is less than 2 var predicate = QueryPredicate ( id @idVariable , { idVariable : 2 }); The text following the @ token may contain [A-Za-z0-9_] . The resulting where clause will be formed by replacing each token with the matching key in the parameters map. The value is not transformed in any way, so it must be the appropriate type for the column. If a key is not present in the Map , an exception will be thrown. Extra keys will be ignored.","title":"Advanced Queries"},{"location":"db/advanced_queries/#advanced-queries-filtering-joins-paging-and-reduce","text":"","title":"Advanced Queries: Filtering, Joins, Paging and Reduce"},{"location":"db/advanced_queries/#paging-fetched-result-sets","text":"In larger data sets, it may make sense to only return a portion of rows from a database. For example, in a social media application, a user could have thousands of pieces of content they had created over many years. The likely use case for fetching their content would be to grab only the most recent content, and only grab earlier content as necessary. Aqueduct has two mechanisms in Query T for building queries that can fetch a subset of rows within a certain range. Naive paging can be accomplished using the fetchLimit and offset properties of a Query T . For example, if a table contains 100 rows, and you would like to grab 10 at a time, each query would have a value of 10 for its fetchLimit . The first query would have an offset of 0, then 10, then 20, and so on. Especially when using sortBy , this type of paging can be effective. One of the drawbacks to this type of paging is that it can skip or duplicate rows if rows are being added or deleted between fetches. For example, consider the seven objects above that are ordered by time. If we page by two objects at a time ( fetchLimit=2 ) starting at the first item ( offset=0 ), our first result set is the first two objects. The next page is the original offset plus the same limit - we grab the next two rows. But before the next page is fetched, a new object is inserted and its at an index that we already fetched. The next page would return 3:00pm again. A similar problem occurs if a row is deleted when paging in this way. It is really annoying for client applications to have to check for and merge duplicates. Another paging technique that doesn't suffer from this problem relies on the client sending a value from the last object in the previous page, instead of an offset. So in the above example, instead of asking for offset 2 in the second query, it'd send the value 1:30pm . The query filters out rows with a value less than the one it was sent, orders the remaining rows and then fetches the newest from the top. Query.pageBy uses this technique. Its usage is similar to sortBy : var firstQuery = Query Post ( context ) .. pageBy (( p ) = p . dateCreated , QuerySortOrder . descending ) .. fetchLimit = 10 ; var firstQueryResults = await firstQuery . fetch (); var oldestPostWeGot = firstQueryResults . last . dateCreated ; var nextQuery = Query Post ( context ) .. pageBy (( p ) = p . dateCreated , QuerySortOrder . descending , boundingValue: oldestPostWeGot ) .. fetchLimit = 10 ; This query would fetch the newest 10 posts. Then, it fetches the next 10 after skipping past all of the ones newer than the oldest post it got in the first result set. When paging, the query must have a fetchLimit - otherwise you're just sorting and returning every row. You identify which property to page on by using a property selector. The second argument to pageBy defines the order the rows will be sorted in. When you first start paging, you don't have any results yet, so you can't specify a value from the last result set. In this case, the boundingValue of pageBy is null - meaning start from the beginning. Once the first set has been fetched, the boundingValue is the value of the paging property in the last object returned. This is often accomplished by adding a query parameter to an endpoint that takes in a bounding value. (See ManagedObjectController T as an example.) A pageBy query will return an empty list of objects when no more values are left. If the number of objects remaining in the last page are less than the fetchLimit , only those objects will be returned. For example, if there four more objects left and the fetchLimit is 10, the number of objects returned will be four. You should index properties that will be paged by: @ Column ( indexed: true ) int pageableProperty ;","title":"Paging Fetched Result Sets"},{"location":"db/advanced_queries/#filtering-results-of-a-fetch-operation","text":"Fetching every row of a table usually doesn't make sense. Instead, we want a specific object or a set of objects matching some criteria. A Query 's where method is a safe and elegant way to add this criteria to a query. This method allows you to assign boolean expressions to the properties of the object being queried. Each expression is added to the WHERE clause of the generated SQL query. Here's an example of a query that finds a User with an id equal to 1: var query = Query User ( context ) .. where (( u ) = u . id ). equalTo ( 1 ); (The generated SQL here would be 'SELECT _user.id, _user.name, ... FROM _user WHERE _user.id = 1'.) There are many expression methods like equalTo - see the documentation for QueryExpression T for a complete list. You may add multiple criteria to a query by invoking where multiple times. Each criteria is combined together with a logical 'and'. For example, the following query will find all users whose name is \"Bob\" and email is not null: final query = Query User ( context ) .. where (( u ) = u . name ). equalTo ( Bob ) .. where (( u ) = u . email ). isNotNull (); You may apply criteria to relationship properties, too. For nullable relationships, you can apply null/not null checks: var employedQuery = Query Person ( context ) .. where (( c ) = c . company ). isNotNull (); More often, you use the identifiedBy expression for finding objects that belong to a specific object. For example, when finding all employees for a given company: var preferredQuery = Query Employee ( context ) .. where (( c ) = c . company ). identifiedBy ( 23 ); The above will only return employees who work for company with a primary key value of 23. It is equivalent to the following, and both are acceptable: var sameQuery = Query Employee ( context ) .. where (( c ) = c . company . id ). equalTo ( 23 ); Notice in the above that you may select properties of relationships when building a query. Since an employee 'belongs-to' a company, the employee table has a column to store the primary key of a company. This is called a foreign key column. When building a query that selects the primary key of a belongs-to relationship, Aqueduct can interpret this to use the foreign key column value. For selecting properties that are not backed by a foreign key column in the table being queried, see the next section on Joins.","title":"Filtering Results of a Fetch Operation"},{"location":"db/advanced_queries/#including-relationships-in-a-fetch-aka-joins","text":"A Query T can also fetch relationship properties. This allows queries to fetch entire model graphs and reduces the number of round-trips to a database. By default, relationship properties are not fetched in a query and therefore aren't included in an object's asMap() . For example, consider the following definitions, where a User has-many Task s: class User extends ManagedObject _User implements _User {} class _User { @ primaryKey int id ; String name ; ManagedSet Task tasks ; } class Task extends ManagedObject _Task implements _Task {} class _Task { @ primaryKey int id ; @ Column ( # tasks ) User user ; String contents ; } A Query User will fetch the name and id of each User . A User 's tasks are not fetched, so the data returned looks like this: var q = Query User ( context ); var users = await q . fetch (); users . first . asMap () == { id : 1 , name : Bob }; // yup The join() method will tell a query to also include related objects. The following shows a fetch that gets users and their tasks: var q = Query User ( context ) .. join ( set : ( u ) = u . tasks ); var users = await q . fetch (); users . first . asMap () == { id : 1 , name : Bob , tasks : [ { id : 1 , contents : Take out trash , user : { id : 1 }}, ... ] }; // yup When joining a has-many relationship, the set: argument takes a property selector that must select a ManagedSet . (When fetching a has-one or belongs-to relationship, use the object: argument.) The method join() returns a new Query T , where T is the type of the joined object. That is, the above code could also be written as such: var q = Query User ( context ); // type annotation added for clarity Query Task taskSubQuery = q . join ( set : ( u ) = u . tasks );","title":"Including Relationships in a Fetch (aka, Joins)"},{"location":"db/advanced_queries/#configuring-join-queries","text":"You do not execute a query created by a join, but you do configure it like any other query. (The parent query keeps track of the joined query and you execute the parent query.) For example, you may modify the properties that are returned for the joined objects: var q = Query User ( context ); q . join ( set : ( u ) = u . tasks ) .. returningProperties (( t ) = [ t . id , t . contents ]); final usersAndTasks = await q . fetch (); You may also apply filtering criteria to a join query. Consider a Parent that has-many Children . When fetching parents and joining their children, a where expression on the join query impacts which children are returned, but does not impact which parents are returned. For example, the following query would fetch every parent, but would only include children who are greater than 1 years old: final q = Query Parent ( context ); q . join ( set : ( p ) = p . children ) .. where (( c ) = c . age ). greaterThan ( 1 ); final parentsAndTheirChildren = await q . fetch ();","title":"Configuring Join Queries"},{"location":"db/advanced_queries/#filtering-objects-by-their-relationships","text":"However, consider if we applied a similar expression to the parent query - it would only return parents who have children that are greater than 1 years old . final q = Query Parent ( context ) .. where (( c ) = c . children . haveAtLeastOneWhere . age ). greaterThan ( 1 ); .. join ( set : ( p ) = p . children ); final parentsWithOlderChildren = await q . fetch (); The difference is where the expression is applied. When applying it to the child query, it removes child objects that don't meet the criteria. When applying it to the parent query, it removes parents that don't meet the criteria. The property haveAtLeastOneWhere is specific to has-many relationships. When selecting properties of a has-one or belongs-to relationship, you access the property directly: final q = Query Child ( context ) .. where (( p ) = p . parent . age ). greaterThan ( 30 ) .. join ( object: ( p ) = e . parent ); final childrenWithParentsOver30 = await q . fetch (); Note that you may use relationship properties without explicitly joining the property. A SQL JOIN is still performed, but the related object is not included in the result set. final q = Query Child ( context ) .. where (( p ) = p . parent . age ). greaterThan ( 30 ); final employeesWithManagersOver30YearsOld = await q . fetch ();","title":"Filtering Objects by Their Relationships"},{"location":"db/advanced_queries/#multiple-joins","text":"More than one join can be applied to a query, and subqueries can be nested. So, this is all valid, assuming the relationship properties exist: var q = Query User ( context ) .. join ( object: ( u ) = u . address ); q . join ( set : ( u ) = u . tasks ) .. join ( object: ( u ) = u . location ); This would fetch all users, their addresses, all of their tasks, and the location for each of their tasks. You'd get a nice sized tree of objects here.","title":"Multiple Joins"},{"location":"db/advanced_queries/#reduce-functions-aka-aggregate-functions","text":"Queries can also be used to perform functions like count , sum , average , min and max . Here's an example: var query = Query User ( context ); var numberOfUsers = await query . reduce . count (); For reduce functions that use the value of some property, a property selector is used to identify that property. var averageSalary = await query . reduce . sum (( u ) = u . salary ); Any values configured in a Query T also impact the reduce function. For example, applying a Query.where and then executing a sum function will only sum the rows that meet the criteria of the where clause: var query = Query User ( context ) .. where (( u ) = u . name . equalTo ( Bob ); var averageSalaryOfPeopleNamedBob = await query . reduce . sum (( u ) = u . salary );","title":"Reduce Functions (aka, Aggregate Functions)"},{"location":"db/advanced_queries/#fallbacks","text":"You may always execute arbitrary SQL with PersistentStore.execute . Note that the objects returned will be a List List dynamic - a list of rows, for each a list of columns. You may also provide raw WHERE clauses with Query.predicate . A QueryPredicate is a String that is set as the query's where clause. A QueryPredicate has two properties, a format string and a Map String, dynamic of parameter values. The format string can (and should) parameterize any input values. Parameters are indicated in the format string using the @ token: // Creates a predicate that would only include instances where some column id is less than 2 var predicate = QueryPredicate ( id @idVariable , { idVariable : 2 }); The text following the @ token may contain [A-Za-z0-9_] . The resulting where clause will be formed by replacing each token with the matching key in the parameters map. The value is not transformed in any way, so it must be the appropriate type for the column. If a key is not present in the Map , an exception will be thrown. Extra keys will be ignored.","title":"Fallbacks"},{"location":"db/connecting/","text":"Connecting to a Database from Aqueduct The purpose of this document is to guide you through creating a new PostgreSQL database and setting up an Aqueduct application that connects to it. Creating a Database To use the Aqueduct ORM, you must have a PostgreSQL database server and create a database for your application. When developing locally, use Postgres.app to set up a development database server quickly. After running this application, create or select a new database server from the left-hand menu, and then double-click any of the database icons to open the psql command-line tool. (If you are not using Postgres.app , make sure psql is in your $PATH and run it from the command-line.) Inside psql , enter the following commands to create a database and a database user for your application: CREATE DATABASE my_app_name ; CREATE USER my_app_name_user WITH PASSWORD password ; GRANT ALL ON DATABASE my_app_name TO my_app_name_user ; Using ManagedContext to Connect to a Database The interface to a database from Aqueduct is an instance of ManagedContext , which contains the following two objects: a ManagedDataModel that describes your application's data model a PersistentStore that creates database connections and transmits data across that connection. A ManagedContext uses these two objects to coordinate moving data to and from your application and a database when executing Query T s. A ManagedContext - and its store and data model - are created in a ApplicationChannel constructor. class MyApplicationChannel extends ApplicationChannel { ManagedContext context ; @ override Future prepare () async { var dataModel = ManagedDataModel . fromCurrentMirrorSystem (); var psc = PostgreSQLPersistentStore . fromConnectionInfo ( my_app_name_user , password , localhost , 5432 , my_app_name ); context = ManagedContext ( dataModel , psc ); } } A ManagedDataModel should be instantiated with its fromCurrentMirrorSystem convenience constructor. You may optionally pass a list of ManagedObject T subclasses to its default constructor. var dataModel = ManagedDataModel ([ User , Post , Friendship ]); A ManagedContext is required to create and execute a Query T . The context determines which database the query is executed in. A context must exist before creating instances of any ManagedObject subclass in your application. Controllers that need to execute database queries must have a reference to a context; this is typically accomplished by passing the context to a controller's constructor. Using a Configuration File Connection information for a database is most often configured through a configuration file. This allows you to build configurations for different environments (production, testing, etc.), without having to modify code. class MyConfiguration extends Configuration { MyConfiguration ( String configPath ) : super . fromFile ( configPath ); DatabaseConnectionConfiguration database ; } class MyApplicationChannel extends ApplicationChannel { ManagedContext context ; @ override Future prepare () async { final config = MyConfiguration ( options . configurationFilePath ); final dataModel = ManagedDataModel . fromCurrentMirrorSystem (); final psc = PostgreSQLPersistentStore . fromConnectionInfo ( config . database . username , config . database . password , config . database . host , config . database . port , config . database . databaseName ); context = ManagedContext ( dataModel , psc ); } } A YAML configuration file loaded by this application must look like this: database : username : bob password : bobspassword host : localhost port : 5432 databaseName : my_app A PersistentStore is an interface. Concrete implementations - like PostgreSQLPersistentStore - implement that interface to transmit data to a database in the format it expects. A PostgreSQLPersistentStore will automatically connect and maintain a persistent connection to a database. If the connection is lost for some reason, it will automatically reconnect the next time a query is executed. If a connection cannot be established, an exception is thrown that sends a 503 status code response by default.","title":"Connecting to a Database"},{"location":"db/connecting/#connecting-to-a-database-from-aqueduct","text":"The purpose of this document is to guide you through creating a new PostgreSQL database and setting up an Aqueduct application that connects to it.","title":"Connecting to a Database from Aqueduct"},{"location":"db/connecting/#creating-a-database","text":"To use the Aqueduct ORM, you must have a PostgreSQL database server and create a database for your application. When developing locally, use Postgres.app to set up a development database server quickly. After running this application, create or select a new database server from the left-hand menu, and then double-click any of the database icons to open the psql command-line tool. (If you are not using Postgres.app , make sure psql is in your $PATH and run it from the command-line.) Inside psql , enter the following commands to create a database and a database user for your application: CREATE DATABASE my_app_name ; CREATE USER my_app_name_user WITH PASSWORD password ; GRANT ALL ON DATABASE my_app_name TO my_app_name_user ;","title":"Creating a Database"},{"location":"db/connecting/#using-managedcontext-to-connect-to-a-database","text":"The interface to a database from Aqueduct is an instance of ManagedContext , which contains the following two objects: a ManagedDataModel that describes your application's data model a PersistentStore that creates database connections and transmits data across that connection. A ManagedContext uses these two objects to coordinate moving data to and from your application and a database when executing Query T s. A ManagedContext - and its store and data model - are created in a ApplicationChannel constructor. class MyApplicationChannel extends ApplicationChannel { ManagedContext context ; @ override Future prepare () async { var dataModel = ManagedDataModel . fromCurrentMirrorSystem (); var psc = PostgreSQLPersistentStore . fromConnectionInfo ( my_app_name_user , password , localhost , 5432 , my_app_name ); context = ManagedContext ( dataModel , psc ); } } A ManagedDataModel should be instantiated with its fromCurrentMirrorSystem convenience constructor. You may optionally pass a list of ManagedObject T subclasses to its default constructor. var dataModel = ManagedDataModel ([ User , Post , Friendship ]); A ManagedContext is required to create and execute a Query T . The context determines which database the query is executed in. A context must exist before creating instances of any ManagedObject subclass in your application. Controllers that need to execute database queries must have a reference to a context; this is typically accomplished by passing the context to a controller's constructor.","title":"Using ManagedContext to Connect to a Database"},{"location":"db/connecting/#using-a-configuration-file","text":"Connection information for a database is most often configured through a configuration file. This allows you to build configurations for different environments (production, testing, etc.), without having to modify code. class MyConfiguration extends Configuration { MyConfiguration ( String configPath ) : super . fromFile ( configPath ); DatabaseConnectionConfiguration database ; } class MyApplicationChannel extends ApplicationChannel { ManagedContext context ; @ override Future prepare () async { final config = MyConfiguration ( options . configurationFilePath ); final dataModel = ManagedDataModel . fromCurrentMirrorSystem (); final psc = PostgreSQLPersistentStore . fromConnectionInfo ( config . database . username , config . database . password , config . database . host , config . database . port , config . database . databaseName ); context = ManagedContext ( dataModel , psc ); } } A YAML configuration file loaded by this application must look like this: database : username : bob password : bobspassword host : localhost port : 5432 databaseName : my_app A PersistentStore is an interface. Concrete implementations - like PostgreSQLPersistentStore - implement that interface to transmit data to a database in the format it expects. A PostgreSQLPersistentStore will automatically connect and maintain a persistent connection to a database. If the connection is lost for some reason, it will automatically reconnect the next time a query is executed. If a connection cannot be established, an exception is thrown that sends a 503 status code response by default.","title":"Using a Configuration File"},{"location":"db/db_tools/","text":"Database Migration and Tooling The aqueduct db command line tool creates and executes migration files . A migration file contains SQL commands that create and modify database tables to match your application's data model. PostgreSQL 9.6 and Greater The minimum version of PostgreSQL needed to work with Aqueduct is 9.6. Migration Files Database tables are described by ManagedObject T subclasses and their table definition. Migration files describe a series of database commands that will create or modify a database schema to match an application's ManagedObject T declarations. Migration files are executed on a database when an application is first deployed and when changes to the data model occur - like adding new ManagedObject T subclasses or changing the name of a ManagedObject T property. Each migration file contains only the changes made since the last migration file was generated. For example, let's say that version 1 of your application has two ManagedObject T subclasses, User and Post . Before you launch, you create a migration file that creates two tables, one for User and one for Post . A month later, you have developed version 1.1 of your application and now you have a third ManagedObject T named Location . Prior to deploying version 1.1, you generate a new migration file and execute it. This migration file only contains instructions to create a table for Location . The 'final product' of your database is the sum of both migration files. For this reason, migrations files should be stored in source control. Generating Migration Files Migration files are automatically generated by running aqueduct db generate in an Aqueduct project directory. This tool finds every ManagedObject T subclass and adds commands to the migration file to create a database table that matches its declaration. When subsequent migration files are generated, the difference between the schema created by existing migration files is compared to the current schema declared in an application's code. The commands to rectify those differences are added to the new migration file. This tool will find ManagedObject T subclasses in an application. As a convention, every ManagedObject T subclass is declared in its own file in lib/model/ . For example, a User class is defined in lib/model/user.dart . Migration files are stored in an application's migrations directory. Migration files are prefixed with a version number, a \"0\" padded eight digit number, ad suffixed with .migration.dart . For example, 00000001_initial.migration.dart is a migration filename. The version number portion of the filename is required, as is the .migration.dart suffix. The underscore and remainder of the filename are optional and have no effect, they are just a way to name the file. Here is an example of two migration file names: 00000001_initial.migration.dart 00000002_add_user_nickname.migration.dart The version number of migration files indicate the order in which they are applied. Leading zeros are stripped from the filenames before their version numbers are compared. Version numbers do not necessarily have to be continuous, but doing otherwise is not recommended. Migration files may be created manually or altered after they are generated by aqueduct db generate . A migration file's Migration.upgrade method makes calls to Migration.database (an instance of SchemaBuilder ) property to add, remove, and modify tables and columns. Each method invocation creates one or more SQL commands. When a migration file is executed, its upgrade method is invoked and each command is collected and run within a transaction. The commands are executed in order, and it's important to note that the order often matters. There are scenarios where there are more than one operation can rectify a change in the data model. It is important to review migration files after they have been generated to ensure the expected behavior. Validating Migration Files Migration files may be altered after they have been generated. This is often the case if aqueduct db generate can't say for certain how a database should change. For example, is renaming a property just renaming a column, or is it deleting a column and creating a new column? The aqueduct db validate tool ensures that the database schema after running all migration files matches the database schema declared by an application's ManagedObject T s. Any generated migration file will pass aqueduct db validate . The validate tool will display differences found between the schema in code and the schema created by migration files. Listing Migration Files Use aqueduct db list to list all database migration files and their resolved version number. Executing Migration Files The tool aqueduct db upgrade will apply migration files to a running database. This tool is run in an application's directory and finds migration files in the migrations directory. The connection info for a the running database is provided with the --connect option. For example, the following would execute migration files on a PostgreSQL database: aqueduct db upgrade --connect postgres://username:password@localhost:5432/my_application The first time aqueduct db upgrade is executed, it creates a version table that keeps the version number and dates of upgrades. When aqueduct db upgrade is ran after the initial migration, the version number is fetched from the database. The tool only runs migration files after the version number stored in the database. Connection information can also be stored in a database configuration file named database.yaml in the application directory. If this file exists with the following format, --connect can be omitted and connection information will be read from this file: username: user password: password host: host port: port databaseName: database Getting a Database's Version You can fetch a database's current version number with aqueduct db get-version . This command takes --connect or a database.yaml file as described in the previous section to get connection info for the database. When to Execute Migration Files During development, there is no need to create a migration file for each change. Execute migration files prior to deployment of a new version of an application. You may delete migration files. When aqueduct db generate is run again, will replay only the existing migration files before determining which commands to add to the new migration file. For example, if you have 10 migration files over time and delete them all - the next generated migration file will contain commands to recreate the entire database schema.","title":"Migration and Tooling"},{"location":"db/db_tools/#database-migration-and-tooling","text":"The aqueduct db command line tool creates and executes migration files . A migration file contains SQL commands that create and modify database tables to match your application's data model. PostgreSQL 9.6 and Greater The minimum version of PostgreSQL needed to work with Aqueduct is 9.6.","title":"Database Migration and Tooling"},{"location":"db/db_tools/#migration-files","text":"Database tables are described by ManagedObject T subclasses and their table definition. Migration files describe a series of database commands that will create or modify a database schema to match an application's ManagedObject T declarations. Migration files are executed on a database when an application is first deployed and when changes to the data model occur - like adding new ManagedObject T subclasses or changing the name of a ManagedObject T property. Each migration file contains only the changes made since the last migration file was generated. For example, let's say that version 1 of your application has two ManagedObject T subclasses, User and Post . Before you launch, you create a migration file that creates two tables, one for User and one for Post . A month later, you have developed version 1.1 of your application and now you have a third ManagedObject T named Location . Prior to deploying version 1.1, you generate a new migration file and execute it. This migration file only contains instructions to create a table for Location . The 'final product' of your database is the sum of both migration files. For this reason, migrations files should be stored in source control.","title":"Migration Files"},{"location":"db/db_tools/#generating-migration-files","text":"Migration files are automatically generated by running aqueduct db generate in an Aqueduct project directory. This tool finds every ManagedObject T subclass and adds commands to the migration file to create a database table that matches its declaration. When subsequent migration files are generated, the difference between the schema created by existing migration files is compared to the current schema declared in an application's code. The commands to rectify those differences are added to the new migration file. This tool will find ManagedObject T subclasses in an application. As a convention, every ManagedObject T subclass is declared in its own file in lib/model/ . For example, a User class is defined in lib/model/user.dart . Migration files are stored in an application's migrations directory. Migration files are prefixed with a version number, a \"0\" padded eight digit number, ad suffixed with .migration.dart . For example, 00000001_initial.migration.dart is a migration filename. The version number portion of the filename is required, as is the .migration.dart suffix. The underscore and remainder of the filename are optional and have no effect, they are just a way to name the file. Here is an example of two migration file names: 00000001_initial.migration.dart 00000002_add_user_nickname.migration.dart The version number of migration files indicate the order in which they are applied. Leading zeros are stripped from the filenames before their version numbers are compared. Version numbers do not necessarily have to be continuous, but doing otherwise is not recommended. Migration files may be created manually or altered after they are generated by aqueduct db generate . A migration file's Migration.upgrade method makes calls to Migration.database (an instance of SchemaBuilder ) property to add, remove, and modify tables and columns. Each method invocation creates one or more SQL commands. When a migration file is executed, its upgrade method is invoked and each command is collected and run within a transaction. The commands are executed in order, and it's important to note that the order often matters. There are scenarios where there are more than one operation can rectify a change in the data model. It is important to review migration files after they have been generated to ensure the expected behavior.","title":"Generating Migration Files"},{"location":"db/db_tools/#validating-migration-files","text":"Migration files may be altered after they have been generated. This is often the case if aqueduct db generate can't say for certain how a database should change. For example, is renaming a property just renaming a column, or is it deleting a column and creating a new column? The aqueduct db validate tool ensures that the database schema after running all migration files matches the database schema declared by an application's ManagedObject T s. Any generated migration file will pass aqueduct db validate . The validate tool will display differences found between the schema in code and the schema created by migration files.","title":"Validating Migration Files"},{"location":"db/db_tools/#listing-migration-files","text":"Use aqueduct db list to list all database migration files and their resolved version number.","title":"Listing Migration Files"},{"location":"db/db_tools/#executing-migration-files","text":"The tool aqueduct db upgrade will apply migration files to a running database. This tool is run in an application's directory and finds migration files in the migrations directory. The connection info for a the running database is provided with the --connect option. For example, the following would execute migration files on a PostgreSQL database: aqueduct db upgrade --connect postgres://username:password@localhost:5432/my_application The first time aqueduct db upgrade is executed, it creates a version table that keeps the version number and dates of upgrades. When aqueduct db upgrade is ran after the initial migration, the version number is fetched from the database. The tool only runs migration files after the version number stored in the database. Connection information can also be stored in a database configuration file named database.yaml in the application directory. If this file exists with the following format, --connect can be omitted and connection information will be read from this file: username: user password: password host: host port: port databaseName: database","title":"Executing Migration Files"},{"location":"db/db_tools/#getting-a-databases-version","text":"You can fetch a database's current version number with aqueduct db get-version . This command takes --connect or a database.yaml file as described in the previous section to get connection info for the database.","title":"Getting a Database's Version"},{"location":"db/db_tools/#when-to-execute-migration-files","text":"During development, there is no need to create a migration file for each change. Execute migration files prior to deployment of a new version of an application. You may delete migration files. When aqueduct db generate is run again, will replay only the existing migration files before determining which commands to add to the new migration file. For example, if you have 10 migration files over time and delete them all - the next generated migration file will contain commands to recreate the entire database schema.","title":"When to Execute Migration Files"},{"location":"db/executing_queries/","text":"Inserting, Updating, Deleting and Fetching Objects To send commands to a database - whether to fetch, insert, delete or update objects - you will create, configure and execute instances of Query T . The type of object the query is performed on is determined by the type argument. The argument must be a subclass of ManagedObject . A query compiles and executes a SQL query on a given ManagedContext . Here's an example of a Query T that fetches all instances of User : var query = Query User ( context ); var allUsers = await query . fetch (); A Query T has four basic execution methods: fetch , update , insert , delete . fetch will retrieve data from a database (it is equivalent to the SQL operation SELECT ). update will modify existing data in a database (it is equivalent to the SQL operation UPDATE ). insert will add new data to a database (it is equivalent to the SQL operation INSERT ). delete will remove data from a database (it is equivalent to the SQL operation DELETE ). A Query T has many configurable properties. These properties will impact which objects get fetched, the data that gets sent to the database, the order that data is returned in, and so on. Inserting Data with a Query Let's assume this User type exists: class User extends ManagedObject _User implements _User {} class _User { @ primaryKey int id ; @ Column ( indexed: true ) String email ; String name ; } To insert a new row into the _User table, a Query T is constructed and executed: var query = Query User ( context ) .. values . name = Bob .. values . email = bob@stablekernel.com ; var user = await query . insert (); user . asMap () == { id : 1 , name : Bob , email : bob@stablekernel.com }; Every Query T has a values property that is the type of managed object being inserted. Here, values is an instance of User . When a Query T is executed with insert() , a new row is created in the database with every property that has been set in values . In this case, both name and email have been set. The generated SQL looks like this: INSERT INTO _user ( name , email ) VALUES ( Bob , bob@stablekernel.com ) Note there is no value provided for the id property in this query. Recall that primaryKey is a convenience for Column with auto-incrementing behavior. Therefore, the database will assign a value for id during insertion. The object returned from insert() will be an instance of User that represents the inserted row and will include the auto-generated id . Properties that are not set in the values property will not be sent to the database. Values that are explicitly set to null will be sent as NULL . For example, consider the following Query T : var query = Query User ( context ) .. values . name = null ; await query . insert (); The generated SQL for this query does not send email - because it isn't included - and sends NULL for name : INSERT INTO _user ( name ) VALUES ( NULL ); If a property is not nullable (its Column has nullable: false ) and its value is not set in a query prior to inserting it, the query will fail and throw an exception. You may also set Query.values with an instance of a managed object. This is valuable when reading an object from a HTTP request body: var user = User () .. readFromMap ( request . body . asMap ()); var query = Query User ( context ) .. values = user ; If an insert query fails because of a unique constraint is violated, a QueryException will be thrown. See a later section on how QueryException s are gracefully handled by Controller s. In short, it is unlikely that you have to handle QueryException directly - Controller s know how to turn them into the appropriate HTTP response. Setting Query.values By default, Query.values is an empty instance of the object being inserted. If you replace it with an object - that you got from a request body or instantiated yourself - the properties are copied into Query.values . Further modifications of the replacement object have no effect on Query.values . There are convenience static methods on Query for inserting object(s) without having to create a Query object. final bob = User ().. name = Bob ; final jay = User ().. name = Jay ; final insertedObject = await Query . insertObject ( context , bob ); final insertedObjects = await Query . insertObjects ( context , [ bob , jay ]); Updating Data with a Query Updating rows with a Query T is similar to inserting data: you set the Query.values for properties you want to change. The type parameter for the Query T indicates which database table will get updated when the query is executed. An update query can - and likely should - be restricted to a single row or subset of rows. This is done by configuring the Query.where property - which gets translated into the where clause of the SQL command. Here's an example: // A Query that will change any user s whose name is Bob to Fred var query = Query User ( context ) .. values . name = Fred .. where (( u ) = u . name ). equalTo ( Bob ); List User bobsThatAreNowFreds = await query . update (); Like values , where is also the same managed object type the query is being executed on. In the above example, then, both values and where and instances of User . This query executes the following SQL: UPDATE _user SET name = Fred WHERE name = Bob ; The where property is a very powerful and flexible, and so there is an entire section dedicated to it later in this guide. For now, we'll stick to some of the things specific to update() . Like insert() , only the values set in the values property of a query get updated when executing update() . Values that are omitted are not included. Values that need to be set to null must explicitly be set to null in the query: // A Query that will remove names from anyone currently named Bob. var query = Query User ( context ) .. values . name = null .. where (( u ) = u . name ). equalTo ( Bob ); An update query returns every modified row as a result. If no rows are updated, the return value is an empty list. There is a variant to Query T .update named updateOne . The updateOne method will build and execute a SQL query in the same way a normal update does, however, it will only return the single instance that was updated instead of a list. This is convenience method for the caller to get back a single instance instead of a list: // Update user with id = 1 to have the name Fred var query = Query User ( context ) .. values . name = Fred .. where (( u ) = u . id ). equalTo ( 1 ); var updatedUser = await query . updateOne (); The updateOne method will return null if no rows were updated. It is important to note that if updateOne is used and more than one row is updated, updateOne will throw an exception and the changes to the data are not reversible . Because this is likely a mistake, this is considered an error, hence the exception is thrown. It is up to the programmer to recognize whether or not a particular updateOne query would impact multiple rows. Update queries have a safety feature that prevents you from accidentally updating every row. If you try to execute a Query T to do an update without configuring where , an exception is thrown prior to carrying out the request. If you actually want to update every row of a table, you must set the Query.canModifyAllInstances to true prior to execution. (This property defaults to false .) Deleting Data with a Query A Query T will delete rows from a database when using delete() . Like update queries, you should specify a row or rows using where properties of the Query T . The result of a delete operation will be a Future int with the number of rows deleted. var query = Query User ( context ) .. where (( u ) = u . id ). equalTo ( 1 ); int usersDeleted = await query . delete (); Also like update queries, delete queries have a safety feature that prevents you from accidentally deleting every row in a table with canModifyAllInstances . Any properties set in the query's values are ignored when executing a delete. Fetching Data with a Query Of the four basic operations of a Query T , fetching data is the most configurable. A simple Query T that would fetch every instance of some entity looks like this: var query = Query User ( context ); List User allUsers = await query . fetch (); A fetch Query T uses its where property to filter the result set, just like delete and update queries. Any properties set in the query's values are ignored when executing a fetch, since there is no need for them. In addition to fetching a list of instances from a database, you may also fetch a single instance with fetchOne . If no instance is found, null is returned. var query = Query User ( context ) .. where (( u ) = u . id ). equalTo ( 1 ); User oneUser = await query . fetchOne (); Fetch queries can be limited to a number of instances with the fetchLimit property. You may also set the offset of a Query T to skip the first offset number of rows. Between fetchLimit and offset , you can implement naive paging. However, this type of paging suffers from a number of problems and so there is another paging mechanism covered in later sections. Sorting Results of a fetch can be sorted using the sortBy method of a Query T . Here's an example: var q = Query User ( context ) .. sortBy (( u ) = u . dateCreated , QuerySortOrder . ascending ); sortBy takes two arguments: a closure that returns which property to sort by and the order of the sort. A Query T results can be sorted by multiple properties. When multiple sortBy s are invoked on a Query T , later sortBy s are used to break ties in previous sortBy s. For example, the following query will sort by last name, then by first name: var q = Query User ( context ) .. sortBy (( u ) = u . lastName , QuerySortOrder . ascending ) .. sortBy (( u ) = u . firstName , QuerySortOrder . ascending ); Thus, the following three names would be ordered like so: 'Sally Smith', 'John Wu', 'Sally Wu'. Property Selectors In the section on sorting, you saw the use of a property selector to select the property of the user to sort by. This syntax is used for many other query manipulations, like filtering and joining. A property selector is a closure that gives you an object of the type you are querying and must return a property of that object. The selector (u) = u.lastName in the previous section is a property selector that selects the last name of a user. The Dart analyzer will infer that the argument of a property selector, and it is always the same type as the object being queried. This enables IDE auto-completion, static error checking, and other tools like project-wide renaming. Live Templates To speed up query building, create a Live Template in IntelliJ that generates a property selector when typing 'ps'. The source of the template is (o) = o.$END$ . A downloadable settings configuration for IntelliJ exists here that includes this shortcut. Specifying Result Properties When executing queries that return managed objects (i.e., insert() , update() and fetch() ), the default properties for each object are fetched. The default properties of a managed object are properties that correspond to a database column - attributes declared in the table definition. A managed object's default properties can be modified when declaring its table definition: class _User { @ Column ( omitByDefault: true ) String hashedPassword ; } Any property with omitByDefault set to true will not be fetched by default. A property that is omitByDefault can still be fetched. Likewise, a property that is in the defaults can still be omitted. Each Query T has a returningProperties method to adjust which properties do get returned from the query. Its usage looks like this: var query = Query User ( context ) .. returningProperties (( user ) = [ user . id , user . name ]); returningProperties is a multiple property selector - instead of returning just one property, it returns a list of properties. You may include 'belongs-to' relationships in returningProperties , but you may not include 'has-many' or 'has-one' relationships. An exception will be thrown if you attempt to. To include properties from relationships like these, see join in Advanced Queries . Note that if you omit the primary key of a managed object from returningProperties , it will automatically be added. The primary key is necessary to transform the rows into instances of their ManagedObject T subclass. Exceptions and Errors When executing a query, it may fail for any number of reasons: the query is invalid, a database couldn't be reached, constraints were violated, etc. In many cases, this exception originates from the underlying database driver. When thrown in a controller, these exceptions will trigger a 500 Server Error response. Exceptions that are thrown in response to user input (e.g., violating a database constraint, invalid data type) are re-interpreted into a QueryException or ValidationException . Both of these exception types have an associated Response object that is sent instead of the default 500 Server error. For this reason, you don't need to catch database query exceptions in a controller; an appropriate response will be sent on your behalf. Statement Reuse Aqueduct will parameterize and reuse queries when possible. This allows for significant speed and security improvements. Note that you do not have to do anything special to take advantage of this feature. However, currently at this time, you may not disable this feature.","title":"Executing Queries"},{"location":"db/executing_queries/#inserting-updating-deleting-and-fetching-objects","text":"To send commands to a database - whether to fetch, insert, delete or update objects - you will create, configure and execute instances of Query T . The type of object the query is performed on is determined by the type argument. The argument must be a subclass of ManagedObject . A query compiles and executes a SQL query on a given ManagedContext . Here's an example of a Query T that fetches all instances of User : var query = Query User ( context ); var allUsers = await query . fetch (); A Query T has four basic execution methods: fetch , update , insert , delete . fetch will retrieve data from a database (it is equivalent to the SQL operation SELECT ). update will modify existing data in a database (it is equivalent to the SQL operation UPDATE ). insert will add new data to a database (it is equivalent to the SQL operation INSERT ). delete will remove data from a database (it is equivalent to the SQL operation DELETE ). A Query T has many configurable properties. These properties will impact which objects get fetched, the data that gets sent to the database, the order that data is returned in, and so on.","title":"Inserting, Updating, Deleting and Fetching Objects"},{"location":"db/executing_queries/#inserting-data-with-a-query","text":"Let's assume this User type exists: class User extends ManagedObject _User implements _User {} class _User { @ primaryKey int id ; @ Column ( indexed: true ) String email ; String name ; } To insert a new row into the _User table, a Query T is constructed and executed: var query = Query User ( context ) .. values . name = Bob .. values . email = bob@stablekernel.com ; var user = await query . insert (); user . asMap () == { id : 1 , name : Bob , email : bob@stablekernel.com }; Every Query T has a values property that is the type of managed object being inserted. Here, values is an instance of User . When a Query T is executed with insert() , a new row is created in the database with every property that has been set in values . In this case, both name and email have been set. The generated SQL looks like this: INSERT INTO _user ( name , email ) VALUES ( Bob , bob@stablekernel.com ) Note there is no value provided for the id property in this query. Recall that primaryKey is a convenience for Column with auto-incrementing behavior. Therefore, the database will assign a value for id during insertion. The object returned from insert() will be an instance of User that represents the inserted row and will include the auto-generated id . Properties that are not set in the values property will not be sent to the database. Values that are explicitly set to null will be sent as NULL . For example, consider the following Query T : var query = Query User ( context ) .. values . name = null ; await query . insert (); The generated SQL for this query does not send email - because it isn't included - and sends NULL for name : INSERT INTO _user ( name ) VALUES ( NULL ); If a property is not nullable (its Column has nullable: false ) and its value is not set in a query prior to inserting it, the query will fail and throw an exception. You may also set Query.values with an instance of a managed object. This is valuable when reading an object from a HTTP request body: var user = User () .. readFromMap ( request . body . asMap ()); var query = Query User ( context ) .. values = user ; If an insert query fails because of a unique constraint is violated, a QueryException will be thrown. See a later section on how QueryException s are gracefully handled by Controller s. In short, it is unlikely that you have to handle QueryException directly - Controller s know how to turn them into the appropriate HTTP response. Setting Query.values By default, Query.values is an empty instance of the object being inserted. If you replace it with an object - that you got from a request body or instantiated yourself - the properties are copied into Query.values . Further modifications of the replacement object have no effect on Query.values . There are convenience static methods on Query for inserting object(s) without having to create a Query object. final bob = User ().. name = Bob ; final jay = User ().. name = Jay ; final insertedObject = await Query . insertObject ( context , bob ); final insertedObjects = await Query . insertObjects ( context , [ bob , jay ]);","title":"Inserting Data with a Query"},{"location":"db/executing_queries/#updating-data-with-a-query","text":"Updating rows with a Query T is similar to inserting data: you set the Query.values for properties you want to change. The type parameter for the Query T indicates which database table will get updated when the query is executed. An update query can - and likely should - be restricted to a single row or subset of rows. This is done by configuring the Query.where property - which gets translated into the where clause of the SQL command. Here's an example: // A Query that will change any user s whose name is Bob to Fred var query = Query User ( context ) .. values . name = Fred .. where (( u ) = u . name ). equalTo ( Bob ); List User bobsThatAreNowFreds = await query . update (); Like values , where is also the same managed object type the query is being executed on. In the above example, then, both values and where and instances of User . This query executes the following SQL: UPDATE _user SET name = Fred WHERE name = Bob ; The where property is a very powerful and flexible, and so there is an entire section dedicated to it later in this guide. For now, we'll stick to some of the things specific to update() . Like insert() , only the values set in the values property of a query get updated when executing update() . Values that are omitted are not included. Values that need to be set to null must explicitly be set to null in the query: // A Query that will remove names from anyone currently named Bob. var query = Query User ( context ) .. values . name = null .. where (( u ) = u . name ). equalTo ( Bob ); An update query returns every modified row as a result. If no rows are updated, the return value is an empty list. There is a variant to Query T .update named updateOne . The updateOne method will build and execute a SQL query in the same way a normal update does, however, it will only return the single instance that was updated instead of a list. This is convenience method for the caller to get back a single instance instead of a list: // Update user with id = 1 to have the name Fred var query = Query User ( context ) .. values . name = Fred .. where (( u ) = u . id ). equalTo ( 1 ); var updatedUser = await query . updateOne (); The updateOne method will return null if no rows were updated. It is important to note that if updateOne is used and more than one row is updated, updateOne will throw an exception and the changes to the data are not reversible . Because this is likely a mistake, this is considered an error, hence the exception is thrown. It is up to the programmer to recognize whether or not a particular updateOne query would impact multiple rows. Update queries have a safety feature that prevents you from accidentally updating every row. If you try to execute a Query T to do an update without configuring where , an exception is thrown prior to carrying out the request. If you actually want to update every row of a table, you must set the Query.canModifyAllInstances to true prior to execution. (This property defaults to false .)","title":"Updating Data with a Query"},{"location":"db/executing_queries/#deleting-data-with-a-query","text":"A Query T will delete rows from a database when using delete() . Like update queries, you should specify a row or rows using where properties of the Query T . The result of a delete operation will be a Future int with the number of rows deleted. var query = Query User ( context ) .. where (( u ) = u . id ). equalTo ( 1 ); int usersDeleted = await query . delete (); Also like update queries, delete queries have a safety feature that prevents you from accidentally deleting every row in a table with canModifyAllInstances . Any properties set in the query's values are ignored when executing a delete.","title":"Deleting Data with a Query"},{"location":"db/executing_queries/#fetching-data-with-a-query","text":"Of the four basic operations of a Query T , fetching data is the most configurable. A simple Query T that would fetch every instance of some entity looks like this: var query = Query User ( context ); List User allUsers = await query . fetch (); A fetch Query T uses its where property to filter the result set, just like delete and update queries. Any properties set in the query's values are ignored when executing a fetch, since there is no need for them. In addition to fetching a list of instances from a database, you may also fetch a single instance with fetchOne . If no instance is found, null is returned. var query = Query User ( context ) .. where (( u ) = u . id ). equalTo ( 1 ); User oneUser = await query . fetchOne (); Fetch queries can be limited to a number of instances with the fetchLimit property. You may also set the offset of a Query T to skip the first offset number of rows. Between fetchLimit and offset , you can implement naive paging. However, this type of paging suffers from a number of problems and so there is another paging mechanism covered in later sections.","title":"Fetching Data with a Query"},{"location":"db/executing_queries/#sorting","text":"Results of a fetch can be sorted using the sortBy method of a Query T . Here's an example: var q = Query User ( context ) .. sortBy (( u ) = u . dateCreated , QuerySortOrder . ascending ); sortBy takes two arguments: a closure that returns which property to sort by and the order of the sort. A Query T results can be sorted by multiple properties. When multiple sortBy s are invoked on a Query T , later sortBy s are used to break ties in previous sortBy s. For example, the following query will sort by last name, then by first name: var q = Query User ( context ) .. sortBy (( u ) = u . lastName , QuerySortOrder . ascending ) .. sortBy (( u ) = u . firstName , QuerySortOrder . ascending ); Thus, the following three names would be ordered like so: 'Sally Smith', 'John Wu', 'Sally Wu'.","title":"Sorting"},{"location":"db/executing_queries/#property-selectors","text":"In the section on sorting, you saw the use of a property selector to select the property of the user to sort by. This syntax is used for many other query manipulations, like filtering and joining. A property selector is a closure that gives you an object of the type you are querying and must return a property of that object. The selector (u) = u.lastName in the previous section is a property selector that selects the last name of a user. The Dart analyzer will infer that the argument of a property selector, and it is always the same type as the object being queried. This enables IDE auto-completion, static error checking, and other tools like project-wide renaming. Live Templates To speed up query building, create a Live Template in IntelliJ that generates a property selector when typing 'ps'. The source of the template is (o) = o.$END$ . A downloadable settings configuration for IntelliJ exists here that includes this shortcut.","title":"Property Selectors"},{"location":"db/executing_queries/#specifying-result-properties","text":"When executing queries that return managed objects (i.e., insert() , update() and fetch() ), the default properties for each object are fetched. The default properties of a managed object are properties that correspond to a database column - attributes declared in the table definition. A managed object's default properties can be modified when declaring its table definition: class _User { @ Column ( omitByDefault: true ) String hashedPassword ; } Any property with omitByDefault set to true will not be fetched by default. A property that is omitByDefault can still be fetched. Likewise, a property that is in the defaults can still be omitted. Each Query T has a returningProperties method to adjust which properties do get returned from the query. Its usage looks like this: var query = Query User ( context ) .. returningProperties (( user ) = [ user . id , user . name ]); returningProperties is a multiple property selector - instead of returning just one property, it returns a list of properties. You may include 'belongs-to' relationships in returningProperties , but you may not include 'has-many' or 'has-one' relationships. An exception will be thrown if you attempt to. To include properties from relationships like these, see join in Advanced Queries . Note that if you omit the primary key of a managed object from returningProperties , it will automatically be added. The primary key is necessary to transform the rows into instances of their ManagedObject T subclass.","title":"Specifying Result Properties"},{"location":"db/executing_queries/#exceptions-and-errors","text":"When executing a query, it may fail for any number of reasons: the query is invalid, a database couldn't be reached, constraints were violated, etc. In many cases, this exception originates from the underlying database driver. When thrown in a controller, these exceptions will trigger a 500 Server Error response. Exceptions that are thrown in response to user input (e.g., violating a database constraint, invalid data type) are re-interpreted into a QueryException or ValidationException . Both of these exception types have an associated Response object that is sent instead of the default 500 Server error. For this reason, you don't need to catch database query exceptions in a controller; an appropriate response will be sent on your behalf.","title":"Exceptions and Errors"},{"location":"db/executing_queries/#statement-reuse","text":"Aqueduct will parameterize and reuse queries when possible. This allows for significant speed and security improvements. Note that you do not have to do anything special to take advantage of this feature. However, currently at this time, you may not disable this feature.","title":"Statement Reuse"},{"location":"db/json_columns/","text":"JSON Document Storage Learn how to store unstructured, binary JSON data in ManagedObject T properties. JSON Columns in Relational Databases PostgreSQL supports many column data types like integers, strings, booleans and dates. A column may also be JSON data. This allows for storing unstructured data and simple objects in a table column. The data from JSON columns can be fetched all at once, or in pieces. Elements of JSON data can be used to filter the results of a query. The Document Data Type JSON document columns are added to a database table by declaring a Document property in a ManagedObject T 's table definition. In PostgreSQL, a Document column data type is jsonb . A document column can only contain JSON-encodable data. This data is typically a Map or List that contains only JSON-encodable data. The following ManagedObject T declaration will have a contents column of type jsonb . class Event extends ManagedObject _Event implements _Event {} class _Event { @ primaryKey int id ; @ Column ( indexed: true ) DateTime timestamp ; Document contents ; } A Document object has a data property to hold its JSON-encodable data. When instantiating Document , this property defaults to null unless a value has been provided to the optional, ordered parameter in its constructor. final doc = new Document (); assert ( doc . data == null ); final doc = new Document ({ key : value }); assert ( doc . data is Map ); final doc = new Document ([ 0 ]); assert ( doc . data is List ); The data in a document can be accessed through its data property, or through its subscript operator. Document 's subscript operator forwards the invocation to its data property. final doc = new Document ({ key : value }); assert ( doc [ key ] == doc . data [ key ]); The argument to the subscript operator may be a string (if data is a map) or an integer (if data is a list). Basic Operations on Document Properties Document columns are like any other type of column, and can therefore be set during an insert or update, and read during a fetch. Inserting Rows with Document Properties A Document property is first set when inserting with a Query T . The values property of the query is set to a Document object initialized with a JSON-encodable value. final query = Query Event ( context ) .. values . timestamp = DateTime . now () .. values . contents = Document ({ type : push , user : bob , tags : [ v1 ] }); final event = await query . insert (); In the above, the argument to Document will be JSON-encoded and stored in the database for column contents . If the object can't be encoded as JSON, an exception will be thrown. Fetching Rows with Document Properties When fetching an object with Document properties with a Query T , you access the column's value through the document's data property. final query = Query Event ( context ) .. where (( e ) = e . id ). equalTo ( 1 ); final event1 = await query . fetchOne (); event1 . contents . data == { type : push , user : bob , tags : [ v1 ] }; When fetching Document properties, the JSON data is decoded into the appropriate type. This is likely a Map or List , but can be any JSON-encodable object. Because the data stored in a Document property is unstructured, the type of data is dynamic . It is good practice to store consistent data structures in a column; i.e., always storing a Map or always storing a List . Updating Rows with Document Properties Updating a row with Document properties works the same as inserting rows. final query = Query Event ( context ) .. where (( e ) = e . id ). equalTo ( 1 ) .. values . contents = Document ({ type : push , user : bob , tags : [ v1 , new ] }); final event = await query . updateOne (); When updating in this way, the document stored in the column is replaced entirely. Accessing Document Values The type of Document.data is dynamic - it can be any valid JSON type and may be casted to the expected type when used. This data can also be nested - a List of Maps , for example. When accessing object keys or list indices, you may use the subscript operator directly on Document . // Object Access by key final doc = Document ({ key : value }); final value = doc [ key ] == value ; // List Access by index final doc = Document ([ v1 , v2 ]); final value = doc [ 0 ] == v1 ; You can access nested elements with the same syntax: final doc = Document ([ { id : 1 }, { id : 2 } ]); final obj1 = doc [ 0 ][ id ]; // == 1 final obj2 = doc [ 1 ][ id ]; // == 2 Note that using the subscript operator on a Document simply invokes it on its data property. Therefore, any subscript values must be valid for Dart List and Map types. Fetching Sub-documents When fetching a Document property, the default behavior is to return the entire JSON document as it is stored in the database column. You may fetch parts of the document you need by using Query.returningProperties and the subscript operator. final query = Query Event ( context ) .. returningProperties (( e ) = [ e . id , e . contents [ tags ]]); final eventsWithTags = query . fetch (); When using the subscript operator on a returned Document property, only the value for that key is returned. For example, if the above query were executed and the stored column's value were: { type : push , user : bob , tags : [ v1 ] } The value of Event.contents would only contain the array for the key \"tags\": [ v1 ] You may also index arrays in a JSON column using the same subscript operator, and the subscript operator can also be nested. For example, the following query would fetch the \"tags\" array, and then fetch the string at index 0 from it: final query = Query Event ( context ) .. returningProperties (( e ) = [ e . id , e . contents [ tags ][ 0 ]]); final eventsWithFirstTag = await query . fetchOne (); eventsWithFirstTag . contents . data == v1 ; If a key or index does not exist in the JSON document, the value of the returned property will be null. For this reason, you should use null-aware operators when accessing Document.data : final query = Query Event ( context ) .. returningProperties (( e ) = [ e . id , e . contents [ tags ][ 7 ]]); // 7 is out of bounds final eventsWithFirstTag = await query . fetchOne (); if ( eventsWithFirstTag . contents ? . data == v1 ) { ... } When fetching elements from a JSON array, you may use negative indices to specify a index from the end of the array. final query = Query Event ( context ) .. returningProperties (( e ) = [ e . id , e . contents [ tags ][ - 1 ]]); final eventsWithLastTag = await query . fetchOne (); Note that you can only fetch a single sub-structure from a Document column per query. That is, you may not do the following: // Invalid final query = Query Event ( context ) .. returningProperties (( e ) = [ e . id , e . contents [ type ], e . contents [ user ]]); For operations not supported by Query T , you may use SQL directly: final eventTagCounts = await context . persistentStore . execute ( SELECT jsonb_array_length(contents- tags ) from _Event );","title":"JSON Document Storage"},{"location":"db/json_columns/#json-document-storage","text":"Learn how to store unstructured, binary JSON data in ManagedObject T properties.","title":"JSON Document Storage"},{"location":"db/json_columns/#json-columns-in-relational-databases","text":"PostgreSQL supports many column data types like integers, strings, booleans and dates. A column may also be JSON data. This allows for storing unstructured data and simple objects in a table column. The data from JSON columns can be fetched all at once, or in pieces. Elements of JSON data can be used to filter the results of a query.","title":"JSON Columns in Relational Databases"},{"location":"db/json_columns/#the-document-data-type","text":"JSON document columns are added to a database table by declaring a Document property in a ManagedObject T 's table definition. In PostgreSQL, a Document column data type is jsonb . A document column can only contain JSON-encodable data. This data is typically a Map or List that contains only JSON-encodable data. The following ManagedObject T declaration will have a contents column of type jsonb . class Event extends ManagedObject _Event implements _Event {} class _Event { @ primaryKey int id ; @ Column ( indexed: true ) DateTime timestamp ; Document contents ; } A Document object has a data property to hold its JSON-encodable data. When instantiating Document , this property defaults to null unless a value has been provided to the optional, ordered parameter in its constructor. final doc = new Document (); assert ( doc . data == null ); final doc = new Document ({ key : value }); assert ( doc . data is Map ); final doc = new Document ([ 0 ]); assert ( doc . data is List ); The data in a document can be accessed through its data property, or through its subscript operator. Document 's subscript operator forwards the invocation to its data property. final doc = new Document ({ key : value }); assert ( doc [ key ] == doc . data [ key ]); The argument to the subscript operator may be a string (if data is a map) or an integer (if data is a list).","title":"The Document Data Type"},{"location":"db/json_columns/#basic-operations-on-document-properties","text":"Document columns are like any other type of column, and can therefore be set during an insert or update, and read during a fetch.","title":"Basic Operations on Document Properties"},{"location":"db/json_columns/#inserting-rows-with-document-properties","text":"A Document property is first set when inserting with a Query T . The values property of the query is set to a Document object initialized with a JSON-encodable value. final query = Query Event ( context ) .. values . timestamp = DateTime . now () .. values . contents = Document ({ type : push , user : bob , tags : [ v1 ] }); final event = await query . insert (); In the above, the argument to Document will be JSON-encoded and stored in the database for column contents . If the object can't be encoded as JSON, an exception will be thrown.","title":"Inserting Rows with Document Properties"},{"location":"db/json_columns/#fetching-rows-with-document-properties","text":"When fetching an object with Document properties with a Query T , you access the column's value through the document's data property. final query = Query Event ( context ) .. where (( e ) = e . id ). equalTo ( 1 ); final event1 = await query . fetchOne (); event1 . contents . data == { type : push , user : bob , tags : [ v1 ] }; When fetching Document properties, the JSON data is decoded into the appropriate type. This is likely a Map or List , but can be any JSON-encodable object. Because the data stored in a Document property is unstructured, the type of data is dynamic . It is good practice to store consistent data structures in a column; i.e., always storing a Map or always storing a List .","title":"Fetching Rows with Document Properties"},{"location":"db/json_columns/#updating-rows-with-document-properties","text":"Updating a row with Document properties works the same as inserting rows. final query = Query Event ( context ) .. where (( e ) = e . id ). equalTo ( 1 ) .. values . contents = Document ({ type : push , user : bob , tags : [ v1 , new ] }); final event = await query . updateOne (); When updating in this way, the document stored in the column is replaced entirely.","title":"Updating Rows with Document Properties"},{"location":"db/json_columns/#accessing-document-values","text":"The type of Document.data is dynamic - it can be any valid JSON type and may be casted to the expected type when used. This data can also be nested - a List of Maps , for example. When accessing object keys or list indices, you may use the subscript operator directly on Document . // Object Access by key final doc = Document ({ key : value }); final value = doc [ key ] == value ; // List Access by index final doc = Document ([ v1 , v2 ]); final value = doc [ 0 ] == v1 ; You can access nested elements with the same syntax: final doc = Document ([ { id : 1 }, { id : 2 } ]); final obj1 = doc [ 0 ][ id ]; // == 1 final obj2 = doc [ 1 ][ id ]; // == 2 Note that using the subscript operator on a Document simply invokes it on its data property. Therefore, any subscript values must be valid for Dart List and Map types.","title":"Accessing Document Values"},{"location":"db/json_columns/#fetching-sub-documents","text":"When fetching a Document property, the default behavior is to return the entire JSON document as it is stored in the database column. You may fetch parts of the document you need by using Query.returningProperties and the subscript operator. final query = Query Event ( context ) .. returningProperties (( e ) = [ e . id , e . contents [ tags ]]); final eventsWithTags = query . fetch (); When using the subscript operator on a returned Document property, only the value for that key is returned. For example, if the above query were executed and the stored column's value were: { type : push , user : bob , tags : [ v1 ] } The value of Event.contents would only contain the array for the key \"tags\": [ v1 ] You may also index arrays in a JSON column using the same subscript operator, and the subscript operator can also be nested. For example, the following query would fetch the \"tags\" array, and then fetch the string at index 0 from it: final query = Query Event ( context ) .. returningProperties (( e ) = [ e . id , e . contents [ tags ][ 0 ]]); final eventsWithFirstTag = await query . fetchOne (); eventsWithFirstTag . contents . data == v1 ; If a key or index does not exist in the JSON document, the value of the returned property will be null. For this reason, you should use null-aware operators when accessing Document.data : final query = Query Event ( context ) .. returningProperties (( e ) = [ e . id , e . contents [ tags ][ 7 ]]); // 7 is out of bounds final eventsWithFirstTag = await query . fetchOne (); if ( eventsWithFirstTag . contents ? . data == v1 ) { ... } When fetching elements from a JSON array, you may use negative indices to specify a index from the end of the array. final query = Query Event ( context ) .. returningProperties (( e ) = [ e . id , e . contents [ tags ][ - 1 ]]); final eventsWithLastTag = await query . fetchOne (); Note that you can only fetch a single sub-structure from a Document column per query. That is, you may not do the following: // Invalid final query = Query Event ( context ) .. returningProperties (( e ) = [ e . id , e . contents [ type ], e . contents [ user ]]); For operations not supported by Query T , you may use SQL directly: final eventTagCounts = await context . persistentStore . execute ( SELECT jsonb_array_length(contents- tags ) from _Event );","title":"Fetching Sub-documents"},{"location":"db/modeling_data/","text":"Modeling Data In this guide, you will learn how to create ManagedObject T subclasses that can be stored in and retrieved from a database. Defining a Table In your application, you define types whose instances can be stored in a database. Each type you create for this purpose corresponds to a database table. The properties of these types are columns of the corresponding table. Instances of these types represent a row in that table. For example, consider a Article type. When you create articles and store them in a database, they are inserted into an 'article' table. That table has a column to store the properties of the article, like its category and contents. Each individual article is a row in this table. A type that can be stored in a database is created by declaring two classes. The first class is a table definition . A table definition is a plain Dart type that represents a table in the database. Each property of a table definition type is a column in that database. These properties often have annotations to further define the behavior of the column. An example looks like this: // This is a table definition of an article class _Article { @ primaryKey int id ; String contents ; @ Column ( indexed: true ) String category ; } This class declares a table named _Article with three columns: id : an integer column that is the primary key of the table contents : a text column category : a text column that has an index so that it can more efficiently be searched A property's type determines the type of column in the table. Dart Type General Column Type PostgreSQL Column Type int integer number INT or SERIAL double floating point number DOUBLE PRECISION String text TEXT DateTime timestamp TIMESTAMP bool boolean BOOLEAN Document a JSON object or array JSONB Any enum text, restricted to enum cases TEXT Some types can be represented by many database types; for example, an integer can be stored as 2, 4 or 8 bytes. The Column annotation can be applied to a table definition's property to further specify the type. This same annotation allows for the customization of indices, uniqueness and other column behavior. Available options are optional arguments to the Column constructor and shown in the following table: Option Type Behavior Default primaryKey bool sets primary key column false (not primary key) databaseType ManagedPropertyType sets underlying column type inferred from Dart type nullable bool toggles whether column can be null false (not nullable) unique bool toggles whether column is unique across all rows false (not unique) defaultValue String provides default value for new rows when value is undefined null indexed bool whether an index should be created for the column false (no index) omitByDefault bool whether this column should be fetched by default true (fetch column value) autoincrement bool whether this column's value is automatically generated from a series false (not generated) Exactly one property per table definition must have a Column annotation with the 'primary key' option. That property's column is the primary key of the database table. It is common for primary keys to be 64-bit, auto-incrementing integers; therefore, the primaryKey constant exists as a convenience for a Column with these options. The _Article type from above is equivalent to: // This is a table definition of an article class _Article { @ Column ( primaryKey: true , databaseType: ManagedPropertyType . bigInteger , autoincrement: true ) int id ; String contents ; @ Column ( indexed: true ) String category ; } Creating Tables Tables are created in a database by using the aqueduct command line tool to generate and execute migration scripts. The tool inspects your database types and automatically synchronizes a databases schema to match your them. The ORM assumes that a database table has the same name as a table definition, i.e. the _Article table definition instructs the ORM that there is a table named _Article . You may provide another name for the table by implementing a static tableName method in your table definition to return this name: class _Article { static String tableName () = ArticleTable ; @ primaryKey int id ; String contents ; @ Column ( indexed: true ) String category ; } Defining an Instance Type Alongside the table definition, you must create an instance type . An instance type is used in your application code. It must be a subclass of ManagedObject T and implement T , where T is your table definition. The instance type for _Article is declared like so: class Article extends ManagedObject _Article implements _Article {} This Article instance type inherits all of the properties from the _Article table definition; i.e., an Article has an id , contents and category . You create instances of an instance type like any other type. final article = new Article (); article . id = 1 ; article . category = Baseball ; When you fetch rows from a database, you will be returned instances of your instance type that are automatically created for you by the ORM. Instance Type Constructors You can add new constructors to an instance type, but you must always have a default, no-argument constructor that properly instantiates your object. This default constructor is used when the ORM creates instances from rows in your database. Transient Properties An instance type can declare additional properties and methods. Any property declared in the instance type is not stored in the database, and are often used for computed or derived values for an object. Properties declared on the instance type are called transient properties . For example, consider an Author type whose table definition stores first and last name as separate columns. Instead of redundantly storing a 'full name' in the database, a transient property can be derived from properties stored in the database: class Author extends ManagedObject _Author implements _Author { String get name = $ firstName $ lastName ; set name ( String fullName ) { firstName = fullName . split ( ). first ; lastName = fullName . split ( ). last ; } } class _Author { @ primaryKey int id ; String firstName ; String lastName ; } Transient properties don't necessarily have to access columns of the underlying table, but note that if an object has a transient property, that value is not available on another object that represents the same row. By default, a transient property is ignored when reading an object from a request body or writing the object to a response body. You can annotate a transient property with Serialize so that it is able to be read from a request body, written to a response body, or both. The following allows name to be both read and written over HTTP: class Author extends ManagedObject _Author implements _Author { @ Serialize () String get name = $ firstName $ lastName ; @ Serialize () set name ( String fullName ) { firstName = fullName . split ( ). first ; lastName = fullName . split ( ). last ; } } Project Structure The combination of an instance type and its table definition is called an entity . Each entity should be declared in the same file, and the table definition should be prefixed with an _ to prevent it from being used elsewhere in the project. It is preferable to declare one entity per file, and store all entities in the lib/model/ directory of your project. The files your model definitions are declared in must be visible to Aqueduct tooling. In normal circumstances, this happens automatically because of the following: Aqueduct tooling can find any file that is imported (directly or transitively) from your library file. Your library file, by default, can see the file your ApplicationChannel is declared in. Your application channel file must import any controller that it links. Your controllers must import any model file they use. When you use the aqueduct CLI to generate database migration scripts, it will report all of the ManagedObject s in your application that it was able to find. If a particular type is not listed, it may reveal that you aren't using that type. If you need to ensure that the tooling can see a particular model file that it is not locating, you may import it in your channel.dart file. Modeling Relationships So far, we've shown that table definitions can declare scalar properties like integers and strings, and that those properties are backed by a column in a database table. These types of properties are called attributes . Table definitions may also contain relationship properties that are references to another entity in your application. For example, an Author can have a property that holds all of the Article s they have written. There are two types of relationships: has-many and has-one . A has-one relationship restricts a relationship to a single object (e.g., an author may have one article), whereas a has-many relationship allows for any number of related objects (e.g., an author has multiple articles). Relationship properties are also declared in a table definition. The type of the property must either be a ManagedSet T or a T , where T is another instance type. If the type is ManagedSet T , the relationship is a has-many relationship, otherwise, it is a has-one relationship. The following shows an articles relationship that allows an author to have many Article s: class _Author { @ primaryKey int id ; String name ; // a has-many relationship to Article ManagedSet Article articles ; // If we were declaring a has-one relationship: // Article article; } A ManagedSet is a special type of List used in the Aqueduct ORM. It can do everything a list can do, but adds some additional behavior for the ORM. All relationships must have an inverse. For example, if an author has articles, an article must have an author. This is true regardless of whether or not the relationship is has-many or has-one. An inverse is declared in the related table definition with a Relate annotation: class _Article { @ primaryKey int id ; @ Relate ( # articles ) Author author ; ... } A relationship property with this annotation is neither has-one or has-many; it belongs to the related entity. The argument to Relate is the symbolic name of the property on the 'has' side of the relationship. In our examples, an author has many articles, and an article belongs to an author. Symbols A symbol is a name identifier in Dart; a symbol can refer to a class, method, or property. Symbols are objects can be instantiated like all objects, but the # identifier is shorthand for creating a symbol. Only one side of a relationship may have the Relate annotation on its relationship property. The property with this annotation is a foreign key column on the table definition it is defined in. In this example, the _Article table has a foreign key reference to the id of the _Author table. Choosing which side of the relationship has the Relate annotation depends on how you wish to model your data. In has-many relationships, this is easy - a ManagedSet T may not have the Relate annotation. In a has-one relationship, you must determine which side of the relationship should have the foreign key reference. When making this decision, it is important to understand how objects are fetched with Query s. In a default query, the objects that are returned will contain 'null' for every 'has' relationship, and only contain the foreign key of any 'belongs to' relationships. To fetch a related object in its entirety, you must use Query.join . Foreign Keys The foreign key column always references the primary key of the related table, and its name is derived by combining the name of the relationship property and the primary key of the related table. For example, the above definitions would add a column named author_id to the _Article table. The Relate annotation has optional arguments to further define the relationship. A relationship may be be required or optional. For example, if Article.author were required, than an Article must always have an Author . By default, relationships are optional. A relationship has a delete rule. When an object is deleted, any objects that belong to its relationships are subject to this rule. The following table shows the rules and their behavior: Rule Behavior Example nullify (default) inverse is set to null When deleting an author, its articles' author becomes null cascade related objects are also deleted When deleting an author, its articles are deleted restrict delete fails When attempting to delete an author with articles, the delete operation fails default inverse set to a default value When deleting an author, its articles author is set to the default value of the column Additional Data Modeling This section covers additional features when defining your data model. Enum Types When a table definition property is an enum type, the enumeration is stored as a string in the database. Consider the following definition where a user can be an admin or a normal user: enum UserType { admin , user } class User extends ManagedObject _User implements _User {} class _User { @ primaryKey int id ; String name ; UserType type ; } You may assign valid enumeration cases to the User.type property: var query = Query User ( context ) .. values . name = Bob .. values . type = UserType . admin ; var bob = await query . insert (); query = Query User ( context ) .. where (( u ) = u . type ). equalTo ( UserType . admin ); var allAdmins = await query . fetch (); In the database, the type column is stored as a string. Its value is either \"admin\" or \"user\" - which is derived from the two enumeration case names. A enumerated type property has an implicit Validate.oneOf validator that asserts the value is one of the valid enumeration cases. Private Variables A property of a table definition that is Dart private (prefixed with an _ ) will not be included when writing a ManagedObject T to an HTTP response. It also may not be read from an HTTP request body. This behavior differs slightly from the omitByDefault flag of Column . When omitting by default, the value is simply not fetched from the database. When a property is private, it is fetched, but it is just not accessible from outside the object. This can be useful when combined with transient accessors. For example, the following ensures that the title property is uppercased before storage: class User extends ManagedObject _User implements _User { @ Serialize () set title ( String title ) { _title = title . toUpperCase (); } @ Serialize () String get title = _title ; } class _User { String _title ; ... }","title":"Modeling Data"},{"location":"db/modeling_data/#modeling-data","text":"In this guide, you will learn how to create ManagedObject T subclasses that can be stored in and retrieved from a database.","title":"Modeling Data"},{"location":"db/modeling_data/#defining-a-table","text":"In your application, you define types whose instances can be stored in a database. Each type you create for this purpose corresponds to a database table. The properties of these types are columns of the corresponding table. Instances of these types represent a row in that table. For example, consider a Article type. When you create articles and store them in a database, they are inserted into an 'article' table. That table has a column to store the properties of the article, like its category and contents. Each individual article is a row in this table. A type that can be stored in a database is created by declaring two classes. The first class is a table definition . A table definition is a plain Dart type that represents a table in the database. Each property of a table definition type is a column in that database. These properties often have annotations to further define the behavior of the column. An example looks like this: // This is a table definition of an article class _Article { @ primaryKey int id ; String contents ; @ Column ( indexed: true ) String category ; } This class declares a table named _Article with three columns: id : an integer column that is the primary key of the table contents : a text column category : a text column that has an index so that it can more efficiently be searched A property's type determines the type of column in the table. Dart Type General Column Type PostgreSQL Column Type int integer number INT or SERIAL double floating point number DOUBLE PRECISION String text TEXT DateTime timestamp TIMESTAMP bool boolean BOOLEAN Document a JSON object or array JSONB Any enum text, restricted to enum cases TEXT Some types can be represented by many database types; for example, an integer can be stored as 2, 4 or 8 bytes. The Column annotation can be applied to a table definition's property to further specify the type. This same annotation allows for the customization of indices, uniqueness and other column behavior. Available options are optional arguments to the Column constructor and shown in the following table: Option Type Behavior Default primaryKey bool sets primary key column false (not primary key) databaseType ManagedPropertyType sets underlying column type inferred from Dart type nullable bool toggles whether column can be null false (not nullable) unique bool toggles whether column is unique across all rows false (not unique) defaultValue String provides default value for new rows when value is undefined null indexed bool whether an index should be created for the column false (no index) omitByDefault bool whether this column should be fetched by default true (fetch column value) autoincrement bool whether this column's value is automatically generated from a series false (not generated) Exactly one property per table definition must have a Column annotation with the 'primary key' option. That property's column is the primary key of the database table. It is common for primary keys to be 64-bit, auto-incrementing integers; therefore, the primaryKey constant exists as a convenience for a Column with these options. The _Article type from above is equivalent to: // This is a table definition of an article class _Article { @ Column ( primaryKey: true , databaseType: ManagedPropertyType . bigInteger , autoincrement: true ) int id ; String contents ; @ Column ( indexed: true ) String category ; } Creating Tables Tables are created in a database by using the aqueduct command line tool to generate and execute migration scripts. The tool inspects your database types and automatically synchronizes a databases schema to match your them. The ORM assumes that a database table has the same name as a table definition, i.e. the _Article table definition instructs the ORM that there is a table named _Article . You may provide another name for the table by implementing a static tableName method in your table definition to return this name: class _Article { static String tableName () = ArticleTable ; @ primaryKey int id ; String contents ; @ Column ( indexed: true ) String category ; }","title":"Defining a Table"},{"location":"db/modeling_data/#defining-an-instance-type","text":"Alongside the table definition, you must create an instance type . An instance type is used in your application code. It must be a subclass of ManagedObject T and implement T , where T is your table definition. The instance type for _Article is declared like so: class Article extends ManagedObject _Article implements _Article {} This Article instance type inherits all of the properties from the _Article table definition; i.e., an Article has an id , contents and category . You create instances of an instance type like any other type. final article = new Article (); article . id = 1 ; article . category = Baseball ; When you fetch rows from a database, you will be returned instances of your instance type that are automatically created for you by the ORM. Instance Type Constructors You can add new constructors to an instance type, but you must always have a default, no-argument constructor that properly instantiates your object. This default constructor is used when the ORM creates instances from rows in your database.","title":"Defining an Instance Type"},{"location":"db/modeling_data/#transient-properties","text":"An instance type can declare additional properties and methods. Any property declared in the instance type is not stored in the database, and are often used for computed or derived values for an object. Properties declared on the instance type are called transient properties . For example, consider an Author type whose table definition stores first and last name as separate columns. Instead of redundantly storing a 'full name' in the database, a transient property can be derived from properties stored in the database: class Author extends ManagedObject _Author implements _Author { String get name = $ firstName $ lastName ; set name ( String fullName ) { firstName = fullName . split ( ). first ; lastName = fullName . split ( ). last ; } } class _Author { @ primaryKey int id ; String firstName ; String lastName ; } Transient properties don't necessarily have to access columns of the underlying table, but note that if an object has a transient property, that value is not available on another object that represents the same row. By default, a transient property is ignored when reading an object from a request body or writing the object to a response body. You can annotate a transient property with Serialize so that it is able to be read from a request body, written to a response body, or both. The following allows name to be both read and written over HTTP: class Author extends ManagedObject _Author implements _Author { @ Serialize () String get name = $ firstName $ lastName ; @ Serialize () set name ( String fullName ) { firstName = fullName . split ( ). first ; lastName = fullName . split ( ). last ; } }","title":"Transient Properties"},{"location":"db/modeling_data/#project-structure","text":"The combination of an instance type and its table definition is called an entity . Each entity should be declared in the same file, and the table definition should be prefixed with an _ to prevent it from being used elsewhere in the project. It is preferable to declare one entity per file, and store all entities in the lib/model/ directory of your project. The files your model definitions are declared in must be visible to Aqueduct tooling. In normal circumstances, this happens automatically because of the following: Aqueduct tooling can find any file that is imported (directly or transitively) from your library file. Your library file, by default, can see the file your ApplicationChannel is declared in. Your application channel file must import any controller that it links. Your controllers must import any model file they use. When you use the aqueduct CLI to generate database migration scripts, it will report all of the ManagedObject s in your application that it was able to find. If a particular type is not listed, it may reveal that you aren't using that type. If you need to ensure that the tooling can see a particular model file that it is not locating, you may import it in your channel.dart file.","title":"Project Structure"},{"location":"db/modeling_data/#modeling-relationships","text":"So far, we've shown that table definitions can declare scalar properties like integers and strings, and that those properties are backed by a column in a database table. These types of properties are called attributes . Table definitions may also contain relationship properties that are references to another entity in your application. For example, an Author can have a property that holds all of the Article s they have written. There are two types of relationships: has-many and has-one . A has-one relationship restricts a relationship to a single object (e.g., an author may have one article), whereas a has-many relationship allows for any number of related objects (e.g., an author has multiple articles). Relationship properties are also declared in a table definition. The type of the property must either be a ManagedSet T or a T , where T is another instance type. If the type is ManagedSet T , the relationship is a has-many relationship, otherwise, it is a has-one relationship. The following shows an articles relationship that allows an author to have many Article s: class _Author { @ primaryKey int id ; String name ; // a has-many relationship to Article ManagedSet Article articles ; // If we were declaring a has-one relationship: // Article article; } A ManagedSet is a special type of List used in the Aqueduct ORM. It can do everything a list can do, but adds some additional behavior for the ORM. All relationships must have an inverse. For example, if an author has articles, an article must have an author. This is true regardless of whether or not the relationship is has-many or has-one. An inverse is declared in the related table definition with a Relate annotation: class _Article { @ primaryKey int id ; @ Relate ( # articles ) Author author ; ... } A relationship property with this annotation is neither has-one or has-many; it belongs to the related entity. The argument to Relate is the symbolic name of the property on the 'has' side of the relationship. In our examples, an author has many articles, and an article belongs to an author. Symbols A symbol is a name identifier in Dart; a symbol can refer to a class, method, or property. Symbols are objects can be instantiated like all objects, but the # identifier is shorthand for creating a symbol. Only one side of a relationship may have the Relate annotation on its relationship property. The property with this annotation is a foreign key column on the table definition it is defined in. In this example, the _Article table has a foreign key reference to the id of the _Author table. Choosing which side of the relationship has the Relate annotation depends on how you wish to model your data. In has-many relationships, this is easy - a ManagedSet T may not have the Relate annotation. In a has-one relationship, you must determine which side of the relationship should have the foreign key reference. When making this decision, it is important to understand how objects are fetched with Query s. In a default query, the objects that are returned will contain 'null' for every 'has' relationship, and only contain the foreign key of any 'belongs to' relationships. To fetch a related object in its entirety, you must use Query.join . Foreign Keys The foreign key column always references the primary key of the related table, and its name is derived by combining the name of the relationship property and the primary key of the related table. For example, the above definitions would add a column named author_id to the _Article table. The Relate annotation has optional arguments to further define the relationship. A relationship may be be required or optional. For example, if Article.author were required, than an Article must always have an Author . By default, relationships are optional. A relationship has a delete rule. When an object is deleted, any objects that belong to its relationships are subject to this rule. The following table shows the rules and their behavior: Rule Behavior Example nullify (default) inverse is set to null When deleting an author, its articles' author becomes null cascade related objects are also deleted When deleting an author, its articles are deleted restrict delete fails When attempting to delete an author with articles, the delete operation fails default inverse set to a default value When deleting an author, its articles author is set to the default value of the column","title":"Modeling Relationships"},{"location":"db/modeling_data/#additional-data-modeling","text":"This section covers additional features when defining your data model.","title":"Additional Data Modeling"},{"location":"db/modeling_data/#enum-types","text":"When a table definition property is an enum type, the enumeration is stored as a string in the database. Consider the following definition where a user can be an admin or a normal user: enum UserType { admin , user } class User extends ManagedObject _User implements _User {} class _User { @ primaryKey int id ; String name ; UserType type ; } You may assign valid enumeration cases to the User.type property: var query = Query User ( context ) .. values . name = Bob .. values . type = UserType . admin ; var bob = await query . insert (); query = Query User ( context ) .. where (( u ) = u . type ). equalTo ( UserType . admin ); var allAdmins = await query . fetch (); In the database, the type column is stored as a string. Its value is either \"admin\" or \"user\" - which is derived from the two enumeration case names. A enumerated type property has an implicit Validate.oneOf validator that asserts the value is one of the valid enumeration cases.","title":"Enum Types"},{"location":"db/modeling_data/#private-variables","text":"A property of a table definition that is Dart private (prefixed with an _ ) will not be included when writing a ManagedObject T to an HTTP response. It also may not be read from an HTTP request body. This behavior differs slightly from the omitByDefault flag of Column . When omitting by default, the value is simply not fetched from the database. When a property is private, it is fetched, but it is just not accessible from outside the object. This can be useful when combined with transient accessors. For example, the following ensures that the title property is uppercased before storage: class User extends ManagedObject _User implements _User { @ Serialize () set title ( String title ) { _title = title . toUpperCase (); } @ Serialize () String get title = _title ; } class _User { String _title ; ... }","title":"Private Variables"},{"location":"db/serialization/","text":"Storage, Serialization and Deserialization In the previous chapter, you have seen that ManagedObject T s subclasses are responsible for representing database rows and can be encoded to or decoded from formats like JSON or XML. This chapter explains the behavior of those transformations. ManagedObject T implements Serializable so that they can read from a Map or converted to a Map . A ManagedObject T can be passed as the body object of a Response and bound to Bind.body variables in ResourceController : class UserController extends ResourceController { @ Operation . post () Future Response createUser ( @ Bind . body () User user ) async { var query = Query User ( context ) .. values = user ; return Response . ok ( await query . insert ()); } } Note that ManagedObject T s don't have anything to do with JSON, XML or some other format here. Other parts of Aqueduct manage moving data back and forth between JSON and Map s - ManagedObject T doesn't care about the transmission format as long as its a Map or List Map . Null Behavior It's important to understand how null works when reading from or writing to a Map with a ManagedObject T . Consider the following managed object: class User extends ManagedObject _User implements _User {} class _User { @ primaryKey int id ; String name ; } User has two properties, id and name . If we read a User from a Map that does not contain an id key, its id will be null. If we convert User to a Map , the key id will not be present: var userMap = { name : Bob }; var user = User ().. readFromMap ( userMap ); user . id == null ; // yup user . name == Bob ; // yup var outUserMap = user . asMap (); outUserMap == { name : Bob }; However, if we read User from a Map where the id key is the value null, when we transform it back to a Map the id is present and its value is null: var userMap = { id : null name : Bob }; var user = User ().. readFromMap ( userMap ); user . id == null ; // yup user . name == Bob ; // yup var outUserMap = user . asMap (); outUserMap == { id : null name : Bob }; A ManagedObject T like User makes the distinction between a value that is null and a value that it doesn't have enough information for . A property of a ManagedObject T can get set in three ways: it is read from a map, its setter is invoked or it is read from the database. In all three of these situations, not every property is available. This is no more obvious than when creating a brand new instance: var user = User (); user . id == null ; // yup user . name == null ; // yup user . asMap () == {}; // yup A ManagedObject T will not include keys in its asMap() if it doesn't have a value for them. The value may exist somewhere else - like in the database - but if it doesn't have it, it won't include it. This distinction is useful information for clients of Aqueduct applications. So what about values that are actually null ? A property with the value null will be included in asMap() if its been read from the database, read using readFromMap() or explicitly assigned with a setter. The following three user objects will all have {\"name\": null} : var user1 = User () .. id = 1 .. name = null ; var user2 = User ().. readFromMap ({ id : 2 name : null }); var query = Query User ( context ) .. where (( u ) = u . id ). equalTo ( 3 ) .. where (( u ) = u . name ). isNull (); var user3 = await query . fetchOne (); Note that an unset value that is returned from a getter will be null . If using an object's values to perform some calculation, it's your job to know if the value has been fetched or not. (While ManagedObject T .hasValueForProperty() checks this at runtime, that isn't a good practice.) One last thing to note: if you wish to remove a value from a ManagedObject T s storage (and likewise, its asMap() ), you must use ManagedObject T .removePropertyFromBackingMap() . It is helpful to think of a ManagedObject T as a proxy to a database row that may or may not exist yet, and may have less data than actually exists in the database row. Transient Properties and Serialization/Deserialization By default, transient properties and getters - those declared in the subclass of ManagedObject T - are not included in the asMap() . (Setters are obviously not included, as you can't get a value from them.) To include a transient property or getter in asMap() , you may mark it with @Serialize() metadata. Properties marked with this metadata will be included in asMap() if and only if they are not null. A good reason to use this feature is when you want to provide a value to the consumer of the API that is derived from persistent properties: class User extends ManagedObject _User implements _User { @ Serialize () String get fullName = $ firstName $ lastName ; } class _User { String firstName ; String lastName ; ... } var user = User () .. firstName = Bob .. lastName = Boberson ; var map = user . asMap (); map == { firstName : Bob , lastName : Boberson , fullName : Bob Boberson }; Transient properties with this annotation may also be used as inputs when reading with readFromMap() . For example, consider how to handle user passwords. A password is not stored in plain-text in a database, but they are sent in requests. Thus, a password could read from a request body, but it needs to be salted, hashed and stored in two columns in the database. An instance type could then define a password property, which automatically set the salt and hash of the password in the table definition: class User extends ManagedObject _User implements _User { @ Serialize () void set password ( String pw ) { salt = generateSalt (); hashedPassword = hash ( pw , salt ); } } class _User { String salt ; String hashedPassword ; ... } var map = { password : mypassword }; var user = User ().. readFromMap ( map ); var salt = user . salt ; // somerandomstring var hashedPassword = user . hashedPassword ; // somehashedstring var password = user . password ; // Analyzer error - user.password doesn t exist! A transient property can also be used only when reading or only when writing. class User extends ManagedObject _User implements _User { @ Serialize ( input: true , output: false ) String readable ; // Can be readFromMap, but not emitted in asMap @ Serialize ( input: false , output: true ) String writable ; // Is emitted in asMap, but cannot be readFromMap. } Also, a separate getter and setter may exist for the same name to allow both input and output: class User extends ManagedObject _User implements _User { @ Serialize () void set transientValue ( String s ) { ... } @ Serialize () String get transientValue = ...; } On a related note, persistent properties are always included in asMap() by default, but can be omitted by adding Column metadata with the omitByDefault option: class _User { @ Column ( omitByDefault: true ) String salt ; @ Column ( omitByDefault: true ) String hashedPassword ; ... } Serialization and Deserialization of Relationship Properties Relationship properties - references to other ManagedObject T subclasses - can also be included in asMap() and read from readFromMap() . Relationship properties are populated when using Query.join - aka, a SQL JOIN. If a relationship property has been set or read from the database, its asMap() will contain the nested Map produced by the related objects asMap() . For example, recall the User with a job : var job = Job () .. title = Programmer ; var user = User () .. name = Bob .. job = job ; var userMap = user . asMap (); userMap == { id : 1 , name : Bob , job : { id : 1 title : Programmer } }; // yup Notice that the names of the keys - including relationship properties and properties of the related object - all match the names of their declared properties. It's important to note that \"belongs to\" relationships - those with Relate metadata - are always returned in asMap() when fetching an object from the database. However, the full object is not returned - only its primary key. Therefore, you will get the following result: var jobQuery = Query Job ( context ); var job = await jobQuery . fetchOne (); job . asMap () == { id : 1 , title : Programmer , user : { id : 1 } }; // yup This behavior might be different than some ORMs, which may collapse the user into a scalar user_id : job . asMap () == { id : 1 , title : Programmer , user_id : 1 }; // nope Aqueduct treats relationships consistently and chooses not to expose any of the underlying database details to the API consumer. An iOS app, for example, shouldn't care - a relationship could be maintained by foreign key references or by witchcraft. The interesting piece to the API consumer is that job's have a user, and user's have a job. \"Has-many\" relationships, which are represented as ManagedSet T s, are written as List Map s in asMap() . var user = User () .. id = 1 ; .. posts = ManagedSet . from ([ Post ().. id = 2 , Post ().. id = 3 ]); var userMap = user . asMap (); userMap == { id : 1 , posts : [ { id : 2 }, { id : 3 } ] }; It is important to note the potential for cyclic object graphs. Since all relationship properties are two-sided, the two properties in that relationship are references to one another. That is, you could do something like this: identical ( user . profile . user , user ); identical ( user . posts . first . user , user ); When fetching objects from a database, this won't happen - Aqueduct will create multiple instances of the same row when necessary to avoid this. Therefore, the previous code snippet would not be true, but the following two statements that check the values inside those objects would be: user.profile.user.id == user.id; user.posts.first.user.id == user.id While managed objects from a database will not have cyclic references, managed objects you instantiate yourself can if you mistakenly do so. When you invoke asMap() on a cyclic graph, you'll get a stack overflow error. It's best to avoid creating cyclic graphs altogether. For example: // do: var user = User (); posts . forEach (( p ) { p . user = User ().. id = user . id ; }); // do not: var user = User (); posts . forEach (( p ) { p . user = user ; }); When reading the values of a ManagedObject T with readFromMap() , relationship properties must also be represented as nested Map s or List Map . Thus: var userMap = { id : 1 , name : Bob , posts : [ { id : 1 , text : hello } ] }; var user = User ().. readFromMap ( userMap ); user . posts == ManagedSet Post [ Post () .. id = 1 .. text = hello ]; // yup, other Post doesn t implement == to check property equality","title":"Storage, Serialization and Deserialization"},{"location":"db/serialization/#storage-serialization-and-deserialization","text":"In the previous chapter, you have seen that ManagedObject T s subclasses are responsible for representing database rows and can be encoded to or decoded from formats like JSON or XML. This chapter explains the behavior of those transformations. ManagedObject T implements Serializable so that they can read from a Map or converted to a Map . A ManagedObject T can be passed as the body object of a Response and bound to Bind.body variables in ResourceController : class UserController extends ResourceController { @ Operation . post () Future Response createUser ( @ Bind . body () User user ) async { var query = Query User ( context ) .. values = user ; return Response . ok ( await query . insert ()); } } Note that ManagedObject T s don't have anything to do with JSON, XML or some other format here. Other parts of Aqueduct manage moving data back and forth between JSON and Map s - ManagedObject T doesn't care about the transmission format as long as its a Map or List Map .","title":"Storage, Serialization and Deserialization"},{"location":"db/serialization/#null-behavior","text":"It's important to understand how null works when reading from or writing to a Map with a ManagedObject T . Consider the following managed object: class User extends ManagedObject _User implements _User {} class _User { @ primaryKey int id ; String name ; } User has two properties, id and name . If we read a User from a Map that does not contain an id key, its id will be null. If we convert User to a Map , the key id will not be present: var userMap = { name : Bob }; var user = User ().. readFromMap ( userMap ); user . id == null ; // yup user . name == Bob ; // yup var outUserMap = user . asMap (); outUserMap == { name : Bob }; However, if we read User from a Map where the id key is the value null, when we transform it back to a Map the id is present and its value is null: var userMap = { id : null name : Bob }; var user = User ().. readFromMap ( userMap ); user . id == null ; // yup user . name == Bob ; // yup var outUserMap = user . asMap (); outUserMap == { id : null name : Bob }; A ManagedObject T like User makes the distinction between a value that is null and a value that it doesn't have enough information for . A property of a ManagedObject T can get set in three ways: it is read from a map, its setter is invoked or it is read from the database. In all three of these situations, not every property is available. This is no more obvious than when creating a brand new instance: var user = User (); user . id == null ; // yup user . name == null ; // yup user . asMap () == {}; // yup A ManagedObject T will not include keys in its asMap() if it doesn't have a value for them. The value may exist somewhere else - like in the database - but if it doesn't have it, it won't include it. This distinction is useful information for clients of Aqueduct applications. So what about values that are actually null ? A property with the value null will be included in asMap() if its been read from the database, read using readFromMap() or explicitly assigned with a setter. The following three user objects will all have {\"name\": null} : var user1 = User () .. id = 1 .. name = null ; var user2 = User ().. readFromMap ({ id : 2 name : null }); var query = Query User ( context ) .. where (( u ) = u . id ). equalTo ( 3 ) .. where (( u ) = u . name ). isNull (); var user3 = await query . fetchOne (); Note that an unset value that is returned from a getter will be null . If using an object's values to perform some calculation, it's your job to know if the value has been fetched or not. (While ManagedObject T .hasValueForProperty() checks this at runtime, that isn't a good practice.) One last thing to note: if you wish to remove a value from a ManagedObject T s storage (and likewise, its asMap() ), you must use ManagedObject T .removePropertyFromBackingMap() . It is helpful to think of a ManagedObject T as a proxy to a database row that may or may not exist yet, and may have less data than actually exists in the database row.","title":"Null Behavior"},{"location":"db/serialization/#transient-properties-and-serializationdeserialization","text":"By default, transient properties and getters - those declared in the subclass of ManagedObject T - are not included in the asMap() . (Setters are obviously not included, as you can't get a value from them.) To include a transient property or getter in asMap() , you may mark it with @Serialize() metadata. Properties marked with this metadata will be included in asMap() if and only if they are not null. A good reason to use this feature is when you want to provide a value to the consumer of the API that is derived from persistent properties: class User extends ManagedObject _User implements _User { @ Serialize () String get fullName = $ firstName $ lastName ; } class _User { String firstName ; String lastName ; ... } var user = User () .. firstName = Bob .. lastName = Boberson ; var map = user . asMap (); map == { firstName : Bob , lastName : Boberson , fullName : Bob Boberson }; Transient properties with this annotation may also be used as inputs when reading with readFromMap() . For example, consider how to handle user passwords. A password is not stored in plain-text in a database, but they are sent in requests. Thus, a password could read from a request body, but it needs to be salted, hashed and stored in two columns in the database. An instance type could then define a password property, which automatically set the salt and hash of the password in the table definition: class User extends ManagedObject _User implements _User { @ Serialize () void set password ( String pw ) { salt = generateSalt (); hashedPassword = hash ( pw , salt ); } } class _User { String salt ; String hashedPassword ; ... } var map = { password : mypassword }; var user = User ().. readFromMap ( map ); var salt = user . salt ; // somerandomstring var hashedPassword = user . hashedPassword ; // somehashedstring var password = user . password ; // Analyzer error - user.password doesn t exist! A transient property can also be used only when reading or only when writing. class User extends ManagedObject _User implements _User { @ Serialize ( input: true , output: false ) String readable ; // Can be readFromMap, but not emitted in asMap @ Serialize ( input: false , output: true ) String writable ; // Is emitted in asMap, but cannot be readFromMap. } Also, a separate getter and setter may exist for the same name to allow both input and output: class User extends ManagedObject _User implements _User { @ Serialize () void set transientValue ( String s ) { ... } @ Serialize () String get transientValue = ...; } On a related note, persistent properties are always included in asMap() by default, but can be omitted by adding Column metadata with the omitByDefault option: class _User { @ Column ( omitByDefault: true ) String salt ; @ Column ( omitByDefault: true ) String hashedPassword ; ... }","title":"Transient Properties and Serialization/Deserialization"},{"location":"db/serialization/#serialization-and-deserialization-of-relationship-properties","text":"Relationship properties - references to other ManagedObject T subclasses - can also be included in asMap() and read from readFromMap() . Relationship properties are populated when using Query.join - aka, a SQL JOIN. If a relationship property has been set or read from the database, its asMap() will contain the nested Map produced by the related objects asMap() . For example, recall the User with a job : var job = Job () .. title = Programmer ; var user = User () .. name = Bob .. job = job ; var userMap = user . asMap (); userMap == { id : 1 , name : Bob , job : { id : 1 title : Programmer } }; // yup Notice that the names of the keys - including relationship properties and properties of the related object - all match the names of their declared properties. It's important to note that \"belongs to\" relationships - those with Relate metadata - are always returned in asMap() when fetching an object from the database. However, the full object is not returned - only its primary key. Therefore, you will get the following result: var jobQuery = Query Job ( context ); var job = await jobQuery . fetchOne (); job . asMap () == { id : 1 , title : Programmer , user : { id : 1 } }; // yup This behavior might be different than some ORMs, which may collapse the user into a scalar user_id : job . asMap () == { id : 1 , title : Programmer , user_id : 1 }; // nope Aqueduct treats relationships consistently and chooses not to expose any of the underlying database details to the API consumer. An iOS app, for example, shouldn't care - a relationship could be maintained by foreign key references or by witchcraft. The interesting piece to the API consumer is that job's have a user, and user's have a job. \"Has-many\" relationships, which are represented as ManagedSet T s, are written as List Map s in asMap() . var user = User () .. id = 1 ; .. posts = ManagedSet . from ([ Post ().. id = 2 , Post ().. id = 3 ]); var userMap = user . asMap (); userMap == { id : 1 , posts : [ { id : 2 }, { id : 3 } ] }; It is important to note the potential for cyclic object graphs. Since all relationship properties are two-sided, the two properties in that relationship are references to one another. That is, you could do something like this: identical ( user . profile . user , user ); identical ( user . posts . first . user , user ); When fetching objects from a database, this won't happen - Aqueduct will create multiple instances of the same row when necessary to avoid this. Therefore, the previous code snippet would not be true, but the following two statements that check the values inside those objects would be: user.profile.user.id == user.id; user.posts.first.user.id == user.id While managed objects from a database will not have cyclic references, managed objects you instantiate yourself can if you mistakenly do so. When you invoke asMap() on a cyclic graph, you'll get a stack overflow error. It's best to avoid creating cyclic graphs altogether. For example: // do: var user = User (); posts . forEach (( p ) { p . user = User ().. id = user . id ; }); // do not: var user = User (); posts . forEach (( p ) { p . user = user ; }); When reading the values of a ManagedObject T with readFromMap() , relationship properties must also be represented as nested Map s or List Map . Thus: var userMap = { id : 1 , name : Bob , posts : [ { id : 1 , text : hello } ] }; var user = User ().. readFromMap ( userMap ); user . posts == ManagedSet Post [ Post () .. id = 1 .. text = hello ]; // yup, other Post doesn t implement == to check property equality","title":"Serialization and Deserialization of Relationship Properties"},{"location":"db/transactions/","text":"Database Transactions Learn how to execute multiple Query T s in a database transaction. Transactions Consider an application that keeps employee records. Each employee belongs to a department. Management decides to combine two departments into a totally new department. To do this, the application must insert a new department, set each employee's foreign key reference to that department, and then delete the old departments. It'd look like this: // Create the new department final newDepartment = await Query . insertObject ( ctx , Department ().. name = New Department ); // Set employee s departments to the new one final changeDepartmentQuery = Query Employee ( ctx ) .. where (( e ) = e . department . id ). oneOf ([ 1 , 2 ]) .. values . department . id = newDepartment . id ; await changeDepartmentQuery . update (); // Delete the old ones final deleteDepartmentQuery = Query Department ( ctx ) .. where (( e ) = e . department . id ). oneOf ([ 1 , 2 ]); await deleteDepartmentQuery . delete (); This change to your database is three separate queries, but they all most complete for the 'transfer' to be successful. If one of them fails, our database can be left in an inconsistent state. For example, if deleting the departments succeeds, but the employees failed to be transferred to the new department, then a lot of employees would be without a department. A database transaction combines queries together as a single unit. If a query in a transaction fails, the previous queries in that transaction are reverted and the remaining queries are aborted. You create transactions by invoking ManagedContext.transaction and writing your queries in its closure argument. await context . transaction (( transaction ) async { // note that transaction is the context for each of these queries. final newDepartment = await Query . insertObject ( transaction , Department ().. name = New Department ); final changeDepartmentQuery = Query Employee ( transaction ) .. where (( e ) = e . department . id ). oneOf ([ 1 , 2 ]) .. values . department . id = newDepartment . id ; await changeDepartmentQuery . update (); final deleteDepartmentQuery = Query Department ( transaction ) .. where (( e ) = e . department . id ). oneOf ([ 1 , 2 ]); await deleteDepartmentQuery (); }); All of the queries in the transaction closure will run in the same transaction. Once they have all succeeded, the transaction method's future completes. If an exception is thrown in the closure, the transaction is rolled back and the transaction method re-throws that exception. Notice that the context for each query is the transaction object passed to the transaction closure. You must use this object when using Query in a transaction closure. Failing to Use the Transaction Context will Deadlock your Application A ManagedContext has a single database connection. While a transaction is in progress, any query sent by the same connection becomes part of that transaction. Because Dart is asynchronous, a its likely that another request will trigger a database request while a transaction is in progress. For this reason, a context must queue queries from outside of a transaction while the transaction is running. A new context is created for each transaction and the database connection is shared with the original context. If you await on a query on the original context from inside a transaction closure, it won't complete until the transaction completes - but the transaction can't complete because it is awaiting for the query to complete. This will prevent the connection from being used until the transaction or query times out. Returning Values The value returned from a transaction closure is returned to the caller, so values created within the transaction closure can escape its scope. final employees = [...]; final insertedEmployees = await context . transaction (( t ) async { return Future . wait ( employees . map (( e ) = Query . insertObject ( t , e ))); }); Rollbacks You can cancel a transaction and revert its changes at anytime within the transaction closure by throwing a Rollback object. try { await context . transaction (( t ) async { // do something if ( somethingIsTrue ) { throw Rollback ( something was true ); } // do something }); } on Rollback catch ( rollback ) { print ( ${ rollback . reason } ); // prints something was true } When you rollback, your transaction fails, the transaction closure is aborted and all changes are reverted. The transaction method completes with an error, where the error object is the Rollback .","title":"Transactions"},{"location":"db/transactions/#database-transactions","text":"Learn how to execute multiple Query T s in a database transaction.","title":"Database Transactions"},{"location":"db/transactions/#transactions","text":"Consider an application that keeps employee records. Each employee belongs to a department. Management decides to combine two departments into a totally new department. To do this, the application must insert a new department, set each employee's foreign key reference to that department, and then delete the old departments. It'd look like this: // Create the new department final newDepartment = await Query . insertObject ( ctx , Department ().. name = New Department ); // Set employee s departments to the new one final changeDepartmentQuery = Query Employee ( ctx ) .. where (( e ) = e . department . id ). oneOf ([ 1 , 2 ]) .. values . department . id = newDepartment . id ; await changeDepartmentQuery . update (); // Delete the old ones final deleteDepartmentQuery = Query Department ( ctx ) .. where (( e ) = e . department . id ). oneOf ([ 1 , 2 ]); await deleteDepartmentQuery . delete (); This change to your database is three separate queries, but they all most complete for the 'transfer' to be successful. If one of them fails, our database can be left in an inconsistent state. For example, if deleting the departments succeeds, but the employees failed to be transferred to the new department, then a lot of employees would be without a department. A database transaction combines queries together as a single unit. If a query in a transaction fails, the previous queries in that transaction are reverted and the remaining queries are aborted. You create transactions by invoking ManagedContext.transaction and writing your queries in its closure argument. await context . transaction (( transaction ) async { // note that transaction is the context for each of these queries. final newDepartment = await Query . insertObject ( transaction , Department ().. name = New Department ); final changeDepartmentQuery = Query Employee ( transaction ) .. where (( e ) = e . department . id ). oneOf ([ 1 , 2 ]) .. values . department . id = newDepartment . id ; await changeDepartmentQuery . update (); final deleteDepartmentQuery = Query Department ( transaction ) .. where (( e ) = e . department . id ). oneOf ([ 1 , 2 ]); await deleteDepartmentQuery (); }); All of the queries in the transaction closure will run in the same transaction. Once they have all succeeded, the transaction method's future completes. If an exception is thrown in the closure, the transaction is rolled back and the transaction method re-throws that exception. Notice that the context for each query is the transaction object passed to the transaction closure. You must use this object when using Query in a transaction closure. Failing to Use the Transaction Context will Deadlock your Application A ManagedContext has a single database connection. While a transaction is in progress, any query sent by the same connection becomes part of that transaction. Because Dart is asynchronous, a its likely that another request will trigger a database request while a transaction is in progress. For this reason, a context must queue queries from outside of a transaction while the transaction is running. A new context is created for each transaction and the database connection is shared with the original context. If you await on a query on the original context from inside a transaction closure, it won't complete until the transaction completes - but the transaction can't complete because it is awaiting for the query to complete. This will prevent the connection from being used until the transaction or query times out.","title":"Transactions"},{"location":"db/transactions/#returning-values","text":"The value returned from a transaction closure is returned to the caller, so values created within the transaction closure can escape its scope. final employees = [...]; final insertedEmployees = await context . transaction (( t ) async { return Future . wait ( employees . map (( e ) = Query . insertObject ( t , e ))); });","title":"Returning Values"},{"location":"db/transactions/#rollbacks","text":"You can cancel a transaction and revert its changes at anytime within the transaction closure by throwing a Rollback object. try { await context . transaction (( t ) async { // do something if ( somethingIsTrue ) { throw Rollback ( something was true ); } // do something }); } on Rollback catch ( rollback ) { print ( ${ rollback . reason } ); // prints something was true } When you rollback, your transaction fails, the transaction closure is aborted and all changes are reverted. The transaction method completes with an error, where the error object is the Rollback .","title":"Rollbacks"},{"location":"db/validations/","text":"Validating Data Data is added to a database through update and insert queries. As part of these two operations, a ManagedObject T will ensure that its properties have valid values. For example, a Person object might ensure that its name starts with a capital letter and that its phone number has only numeric values. If one or more validation fails, the update or insert operation will fail and the data is not sent to the database. A validation failure will throw a QueryException , which automatically sends an HTTP response with error messaging to help the client correct their request. The preferred way of setting a validation is to add Validate metadata to properties of a table definition. Here's an example of a validation that ensures a tweet is less than 140 characters: class Tweet extends ManagedObject _Tweet implements _Tweet {} class _Tweet { @ primaryKey int id ; @ Validate . length ( lessThan: 140 ) String message ; } Built-in Validators There are a handful of built-in validations for common operations. For example, it is common to apply a regular expression to a value to ensure it formatted correctly or restrict the possible values to a list of available options. Common validators are available as named constructors on the Validate class. Here is an example: class _Story { @ primaryKey int id ; @ Validate . oneOf ( const [ started , accepted , rejected , delivered ]) String state ; } A built-in validator is useful because it automatically generates an error message that is returned in an HTTP response. For example, the previous code snippet indicates that the state property must be one of the four listed strings. If a value other than one of those four strings is used, the error message returned to the HTTP client would be: The value `invalidValue` is not valid for `state`. Valid values are: started , accepted , rejected , delivered . . See the API reference for Validate and its named constructors for possible options. Validate metadata on transient properties have no effect. This metadata is only valid for database-backed properties declared in a table definition. Custom Validators There will be times where the built-in validators are not sufficient for your application's use case. You may create subclasses of Validate to provide custom validation behavior.For example, a Validate subclass you have declared named ValidatePhoneNumber would be used like so: class _Person { @ primaryKey int id ; @ ValidatePhoneNumber () String phoneNumber ; } A subclass of Validate must override Validate.validate() and call the superclass' primary constructor when instantiated. Here's an example of that phone number validator: class ValidatePhoneNumber extends Validate { ValidatePhoneNumber ({ bool onUpdate: true , bool onInsert: true }) : super ( onUpdate: onUpdate , onInsert: onInsert ); @ override void validate ( ValidationContext context , dynamic value ) { if ( value . length != 15 ) { context . addError ( must be 15 digits ); } if ( containsNonNumericValues ( value )) { context . addError ( must contain characters 0-9 only. ); } } } If value is doesn't meet the validation criteria, this method adds an error string to the ValidationContext it is passed. Error messages should be brief and indicate the successful criteria that failed. Information about the property being validated will automatically be added to the error message, so you do not need to include that information. If the context has no errors at the end of validation, the validation succeeds; otherwise, it fails. A ValidationContext also has information about the property being validated, and whether the validation is running for an object being inserted or an object being updated. Validation Behavior A property may have more than one Validate metadata. In this case, all of the validations for a property must pass. The order in which multiple validations are performed is undefined and subject to change. Here's an example of validations that ensure a property's value is 10 characters long and only contains 10 alphabetic capital letters: @ Validate . length ( equalTo: 10 ) @ Validate . matches ( r $[A-Z]+^ ) String tenCapitalLetters ; By default, validations are executed when a Query T 's insert or update method is invoked. A validator can be restricted to only run on insert or update by passing values for its optional constructor arguments onUpdate and onInsert : @ Validate . matches ( r ^[A-Z]+$ , onInsert: true , onUpdate: false ) String validateOnInsertOnly ; It is important to understand how validations work when a value for a property is not specified in an insert or update query. For example, consider a Person with a name and email property and then inserted in a query where email hasn't been set: var query = new Query Person ( context ) .. values . name = Bob ; await query . insert (); Because email was not set on Query.values , validations will not be run on that property. There are two special validators that can require a property to be set, or require that a property not be set. Validate.present() requires that the associated property must have a value. A property with this validator must be provided each time the object is inserted or updated. Like all validators, Validate.present() can be adjusted to be invoked on only inserts or only updates. For example, the following declaration requires that email is set on insertion, but doesn't have to be for updates: @ Validate . present ( onUpdate: false , onInsert: true ) String email ; The inverse of Validate.present() is Validate.absent() . This validation prevents a property from being set. This is useful when a value should be included during insertion, but can't be updated. Here's an example: @ Validate . absent ( onUpdate: true , onInsert: false ) String canOnlyBeSetOnce ; In the above declaration, the validator is only run on update operations and ensures that the property canOnlyBeSetOnce does not have a value. Because this validator is not run on insert operations, there is no restriction when the object is first inserted. Validators are not run when a value is null. For example, the following insertion explicitly inserts null for the property email : var query = new Query Person ( context ) .. values . email = null .. values . name = Bob ; await query . insert (); Nullability is enforced by Column.isNullable property. Consider the following declaration: @ Column ( nullable: false ) @ Validate . length ( greaterThan: 10 ) String name ; Here, the property name must not be null and must be greater than 10 characters long. The behavior of inserting or updating this property is shown in the following table. Input Value for Name Validation Runs? Outcome Insert value longer than 10 characters Yes Successful database insert Insert value shorter than 10 characters Yes Database insert not executed, exception thrown Insert value not specified No Database insert fails with non-null violation, exception thrown Insert value is null No Database insert fails with non-null violation, exception thrown Update value longer than 10 characters Yes Successful database update Update value shorter than 10 characters Yes Database update not executed, exception thrown Update value not specified No Successful database update Update value is explicit null No Successful database update This behavior allows ManagedObject T instances to be partially updated, which also allows for partial PUTs. Partial PUTs can be prevented by adding Validate.present() metadata to all properties. While partial PUTs are not idiomatic REST, they are pragmatic software development. This also means that any custom validator can safely assume that a value passed to Validate.validate() is non-null. Other Validator Behavior For validators that can't be built by subclassing Validate , you may override ManagedObject T .validate() . This method is useful when a validation involves more than one property. Here's an example: class Person extends ManagedObject _Person implements _Person { @ override ValidationContext validate ({ Validating forEvent: Validating . insert }) { final ctx = super . validate ( forEvent: forEvent ); if ( a + b 10 ) { ctx . addError ( a + b must be greater than 10 ); } return ctx ; } } When overriding this method, the super implementation must be invoked to run validations managed by annotations. You must return the ValidationContext created by the superclass' implementation. Skipping Validations Validations are only run when values are set via Query T .values . Values set via Query T .valueMap are not validated. Therefore, objects should typically be inserted and updated using Query T .values unless validation must be ignored. Here's an example of skipping validation: var query = new Query Person ( context ) .. valueMap = { name : xyz , email : whatever }; Skipping validation should be rare. Update and Insert Callbacks ManagedObject T subclasses may override willUpdate and willInsert to modify its properties prior to being updated or inserted by a Query T . For example, a managed object may have updated and created dates that can be guaranteed to be set when inserted or updated: class Person extends ManagedObject _Person implements _Person { @ override void willUpdate () { updatedAt = new DateTime . now (). toUtc (); } @ override void willInsert () { createdAt = new DateTime . now (). toUtc (); } } class _Person { @ primaryKey int id ; String name ; DateTime createdAt ; DateTime updatedAt ; } Note that all operations must be synchronous in these methods. Both willUpdate and willInsert are invoked prior the validation phase. Thus, any values set in these methods will be subject to the declared validations of the instance. Like validations, willUpdate and willInsert are skipped when using Query.valueMap .","title":"Validations"},{"location":"db/validations/#validating-data","text":"Data is added to a database through update and insert queries. As part of these two operations, a ManagedObject T will ensure that its properties have valid values. For example, a Person object might ensure that its name starts with a capital letter and that its phone number has only numeric values. If one or more validation fails, the update or insert operation will fail and the data is not sent to the database. A validation failure will throw a QueryException , which automatically sends an HTTP response with error messaging to help the client correct their request. The preferred way of setting a validation is to add Validate metadata to properties of a table definition. Here's an example of a validation that ensures a tweet is less than 140 characters: class Tweet extends ManagedObject _Tweet implements _Tweet {} class _Tweet { @ primaryKey int id ; @ Validate . length ( lessThan: 140 ) String message ; }","title":"Validating Data"},{"location":"db/validations/#built-in-validators","text":"There are a handful of built-in validations for common operations. For example, it is common to apply a regular expression to a value to ensure it formatted correctly or restrict the possible values to a list of available options. Common validators are available as named constructors on the Validate class. Here is an example: class _Story { @ primaryKey int id ; @ Validate . oneOf ( const [ started , accepted , rejected , delivered ]) String state ; } A built-in validator is useful because it automatically generates an error message that is returned in an HTTP response. For example, the previous code snippet indicates that the state property must be one of the four listed strings. If a value other than one of those four strings is used, the error message returned to the HTTP client would be: The value `invalidValue` is not valid for `state`. Valid values are: started , accepted , rejected , delivered . . See the API reference for Validate and its named constructors for possible options. Validate metadata on transient properties have no effect. This metadata is only valid for database-backed properties declared in a table definition.","title":"Built-in Validators"},{"location":"db/validations/#custom-validators","text":"There will be times where the built-in validators are not sufficient for your application's use case. You may create subclasses of Validate to provide custom validation behavior.For example, a Validate subclass you have declared named ValidatePhoneNumber would be used like so: class _Person { @ primaryKey int id ; @ ValidatePhoneNumber () String phoneNumber ; } A subclass of Validate must override Validate.validate() and call the superclass' primary constructor when instantiated. Here's an example of that phone number validator: class ValidatePhoneNumber extends Validate { ValidatePhoneNumber ({ bool onUpdate: true , bool onInsert: true }) : super ( onUpdate: onUpdate , onInsert: onInsert ); @ override void validate ( ValidationContext context , dynamic value ) { if ( value . length != 15 ) { context . addError ( must be 15 digits ); } if ( containsNonNumericValues ( value )) { context . addError ( must contain characters 0-9 only. ); } } } If value is doesn't meet the validation criteria, this method adds an error string to the ValidationContext it is passed. Error messages should be brief and indicate the successful criteria that failed. Information about the property being validated will automatically be added to the error message, so you do not need to include that information. If the context has no errors at the end of validation, the validation succeeds; otherwise, it fails. A ValidationContext also has information about the property being validated, and whether the validation is running for an object being inserted or an object being updated.","title":"Custom Validators"},{"location":"db/validations/#validation-behavior","text":"A property may have more than one Validate metadata. In this case, all of the validations for a property must pass. The order in which multiple validations are performed is undefined and subject to change. Here's an example of validations that ensure a property's value is 10 characters long and only contains 10 alphabetic capital letters: @ Validate . length ( equalTo: 10 ) @ Validate . matches ( r $[A-Z]+^ ) String tenCapitalLetters ; By default, validations are executed when a Query T 's insert or update method is invoked. A validator can be restricted to only run on insert or update by passing values for its optional constructor arguments onUpdate and onInsert : @ Validate . matches ( r ^[A-Z]+$ , onInsert: true , onUpdate: false ) String validateOnInsertOnly ; It is important to understand how validations work when a value for a property is not specified in an insert or update query. For example, consider a Person with a name and email property and then inserted in a query where email hasn't been set: var query = new Query Person ( context ) .. values . name = Bob ; await query . insert (); Because email was not set on Query.values , validations will not be run on that property. There are two special validators that can require a property to be set, or require that a property not be set. Validate.present() requires that the associated property must have a value. A property with this validator must be provided each time the object is inserted or updated. Like all validators, Validate.present() can be adjusted to be invoked on only inserts or only updates. For example, the following declaration requires that email is set on insertion, but doesn't have to be for updates: @ Validate . present ( onUpdate: false , onInsert: true ) String email ; The inverse of Validate.present() is Validate.absent() . This validation prevents a property from being set. This is useful when a value should be included during insertion, but can't be updated. Here's an example: @ Validate . absent ( onUpdate: true , onInsert: false ) String canOnlyBeSetOnce ; In the above declaration, the validator is only run on update operations and ensures that the property canOnlyBeSetOnce does not have a value. Because this validator is not run on insert operations, there is no restriction when the object is first inserted. Validators are not run when a value is null. For example, the following insertion explicitly inserts null for the property email : var query = new Query Person ( context ) .. values . email = null .. values . name = Bob ; await query . insert (); Nullability is enforced by Column.isNullable property. Consider the following declaration: @ Column ( nullable: false ) @ Validate . length ( greaterThan: 10 ) String name ; Here, the property name must not be null and must be greater than 10 characters long. The behavior of inserting or updating this property is shown in the following table. Input Value for Name Validation Runs? Outcome Insert value longer than 10 characters Yes Successful database insert Insert value shorter than 10 characters Yes Database insert not executed, exception thrown Insert value not specified No Database insert fails with non-null violation, exception thrown Insert value is null No Database insert fails with non-null violation, exception thrown Update value longer than 10 characters Yes Successful database update Update value shorter than 10 characters Yes Database update not executed, exception thrown Update value not specified No Successful database update Update value is explicit null No Successful database update This behavior allows ManagedObject T instances to be partially updated, which also allows for partial PUTs. Partial PUTs can be prevented by adding Validate.present() metadata to all properties. While partial PUTs are not idiomatic REST, they are pragmatic software development. This also means that any custom validator can safely assume that a value passed to Validate.validate() is non-null.","title":"Validation Behavior"},{"location":"db/validations/#other-validator-behavior","text":"For validators that can't be built by subclassing Validate , you may override ManagedObject T .validate() . This method is useful when a validation involves more than one property. Here's an example: class Person extends ManagedObject _Person implements _Person { @ override ValidationContext validate ({ Validating forEvent: Validating . insert }) { final ctx = super . validate ( forEvent: forEvent ); if ( a + b 10 ) { ctx . addError ( a + b must be greater than 10 ); } return ctx ; } } When overriding this method, the super implementation must be invoked to run validations managed by annotations. You must return the ValidationContext created by the superclass' implementation.","title":"Other Validator Behavior"},{"location":"db/validations/#skipping-validations","text":"Validations are only run when values are set via Query T .values . Values set via Query T .valueMap are not validated. Therefore, objects should typically be inserted and updated using Query T .values unless validation must be ignored. Here's an example of skipping validation: var query = new Query Person ( context ) .. valueMap = { name : xyz , email : whatever }; Skipping validation should be rare.","title":"Skipping Validations"},{"location":"db/validations/#update-and-insert-callbacks","text":"ManagedObject T subclasses may override willUpdate and willInsert to modify its properties prior to being updated or inserted by a Query T . For example, a managed object may have updated and created dates that can be guaranteed to be set when inserted or updated: class Person extends ManagedObject _Person implements _Person { @ override void willUpdate () { updatedAt = new DateTime . now (). toUtc (); } @ override void willInsert () { createdAt = new DateTime . now (). toUtc (); } } class _Person { @ primaryKey int id ; String name ; DateTime createdAt ; DateTime updatedAt ; } Note that all operations must be synchronous in these methods. Both willUpdate and willInsert are invoked prior the validation phase. Thus, any values set in these methods will be subject to the declared validations of the instance. Like validations, willUpdate and willInsert are skipped when using Query.valueMap .","title":"Update and Insert Callbacks"},{"location":"deploy/","text":"Tasks Aqueduct has a built in tool, aqueduct , for deploying Aqueduct applications, managing database schemas, OAuth 2.0 clients and creating projects. See Getting Started for installation instructions. Many of the tasks for deployment rely on using this tool. Aqueduct applications can be run anywhere that Dart can be installed. This topic covers deployment tasks on common hosting services. If you are just getting started or a hobbyist, you should consider using Heroku to host your applications. Guides Running an Aqueduct Application Locally Running an Aqueduct Application with Docker and Kubernetes Running an Aqueduct Application on Heroku Running an Aqueduct Application on Amazon Web Services (AWS) Running an Aqueduct Application without aqueduct serve","title":"Overview"},{"location":"deploy/#tasks","text":"Aqueduct has a built in tool, aqueduct , for deploying Aqueduct applications, managing database schemas, OAuth 2.0 clients and creating projects. See Getting Started for installation instructions. Many of the tasks for deployment rely on using this tool. Aqueduct applications can be run anywhere that Dart can be installed. This topic covers deployment tasks on common hosting services. If you are just getting started or a hobbyist, you should consider using Heroku to host your applications.","title":"Tasks"},{"location":"deploy/#guides","text":"Running an Aqueduct Application Locally Running an Aqueduct Application with Docker and Kubernetes Running an Aqueduct Application on Heroku Running an Aqueduct Application on Amazon Web Services (AWS) Running an Aqueduct Application without aqueduct serve","title":"Guides"},{"location":"deploy/deploy_aws/","text":"Deploying an Aqueduct Application on Remote VMs For other deployment options, see Deploying Aqueduct Applications . Purpose This document will describe the steps to deploy an Aqueduct application to a remote machine that you are able to ssh into. This is often the case for Amazon Web Service (AWS) EC2 instances, Google Cloud Compute Instances, Azure Virtual Machines, and rented boxes on platforms like Digital Ocean or other cloud providers. If you are unfamiliar with deploying applications in this way, this is not a good beginner's guide and will not cover many of the steps necessary to deploy an application. Prefer to use a platform like Heroku or one that supports Docker. See the guides on Heroku and Docker for better options. Summary Aqueduct applications are run by using aqueduct serve or dart bin/main.dart . # in project directory aqueduct serve # or # in project directory dart bin/main.dart The target machine must have Dart installed. If you are using aqueduct serve , you must also activate the CLI on the target machine: pub global activate aqueduct Your source code must also be available on the target machine. You can transfer your source to a machine with tools like ftp , scp , rsync and git . Aqueduct will listen on port 8888 by default. Change this value at the CLI aqueduct serve --port 80 or in bin/main.dart . Ensure that security controls on your instance can accept connections on the port Aqueduct is listening on. It is preferable to use a reverse proxy (e.g. nginx or a load balancer) instead of serving the application directly. Use tools like supervisord to ensure the application restarts if the VM crashes. Configuration Management When deploying directly to a VM, it is your responsibility to manage your configuration file. This can often be done by transferring an environment specific config.yaml file to your target machine and storing it in your project's directory on the remote machine. CLI Tools Many deployments will need to perform database migrations and OAuth 2.0 client identifier management with the aqueduct CLI. You can run these tools locally with the --connect flag to specify the location of your database instance. Ensure that you have the propery security controls to access the database instance from your local machine.","title":"Deploy on AWS"},{"location":"deploy/deploy_aws/#deploying-an-aqueduct-application-on-remote-vms","text":"For other deployment options, see Deploying Aqueduct Applications .","title":"Deploying an Aqueduct Application on Remote VMs"},{"location":"deploy/deploy_aws/#purpose","text":"This document will describe the steps to deploy an Aqueduct application to a remote machine that you are able to ssh into. This is often the case for Amazon Web Service (AWS) EC2 instances, Google Cloud Compute Instances, Azure Virtual Machines, and rented boxes on platforms like Digital Ocean or other cloud providers. If you are unfamiliar with deploying applications in this way, this is not a good beginner's guide and will not cover many of the steps necessary to deploy an application. Prefer to use a platform like Heroku or one that supports Docker. See the guides on Heroku and Docker for better options.","title":"Purpose"},{"location":"deploy/deploy_aws/#summary","text":"Aqueduct applications are run by using aqueduct serve or dart bin/main.dart . # in project directory aqueduct serve # or # in project directory dart bin/main.dart The target machine must have Dart installed. If you are using aqueduct serve , you must also activate the CLI on the target machine: pub global activate aqueduct Your source code must also be available on the target machine. You can transfer your source to a machine with tools like ftp , scp , rsync and git . Aqueduct will listen on port 8888 by default. Change this value at the CLI aqueduct serve --port 80 or in bin/main.dart . Ensure that security controls on your instance can accept connections on the port Aqueduct is listening on. It is preferable to use a reverse proxy (e.g. nginx or a load balancer) instead of serving the application directly. Use tools like supervisord to ensure the application restarts if the VM crashes.","title":"Summary"},{"location":"deploy/deploy_aws/#configuration-management","text":"When deploying directly to a VM, it is your responsibility to manage your configuration file. This can often be done by transferring an environment specific config.yaml file to your target machine and storing it in your project's directory on the remote machine.","title":"Configuration Management"},{"location":"deploy/deploy_aws/#cli-tools","text":"Many deployments will need to perform database migrations and OAuth 2.0 client identifier management with the aqueduct CLI. You can run these tools locally with the --connect flag to specify the location of your database instance. Ensure that you have the propery security controls to access the database instance from your local machine.","title":"CLI Tools"},{"location":"deploy/deploy_docker/","text":"Deploying an Aqueduct Application using Docker For other deployment options, see Deploying Aqueduct Applications . Purpose This document will describe the steps to deploy an Aqueduct application through Docker and/or a container orchestration platform like Kubernetes. For Dockerfile and Kubernetes templates, see this repository . If you are unfamiliar with deploying applications in this way, this is not a good beginner's guide and will not cover the topics of Docker or Kubernetes. Dockerfiles The following Dockerfile will run an Aqueduct application. FROM google/dart WORKDIR /app ADD pubspec.* /app/ RUN pub get --no-precompile ADD . /app/ RUN pub get --offline --no-precompile WORKDIR /app EXPOSE 80 ENTRYPOINT [ pub , run , aqueduct:aqueduct , serve , --port , 80 ] Kubernetes Objects For more Kubernetes objects - including tasks for database migrations and OAuth 2.0 client management - see this repository . The following is Kubernetes configuration file for starting an Aqueduct application and exposing it as a service. Replace APP_NAME with your application's name. apiVersion : v1 kind : Service metadata : name : api - service namespace : APP_NAME spec : selector : app : APP_NAME role : backend type : api ports : - port : 80 targetPort : 8082 --- apiVersion : apps / v1beta1 kind : Deployment metadata : name : api - deployment namespace : APP_NAME spec : replicas : 2 template : metadata : labels : app : APP_NAME role : backend type : api spec : containers : - name : APP_NAME # In development , setting ` imagePullPolicy : Always ` and using : latest tag is useful . # imagePullPolicy : Always image : IMAGE envFrom : - secretRef : name : secrets - configMapRef : name : config ports : - containerPort : 8082 securityContext : runAsNonRoot : true","title":"Deploying with Docker and Kubernetes"},{"location":"deploy/deploy_docker/#deploying-an-aqueduct-application-using-docker","text":"For other deployment options, see Deploying Aqueduct Applications .","title":"Deploying an Aqueduct Application using Docker"},{"location":"deploy/deploy_docker/#purpose","text":"This document will describe the steps to deploy an Aqueduct application through Docker and/or a container orchestration platform like Kubernetes. For Dockerfile and Kubernetes templates, see this repository . If you are unfamiliar with deploying applications in this way, this is not a good beginner's guide and will not cover the topics of Docker or Kubernetes.","title":"Purpose"},{"location":"deploy/deploy_docker/#dockerfiles","text":"The following Dockerfile will run an Aqueduct application. FROM google/dart WORKDIR /app ADD pubspec.* /app/ RUN pub get --no-precompile ADD . /app/ RUN pub get --offline --no-precompile WORKDIR /app EXPOSE 80 ENTRYPOINT [ pub , run , aqueduct:aqueduct , serve , --port , 80 ]","title":"Dockerfiles"},{"location":"deploy/deploy_docker/#kubernetes-objects","text":"For more Kubernetes objects - including tasks for database migrations and OAuth 2.0 client management - see this repository . The following is Kubernetes configuration file for starting an Aqueduct application and exposing it as a service. Replace APP_NAME with your application's name. apiVersion : v1 kind : Service metadata : name : api - service namespace : APP_NAME spec : selector : app : APP_NAME role : backend type : api ports : - port : 80 targetPort : 8082 --- apiVersion : apps / v1beta1 kind : Deployment metadata : name : api - deployment namespace : APP_NAME spec : replicas : 2 template : metadata : labels : app : APP_NAME role : backend type : api spec : containers : - name : APP_NAME # In development , setting ` imagePullPolicy : Always ` and using : latest tag is useful . # imagePullPolicy : Always image : IMAGE envFrom : - secretRef : name : secrets - configMapRef : name : config ports : - containerPort : 8082 securityContext : runAsNonRoot : true","title":"Kubernetes Objects"},{"location":"deploy/deploy_heroku/","text":"Deploying an Aqueduct Application on Heroku For other deployment options, see Deploying Aqueduct Applications . Purpose To run a production Aqueduct application on Heroku. Make sure to also read Testing Aqueduct Applications . Prerequisites Dart has been installed. A Heroku account. git has been installed. heroku has been installed. Aqueduct has been activated. Overview Setting up a Heroku application Setting up an Aqueduct application to run on Heroku Configuring application values Running the Aqueduct application Estimated Time: 5 minutes. Step 1: Setting up a Heroku Application Create a new application in Heroku's web portal, and if you are using a database, add the 'Heroku Postgres' add-on. Navigate to the Settings tab in the Heroku web interface and click 'Reveal Config Vars'. Note that there is a DATABASE_URL environment variable that is the connection details for your PostgreSQL database. You won't need to remember the value, only that this environment variable exists. Step 2: Setting up an Aqueduct Application to Run on Heroku If you have not yet, create a new Aqueduct application on your local machine, go into that directory, and initialize it as a git repository if it is not already: aqueduct create app_name cd app_name git init Run the following commands to configure your project in Heroku's environment. Heroku Application Name In the following commands, ensure that app_name is the name of your Heroku application created in their web portal, not the name of your Aqueduct application. # This is an interactive command that you have to enter your username and password. heroku login # This adds a remote repository hosted by Heroku for your application that you push to. heroku git:remote -a app_name # Specifies the Dart SDK to use heroku config:set DART_SDK_URL = https://storage.googleapis.com/dart-archive/channels/stable/release/latest/sdk/dartsdk-linux-x64-release.zip # Specifies the Heroku Buildpack to use heroku config:set BUILDPACK_URL = https://github.com/stablekernel/heroku-buildpack-dart.git # Specifies that aqueduct should be activated heroku config:set DART_GLOBAL_PACKAGES = aqueduct@3.0.0 heroku config:set PATH = /app/bin:/usr/local/bin:/usr/bin:/bin:/app/.pub-cache/bin:/app/dart-sdk/bin heroku config:set PUB_CACHE = /app/pub-cache Then, create a new file in your project directory named Procfile (with no suffix) and enter the following: release: /app/dart-sdk/bin/pub global run aqueduct:aqueduct db upgrade --connect $DATABASE_URL web: /app/dart-sdk/bin/pub global run aqueduct:aqueduct serve --port $PORT --config-path heroku.yaml This file tells Heroku how to run your application, and to execute any database migrations each time you push a release. Make sure this file is checked into version control: git commit -am Adds Procfile Step 3: Configuring Application Values Heroku provides configuration values through environment variables. In our Procfile , we indicated that we will use a file named heroku.yaml for configuration. This file will map configuration values in our application to environment variables in the Heroku platform. Your configuration file may vary, but it is important to note that if you are using a database, the database credentials are provided through a connection string . A connection string looks like this: postgres://user:password@host:5432/name and by default, Heroku stores it in the environment variable named DATABASE_URL . In heroku.yaml (which you will need to create in your project directory), you can reference an environment variable by prefixing its name with a $ . When using the built-in DatabaseConfiguration type, you can assign the connection string like so: database : $DATABASE_URL Your heroku.yaml might be different Make sure the structure of your heroku.yaml file matches the expected structure in your application's Configuration subclass. Check heroku.yaml into version control. git commit -am add heroku.yaml Step 4: Running the Aqueduct Application If your application uses a database, make sure you have generated your migration file(s) and added it to version control. The Procfile will ensure that database is up to date with any migrations checked into source control before running your app. Generate your migration file with the following command from your project directory and then check it into version control: aqueduct db generate git commit -am adds migration files Now, you can deploy your application. It's as simple as this: git push heroku master This command pushes your code to a remote git server hosted by Heroku, which triggers your application to run its release script. Now that your application's database schema has been uploaded, you can configure your OAuth 2 server with client identifiers if you are using package:aqueduct/managed_auth . The following command will run within your application's remote environment. heroku run /app/dart-sdk/bin/pub global run aqueduct:aqueduct auth add-client --id com.app.standard --secret secret --connect \\$ DATABASE_URL Finally, scale up a dyno and the application will start receiving requests: heroku ps:scale web = 1 Now your application is running!","title":"Deploy on Heroku"},{"location":"deploy/deploy_heroku/#deploying-an-aqueduct-application-on-heroku","text":"For other deployment options, see Deploying Aqueduct Applications .","title":"Deploying an Aqueduct Application on Heroku"},{"location":"deploy/deploy_heroku/#purpose","text":"To run a production Aqueduct application on Heroku. Make sure to also read Testing Aqueduct Applications .","title":"Purpose"},{"location":"deploy/deploy_heroku/#prerequisites","text":"Dart has been installed. A Heroku account. git has been installed. heroku has been installed. Aqueduct has been activated.","title":"Prerequisites"},{"location":"deploy/deploy_heroku/#overview","text":"Setting up a Heroku application Setting up an Aqueduct application to run on Heroku Configuring application values Running the Aqueduct application Estimated Time: 5 minutes.","title":"Overview"},{"location":"deploy/deploy_heroku/#step-1-setting-up-a-heroku-application","text":"Create a new application in Heroku's web portal, and if you are using a database, add the 'Heroku Postgres' add-on. Navigate to the Settings tab in the Heroku web interface and click 'Reveal Config Vars'. Note that there is a DATABASE_URL environment variable that is the connection details for your PostgreSQL database. You won't need to remember the value, only that this environment variable exists.","title":"Step 1: Setting up a Heroku Application"},{"location":"deploy/deploy_heroku/#step-2-setting-up-an-aqueduct-application-to-run-on-heroku","text":"If you have not yet, create a new Aqueduct application on your local machine, go into that directory, and initialize it as a git repository if it is not already: aqueduct create app_name cd app_name git init Run the following commands to configure your project in Heroku's environment. Heroku Application Name In the following commands, ensure that app_name is the name of your Heroku application created in their web portal, not the name of your Aqueduct application. # This is an interactive command that you have to enter your username and password. heroku login # This adds a remote repository hosted by Heroku for your application that you push to. heroku git:remote -a app_name # Specifies the Dart SDK to use heroku config:set DART_SDK_URL = https://storage.googleapis.com/dart-archive/channels/stable/release/latest/sdk/dartsdk-linux-x64-release.zip # Specifies the Heroku Buildpack to use heroku config:set BUILDPACK_URL = https://github.com/stablekernel/heroku-buildpack-dart.git # Specifies that aqueduct should be activated heroku config:set DART_GLOBAL_PACKAGES = aqueduct@3.0.0 heroku config:set PATH = /app/bin:/usr/local/bin:/usr/bin:/bin:/app/.pub-cache/bin:/app/dart-sdk/bin heroku config:set PUB_CACHE = /app/pub-cache Then, create a new file in your project directory named Procfile (with no suffix) and enter the following: release: /app/dart-sdk/bin/pub global run aqueduct:aqueduct db upgrade --connect $DATABASE_URL web: /app/dart-sdk/bin/pub global run aqueduct:aqueduct serve --port $PORT --config-path heroku.yaml This file tells Heroku how to run your application, and to execute any database migrations each time you push a release. Make sure this file is checked into version control: git commit -am Adds Procfile","title":"Step 2: Setting up an Aqueduct Application to Run on Heroku"},{"location":"deploy/deploy_heroku/#step-3-configuring-application-values","text":"Heroku provides configuration values through environment variables. In our Procfile , we indicated that we will use a file named heroku.yaml for configuration. This file will map configuration values in our application to environment variables in the Heroku platform. Your configuration file may vary, but it is important to note that if you are using a database, the database credentials are provided through a connection string . A connection string looks like this: postgres://user:password@host:5432/name and by default, Heroku stores it in the environment variable named DATABASE_URL . In heroku.yaml (which you will need to create in your project directory), you can reference an environment variable by prefixing its name with a $ . When using the built-in DatabaseConfiguration type, you can assign the connection string like so: database : $DATABASE_URL Your heroku.yaml might be different Make sure the structure of your heroku.yaml file matches the expected structure in your application's Configuration subclass. Check heroku.yaml into version control. git commit -am add heroku.yaml","title":"Step 3: Configuring Application Values"},{"location":"deploy/deploy_heroku/#step-4-running-the-aqueduct-application","text":"If your application uses a database, make sure you have generated your migration file(s) and added it to version control. The Procfile will ensure that database is up to date with any migrations checked into source control before running your app. Generate your migration file with the following command from your project directory and then check it into version control: aqueduct db generate git commit -am adds migration files Now, you can deploy your application. It's as simple as this: git push heroku master This command pushes your code to a remote git server hosted by Heroku, which triggers your application to run its release script. Now that your application's database schema has been uploaded, you can configure your OAuth 2 server with client identifiers if you are using package:aqueduct/managed_auth . The following command will run within your application's remote environment. heroku run /app/dart-sdk/bin/pub global run aqueduct:aqueduct auth add-client --id com.app.standard --secret secret --connect \\$ DATABASE_URL Finally, scale up a dyno and the application will start receiving requests: heroku ps:scale web = 1 Now your application is running!","title":"Step 4: Running the Aqueduct Application"},{"location":"deploy/deploy_local/","text":"Deploying an Aqueduct Application on a Local Machine For other deployment options, see Deploying Aqueduct Applications . Purpose To run a local development version of an Aqueduct application with persistent storage. This is useful when developing client applications with an Aqueduct application. Make sure to also read Testing Aqueduct Applications . Prerequisites Dart has been installed. PostgreSQL has been installed locally. Aqueduct has been activated globally. An application has been created with aqueduct create . If one or more of these is not true, see Getting Started . Overview Create a local database. Upload the application schema to the local database. Add an OAuth 2.0 client. Modify the configuration file. Run the application. Estimated Time: 5 minutes. Step 1: Create a Local Database Create a database with the same name as your application and a user that can access that database. Run the following SQL locally with a user that has privileges to create databases. CREATE DATABASE app_name ; CREATE USER app_name_user WITH CREATEDB ; ALTER USER app_name_user WITH PASSWORD yourpassword ; GRANT ALL ON DATABASE app_name TO app_name_user ; dart_test database Do not use the name 'dart_test' for the database; this database is used by Aqueduct to run tests by default. Step 2: Upload the Application Schema If you have not yet created database migration files for your project, run the database schema generation tool from the project directory: aqueduct db generate This command creates the file migrations/00000001_initial.migration.dart . Now, run the database migration tool to execute the migration file against the local database. Ensure that the values for the option --connect match those of the database created in the last step. aqueduct db upgrade --connect postgres://app_name_user:yourpassword@localhost:5432/app_name (Note that you may provide database credentials in a file named database.yaml instead of using --connect . See aqueduct db --help for details.) Step 3: Add an OAuth 2.0 client. If you are using package:aqueduct/managed_auth , you'll want to create an OAuth2 client identifier. From the command line, run the following, ensuring that the values for the option --connect match the recently created database. aqueduct auth add-client --id com.app_name.standard --secret abcdefghi --connect postgres://app_name_user:yourpassword@localhost:5432/app_name Step 4: Modify the Configuration File If config.yaml doesn't exist, create it by copying the configuration file template config.yaml.src . In config.yaml , update the database credentials to the local database. database : username : app_name_user password : yourpassword host : localhost port : 5432 databaseName : app_name Step 5: Run the Application From the project directory, run: aqueduct serve Your application is now running. You may also run the generated start script in your project's bin directory: dart bin/main.dart If you restart the application, the data in your database will remain.","title":"Deploy Locally"},{"location":"deploy/deploy_local/#deploying-an-aqueduct-application-on-a-local-machine","text":"For other deployment options, see Deploying Aqueduct Applications .","title":"Deploying an Aqueduct Application on a Local Machine"},{"location":"deploy/deploy_local/#purpose","text":"To run a local development version of an Aqueduct application with persistent storage. This is useful when developing client applications with an Aqueduct application. Make sure to also read Testing Aqueduct Applications .","title":"Purpose"},{"location":"deploy/deploy_local/#prerequisites","text":"Dart has been installed. PostgreSQL has been installed locally. Aqueduct has been activated globally. An application has been created with aqueduct create . If one or more of these is not true, see Getting Started .","title":"Prerequisites"},{"location":"deploy/deploy_local/#overview","text":"Create a local database. Upload the application schema to the local database. Add an OAuth 2.0 client. Modify the configuration file. Run the application. Estimated Time: 5 minutes.","title":"Overview"},{"location":"deploy/deploy_local/#step-1-create-a-local-database","text":"Create a database with the same name as your application and a user that can access that database. Run the following SQL locally with a user that has privileges to create databases. CREATE DATABASE app_name ; CREATE USER app_name_user WITH CREATEDB ; ALTER USER app_name_user WITH PASSWORD yourpassword ; GRANT ALL ON DATABASE app_name TO app_name_user ; dart_test database Do not use the name 'dart_test' for the database; this database is used by Aqueduct to run tests by default.","title":"Step 1: Create a Local Database"},{"location":"deploy/deploy_local/#step-2-upload-the-application-schema","text":"If you have not yet created database migration files for your project, run the database schema generation tool from the project directory: aqueduct db generate This command creates the file migrations/00000001_initial.migration.dart . Now, run the database migration tool to execute the migration file against the local database. Ensure that the values for the option --connect match those of the database created in the last step. aqueduct db upgrade --connect postgres://app_name_user:yourpassword@localhost:5432/app_name (Note that you may provide database credentials in a file named database.yaml instead of using --connect . See aqueduct db --help for details.)","title":"Step 2: Upload the Application Schema"},{"location":"deploy/deploy_local/#step-3-add-an-oauth-20-client","text":"If you are using package:aqueduct/managed_auth , you'll want to create an OAuth2 client identifier. From the command line, run the following, ensuring that the values for the option --connect match the recently created database. aqueduct auth add-client --id com.app_name.standard --secret abcdefghi --connect postgres://app_name_user:yourpassword@localhost:5432/app_name","title":"Step 3: Add an OAuth 2.0 client."},{"location":"deploy/deploy_local/#step-4-modify-the-configuration-file","text":"If config.yaml doesn't exist, create it by copying the configuration file template config.yaml.src . In config.yaml , update the database credentials to the local database. database : username : app_name_user password : yourpassword host : localhost port : 5432 databaseName : app_name","title":"Step 4: Modify the Configuration File"},{"location":"deploy/deploy_local/#step-5-run-the-application","text":"From the project directory, run: aqueduct serve Your application is now running. You may also run the generated start script in your project's bin directory: dart bin/main.dart If you restart the application, the data in your database will remain.","title":"Step 5: Run the Application"},{"location":"deploy/script/","text":"You may also run Aqueduct applications with a standalone script, instead of aqueduct serve . In fact, aqueduct serve creates a temporary Dart script to run the application. If you created your application with aqueduct create , a standalone already exists in your project named bin/main.dart . A sample script looks like this: import dart:async ; import dart:io ; import package:aqueduct/aqueduct.dart ; import package:my_application/my_application.dart ; Future main () async { var app = new Application MyApplicationChannel () .. options . port = 8888 .. options . configurationFilePath = config.yaml ; await app . start ( numberOfInstances: 3 ); } This script can be used in place of aqueduct serve , but you must configure all ApplicationOptions in this script and not through the CLI.","title":"Deploying without aqueduct serve"},{"location":"http/","text":"Tasks An Aqueduct application serves HTTP clients by sending responses for requests. You create and link Controller objects to handle requests. There are many subclasses of Controller that handle common tasks, and you often create your own subclasses of Controller to implement application logic. Most of your logic is implemented in subclasses of ResourceController , a controller type geared for REST API endpoints. You create a subclass of ApplicationChannel to configure controllers used by your application. This subclass also initializes any services your application will use to fulfill requests, like database connections or third party API connections. Most often, you use a Router controller at the entry point of your application channel to modularize your application logic. Your application may have many configurable options. This configuration is handled in your application channel. Configuration file management is provided by application-specific Configuration subclasses that add type and name safety to your configuration files. Your application is run by using the aqueduct serve command or the bin/main.dart script. In either case, your application starts by creating multiple, memory-isolated threads that replicate your ApplicationChannel . Guides Request and Response Objects Handling Requests Routing ResourceControllers Serving Files and Caching Websockets","title":"Overview"},{"location":"http/#tasks","text":"An Aqueduct application serves HTTP clients by sending responses for requests. You create and link Controller objects to handle requests. There are many subclasses of Controller that handle common tasks, and you often create your own subclasses of Controller to implement application logic. Most of your logic is implemented in subclasses of ResourceController , a controller type geared for REST API endpoints. You create a subclass of ApplicationChannel to configure controllers used by your application. This subclass also initializes any services your application will use to fulfill requests, like database connections or third party API connections. Most often, you use a Router controller at the entry point of your application channel to modularize your application logic. Your application may have many configurable options. This configuration is handled in your application channel. Configuration file management is provided by application-specific Configuration subclasses that add type and name safety to your configuration files. Your application is run by using the aqueduct serve command or the bin/main.dart script. In either case, your application starts by creating multiple, memory-isolated threads that replicate your ApplicationChannel .","title":"Tasks"},{"location":"http/#guides","text":"Request and Response Objects Handling Requests Routing ResourceControllers Serving Files and Caching Websockets","title":"Guides"},{"location":"http/controller/","text":"Handling Requests: Fundamentals Learn how Controller objects are linked together to handle HTTP requests. Overview A controller is the basic building block of an Aqueduct application. A controller handles an HTTP request in some way. For example, a controller could return a 200 OK response with a JSON-encoded list of city names. A controller could also check a request to make sure it had the right credentials in its authorization header. Controllers are linked together to compose their behaviors into a channel . A channel handles a request by performing each of its controllers' behavior in order. For example, a channel with the aforementioned controllers would verify the credentials of a request and then returning a list of city names. The Controller class provides the behavior for linking controllers together, and you subclass it to provide the logic for a particular controller behavior. Linking Controllers Controllers are linked with their link method. This method takes a closure that returns the next controller in the channel. The following shows a channel composed of two controllers: final controllerA = Controller (); controller . link (() = Controller ()); When controllerA handles a request, it can choose to respond to the request or let the request continue in the channel. When the request continues in this channel, the controller created by the closure passed to link handles the request. Any number of controllers can be linked together in a channel, but the last controller must respond to the request. Controllers that always responder to request are called endpoint controllers , as opposed to middleware controllers that verify or modify the request and let the next controller in the channel handle it. Linking occurs in an application channel , and is finalized during startup of your application (i.e., once you have set up your controllers, the cannot be changed once the application starts receiving requests). In a typical application, a Router controller splits an application channel into multiple sub-channels. Creating Request Handling Behavior by Subclassing Controller Every Controller implements its handle method to handle a request. You override this method in your controllers to provide the logic for your application's controllers. The following is an example of an endpoint controller, because it always sends a response: class NoteController extends Controller { @ override Future RequestOrResponse handle ( Request request ) async { final notes = await fetchNotesFromDatabase (); return new Response . ok ( notes ); } } This handle method creates and returns a Response object. When a handle method returns a response, that response is sent to the client. Any linked controllers do not have their handle method invoked; the request is removed from the channel. A middleware controller returns a response when the request is invalid. For example, an Authorizer controller returns a 401 Unauthorized response if the request's credentials are invalid (this removes the request from the channel). If a middleware controller deems the request acceptable, it returns the request from its handle method. This signals to Aqueduct that the next controller in the channel should handle the request. As an example, the pseudo-code for an Authorizer looks like this: class Authorizer extends Controller { @ override Future RequestOrResponse handle ( Request request ) async { if ( isValid ( request )) { return request ; } return new Response . unauthorized (); } } Endpoint Controllers In most cases, endpoint controllers are created by subclassing ResourceController . This controller allows you to declare more than one handler method in a controller to better organize logic. For example, one method might handle POST requests, while another handles GET requests. Modifying a Response with Middleware A middleware controller can add a response modifier to a request. When an endpoint controller eventually creates a response, these modifiers are applied to the response before it is sent. Modifiers are added by invoking addResponseModifier on a request. class Versioner extends Controller { Future RequestOrResponse handle ( Request request ) async { request . addResponseModifier (( response ) { response . headers [ x-api-version ] = 2.1 ; }); return request ; } } Any number of controllers can add a response modifier to a request; they will be processed in the order that they were added. Response modifiers are applied before the response body is encoded, allowing the body object to be manipulated. Response modifiers are invoked regardless of the response generated by the endpoint controller. If an uncaught error is thrown while adding response modifiers, any remaining response modifiers are not called and a 500 Server Error response is sent. Linking Functions For simple behavior, functions with the same signature as handle can be linked to controllers: router . route ( /path ) . linkFunction (( req ) async = req ); . linkFunction (( req ) async = new Response . ok ( null )); Linking a function has all of the same behavior as Controller.handle : it can return a request or response, automatically handles exceptions, and can have controllers (and functions) linked to it. Controller Instantiation and Recycling It is important to understand why link takes a closure, instead of a controller object. Aqueduct is an object oriented framework. Objects have both state and behavior. An application will receive multiple requests that will be handled by the same type of controller. If a mutable controller object were reused to handle multiple requests, it could retain some of its state between requests. This would create problems that are difficult to debug. Most controllers are immutable - in other words, all of their properties are final and they have no setters. This (mostly) ensures that the controller won't change behavior between requests. When a controller is immutable, the link closure is invoked once to create and link the controller object, and then the closure is discarded. The same controller object will be reused for every request. Controllers can be mutable, with the caveat that they cannot be reused for multiple requests. For example, a ResourceController can have properties that are bound to the values of a request, and therefore these properties will change and a new instance must be created for each request. A mutable Controller subclass must implement Recyclable T . The link closure will be invoked for each request, creating a new instance of the recyclable controller to handle the request. If a controller has an expensive initialization process, the results of that initialization can be calculated once and reused for each controller instance by implementing the methods from Recyclable T . class MyControllerState { dynamic stuff ; } class MyController extends Controller implements Recyclable MyControllerState { @ override MyControllerState get recycledState = expensiveCalculation (); @ override void restore ( MyControllerState state ) { _restoredState = state ; } MyControllerState _restoredState ; @ override FutureOr RequestOrResponse handle ( Request request ) async { /* use _restoredState */ return new Response . ok (...); } } The recycledState getter is called once, when the controller is first linked. Each new instance of a recyclable controller has its restore method invoked prior to handling the request, and the data returned by recycledState is passed as an argument. As an example, ResourceController 'compiles' its operation methods. The compiled product is stored as recycled state so that future instances can bind request data more efficiently. Exception Handling If an exception or error is thrown during the handling of a request, the controller currently handling the request will catch it. For the majority of values caught, a controller will send a 500 Server Response. The details of the exception or error will be logged , and the request is removed from the channel (it will not be passed to a linked controller). This is the default behavior for all thrown values except Response and HandlerException . Throwing Responses A Response can be thrown at any time; the controller handling the request will catch it and send it to the client. This completes the request. This might not seem useful, for example, the following shows a silly use of this behavior: class Thrower extends Controller { @ override Future RequestOrResponse handle ( Request request ) async { if ( ! isForbidden ( request )) { throw new Response . forbidden (); } return new Response . ok ( null ); } } However, it can be valuable to send error responses from elsewhere in code as an application's codebase becomes more layered. Throwing HandlerExceptions Exceptions can implement HandlerException to provide a response other than the default when thrown. For example, an application that handles bank transactions might declare an exception for invalid withdrawals: enum WithdrawalProblem { insufficientFunds , bankClosed } class WithdrawalException implements Exception { WithdrawalException ( this . problem ); final WithdrawalProblem problem ; } Controller code can catch this exception to return a different status code depending on the exact problem with a withdrawal. If this code has to be written in multiple places, it is useful for WithdrawalException to implement HandlerException . An implementor must provide an implementation for response : class WithdrawalException implements HandlerException { WithdrawalException ( this . problem ); final WithdrawalProblem problem ; @ override Response get response { switch ( problem ) { case WithdrawalProblem . insufficientFunds: return new Response . badRequest ( body: { error : insufficient_funds }); case WithdrawalProblem . bankClosed: return new Response . badRequest ( body: { error : bank_closed }); } } } The Aqueduct ORM exceptions ( QueryException ) implement HandlerException to return a response that best represents the ORM exception. For example, if a unique constraint is violated by a query, the thrown exception implements response to return a 409 Conflict response. CORS Headers and Preflight Requests Controller s have built-in behavior for handling CORS requests. They will automatically respond to OPTIONS preflight requests and attach CORS headers to any other response. See the chapter on CORS for more details.","title":"Handling Requests: Fundamentals"},{"location":"http/controller/#handling-requests-fundamentals","text":"Learn how Controller objects are linked together to handle HTTP requests.","title":"Handling Requests: Fundamentals"},{"location":"http/controller/#overview","text":"A controller is the basic building block of an Aqueduct application. A controller handles an HTTP request in some way. For example, a controller could return a 200 OK response with a JSON-encoded list of city names. A controller could also check a request to make sure it had the right credentials in its authorization header. Controllers are linked together to compose their behaviors into a channel . A channel handles a request by performing each of its controllers' behavior in order. For example, a channel with the aforementioned controllers would verify the credentials of a request and then returning a list of city names. The Controller class provides the behavior for linking controllers together, and you subclass it to provide the logic for a particular controller behavior.","title":"Overview"},{"location":"http/controller/#linking-controllers","text":"Controllers are linked with their link method. This method takes a closure that returns the next controller in the channel. The following shows a channel composed of two controllers: final controllerA = Controller (); controller . link (() = Controller ()); When controllerA handles a request, it can choose to respond to the request or let the request continue in the channel. When the request continues in this channel, the controller created by the closure passed to link handles the request. Any number of controllers can be linked together in a channel, but the last controller must respond to the request. Controllers that always responder to request are called endpoint controllers , as opposed to middleware controllers that verify or modify the request and let the next controller in the channel handle it. Linking occurs in an application channel , and is finalized during startup of your application (i.e., once you have set up your controllers, the cannot be changed once the application starts receiving requests). In a typical application, a Router controller splits an application channel into multiple sub-channels.","title":"Linking Controllers"},{"location":"http/controller/#creating-request-handling-behavior-by-subclassing-controller","text":"Every Controller implements its handle method to handle a request. You override this method in your controllers to provide the logic for your application's controllers. The following is an example of an endpoint controller, because it always sends a response: class NoteController extends Controller { @ override Future RequestOrResponse handle ( Request request ) async { final notes = await fetchNotesFromDatabase (); return new Response . ok ( notes ); } } This handle method creates and returns a Response object. When a handle method returns a response, that response is sent to the client. Any linked controllers do not have their handle method invoked; the request is removed from the channel. A middleware controller returns a response when the request is invalid. For example, an Authorizer controller returns a 401 Unauthorized response if the request's credentials are invalid (this removes the request from the channel). If a middleware controller deems the request acceptable, it returns the request from its handle method. This signals to Aqueduct that the next controller in the channel should handle the request. As an example, the pseudo-code for an Authorizer looks like this: class Authorizer extends Controller { @ override Future RequestOrResponse handle ( Request request ) async { if ( isValid ( request )) { return request ; } return new Response . unauthorized (); } } Endpoint Controllers In most cases, endpoint controllers are created by subclassing ResourceController . This controller allows you to declare more than one handler method in a controller to better organize logic. For example, one method might handle POST requests, while another handles GET requests.","title":"Creating Request Handling Behavior by Subclassing Controller"},{"location":"http/controller/#modifying-a-response-with-middleware","text":"A middleware controller can add a response modifier to a request. When an endpoint controller eventually creates a response, these modifiers are applied to the response before it is sent. Modifiers are added by invoking addResponseModifier on a request. class Versioner extends Controller { Future RequestOrResponse handle ( Request request ) async { request . addResponseModifier (( response ) { response . headers [ x-api-version ] = 2.1 ; }); return request ; } } Any number of controllers can add a response modifier to a request; they will be processed in the order that they were added. Response modifiers are applied before the response body is encoded, allowing the body object to be manipulated. Response modifiers are invoked regardless of the response generated by the endpoint controller. If an uncaught error is thrown while adding response modifiers, any remaining response modifiers are not called and a 500 Server Error response is sent.","title":"Modifying a Response with Middleware"},{"location":"http/controller/#linking-functions","text":"For simple behavior, functions with the same signature as handle can be linked to controllers: router . route ( /path ) . linkFunction (( req ) async = req ); . linkFunction (( req ) async = new Response . ok ( null )); Linking a function has all of the same behavior as Controller.handle : it can return a request or response, automatically handles exceptions, and can have controllers (and functions) linked to it.","title":"Linking Functions"},{"location":"http/controller/#controller-instantiation-and-recycling","text":"It is important to understand why link takes a closure, instead of a controller object. Aqueduct is an object oriented framework. Objects have both state and behavior. An application will receive multiple requests that will be handled by the same type of controller. If a mutable controller object were reused to handle multiple requests, it could retain some of its state between requests. This would create problems that are difficult to debug. Most controllers are immutable - in other words, all of their properties are final and they have no setters. This (mostly) ensures that the controller won't change behavior between requests. When a controller is immutable, the link closure is invoked once to create and link the controller object, and then the closure is discarded. The same controller object will be reused for every request. Controllers can be mutable, with the caveat that they cannot be reused for multiple requests. For example, a ResourceController can have properties that are bound to the values of a request, and therefore these properties will change and a new instance must be created for each request. A mutable Controller subclass must implement Recyclable T . The link closure will be invoked for each request, creating a new instance of the recyclable controller to handle the request. If a controller has an expensive initialization process, the results of that initialization can be calculated once and reused for each controller instance by implementing the methods from Recyclable T . class MyControllerState { dynamic stuff ; } class MyController extends Controller implements Recyclable MyControllerState { @ override MyControllerState get recycledState = expensiveCalculation (); @ override void restore ( MyControllerState state ) { _restoredState = state ; } MyControllerState _restoredState ; @ override FutureOr RequestOrResponse handle ( Request request ) async { /* use _restoredState */ return new Response . ok (...); } } The recycledState getter is called once, when the controller is first linked. Each new instance of a recyclable controller has its restore method invoked prior to handling the request, and the data returned by recycledState is passed as an argument. As an example, ResourceController 'compiles' its operation methods. The compiled product is stored as recycled state so that future instances can bind request data more efficiently.","title":"Controller Instantiation and Recycling"},{"location":"http/controller/#exception-handling","text":"If an exception or error is thrown during the handling of a request, the controller currently handling the request will catch it. For the majority of values caught, a controller will send a 500 Server Response. The details of the exception or error will be logged , and the request is removed from the channel (it will not be passed to a linked controller). This is the default behavior for all thrown values except Response and HandlerException .","title":"Exception Handling"},{"location":"http/controller/#throwing-responses","text":"A Response can be thrown at any time; the controller handling the request will catch it and send it to the client. This completes the request. This might not seem useful, for example, the following shows a silly use of this behavior: class Thrower extends Controller { @ override Future RequestOrResponse handle ( Request request ) async { if ( ! isForbidden ( request )) { throw new Response . forbidden (); } return new Response . ok ( null ); } } However, it can be valuable to send error responses from elsewhere in code as an application's codebase becomes more layered.","title":"Throwing Responses"},{"location":"http/controller/#throwing-handlerexceptions","text":"Exceptions can implement HandlerException to provide a response other than the default when thrown. For example, an application that handles bank transactions might declare an exception for invalid withdrawals: enum WithdrawalProblem { insufficientFunds , bankClosed } class WithdrawalException implements Exception { WithdrawalException ( this . problem ); final WithdrawalProblem problem ; } Controller code can catch this exception to return a different status code depending on the exact problem with a withdrawal. If this code has to be written in multiple places, it is useful for WithdrawalException to implement HandlerException . An implementor must provide an implementation for response : class WithdrawalException implements HandlerException { WithdrawalException ( this . problem ); final WithdrawalProblem problem ; @ override Response get response { switch ( problem ) { case WithdrawalProblem . insufficientFunds: return new Response . badRequest ( body: { error : insufficient_funds }); case WithdrawalProblem . bankClosed: return new Response . badRequest ( body: { error : bank_closed }); } } } The Aqueduct ORM exceptions ( QueryException ) implement HandlerException to return a response that best represents the ORM exception. For example, if a unique constraint is violated by a query, the thrown exception implements response to return a 409 Conflict response.","title":"Throwing HandlerExceptions"},{"location":"http/controller/#cors-headers-and-preflight-requests","text":"Controller s have built-in behavior for handling CORS requests. They will automatically respond to OPTIONS preflight requests and attach CORS headers to any other response. See the chapter on CORS for more details.","title":"CORS Headers and Preflight Requests"},{"location":"http/request_and_response/","text":"Request and Response Objects; Serialization In Aqueduct, HTTP requests and responses are instances of Request and Response , respectively. For every HTTP request an application receives, an instance of Request is created. A Response must be created for each Request . Requests pass through a channel of Controllers to be validated, modified and finally responded to. The Request Object An instance of Request represents an HTTP request and are automatically created when the application receives a request. A Request is a wrapper around the Dart standard library HttpRequest and its values - such as its URI or headers - can be accessed through its raw property. A Request has a body property. This property decodes the body contents into Dart objects based on the request's content type. The mechanism to decode the body is determined by CodecRegistry , which is covered in more detail in a later section. By default, decoders exist for text, JSON and form data. The size of a request body is limited to 10MB by default and can be changed by setting the value of RequestBody.maxSize during application initialization. A Request is handled by one or more Controller s before to be responded to. Controller s may validate or add more information to the request, so that later controllers can use this information. For example, an Authorizer controller will validate the Authorization header of a request. Once validated, it will add authorization info to the request - like the authorized user ID - and pass it to the next controller. The next controller in the channel has access to the authorization info without having to perform another fetch. These additional values are added to a Request.attachments property. Subsequent controllers can access these values. class APIKeyController extends Controller { APIKeyController ( this . apiService ); final APIService apiService ; @ override Future RequestOrResponse handle ( Request request ) async { final apiKey = request . raw . headers . value ( x-api-key ); if ( apiKey == null ) { return Response . badRequest ( body: { error : missing required header x-api-key }); } request . attachments [ clientId ] = await apiService . getClientId ( apiKey ); return request ; } } A Request also has two built-in attachments, authorization and path . authorization contains authorization information from an Authorizer and path has request path information from a Router . Request s are responded to when a controller creates a Response . The Response Object An instance of Response represents the status code, headers and body of an HTTP response. Response objects are returned from controller methods like handle or a ResourceController operation method . Aqueduct sends the contents of a response returned from a controller to the requesting HTTP client. The default constructor takes a status code, header map and body object. There are many named constructors for common response types: Response ( 200 , { x-header : value }, body: [ 1 , 2 , 3 ]); Response . ok ({ key : value }); Response . created (); Response . badRequest ( body: { error : reason }); A response can be modified after it is created by middleware controllers. Middleware controllers add response modifiers to a Request ; when the response is created for that request, the modifiers are ran in the order they were added. class RequestIdentifyingController extends Controller { @ override Future RequestOrResponse handle ( Request request ) async { // Invoked after another controller in the channel creates a response request . addResponseModifier (( resp ) { resp . headers [ x-request-id ] = generateRequestId (); }); return request ; } } Headers are encoded according to dart:io.HttpHeaders.add . For body encoding behavior, see the following sections. Encoding and Decoding the HTTP Body Request and Response objects have behavior for handling the HTTP body. You decode the contents of a Request body into Dart objects that are used in your code. You provide a Dart object to a Response and it is automatically encoded according to the content-type of the response. Decoding Request Bodies Every Request has a Request.body property. This object decodes the bytestream from the request body into Dart objects, and caches that decoded object for subsequent access. The behavior for decoding is determined by the content-type header of the request (see the section on CodecRegistry later in this guide). When you decode a body, you can specify the Dart object type you expect it to be. If the decoded body object is not the expected type, an exception that sends a 400 Bad Request error is thrown. // Ensures that the decoded body is a Map String, dynamic final map = await request . body . decode Map String , dynamic (); // Takes whatever object the body is decoded into final anyObject = await request . body . decode (); Once a request's body has been decoded, it can be accessed through a synchronous as method. This method also takes a type argument to enforce the type of the decoded body object. final map = request . body . as Map String , dynamic (); Inferred Types You don't need to provide a type argument to as or decode if the type can be inferred. For example, ManagedObject.readFromMap(await request.body.decode()) will infer the type of the decoded body as a Map String, dynamic without having to provide type parameters. If a body cannot be decoded according to its content-type (the data is malformed), an error is thrown that sends the appropriate error response to the client. By default, the maximum size of a request body is 10MB (see RequestBody.maxSize ). For more request body behavior, see the API reference for RequestBody , the section on body binding for ResourceControllers and a later section in this guide on Serializable . Encoding Response Body Objects An HTTP response often contains a body . For example, the body in response to GET /users/1 might be JSON object that represents a user. To ensure the client understands that the body is a JSON object, it includes the header Content-Type: application/json; charset=utf-8 . When creating a Response that has a body, you provide a body object and a contentType . For example: var map = { key : value }; // ContentType.json is the default, setting it may be omitted. // ContentType.json == `application/json; charset=utf-8 final response = Response . ok ( map ) .. contentType = ContentType . json ; Body objects are encoded according to their content-type. In the above, map is first encoded as a JSON string and then to a list of UTF8 bytes. A ContentType is made up of three components: a primary type, a subtype and an optional character set. The primary and subtype determine the first conversion step and the charset determines the next. Each step is performed by an instance of Codec (from dart:convert ). For example, the content type application/json selects JsonCodec , while charset utf-8 selects Utf8Codec . These two codecs are run in succession to convert the Map to a list of bytes. The codec is selected by your application's CodecRegistry ; this is covered in later section. The body object must be a valid input for the selected codec. In the above example, a Map String, dynamic can be encoded by a JsonCodec . But if the body object was something silly - like an Controller - encoding would fail at runtime and the client would be sent a 500 Server Error response. A valid input for one Codec may not be valid for another; it is up to you to ensure that the body object is valid for the contentType of the response. Not all content types require two conversion steps. For example, when serving an HTML file, the body object is already an HTML String . It will only be converted by a charset encoder: var html = html /html ; var response = Response . ok ( html ) .. contentType = ContentType . html ; And an image body object needs no conversion at all, since it is already a list of bytes. If there is no registered codec for a content-type, the body object must be a byte array ( List int where each value is between 0-255). final imageFile = File ( image.jpg ); final imageBytes = await imageFile . readAsBytes (); final response = Response . ok ( imageBytes ) .. contentType = ContentType ( image , jpeg ); You may disable the automatic encoding of a body as long as the body object is a byte array: final jsonBytes = utf8 . encode ( json . encode ({ key : value })); final response = Response . ok ( jsonBytes ).. encodeBody = false ; See a later section for more details on content type to codec mappings. Also, see the documentation for CodecRegistry for details on built-in codecs and adding codecs. Streaming Response Bodies A body object may also be a Stream T . Stream T body objects are most often used when serving files. This allows the contents of the file to be streamed from disk to the HTTP client without having to load the whole file into memory first. (See also FileController .) final imageFile = File ( image.jpg ); final imageByteStream = imageFile . openRead (); final response = new Response . ok ( imageByteStream ) .. contentType = new ContentType ( image , jpeg ); When a body object is a Stream T , the response will not be sent until the stream is closed. For finite streams - like those from opened filed - this happens as soon as the entire file is read. For streams that you construct yourself, you must close the stream some time after the response has been returned. Codecs and Content Types In the above sections, we glossed over how a codec gets selected when preparing the response body. The common case of ManagedObject T body objects that are sent as UTF8 encoded JSON 'just works' and is suitable for most applications. When serving assets for a web application or different data formats like XML, it becomes important to understand how Aqueduct's codec registry works. CodecRegistry contains mappings from content types to Codec s. These codecs encode response bodies and decode request bodies. There are three built-in codecs for application/json , application/x-www-form-urlencoded and text/* . When a response is being sent, the repository is searched for an entry that exactly matches the primary and subtype of the Response.contentType . If an entry exists, the associated Codec starts the conversion. For example, if the content type is application/json; charset=utf-8 , the built-in application/json codec encodes the body object. If there isn't an exact match, but there is an entry for the primary type with the wildcard ( * ) subtype, that codec is used. For example, the built-in codec for text/* will be selected for both text/plain and text/html . If there was something special that had to be done for text/html , a more specific codec may be added for that type: class MyChannel extends ApplicationChannel { @ override Future prepare () async { CodecRegistry . defaultInstance . add ( ContentType ( application , html ), HTMLCodec ()); } } Codecs must be added in your ApplicationChannel.prepare method. The codec must implement Codec from dart:convert . In the above example, when a response's content type is text/html , the HTMLCodec will encode the body object. This codec takes precedence over text/* because it is more specific. When selecting a codec for a response body, the ContentType.charset doesn't impact which codec is selected. If a response's content-type has a charset, then a charset encoder like UTF8 will be applied as a last encoding step. For example, a response with content-type application/json; charset=utf-8 will encode the body object as a JSON string, which is then encoded as a list of UTF8 bytes. It is required that a response body's eventually encoded type is a list of bytes, so it follows that a codec that produces a string must have a charset. If there is no codec in the repository for the content type of a Response , the body object must be a List int or Stream List int . If you find yourself converting data prior to setting it as a body object, it may make sense to add your own codec to CodecRegistry . A request's body always starts as a list of bytes and is decoded into Dart objects. To decode a JSON request body, it first must be decoded from the list of UTF8 bytes into a string. It is possible that a client could omit the charset in its content-type header. Codecs added to CodecRegistry may specify a default charset to interpret a charset-less content-type. When a codec is added to the repository, if content-type's charset is non-null, that is the default. For example, the JSON codec is added like this: CodecRegistry . defaultInstance . add ( ContentType ( application , json , charset: utf-8 ), const JsonCodec (), allowCompression: true ); If no charset is specified when registering a codec, no charset decoding occurs on a request body if one doesn't exist. Content-types that are decoded from a String should not use a default charset because the repository would always attempt to decode the body as a string first. Compression with gzip Body objects may be compressed with gzip if the HTTP client allows it and the CodecRegistry has been configured to compress the content type of the response. The three built-in codecs - application/json , application/x-www-form-urlencoded and text/* - are all configured to allow compression. Compression occurs as the last step of conversion and only if the HTTP client sends the Accept-Encoding: gzip header. Content types that are not in the codec repository will not trigger compression, even if the HTTP client allows compression with the Accept-Encoding header. This is to prevent binary contents like images from being 'compressed', since they are likely already compressed by a content-specific algorithm. In order for Aqueduct to compress a content type other than the built-in types, you may add a codec to the repository with the allowCompression flag. (The default value is true .) CodecRegistry . add ( ContentType ( application , x-special ), MyCodec (), allowCompression: true ); You may also set whether or not a content type uses compression without having to specify a codec if no conversion step needs to occur: CodecRegistry . setAllowsCompression ( new ContentType ( application , x-special ), true ); Serializable Objects Encoding and decoding primarily takes or yields simple Dart objects like Map , List and String . It is often beneficial to add structure to body objects for use in your code. Classes that implement Serializable provide this structure. A Serializable object must implement a readFromMap() and asMap() method to convert their structure into or from a Dart Map . An object that extends Serializable may be used as a response body object directly: class Person extends Serializable { String name ; String email ; Map String , dynamic asMap () { return { name : name , email : email }; } void readFromMap ( Map String , dynamic inputMap ) { name = inputMap [ name ]; email = inputMap [ email ]; } } final person = Person (); final response = Response . ok ( person ); When responding with a Serializable , its asMap() is called prior to any encoding by the codec registry. ManagedObject T , part of the Aqueduct ORM, implements Serializable so results from Query T may be body objects: final query = Query Person ( context ).. where (( p ) = p . id ). equalTo ( 1 ); final person = await query . fetchOne (); final response = Response . ok ( person ); A response body object can also be a list of Serializable objects. final query = Query Person ( context ); final people = await query . fetch (); final response = Response . ok ( people ); The entire flow of a body object is shown in the following diagram. Each orange item is an allowed body object type and shows the steps it will go through when being encoded to the HTTP response body. For example, a Serializable goes through three steps, whereas a List int goes through zero steps and is added as-is to the HTTP response. A serializable object can be read from a request body: final person = Person ().. readFromMap ( await request . body . decode ()); Serializable objects are the only types of objects that can be bound to a ResourceController argument . @ Operation . post () Future Response addPerson ( @ Bind . body () Person person ) async { final insertedPerson = await Query . insertObject ( context , person ); return Response . ok ( insertedPerson ); } Serializable and OpenAPI Generation See the section on how Serializable types work with OpenAPI documentation generation here .","title":"Request and Response Objects; Serialization"},{"location":"http/request_and_response/#request-and-response-objects-serialization","text":"In Aqueduct, HTTP requests and responses are instances of Request and Response , respectively. For every HTTP request an application receives, an instance of Request is created. A Response must be created for each Request . Requests pass through a channel of Controllers to be validated, modified and finally responded to.","title":"Request and Response Objects; Serialization"},{"location":"http/request_and_response/#the-request-object","text":"An instance of Request represents an HTTP request and are automatically created when the application receives a request. A Request is a wrapper around the Dart standard library HttpRequest and its values - such as its URI or headers - can be accessed through its raw property. A Request has a body property. This property decodes the body contents into Dart objects based on the request's content type. The mechanism to decode the body is determined by CodecRegistry , which is covered in more detail in a later section. By default, decoders exist for text, JSON and form data. The size of a request body is limited to 10MB by default and can be changed by setting the value of RequestBody.maxSize during application initialization. A Request is handled by one or more Controller s before to be responded to. Controller s may validate or add more information to the request, so that later controllers can use this information. For example, an Authorizer controller will validate the Authorization header of a request. Once validated, it will add authorization info to the request - like the authorized user ID - and pass it to the next controller. The next controller in the channel has access to the authorization info without having to perform another fetch. These additional values are added to a Request.attachments property. Subsequent controllers can access these values. class APIKeyController extends Controller { APIKeyController ( this . apiService ); final APIService apiService ; @ override Future RequestOrResponse handle ( Request request ) async { final apiKey = request . raw . headers . value ( x-api-key ); if ( apiKey == null ) { return Response . badRequest ( body: { error : missing required header x-api-key }); } request . attachments [ clientId ] = await apiService . getClientId ( apiKey ); return request ; } } A Request also has two built-in attachments, authorization and path . authorization contains authorization information from an Authorizer and path has request path information from a Router . Request s are responded to when a controller creates a Response .","title":"The Request Object"},{"location":"http/request_and_response/#the-response-object","text":"An instance of Response represents the status code, headers and body of an HTTP response. Response objects are returned from controller methods like handle or a ResourceController operation method . Aqueduct sends the contents of a response returned from a controller to the requesting HTTP client. The default constructor takes a status code, header map and body object. There are many named constructors for common response types: Response ( 200 , { x-header : value }, body: [ 1 , 2 , 3 ]); Response . ok ({ key : value }); Response . created (); Response . badRequest ( body: { error : reason }); A response can be modified after it is created by middleware controllers. Middleware controllers add response modifiers to a Request ; when the response is created for that request, the modifiers are ran in the order they were added. class RequestIdentifyingController extends Controller { @ override Future RequestOrResponse handle ( Request request ) async { // Invoked after another controller in the channel creates a response request . addResponseModifier (( resp ) { resp . headers [ x-request-id ] = generateRequestId (); }); return request ; } } Headers are encoded according to dart:io.HttpHeaders.add . For body encoding behavior, see the following sections.","title":"The Response Object"},{"location":"http/request_and_response/#encoding-and-decoding-the-http-body","text":"Request and Response objects have behavior for handling the HTTP body. You decode the contents of a Request body into Dart objects that are used in your code. You provide a Dart object to a Response and it is automatically encoded according to the content-type of the response.","title":"Encoding and Decoding the HTTP Body"},{"location":"http/request_and_response/#decoding-request-bodies","text":"Every Request has a Request.body property. This object decodes the bytestream from the request body into Dart objects, and caches that decoded object for subsequent access. The behavior for decoding is determined by the content-type header of the request (see the section on CodecRegistry later in this guide). When you decode a body, you can specify the Dart object type you expect it to be. If the decoded body object is not the expected type, an exception that sends a 400 Bad Request error is thrown. // Ensures that the decoded body is a Map String, dynamic final map = await request . body . decode Map String , dynamic (); // Takes whatever object the body is decoded into final anyObject = await request . body . decode (); Once a request's body has been decoded, it can be accessed through a synchronous as method. This method also takes a type argument to enforce the type of the decoded body object. final map = request . body . as Map String , dynamic (); Inferred Types You don't need to provide a type argument to as or decode if the type can be inferred. For example, ManagedObject.readFromMap(await request.body.decode()) will infer the type of the decoded body as a Map String, dynamic without having to provide type parameters. If a body cannot be decoded according to its content-type (the data is malformed), an error is thrown that sends the appropriate error response to the client. By default, the maximum size of a request body is 10MB (see RequestBody.maxSize ). For more request body behavior, see the API reference for RequestBody , the section on body binding for ResourceControllers and a later section in this guide on Serializable .","title":"Decoding Request Bodies"},{"location":"http/request_and_response/#encoding-response-body-objects","text":"An HTTP response often contains a body . For example, the body in response to GET /users/1 might be JSON object that represents a user. To ensure the client understands that the body is a JSON object, it includes the header Content-Type: application/json; charset=utf-8 . When creating a Response that has a body, you provide a body object and a contentType . For example: var map = { key : value }; // ContentType.json is the default, setting it may be omitted. // ContentType.json == `application/json; charset=utf-8 final response = Response . ok ( map ) .. contentType = ContentType . json ; Body objects are encoded according to their content-type. In the above, map is first encoded as a JSON string and then to a list of UTF8 bytes. A ContentType is made up of three components: a primary type, a subtype and an optional character set. The primary and subtype determine the first conversion step and the charset determines the next. Each step is performed by an instance of Codec (from dart:convert ). For example, the content type application/json selects JsonCodec , while charset utf-8 selects Utf8Codec . These two codecs are run in succession to convert the Map to a list of bytes. The codec is selected by your application's CodecRegistry ; this is covered in later section. The body object must be a valid input for the selected codec. In the above example, a Map String, dynamic can be encoded by a JsonCodec . But if the body object was something silly - like an Controller - encoding would fail at runtime and the client would be sent a 500 Server Error response. A valid input for one Codec may not be valid for another; it is up to you to ensure that the body object is valid for the contentType of the response. Not all content types require two conversion steps. For example, when serving an HTML file, the body object is already an HTML String . It will only be converted by a charset encoder: var html = html /html ; var response = Response . ok ( html ) .. contentType = ContentType . html ; And an image body object needs no conversion at all, since it is already a list of bytes. If there is no registered codec for a content-type, the body object must be a byte array ( List int where each value is between 0-255). final imageFile = File ( image.jpg ); final imageBytes = await imageFile . readAsBytes (); final response = Response . ok ( imageBytes ) .. contentType = ContentType ( image , jpeg ); You may disable the automatic encoding of a body as long as the body object is a byte array: final jsonBytes = utf8 . encode ( json . encode ({ key : value })); final response = Response . ok ( jsonBytes ).. encodeBody = false ; See a later section for more details on content type to codec mappings. Also, see the documentation for CodecRegistry for details on built-in codecs and adding codecs.","title":"Encoding Response Body Objects"},{"location":"http/request_and_response/#streaming-response-bodies","text":"A body object may also be a Stream T . Stream T body objects are most often used when serving files. This allows the contents of the file to be streamed from disk to the HTTP client without having to load the whole file into memory first. (See also FileController .) final imageFile = File ( image.jpg ); final imageByteStream = imageFile . openRead (); final response = new Response . ok ( imageByteStream ) .. contentType = new ContentType ( image , jpeg ); When a body object is a Stream T , the response will not be sent until the stream is closed. For finite streams - like those from opened filed - this happens as soon as the entire file is read. For streams that you construct yourself, you must close the stream some time after the response has been returned.","title":"Streaming Response Bodies"},{"location":"http/request_and_response/#codecs-and-content-types","text":"In the above sections, we glossed over how a codec gets selected when preparing the response body. The common case of ManagedObject T body objects that are sent as UTF8 encoded JSON 'just works' and is suitable for most applications. When serving assets for a web application or different data formats like XML, it becomes important to understand how Aqueduct's codec registry works. CodecRegistry contains mappings from content types to Codec s. These codecs encode response bodies and decode request bodies. There are three built-in codecs for application/json , application/x-www-form-urlencoded and text/* . When a response is being sent, the repository is searched for an entry that exactly matches the primary and subtype of the Response.contentType . If an entry exists, the associated Codec starts the conversion. For example, if the content type is application/json; charset=utf-8 , the built-in application/json codec encodes the body object. If there isn't an exact match, but there is an entry for the primary type with the wildcard ( * ) subtype, that codec is used. For example, the built-in codec for text/* will be selected for both text/plain and text/html . If there was something special that had to be done for text/html , a more specific codec may be added for that type: class MyChannel extends ApplicationChannel { @ override Future prepare () async { CodecRegistry . defaultInstance . add ( ContentType ( application , html ), HTMLCodec ()); } } Codecs must be added in your ApplicationChannel.prepare method. The codec must implement Codec from dart:convert . In the above example, when a response's content type is text/html , the HTMLCodec will encode the body object. This codec takes precedence over text/* because it is more specific. When selecting a codec for a response body, the ContentType.charset doesn't impact which codec is selected. If a response's content-type has a charset, then a charset encoder like UTF8 will be applied as a last encoding step. For example, a response with content-type application/json; charset=utf-8 will encode the body object as a JSON string, which is then encoded as a list of UTF8 bytes. It is required that a response body's eventually encoded type is a list of bytes, so it follows that a codec that produces a string must have a charset. If there is no codec in the repository for the content type of a Response , the body object must be a List int or Stream List int . If you find yourself converting data prior to setting it as a body object, it may make sense to add your own codec to CodecRegistry . A request's body always starts as a list of bytes and is decoded into Dart objects. To decode a JSON request body, it first must be decoded from the list of UTF8 bytes into a string. It is possible that a client could omit the charset in its content-type header. Codecs added to CodecRegistry may specify a default charset to interpret a charset-less content-type. When a codec is added to the repository, if content-type's charset is non-null, that is the default. For example, the JSON codec is added like this: CodecRegistry . defaultInstance . add ( ContentType ( application , json , charset: utf-8 ), const JsonCodec (), allowCompression: true ); If no charset is specified when registering a codec, no charset decoding occurs on a request body if one doesn't exist. Content-types that are decoded from a String should not use a default charset because the repository would always attempt to decode the body as a string first.","title":"Codecs and Content Types"},{"location":"http/request_and_response/#compression-with-gzip","text":"Body objects may be compressed with gzip if the HTTP client allows it and the CodecRegistry has been configured to compress the content type of the response. The three built-in codecs - application/json , application/x-www-form-urlencoded and text/* - are all configured to allow compression. Compression occurs as the last step of conversion and only if the HTTP client sends the Accept-Encoding: gzip header. Content types that are not in the codec repository will not trigger compression, even if the HTTP client allows compression with the Accept-Encoding header. This is to prevent binary contents like images from being 'compressed', since they are likely already compressed by a content-specific algorithm. In order for Aqueduct to compress a content type other than the built-in types, you may add a codec to the repository with the allowCompression flag. (The default value is true .) CodecRegistry . add ( ContentType ( application , x-special ), MyCodec (), allowCompression: true ); You may also set whether or not a content type uses compression without having to specify a codec if no conversion step needs to occur: CodecRegistry . setAllowsCompression ( new ContentType ( application , x-special ), true );","title":"Compression with gzip"},{"location":"http/request_and_response/#serializable-objects","text":"Encoding and decoding primarily takes or yields simple Dart objects like Map , List and String . It is often beneficial to add structure to body objects for use in your code. Classes that implement Serializable provide this structure. A Serializable object must implement a readFromMap() and asMap() method to convert their structure into or from a Dart Map . An object that extends Serializable may be used as a response body object directly: class Person extends Serializable { String name ; String email ; Map String , dynamic asMap () { return { name : name , email : email }; } void readFromMap ( Map String , dynamic inputMap ) { name = inputMap [ name ]; email = inputMap [ email ]; } } final person = Person (); final response = Response . ok ( person ); When responding with a Serializable , its asMap() is called prior to any encoding by the codec registry. ManagedObject T , part of the Aqueduct ORM, implements Serializable so results from Query T may be body objects: final query = Query Person ( context ).. where (( p ) = p . id ). equalTo ( 1 ); final person = await query . fetchOne (); final response = Response . ok ( person ); A response body object can also be a list of Serializable objects. final query = Query Person ( context ); final people = await query . fetch (); final response = Response . ok ( people ); The entire flow of a body object is shown in the following diagram. Each orange item is an allowed body object type and shows the steps it will go through when being encoded to the HTTP response body. For example, a Serializable goes through three steps, whereas a List int goes through zero steps and is added as-is to the HTTP response. A serializable object can be read from a request body: final person = Person ().. readFromMap ( await request . body . decode ()); Serializable objects are the only types of objects that can be bound to a ResourceController argument . @ Operation . post () Future Response addPerson ( @ Bind . body () Person person ) async { final insertedPerson = await Query . insertObject ( context , person ); return Response . ok ( insertedPerson ); }","title":"Serializable Objects"},{"location":"http/request_and_response/#serializable-and-openapi-generation","text":"See the section on how Serializable types work with OpenAPI documentation generation here .","title":"Serializable and OpenAPI Generation"},{"location":"http/resource_controller/","text":"ResourceController A ResourceController is a controller that provide conveniences for implementing endpoint controllers. A ResourceController must be subclassed, and in that subclass, you write a method for each operation on that type of resource. For example, a UserController might handle the following operations: creating a new user ( POST /users ) getting all users ( GET /users ) getting an individual user ( GET /users/:id ) updating an individual user ( PUT /users/:id ) deleting an individual user ( DELETE /users/:id ) These methods that are invoked for an operation are called operation methods . Operation Methods An operation method is an instance method of a ResourceController subclass that has an @Operation annotation. It must return an instance of Future Response . Here's an example: class CityController extends ResourceController { @ Operation . get () Future Response getAllCities () async { return new Response . ok ([ Atlanta , Madison , Mountain View ]); } } The above operation method will be invoked when CityController handles GET requests without path variables. To handle operation methods with path variables, the name of the path variable is added to the @Operation annotation: class CityController extends ResourceController { @ Operation . get () Future Response getAllCities () async { return new Response . ok ([ Atlanta , Madison , Mountain View ]); } @ Operation . get ( name ) Future Response getCityByName () async { final id = request . path . variables [ name ]; return new Response . ok ( fetchCityWithName ( name )); } } Path Variables This controller would be linked to the route specification /cities/[:name] , so that it can handle both of these operations. Read more about path variables in Routing . The named constructor of Operation tells us which HTTP method the operation method handles. The following named constructors exist: Operation.post() Operation.get() Operation.put() Operation.delete() The canonical Operation() constructor takes the HTTP method as its first argument for non-standard operations, e.g.: @ Operation ( PATCH , id ) Future Response patchObjectWithID () async = ...; All Operation constructors take a variable list of path variables. There can be multiple path variables for an operation. An operation method will only be invoked if all of its path variables are present in the request path. There can be multiple operation methods for a given HTTP method, as long as each expects a different set of path variables. Here's an example of an operation that requires two path variables: @ Operation . get ( userID , itemID ) Future Response getUserItem () async { final userID = request . path . variables [ userID ]; final itemID = request . path . variables [ itemID ]; return new Response . ok (...); } If no operation method exists for a request, a 405 Method Not Allowed response is automatically sent and no operation method is invoked. Routing to a ResourceController A ResourceController subclass must be preceded by a Router in the application channel. The Router will parse path variables so that the controller can use them to determine which operation method should be invoked. A typical route to a ResourceController contains an optional identifying path variable: router . route ( /cities/[:name] ) . link (() = new CityController ()); This route would allow CityController to implement operation methods for all HTTP methods with both no path variables and the 'name' path variable. It is considered good practice to break sub-resources into their own controller. For example, the following is preferred: router . route ( /cities/[:name] ) . link (() = new CityController ()); router . route ( /cities/:name/attractions/[:id] ) . link (() = new CityAttractionController ()); By contrast, the route /cities/[:name/[attractions/[:id]]] , while valid, makes controller logic much more unwieldy. Request Bindings Operation methods may bind properties of an HTTP request to its parameters. When the operation method is invoked, the value of that property is passed as an argument to the operation method. For example, the following binds the header named 'X-API-Key' to the argument apiKey : @ Operation . get ( name ) Future Response getCityByName ( @ Bind . path ( x-api-key ) String apiKey ) async { if ( ! isValid ( apiKey )) { return new Response . unauthorized (); } return new Response . ok (...); } The following table shows the possible types of bindings: Property Binding Path Variable @Bind.path(pathVariableName) URL Query Parameter @Bind.query(queryParameterName) Header @Bind.header(headerName) Request Body @Bind.body() You may bind any number of HTTP request properties to a single operation method. Optional Bindings Bindings can be made optional. If a binding is optional, the operation method will still be called even if the bound property isn't in a request. To make a binding optional, move it to the optional parameters of an operation method: @ Operation . get () Future Response getAllCities ({ @ Bind . header ( x-api-key ) String apiKey }) async { if ( apiKey == null ) { // No X-API-Key in request ... } ... } A bound parameter will be null if not in the request. Like any other Dart optional parameter, you can provide a default value: @ Operation . get () Future Response getAllCities ({ @ Bind . header ( x-api-key ) String apiKey: public }) async { ... } Automatically Parsing Bindings Query, header and path bindings can automatically be parsed into other types, such as int or DateTime . Simply declare the bound parameter's type to the desired type: Future Response getCityByID ( @ Bind . query ( id ) int cityID ) The type of a bound parameter may be String or any type that implements parse (e.g., int , DateTime ). Query parameters may also be bound to bool parameters; a boolean query parameter will be true if the query parameter has no value (e.g. /path?boolean ). If parsing fails for any reason, an error response is sent and the operation method is not called. For example, the above example binds int cityID - if the path variable 'id' can't be parsed into an int , a 404 Not Found response is sent. If a query parameter or header value cannot be parsed, a 400 Bad Request response is sent. You may also bind List T parameters to headers and query parameters, where T must meet the same criteria as above. Query parameters and headers may appear more than once in a request. For example, the value of ids is [1, 2] if the request URL ends with /path?id=1 id=2 and the operation method looks like this: Future Response getCitiesByIDs ( @ Bind . query ( id ) List int ids ) Note that if a parameter is not bound to a list and there are multiple occurrences of that property in the request, a 400 Bad Request response will be sent. If you want to allow multiple values, you must bind to a List T . Header Bindings The following operation method binds the header named X-API-Key to the apiKey parameter: class CityController extends ResourceController { @ Operation . get () Future Response getAllCities ( @ Bind . header ( x-api-key ) String apiKey ) async { if ( ! isValid ( apiKey )) { return new Response . unauthorized (); } return new Response . ok ([ Atlanta , Madison , Mountain View ]); } } If an X-API-Key header is present in the request, its value will be available in apiKey . If it is not, getAllCities(apiKey) would not be called and a 400 Bad Request response will be sent. If apiKey were optional, the method is called as normal and apiKey is null or a default value. Header names are case-insensitive per the HTTP specification. Therefore, the header name may be 'X-API-KEY', 'X-Api-Key' 'x-api-key', etc. and apiKey will be bound in all cases. Query Parameter Bindings The following operation methods binds the query parameter named 'name' to the parameter cityName : class CityController extends ResourceController { @Operation.get() Future getAllCities(@Bind.query('name') String cityName) async { return new Response.ok(cities.where((c) = c.name == cityName).toList()); } } Query parameters can be required or optional. If required, a 400 Bad Request response is sent and no operation method is called if the query parameter is not present in the request URL. If optional, the bound variable is null or a default value. Query parameters are case-sensitive; this binding will only match the query parameter 'name', but not 'Name' or 'NAME'. Query parameters may also bound for query strings in the request body when the content-type is 'application/x-www-form-urlencoded'. Path Variable Bindings The following operation method binds the path variable 'id' to the parameter cityID : class CityController extends ResourceController { @ Operation . get ( id ) Future Response getCityByID ( @ Bind . query ( id ) String cityID ) async { return new Response . ok ( cities . where (( c ) = c . id == cityID ). toList ()); } } Path variables are made available when creating routes . A Router must have a route that includes a path variable and that path variable must be listed in the Operation annotation. Path variables are case-sensitive and may not be optional. If you attempt to bind a path variable that is not present in the Operation , you will get a runtime exception at startup. You do not have to bind path variables for an operation method to be invoked. HTTP Request Body Bindings The body of an HTTP request can also be bound to a parameter: class CityController extends ResourceController { CityController ( this . context ); final ManagedContext context ; @ Operation . post () Future Response addCity ( @ Bind . body () City city ) async { final insertedCity = await Query . insertObject ( context , city ); return new Response . ok ( insertedCity ); } } Since there is only one request body, Bind.body() doesn't take any identifying arguments. The bound parameter type ( City in this example) must implement Serializable . This interface requires two methods to be implemented: one to read data from a request body and another to write data to a response body. Here is an example: class City extends Serializable { int id ; String name ; @ override void readFromMap ( Map String , dynamic map ) { id = map [ id ]; name = map [ name ]; } @ override Map String , dynamic asMap () { return { id : id , name : name } } } ManagedObject and Serializable ManagedObject s from Aqueduct's ORM implement Serializable without having to implement these two methods. Aqueduct will automatically decode the request body from it's content-type, create a new instance of the bound parameter type, and invoke its readFromMap method. In the above example, a valid request body would be the following JSON: { id : 1 , name : Atlanta } HTTP Body Decoding Request bodies are decoded according to their content-type prior to being deserialized. For more information on request body decoding, including decoding content-types other than JSON, see this guide . If parsing fails or readFromMap throws an exception, a 400 Bad Request response will be sent and the operation method won't be called. You may also bind List Serializable parameters to the request body. Consider the following JSON that contains a list of cities: [ { id : 1 , name : Atlanta }, { id : 2 , name : Madison } ] This body can be bound by declaring the bound parameter to be a List of the desired type: Future Response addCity ( @ Bind . body () List City cities ) !!! tip 'List vs Object' An endpoint should either take a single object or a list of objects, but not both. If the request body is a JSON list and the bound variable is not a list, a 400 Bad Request response will be sent (and vice versa). Declaring a body binding of the appropriate type validates the expected value and aids in automatically generating an OpenAPI specification for your application. Note that if the request's Content-Type is 'x-www-form-urlencoded', its must be bound with Bind.query and not Bind.body . Property Binding The properties of an ResourceController s may also have Bind.query and Bind.header metadata. This binds values from the request to the ResourceController instance itself, making them accessible from all operation methods. class CityController extends ResourceController { @ requiredBinding @ Bind . header ( x-timestamp ) DateTime timestamp ; @ Bind . query ( limit ) int limit ; @ Operation . get () Future Response getCities () async { // can use both limit and timestamp } } In the above, both timestamp and limit are bound prior to getCities being invoked. By default, a bound property is optional. Adding an requiredBinding annotation changes a property to required. If required, any request without the required property fails with a 400 Bad Request status code and none of the operation methods are invoked. Other ResourceController Behavior Besides binding, ResourceController s have some other behavior that is important to understand. Request and Response Bodies An ResourceController can limit the content type of HTTP request bodies it accepts. By default, an ResourceController will accept only application/json request bodies for its POST and PUT methods. This can be modified by setting the acceptedContentTypes property in the constructor. class UserController extends ResourceController { UserController () { acceptedContentTypes = [ ContentType . JSON , ContentType . XML ]; } } If a request is made with a content type other than the accepted content types, the controller automatically responds with a 415 Unsupported Media Type response. The body of an HTTP request is decoded if the content type is accepted and there exists a operation method to handle the request. The body is not decoded if there is not a matching operation method for the request. The body is decoded by ResourceController prior to your operation method being invoked. Therefore, you can always use the synchronous RequestBody.as method to access the body from within an operation method: @ Operation . post () Future Response createThing () async { // do this: Map String , dynamic bodyMap = request . body . as (); // no need to do this: Map String , dynamic bodyMap = await request . body . decode (); return ...; } An ResourceController can also have a default content type for its responses. By default, this is application/json . This default can be changed by changing responseContentType in the constructor: class UserController extends ResourceController { UserController () { responseContentType = ContentType . XML ; } } The responseContentType is the default response content type. An individual Response may set its own contentType , which takes precedence over the responseContentType . For example, the following controller returns JSON by default, but if the request specifically asks for XML, that's what it will return: class UserController extends ResourceController { UserController () { responseContentType = ContentType . JSON ; } @ Operation . get ( id ) Future Response getUserByID ( @ Bind . path ( id ) int id ) async { var response = new Response . ok (...); if ( request . headers . value ( Bind . headers . ACCEPT ). startsWith ( application/xml )) { response . contentType = ContentType . XML ; } return response ; } } More Specialized ResourceControllers Many ResourceController subclasses will execute queries . There are helpful ResourceController subclasses for reducing boilerplate code. A QueryController T builds a Query T based on the incoming request. If the request has a body, this Query T 's values property is read from that body. If the request has a path variable, the Query T assigns an expression to the primary key value. For example, in a normal ResourceController that responds to a PUT request, you might write the following: @ Operation . put ( id ) Future Response updateUser ( @ Bind . path ( id ) int id , @ Bind . body () User user ) async { var query = new Query User ( context ) .. where (( u ) = u . id ). equalTo ( id ) .. values = user ; return new Response . ok ( await query . updateOne ()); } A QueryController T builds this query before a operation method is invoked, storing it in the inherited query property. A ManagedObject T subclass is the type argument to QueryController T . class UserController extends QueryController User { UserController ( ManagedContext context ) : super ( context ); @ Operation . put ( id ) Future Response updateUser ( @ Bind . path ( id ) int id ) async { // query already exists and is identical to the snippet above var result = await query . updateOne (); return new Response . ok ( result ); } } A ManagedObjectController T is significantly more powerful; you don't even need to subclass it. It does all the things a CRUD endpoint does without any code. Here's an example usage: router . route ( /users/[:id] ) . link (() = new ManagedObjectController User ( context )); This controller has the following behavior: Request Action POST /users Inserts a user into the database with values from the request body GET /users Fetches all users in the database GET /users/:id Fetches a single user by id DELETE /users/:id Deletes a single user by id PUT /users/:id Updated a single user by id, using values from the request body The objects returned from getting the collection - e.g, GET /users - can be modified with query parameters. For example, the following request will return the users sorted by their name in ascending order: GET /users?sortBy=name,asc The results can be paged (see Paging in Advanced Queries ) with query parameters offset , count , pageBy , pageAfter and pagePrior . A ManagedObjectController T can also be subclassed. A subclass allows for callbacks to be overridden to adjust the query before execution, or the results before sending the respond. Each operation - fetch, update, delete, etc. - has a pair of methods to do this. For example, the following subclass alters the query and results before any update via PUT : class UserController extends ManagedObjectController User { UserController ( ManagedContext context ) : super ( context ); Future Query User willUpdateObjectWithQuery ( Query User query ) async { query . values . lastUpdatedAt = new DateTime . now (). toUtc (); return query ; } Future Response didUpdateObject ( User object ) async { object . removePropertyFromBackingMap ( private ); return new Response . ok ( object ); } } See the chapter on validations , which are powerful when combined with ManagedObjectController T .","title":"Request Binding with Resource Controllers"},{"location":"http/resource_controller/#resourcecontroller","text":"A ResourceController is a controller that provide conveniences for implementing endpoint controllers. A ResourceController must be subclassed, and in that subclass, you write a method for each operation on that type of resource. For example, a UserController might handle the following operations: creating a new user ( POST /users ) getting all users ( GET /users ) getting an individual user ( GET /users/:id ) updating an individual user ( PUT /users/:id ) deleting an individual user ( DELETE /users/:id ) These methods that are invoked for an operation are called operation methods .","title":"ResourceController"},{"location":"http/resource_controller/#operation-methods","text":"An operation method is an instance method of a ResourceController subclass that has an @Operation annotation. It must return an instance of Future Response . Here's an example: class CityController extends ResourceController { @ Operation . get () Future Response getAllCities () async { return new Response . ok ([ Atlanta , Madison , Mountain View ]); } } The above operation method will be invoked when CityController handles GET requests without path variables. To handle operation methods with path variables, the name of the path variable is added to the @Operation annotation: class CityController extends ResourceController { @ Operation . get () Future Response getAllCities () async { return new Response . ok ([ Atlanta , Madison , Mountain View ]); } @ Operation . get ( name ) Future Response getCityByName () async { final id = request . path . variables [ name ]; return new Response . ok ( fetchCityWithName ( name )); } } Path Variables This controller would be linked to the route specification /cities/[:name] , so that it can handle both of these operations. Read more about path variables in Routing . The named constructor of Operation tells us which HTTP method the operation method handles. The following named constructors exist: Operation.post() Operation.get() Operation.put() Operation.delete() The canonical Operation() constructor takes the HTTP method as its first argument for non-standard operations, e.g.: @ Operation ( PATCH , id ) Future Response patchObjectWithID () async = ...; All Operation constructors take a variable list of path variables. There can be multiple path variables for an operation. An operation method will only be invoked if all of its path variables are present in the request path. There can be multiple operation methods for a given HTTP method, as long as each expects a different set of path variables. Here's an example of an operation that requires two path variables: @ Operation . get ( userID , itemID ) Future Response getUserItem () async { final userID = request . path . variables [ userID ]; final itemID = request . path . variables [ itemID ]; return new Response . ok (...); } If no operation method exists for a request, a 405 Method Not Allowed response is automatically sent and no operation method is invoked.","title":"Operation Methods"},{"location":"http/resource_controller/#routing-to-a-resourcecontroller","text":"A ResourceController subclass must be preceded by a Router in the application channel. The Router will parse path variables so that the controller can use them to determine which operation method should be invoked. A typical route to a ResourceController contains an optional identifying path variable: router . route ( /cities/[:name] ) . link (() = new CityController ()); This route would allow CityController to implement operation methods for all HTTP methods with both no path variables and the 'name' path variable. It is considered good practice to break sub-resources into their own controller. For example, the following is preferred: router . route ( /cities/[:name] ) . link (() = new CityController ()); router . route ( /cities/:name/attractions/[:id] ) . link (() = new CityAttractionController ()); By contrast, the route /cities/[:name/[attractions/[:id]]] , while valid, makes controller logic much more unwieldy.","title":"Routing to a ResourceController"},{"location":"http/resource_controller/#request-bindings","text":"Operation methods may bind properties of an HTTP request to its parameters. When the operation method is invoked, the value of that property is passed as an argument to the operation method. For example, the following binds the header named 'X-API-Key' to the argument apiKey : @ Operation . get ( name ) Future Response getCityByName ( @ Bind . path ( x-api-key ) String apiKey ) async { if ( ! isValid ( apiKey )) { return new Response . unauthorized (); } return new Response . ok (...); } The following table shows the possible types of bindings: Property Binding Path Variable @Bind.path(pathVariableName) URL Query Parameter @Bind.query(queryParameterName) Header @Bind.header(headerName) Request Body @Bind.body() You may bind any number of HTTP request properties to a single operation method.","title":"Request Bindings"},{"location":"http/resource_controller/#optional-bindings","text":"Bindings can be made optional. If a binding is optional, the operation method will still be called even if the bound property isn't in a request. To make a binding optional, move it to the optional parameters of an operation method: @ Operation . get () Future Response getAllCities ({ @ Bind . header ( x-api-key ) String apiKey }) async { if ( apiKey == null ) { // No X-API-Key in request ... } ... } A bound parameter will be null if not in the request. Like any other Dart optional parameter, you can provide a default value: @ Operation . get () Future Response getAllCities ({ @ Bind . header ( x-api-key ) String apiKey: public }) async { ... }","title":"Optional Bindings"},{"location":"http/resource_controller/#automatically-parsing-bindings","text":"Query, header and path bindings can automatically be parsed into other types, such as int or DateTime . Simply declare the bound parameter's type to the desired type: Future Response getCityByID ( @ Bind . query ( id ) int cityID ) The type of a bound parameter may be String or any type that implements parse (e.g., int , DateTime ). Query parameters may also be bound to bool parameters; a boolean query parameter will be true if the query parameter has no value (e.g. /path?boolean ). If parsing fails for any reason, an error response is sent and the operation method is not called. For example, the above example binds int cityID - if the path variable 'id' can't be parsed into an int , a 404 Not Found response is sent. If a query parameter or header value cannot be parsed, a 400 Bad Request response is sent. You may also bind List T parameters to headers and query parameters, where T must meet the same criteria as above. Query parameters and headers may appear more than once in a request. For example, the value of ids is [1, 2] if the request URL ends with /path?id=1 id=2 and the operation method looks like this: Future Response getCitiesByIDs ( @ Bind . query ( id ) List int ids ) Note that if a parameter is not bound to a list and there are multiple occurrences of that property in the request, a 400 Bad Request response will be sent. If you want to allow multiple values, you must bind to a List T .","title":"Automatically Parsing Bindings"},{"location":"http/resource_controller/#header-bindings","text":"The following operation method binds the header named X-API-Key to the apiKey parameter: class CityController extends ResourceController { @ Operation . get () Future Response getAllCities ( @ Bind . header ( x-api-key ) String apiKey ) async { if ( ! isValid ( apiKey )) { return new Response . unauthorized (); } return new Response . ok ([ Atlanta , Madison , Mountain View ]); } } If an X-API-Key header is present in the request, its value will be available in apiKey . If it is not, getAllCities(apiKey) would not be called and a 400 Bad Request response will be sent. If apiKey were optional, the method is called as normal and apiKey is null or a default value. Header names are case-insensitive per the HTTP specification. Therefore, the header name may be 'X-API-KEY', 'X-Api-Key' 'x-api-key', etc. and apiKey will be bound in all cases.","title":"Header Bindings"},{"location":"http/resource_controller/#query-parameter-bindings","text":"The following operation methods binds the query parameter named 'name' to the parameter cityName : class CityController extends ResourceController { @Operation.get() Future getAllCities(@Bind.query('name') String cityName) async { return new Response.ok(cities.where((c) = c.name == cityName).toList()); } } Query parameters can be required or optional. If required, a 400 Bad Request response is sent and no operation method is called if the query parameter is not present in the request URL. If optional, the bound variable is null or a default value. Query parameters are case-sensitive; this binding will only match the query parameter 'name', but not 'Name' or 'NAME'. Query parameters may also bound for query strings in the request body when the content-type is 'application/x-www-form-urlencoded'.","title":"Query Parameter Bindings"},{"location":"http/resource_controller/#path-variable-bindings","text":"The following operation method binds the path variable 'id' to the parameter cityID : class CityController extends ResourceController { @ Operation . get ( id ) Future Response getCityByID ( @ Bind . query ( id ) String cityID ) async { return new Response . ok ( cities . where (( c ) = c . id == cityID ). toList ()); } } Path variables are made available when creating routes . A Router must have a route that includes a path variable and that path variable must be listed in the Operation annotation. Path variables are case-sensitive and may not be optional. If you attempt to bind a path variable that is not present in the Operation , you will get a runtime exception at startup. You do not have to bind path variables for an operation method to be invoked.","title":"Path Variable Bindings"},{"location":"http/resource_controller/#http-request-body-bindings","text":"The body of an HTTP request can also be bound to a parameter: class CityController extends ResourceController { CityController ( this . context ); final ManagedContext context ; @ Operation . post () Future Response addCity ( @ Bind . body () City city ) async { final insertedCity = await Query . insertObject ( context , city ); return new Response . ok ( insertedCity ); } } Since there is only one request body, Bind.body() doesn't take any identifying arguments. The bound parameter type ( City in this example) must implement Serializable . This interface requires two methods to be implemented: one to read data from a request body and another to write data to a response body. Here is an example: class City extends Serializable { int id ; String name ; @ override void readFromMap ( Map String , dynamic map ) { id = map [ id ]; name = map [ name ]; } @ override Map String , dynamic asMap () { return { id : id , name : name } } } ManagedObject and Serializable ManagedObject s from Aqueduct's ORM implement Serializable without having to implement these two methods. Aqueduct will automatically decode the request body from it's content-type, create a new instance of the bound parameter type, and invoke its readFromMap method. In the above example, a valid request body would be the following JSON: { id : 1 , name : Atlanta } HTTP Body Decoding Request bodies are decoded according to their content-type prior to being deserialized. For more information on request body decoding, including decoding content-types other than JSON, see this guide . If parsing fails or readFromMap throws an exception, a 400 Bad Request response will be sent and the operation method won't be called. You may also bind List Serializable parameters to the request body. Consider the following JSON that contains a list of cities: [ { id : 1 , name : Atlanta }, { id : 2 , name : Madison } ] This body can be bound by declaring the bound parameter to be a List of the desired type: Future Response addCity ( @ Bind . body () List City cities ) !!! tip 'List vs Object' An endpoint should either take a single object or a list of objects, but not both. If the request body is a JSON list and the bound variable is not a list, a 400 Bad Request response will be sent (and vice versa). Declaring a body binding of the appropriate type validates the expected value and aids in automatically generating an OpenAPI specification for your application. Note that if the request's Content-Type is 'x-www-form-urlencoded', its must be bound with Bind.query and not Bind.body .","title":"HTTP Request Body Bindings"},{"location":"http/resource_controller/#property-binding","text":"The properties of an ResourceController s may also have Bind.query and Bind.header metadata. This binds values from the request to the ResourceController instance itself, making them accessible from all operation methods. class CityController extends ResourceController { @ requiredBinding @ Bind . header ( x-timestamp ) DateTime timestamp ; @ Bind . query ( limit ) int limit ; @ Operation . get () Future Response getCities () async { // can use both limit and timestamp } } In the above, both timestamp and limit are bound prior to getCities being invoked. By default, a bound property is optional. Adding an requiredBinding annotation changes a property to required. If required, any request without the required property fails with a 400 Bad Request status code and none of the operation methods are invoked.","title":"Property Binding"},{"location":"http/resource_controller/#other-resourcecontroller-behavior","text":"Besides binding, ResourceController s have some other behavior that is important to understand.","title":"Other ResourceController Behavior"},{"location":"http/resource_controller/#request-and-response-bodies","text":"An ResourceController can limit the content type of HTTP request bodies it accepts. By default, an ResourceController will accept only application/json request bodies for its POST and PUT methods. This can be modified by setting the acceptedContentTypes property in the constructor. class UserController extends ResourceController { UserController () { acceptedContentTypes = [ ContentType . JSON , ContentType . XML ]; } } If a request is made with a content type other than the accepted content types, the controller automatically responds with a 415 Unsupported Media Type response. The body of an HTTP request is decoded if the content type is accepted and there exists a operation method to handle the request. The body is not decoded if there is not a matching operation method for the request. The body is decoded by ResourceController prior to your operation method being invoked. Therefore, you can always use the synchronous RequestBody.as method to access the body from within an operation method: @ Operation . post () Future Response createThing () async { // do this: Map String , dynamic bodyMap = request . body . as (); // no need to do this: Map String , dynamic bodyMap = await request . body . decode (); return ...; } An ResourceController can also have a default content type for its responses. By default, this is application/json . This default can be changed by changing responseContentType in the constructor: class UserController extends ResourceController { UserController () { responseContentType = ContentType . XML ; } } The responseContentType is the default response content type. An individual Response may set its own contentType , which takes precedence over the responseContentType . For example, the following controller returns JSON by default, but if the request specifically asks for XML, that's what it will return: class UserController extends ResourceController { UserController () { responseContentType = ContentType . JSON ; } @ Operation . get ( id ) Future Response getUserByID ( @ Bind . path ( id ) int id ) async { var response = new Response . ok (...); if ( request . headers . value ( Bind . headers . ACCEPT ). startsWith ( application/xml )) { response . contentType = ContentType . XML ; } return response ; } }","title":"Request and Response Bodies"},{"location":"http/resource_controller/#more-specialized-resourcecontrollers","text":"Many ResourceController subclasses will execute queries . There are helpful ResourceController subclasses for reducing boilerplate code. A QueryController T builds a Query T based on the incoming request. If the request has a body, this Query T 's values property is read from that body. If the request has a path variable, the Query T assigns an expression to the primary key value. For example, in a normal ResourceController that responds to a PUT request, you might write the following: @ Operation . put ( id ) Future Response updateUser ( @ Bind . path ( id ) int id , @ Bind . body () User user ) async { var query = new Query User ( context ) .. where (( u ) = u . id ). equalTo ( id ) .. values = user ; return new Response . ok ( await query . updateOne ()); } A QueryController T builds this query before a operation method is invoked, storing it in the inherited query property. A ManagedObject T subclass is the type argument to QueryController T . class UserController extends QueryController User { UserController ( ManagedContext context ) : super ( context ); @ Operation . put ( id ) Future Response updateUser ( @ Bind . path ( id ) int id ) async { // query already exists and is identical to the snippet above var result = await query . updateOne (); return new Response . ok ( result ); } } A ManagedObjectController T is significantly more powerful; you don't even need to subclass it. It does all the things a CRUD endpoint does without any code. Here's an example usage: router . route ( /users/[:id] ) . link (() = new ManagedObjectController User ( context )); This controller has the following behavior: Request Action POST /users Inserts a user into the database with values from the request body GET /users Fetches all users in the database GET /users/:id Fetches a single user by id DELETE /users/:id Deletes a single user by id PUT /users/:id Updated a single user by id, using values from the request body The objects returned from getting the collection - e.g, GET /users - can be modified with query parameters. For example, the following request will return the users sorted by their name in ascending order: GET /users?sortBy=name,asc The results can be paged (see Paging in Advanced Queries ) with query parameters offset , count , pageBy , pageAfter and pagePrior . A ManagedObjectController T can also be subclassed. A subclass allows for callbacks to be overridden to adjust the query before execution, or the results before sending the respond. Each operation - fetch, update, delete, etc. - has a pair of methods to do this. For example, the following subclass alters the query and results before any update via PUT : class UserController extends ManagedObjectController User { UserController ( ManagedContext context ) : super ( context ); Future Query User willUpdateObjectWithQuery ( Query User query ) async { query . values . lastUpdatedAt = new DateTime . now (). toUtc (); return query ; } Future Response didUpdateObject ( User object ) async { object . removePropertyFromBackingMap ( private ); return new Response . ok ( object ); } } See the chapter on validations , which are powerful when combined with ManagedObjectController T .","title":"More Specialized ResourceControllers"},{"location":"http/routing/","text":"Routing What is routing? Every HTTP request has a URL. A URL identifies a resource . In the early days of the Internet, a resource was a file. For example, the URL http://www.geocities.com/my_page/image.jpg would return the file image.jpg from the folder my_page on the webserver located at www.geocities.com . In a web application today, resources come from many other sources of data, like a database or a connected device. The job of a web application is to provide, create or modify a resource for a URL, wherever that resource might come from. A URL is made up of many parts, some of which are optional. The typical URL we see as humans looks like this: http://stablekernel.com/about . Most people recognize that typing this URL into a browser would take them to our company's \"About\" page. In other words, our \"About\" page is a resource and the URL identifies it. More generally, the \"About\" page URL has the three required components of a URL: a scheme ( http ), a host ( stablekernel.com ) and a path ( /about ). The host specifies the computer responsible for providing the resource, the path identifies the resource and the scheme lets both the requester and the host know how they should exchange information. An Aqueduct application receives requests when the scheme is http (or https ) and the host refers to a machine where the application is running. Therefore, once the application gets the request, it only cares about the remaining component: the path. In Aqueduct, a Router routes Request s to a Controller based on the request path. This process is known as routing . When an application starts up, routes are registered in a subclass of ApplicationChannel . Each registered route creates a new channel of Controller s that will handle the request. Route Specifications Match HTTP Request Paths A route is registered by invoking Router.route . This method takes a route specification - a String with some syntax rules that will match the path of a request. This registration occurs when an application first starts by overriding ApplicationChannel.entryPoint . For example: class MyApplicationChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = new Router (); router . route ( /users ) . linkFunction (( req ) async = new Response . ok ( await getAllUsers ()); return router ; } } The argument to route is the route specification string. This particular route matches the path /users . That is, a request for the URL http://myserver.com/users will be handled by the linkFunction closure. (Leading and trailing slashes are stripped out when routes are compiled, so including them has no effect, but it is good style to show a leading slash.) A path can have multiple segments (the characters between slashes). For example, the path /users/foo has two path segments: users and foo . A route specification matches each segment of a path against each of its segments. The path and the route must also have the same number of segments. Thus, the route specification /users/foo would match the path /users/foo , but it would not match the paths /users , /users/7 or /users/foo/1 . Path Variables A route specification may have path variables . A path variable captures the value from a path segment, so that your code can use it. A path variable is most often used to uniquely identify a resource by some identifier, like /users/1 and /users/2 . In a route specification, a path variable starts with a colon ( : ). The name of the variable follows this colon. For example, consider the following route that declares a path variable named userID : router . route ( /users/:userID ) This route specification will match /users/1 , /users/2 , /users/foo , etc. The value of userID is 1 , 2 and foo , respectively. This route won't match /users or /users/1/2 . Optional Path Segments Routes may have optional path segments. This allows a group of routes that all refer to a resource collection and its individual resources to go to the same controller. For example, the requests /users and /users/1 can both be covered by a single route specification. An optional path segment has square brackets ( [] ) around it. The brackets can go before or after slashes. For example, the following two syntaxes register a route that accepts both /users and /users/:userID : route ( /users/[:userID] ) route ( /users[/:userID] ) Conceptually, a request with a path of /users/1 identifies a single user, where /users identifies all users. Optional segments are used to create better code structure by forwarding requests that deal with a specific type of resource to the same controller. Therefore, the code to handle one user or multiple users is written in the same place. You may have any number of optional segments in a route specification. Each optional segment must be nested. The following route would match /a , /a/b and /a/b/c . It would not match /a/c . route ( /a/[b/[c]] ) It's pretty rare to have more than one optional segment in a route. For example, consider the route: route ( /users/[:id/[:subresource/[:subresourceid]]] ); The code to handle one or more users is likely very different than the code to handle one of its subresources - different database tables will be queried and different authorization may be needed. Thus, a better approach is to split subresources into their own routes to keep controller logic modular: // Matches /users and /users/:id route ( /users/[:id] )...; // Matches /users/:userId/posts and /users/:userId/posts/:postId route ( /users/:userId/posts/[:postId] )...; // Matches /users/:userId/posts and /users/:userId/notes/:noteId route ( /users/:userId/notes/[:noteId] )...; Restricting Path Variable Values Path variables may restrict their possible values with a regular expression. The expression comes in parentheses following the path variable name. For example, the following route specification limits userID to numbers only: route ( /users/:userID([0-9]+) ) This regular expression would only apply to the :userID segment. Note that capture groups and parentheses in general can't be included in a route's regular expression. Everything in between the parentheses is evaluated as the regular expression. Therefore, any additional spaces or characters will be a part of the regular expression. Since spaces aren't valid in a URL, you don't want spaces in a regular expression. Matching the Remaining Path Finally, a route specification may have a special 'match-all' token, the asterisk ( * ). This token allows for any remaining request path to be matched, regardless of its contents or length. For example, the route specification /users/* would match the following paths: /users /users/1 /users/foo /users/foo/bar /users/foo/bar/something/else/and/this/goes/on/forever This token is used when another medium is going to interpret the URL. For example, FileController - which reads a file from the filesystem - might have a route /file/* . It uses everything after /file to figure out the path on the filesystem. Accessing Path Variables Information that a router parses from a request path - like path variables - are stored in Request.path . When a Request is handled by a router, its path is set to an instance of this type. Controllers deeper in the channel access Request.path to help determine which resource the request is identifying. The path is an instance of RequestPath . A RequestPath contains an map of variables , where the key is path variable name and the value is the value of that variable in the request. For example, consider a route specification /users/:id . When a request with path /users/1 is routed, the value 1 is stored in this map for the key id : final identifier = request . path . variables [ id ]; // identifier = 1 The values in variables are always String s, since a request path is a String . Controller s may parse path variables into types like int . ResourceController uses path variables to select a operation method to handle a request. Failed Matches Return 404 A Router will return a 404 Not Found if there is no matching route for the request. No linked controllers will handle the request. This behavior may be overridden by providing a closure to Router 's constructor.","title":"Routing"},{"location":"http/routing/#routing","text":"","title":"Routing"},{"location":"http/routing/#what-is-routing","text":"Every HTTP request has a URL. A URL identifies a resource . In the early days of the Internet, a resource was a file. For example, the URL http://www.geocities.com/my_page/image.jpg would return the file image.jpg from the folder my_page on the webserver located at www.geocities.com . In a web application today, resources come from many other sources of data, like a database or a connected device. The job of a web application is to provide, create or modify a resource for a URL, wherever that resource might come from. A URL is made up of many parts, some of which are optional. The typical URL we see as humans looks like this: http://stablekernel.com/about . Most people recognize that typing this URL into a browser would take them to our company's \"About\" page. In other words, our \"About\" page is a resource and the URL identifies it. More generally, the \"About\" page URL has the three required components of a URL: a scheme ( http ), a host ( stablekernel.com ) and a path ( /about ). The host specifies the computer responsible for providing the resource, the path identifies the resource and the scheme lets both the requester and the host know how they should exchange information. An Aqueduct application receives requests when the scheme is http (or https ) and the host refers to a machine where the application is running. Therefore, once the application gets the request, it only cares about the remaining component: the path. In Aqueduct, a Router routes Request s to a Controller based on the request path. This process is known as routing . When an application starts up, routes are registered in a subclass of ApplicationChannel . Each registered route creates a new channel of Controller s that will handle the request.","title":"What is routing?"},{"location":"http/routing/#route-specifications-match-http-request-paths","text":"A route is registered by invoking Router.route . This method takes a route specification - a String with some syntax rules that will match the path of a request. This registration occurs when an application first starts by overriding ApplicationChannel.entryPoint . For example: class MyApplicationChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = new Router (); router . route ( /users ) . linkFunction (( req ) async = new Response . ok ( await getAllUsers ()); return router ; } } The argument to route is the route specification string. This particular route matches the path /users . That is, a request for the URL http://myserver.com/users will be handled by the linkFunction closure. (Leading and trailing slashes are stripped out when routes are compiled, so including them has no effect, but it is good style to show a leading slash.) A path can have multiple segments (the characters between slashes). For example, the path /users/foo has two path segments: users and foo . A route specification matches each segment of a path against each of its segments. The path and the route must also have the same number of segments. Thus, the route specification /users/foo would match the path /users/foo , but it would not match the paths /users , /users/7 or /users/foo/1 .","title":"Route Specifications Match HTTP Request Paths"},{"location":"http/routing/#path-variables","text":"A route specification may have path variables . A path variable captures the value from a path segment, so that your code can use it. A path variable is most often used to uniquely identify a resource by some identifier, like /users/1 and /users/2 . In a route specification, a path variable starts with a colon ( : ). The name of the variable follows this colon. For example, consider the following route that declares a path variable named userID : router . route ( /users/:userID ) This route specification will match /users/1 , /users/2 , /users/foo , etc. The value of userID is 1 , 2 and foo , respectively. This route won't match /users or /users/1/2 .","title":"Path Variables"},{"location":"http/routing/#optional-path-segments","text":"Routes may have optional path segments. This allows a group of routes that all refer to a resource collection and its individual resources to go to the same controller. For example, the requests /users and /users/1 can both be covered by a single route specification. An optional path segment has square brackets ( [] ) around it. The brackets can go before or after slashes. For example, the following two syntaxes register a route that accepts both /users and /users/:userID : route ( /users/[:userID] ) route ( /users[/:userID] ) Conceptually, a request with a path of /users/1 identifies a single user, where /users identifies all users. Optional segments are used to create better code structure by forwarding requests that deal with a specific type of resource to the same controller. Therefore, the code to handle one user or multiple users is written in the same place. You may have any number of optional segments in a route specification. Each optional segment must be nested. The following route would match /a , /a/b and /a/b/c . It would not match /a/c . route ( /a/[b/[c]] ) It's pretty rare to have more than one optional segment in a route. For example, consider the route: route ( /users/[:id/[:subresource/[:subresourceid]]] ); The code to handle one or more users is likely very different than the code to handle one of its subresources - different database tables will be queried and different authorization may be needed. Thus, a better approach is to split subresources into their own routes to keep controller logic modular: // Matches /users and /users/:id route ( /users/[:id] )...; // Matches /users/:userId/posts and /users/:userId/posts/:postId route ( /users/:userId/posts/[:postId] )...; // Matches /users/:userId/posts and /users/:userId/notes/:noteId route ( /users/:userId/notes/[:noteId] )...;","title":"Optional Path Segments"},{"location":"http/routing/#restricting-path-variable-values","text":"Path variables may restrict their possible values with a regular expression. The expression comes in parentheses following the path variable name. For example, the following route specification limits userID to numbers only: route ( /users/:userID([0-9]+) ) This regular expression would only apply to the :userID segment. Note that capture groups and parentheses in general can't be included in a route's regular expression. Everything in between the parentheses is evaluated as the regular expression. Therefore, any additional spaces or characters will be a part of the regular expression. Since spaces aren't valid in a URL, you don't want spaces in a regular expression.","title":"Restricting Path Variable Values"},{"location":"http/routing/#matching-the-remaining-path","text":"Finally, a route specification may have a special 'match-all' token, the asterisk ( * ). This token allows for any remaining request path to be matched, regardless of its contents or length. For example, the route specification /users/* would match the following paths: /users /users/1 /users/foo /users/foo/bar /users/foo/bar/something/else/and/this/goes/on/forever This token is used when another medium is going to interpret the URL. For example, FileController - which reads a file from the filesystem - might have a route /file/* . It uses everything after /file to figure out the path on the filesystem.","title":"Matching the Remaining Path"},{"location":"http/routing/#accessing-path-variables","text":"Information that a router parses from a request path - like path variables - are stored in Request.path . When a Request is handled by a router, its path is set to an instance of this type. Controllers deeper in the channel access Request.path to help determine which resource the request is identifying. The path is an instance of RequestPath . A RequestPath contains an map of variables , where the key is path variable name and the value is the value of that variable in the request. For example, consider a route specification /users/:id . When a request with path /users/1 is routed, the value 1 is stored in this map for the key id : final identifier = request . path . variables [ id ]; // identifier = 1 The values in variables are always String s, since a request path is a String . Controller s may parse path variables into types like int . ResourceController uses path variables to select a operation method to handle a request.","title":"Accessing Path Variables"},{"location":"http/routing/#failed-matches-return-404","text":"A Router will return a 404 Not Found if there is no matching route for the request. No linked controllers will handle the request. This behavior may be overridden by providing a closure to Router 's constructor.","title":"Failed Matches Return 404"},{"location":"http/serving_files/","text":"Serving Files and Caching Aqueduct can serve files by returning the contents of a file as an HTTP response body. FileController Instances of FileController serve a directory from the filesystem through an HTTP interface. Any route that channels requests to an FileController must contain a * match-all token. @ override Controller get entryPoint { final router = new Router (); router . route ( /files/* ). link (() = new FileController ( public/ )); return router ; } The argument to FileController is the directory on the filesystem in which request paths will be resolved against. In the above example, an HTTP request with the path /files/image.jpg would return the contents of the file public/image.jpg . Note that public/ does not have a leading slash - therefore, the directory public must be relative to the directory that the Aqueduct application was served from. In practice, this means you might have a directory structure like: project/ pubspec.yaml lib/ channel.dart ... test/ ... public/ image.jpg Adding a leading slash to the directory served by FileController will resolve it relative to the filesystem root. If the requested path was a directory, the filename index.html will be appended to the path when searching for a file to return. If a file does not exist, an FileController returns a 404 Not Found response. Content-Type of Files An FileController will set the content-type of the HTTP response based on the served files path extension. By default, it recognizes many common extensions like .html , .css , .jpg , .js . You may add content-types for extensions to an instance: var controller = new FileController ( public/ ) .. setContentTypeForExtension ( xml , new ContentType ( application , xml )); If there is no entry for an extension of a file being served, the content-type defaults to application/octet-stream . An FileController will never invoke any encoders from CodecRegistry , but it will GZIP data if the repository allows compression for the content-type of the file (see CodecRegistry.add and CodecRegistry.setAllowsCompression ). Caching An FileController always sets the the Last-Modified header of the response to the last modified date according to the filesystem. If a request sends an If-Modified-Since header and the file has not been modified since that date, a 304 Not Modified response is sent with the appropriate headers. You may provide Cache-Control headers depending on the path of the file being served. Here's an example that adds Cache-Control: public, max-age=31536000 var policy = new CachePolicy ( expirationFromNow: new Duration ( days: 365 )); var controller = new FileController ( public/ ) .. addCachePolicy ( policy , ( path ) = path . endsWith ( .css )); File Serving and Caching Outside of FileController A file can be served by any controller by setting the body object of a Response with its contents: var file = new File ( index.html ); // By loading contents into memory first... var response = new Response . ok ( file . readAsStringSync ()) .. contentType = new ContentType ( application , html ); // Or by streaming the contents from disk var response = new Response . ok ( file . openRead ()) .. encodeBody = false .. contentType = new ContentType ( application , html ); It is important to understand the how Aqueduct uses content-types to manipulate response bodies to serve file contents. You may set the CachePolicy of any Response . Note that CachePolicy only modifies the Cache-Control header of a response - headers like Last-Modified and ETag are not added. var response = new Response . ok ( contents ) .. cachePolicy = new CachePolicy ();","title":"Serving Files and Caching"},{"location":"http/serving_files/#serving-files-and-caching","text":"Aqueduct can serve files by returning the contents of a file as an HTTP response body.","title":"Serving Files and Caching"},{"location":"http/serving_files/#filecontroller","text":"Instances of FileController serve a directory from the filesystem through an HTTP interface. Any route that channels requests to an FileController must contain a * match-all token. @ override Controller get entryPoint { final router = new Router (); router . route ( /files/* ). link (() = new FileController ( public/ )); return router ; } The argument to FileController is the directory on the filesystem in which request paths will be resolved against. In the above example, an HTTP request with the path /files/image.jpg would return the contents of the file public/image.jpg . Note that public/ does not have a leading slash - therefore, the directory public must be relative to the directory that the Aqueduct application was served from. In practice, this means you might have a directory structure like: project/ pubspec.yaml lib/ channel.dart ... test/ ... public/ image.jpg Adding a leading slash to the directory served by FileController will resolve it relative to the filesystem root. If the requested path was a directory, the filename index.html will be appended to the path when searching for a file to return. If a file does not exist, an FileController returns a 404 Not Found response.","title":"FileController"},{"location":"http/serving_files/#content-type-of-files","text":"An FileController will set the content-type of the HTTP response based on the served files path extension. By default, it recognizes many common extensions like .html , .css , .jpg , .js . You may add content-types for extensions to an instance: var controller = new FileController ( public/ ) .. setContentTypeForExtension ( xml , new ContentType ( application , xml )); If there is no entry for an extension of a file being served, the content-type defaults to application/octet-stream . An FileController will never invoke any encoders from CodecRegistry , but it will GZIP data if the repository allows compression for the content-type of the file (see CodecRegistry.add and CodecRegistry.setAllowsCompression ).","title":"Content-Type of Files"},{"location":"http/serving_files/#caching","text":"An FileController always sets the the Last-Modified header of the response to the last modified date according to the filesystem. If a request sends an If-Modified-Since header and the file has not been modified since that date, a 304 Not Modified response is sent with the appropriate headers. You may provide Cache-Control headers depending on the path of the file being served. Here's an example that adds Cache-Control: public, max-age=31536000 var policy = new CachePolicy ( expirationFromNow: new Duration ( days: 365 )); var controller = new FileController ( public/ ) .. addCachePolicy ( policy , ( path ) = path . endsWith ( .css ));","title":"Caching"},{"location":"http/serving_files/#file-serving-and-caching-outside-of-filecontroller","text":"A file can be served by any controller by setting the body object of a Response with its contents: var file = new File ( index.html ); // By loading contents into memory first... var response = new Response . ok ( file . readAsStringSync ()) .. contentType = new ContentType ( application , html ); // Or by streaming the contents from disk var response = new Response . ok ( file . openRead ()) .. encodeBody = false .. contentType = new ContentType ( application , html ); It is important to understand the how Aqueduct uses content-types to manipulate response bodies to serve file contents. You may set the CachePolicy of any Response . Note that CachePolicy only modifies the Cache-Control header of a response - headers like Last-Modified and ETag are not added. var response = new Response . ok ( contents ) .. cachePolicy = new CachePolicy ();","title":"File Serving and Caching Outside of FileController"},{"location":"http/websockets/","text":"Using Websockets in Aqueduct A standard HTTP request will yield an HTTP response from a web server. In order for the server to send data to a client, the client must have sent a request for that data. A websocket is a special type of HTTP request that stays open, and both the server and client can send data to one another whenever they please. For example, a chat application might use websockets to send messages to everyone in a chatroom. In this scenario, the chat client application opens a websocket connection to the server application. When the user types a message, their chat client sends that message on its websocket. The payload might be JSON data that looks like this: { action : send_message , room : general , text : Hi everyone } The server will receive this data, then turn around and send a modified version to every websocket connection it has. That data might look like this: { action : receive_message , room : general , from : Bob , text : Hi everyone } Every connected user will receive this data and draw Bob: Hi everyone to the screen. Note that there's nothing about websockets that says you have to use JSON data - you can use any data format you like. Upgrading an HTTP Request to a WebSocket In Aqueduct, websockets are handled by Dart's standard library WebSocket type. Here's an example: router . route ( /connect ) . linkFunction (( request ) async { var socket = await WebSocketTransformer . upgrade ( request . raw ); socket . listen ( listener ); return null ; }); It's important that a request that is upgraded to a websocket is removed from the channel by returning null from the controller. (See the section on Aqueduct and dart:io in this guide for more details.) A client application can connect to the URL ws://localhost:8888/connect . A Dart application would make this connection like so: var socket = await WebSocket . connect ( ws://localhost:8888/connect ); socket . listen (...); Bi-directional Communication In the simple example above, the server only listens for data from the client. For data to be sent to the client, a reference must be kept to the WebSocket so that data can be added to it. How an Aqueduct application manages its websocket connections depends greatly on the behavior of the application, the number of isolates the application is running on and the infrastructure of the system as a whole. A simple application might keep track of websocket connections in a Map , where the key is a user identifier acquired from the authorization of the request: router . route ( /connect ) . link (() = new Authorizer ( authServer )); . linkFunction (( request ) async { var userID = request . authorization . ownerID ; var socket = await WebSocketTransformer . upgrade ( request . raw ); socket . listen (( event ) = handleEvent ( event , fromUserID: userID )); connections [ userID ] = socket ; return null ; }); If we continue with the 'chat application' example, the code for handleEvent may be something like: void handleEvent ( dynamic event , { int fromUserID }) { var incoming = json . decode ( UTF8 . decode ( event )); var outgoing = utf8 . encode ( json . encode ({ text : incoming [ text ], ... })); connections . keys . where (( userID ) = userID != fromUserID ) . forEach (( userID ) { var connection = connections [ userID ]; connection . add ( outgoing ); }); } Note that this simple implementation doesn't account for multiple connections from the same user or multi-isolate applications. Considerations for Multi-Isolate and Multi-Instance Applications By default, an Aqueduct application runs on multiple isolates. Since each isolate has its own heap, a websocket created on one isolate is not directly accessible by another isolate. In the example above, each isolate would have its own map of connections - therefore, a message is only sent to connections that were opened on the same isolate that the chat message originated from. A simple solution is to only run the application on a single isolate, ensuring that all websockets are on a single isolate and accessible to one another: aqueduct serve - n 1 For many applications, this is a fine solution. For others, it may not be. Recall that one of the benefits of Aqueduct's multi-isolate architecture is that code tested on a single instance will scale to multiple instances behind a load balancer. If an Aqueduct application runs correctly on a single, multi-isolate instance, it will run correctly on multiple instances. This (somewhat) enforced structure prevents us from naively keeping track of websocket connections on a single isolate, which would cause issues when we scale out to a multi-instance system. If you find yourself in a situation where your application is so popular you need multiple servers to efficiently serve requests, you'll have a good idea on how to architect an appropriate solution (or you'll have the money to hire someone that does). In many situations, the REST API and websocket server are separate instances anyhow - they have different lifecycles and deployment behavior. It may make sense to run a websocket server on a single isolate, since you are likely IO-bound instead of CPU bound. If you still prefer to have a multi-isolate server with websockets, the ApplicationMessageHub will come in handy. When broadcasting messages to connected websockets across the application, you first send the data to each websocket connected to the isolate that is originating the message. Then, the message is added to the ApplicationMessageHub : void onChatMessage ( String message ) { connectedSockets . forEach (( socket ) { socket . add ( message ); }); ApplicationChannel . messageHub . add ({ event : websocket_broadcast , message : message }); } Anything added to the messageHub will be delivered to the listener for every other message hub - i.e., every other isolate will receive this data. The other isolates then send the message to each of their connected websockets: class ChatChannel extends ApplicationChannel { @ override Future prepare () async { messageHub . listen (( event ) { if ( event is Map event [ event ] == websocket_broadcast ) { connectedSockets . forEach (( socket ) { socket . add ( event [ message ]); }); } }); } }","title":"Websockets"},{"location":"http/websockets/#using-websockets-in-aqueduct","text":"A standard HTTP request will yield an HTTP response from a web server. In order for the server to send data to a client, the client must have sent a request for that data. A websocket is a special type of HTTP request that stays open, and both the server and client can send data to one another whenever they please. For example, a chat application might use websockets to send messages to everyone in a chatroom. In this scenario, the chat client application opens a websocket connection to the server application. When the user types a message, their chat client sends that message on its websocket. The payload might be JSON data that looks like this: { action : send_message , room : general , text : Hi everyone } The server will receive this data, then turn around and send a modified version to every websocket connection it has. That data might look like this: { action : receive_message , room : general , from : Bob , text : Hi everyone } Every connected user will receive this data and draw Bob: Hi everyone to the screen. Note that there's nothing about websockets that says you have to use JSON data - you can use any data format you like.","title":"Using Websockets in Aqueduct"},{"location":"http/websockets/#upgrading-an-http-request-to-a-websocket","text":"In Aqueduct, websockets are handled by Dart's standard library WebSocket type. Here's an example: router . route ( /connect ) . linkFunction (( request ) async { var socket = await WebSocketTransformer . upgrade ( request . raw ); socket . listen ( listener ); return null ; }); It's important that a request that is upgraded to a websocket is removed from the channel by returning null from the controller. (See the section on Aqueduct and dart:io in this guide for more details.) A client application can connect to the URL ws://localhost:8888/connect . A Dart application would make this connection like so: var socket = await WebSocket . connect ( ws://localhost:8888/connect ); socket . listen (...);","title":"Upgrading an HTTP Request to a WebSocket"},{"location":"http/websockets/#bi-directional-communication","text":"In the simple example above, the server only listens for data from the client. For data to be sent to the client, a reference must be kept to the WebSocket so that data can be added to it. How an Aqueduct application manages its websocket connections depends greatly on the behavior of the application, the number of isolates the application is running on and the infrastructure of the system as a whole. A simple application might keep track of websocket connections in a Map , where the key is a user identifier acquired from the authorization of the request: router . route ( /connect ) . link (() = new Authorizer ( authServer )); . linkFunction (( request ) async { var userID = request . authorization . ownerID ; var socket = await WebSocketTransformer . upgrade ( request . raw ); socket . listen (( event ) = handleEvent ( event , fromUserID: userID )); connections [ userID ] = socket ; return null ; }); If we continue with the 'chat application' example, the code for handleEvent may be something like: void handleEvent ( dynamic event , { int fromUserID }) { var incoming = json . decode ( UTF8 . decode ( event )); var outgoing = utf8 . encode ( json . encode ({ text : incoming [ text ], ... })); connections . keys . where (( userID ) = userID != fromUserID ) . forEach (( userID ) { var connection = connections [ userID ]; connection . add ( outgoing ); }); } Note that this simple implementation doesn't account for multiple connections from the same user or multi-isolate applications.","title":"Bi-directional Communication"},{"location":"http/websockets/#considerations-for-multi-isolate-and-multi-instance-applications","text":"By default, an Aqueduct application runs on multiple isolates. Since each isolate has its own heap, a websocket created on one isolate is not directly accessible by another isolate. In the example above, each isolate would have its own map of connections - therefore, a message is only sent to connections that were opened on the same isolate that the chat message originated from. A simple solution is to only run the application on a single isolate, ensuring that all websockets are on a single isolate and accessible to one another: aqueduct serve - n 1 For many applications, this is a fine solution. For others, it may not be. Recall that one of the benefits of Aqueduct's multi-isolate architecture is that code tested on a single instance will scale to multiple instances behind a load balancer. If an Aqueduct application runs correctly on a single, multi-isolate instance, it will run correctly on multiple instances. This (somewhat) enforced structure prevents us from naively keeping track of websocket connections on a single isolate, which would cause issues when we scale out to a multi-instance system. If you find yourself in a situation where your application is so popular you need multiple servers to efficiently serve requests, you'll have a good idea on how to architect an appropriate solution (or you'll have the money to hire someone that does). In many situations, the REST API and websocket server are separate instances anyhow - they have different lifecycles and deployment behavior. It may make sense to run a websocket server on a single isolate, since you are likely IO-bound instead of CPU bound. If you still prefer to have a multi-isolate server with websockets, the ApplicationMessageHub will come in handy. When broadcasting messages to connected websockets across the application, you first send the data to each websocket connected to the isolate that is originating the message. Then, the message is added to the ApplicationMessageHub : void onChatMessage ( String message ) { connectedSockets . forEach (( socket ) { socket . add ( message ); }); ApplicationChannel . messageHub . add ({ event : websocket_broadcast , message : message }); } Anything added to the messageHub will be delivered to the listener for every other message hub - i.e., every other isolate will receive this data. The other isolates then send the message to each of their connected websockets: class ChatChannel extends ApplicationChannel { @ override Future prepare () async { messageHub . listen (( event ) { if ( event is Map event [ event ] == websocket_broadcast ) { connectedSockets . forEach (( socket ) { socket . add ( event [ message ]); }); } }); } }","title":"Considerations for Multi-Isolate and Multi-Instance Applications"},{"location":"openapi/","text":"Tasks Aqueduct applications auto-generate an OpenAPI 3.0 document. Most of your OpenAPI document is generated by reflecting on your application code, especially ResourceController subclasses. You add customization or additional information by overriding methods in APIComponentDocumenter and APIOperationDocumenter . At minimum, you override methods in your ResourceController to document the responses your application will send for a particular endpoint. You create documents with the aqueduct document command-line tool. Guides Creating an OpenAPI Document Documenting Components Documenting Endpoint Controllers Documenting Middleware Controllers","title":"Overview"},{"location":"openapi/#tasks","text":"Aqueduct applications auto-generate an OpenAPI 3.0 document. Most of your OpenAPI document is generated by reflecting on your application code, especially ResourceController subclasses. You add customization or additional information by overriding methods in APIComponentDocumenter and APIOperationDocumenter . At minimum, you override methods in your ResourceController to document the responses your application will send for a particular endpoint. You create documents with the aqueduct document command-line tool.","title":"Tasks"},{"location":"openapi/#guides","text":"Creating an OpenAPI Document Documenting Components Documenting Endpoint Controllers Documenting Middleware Controllers","title":"Guides"},{"location":"openapi/cli/","text":"Creating OpenAPI Documents In this document, you'll learn how to use the aqueduct command line tool to generate an OpenAPI document for your application. OpenAPI Documents OpenAPI documents describe the details of every request and possible response your application has. These documents are JSON objects that follow a specification. This specification defines which properties the document can (or must) have. By following this specification, your application can take advantage of tools such as documentation viewers and source code generators. The two most important objects in an OpenAPI document are components and path operations. A path operation contains an expected request and possible responses. Components are reusable definitions that you can use in a path operation. For example, a 400 Bad Request response component can be reused across path operations that may send this response. Most of the documentation process revolves around registering components and creating path operations. The aqueduct document Command Documents can be written by hand, but it takes a lot of time and is hard to keep in sync with your code. Aqueduct analyzes your code to build (most) of a document for you. You run the aqueduct document command in your project's directory, and it prints the JSON document to your console. cd my_project/ aqueduct document -- Aqueduct CLI Version: 3 .0.0 -- Aqueduct project version: 3 .0.0 { openapi : 3.0.0 , info :... You may copy the output to use it in another tool; for example, by entering it into Swagger Editor . If you want to build a tool that runs this command, but don't want to parse the version info from the output, use the --machine flag. aqueduct document --machine { openapi : 3.0.0 , info :... Much of the metadata in an OpenAPI document - such as title or version - is derived from your application's pubspec.yaml . If you want to override the derived values, or provide values that can't be derived, use options like --title or --license-name . See aqueduct document --help for all options. How Applications are Documented When you run the aqueduct document command, it creates an empty APIDocument that objects in your application will populate. Your application goes through its normal initialization process (i.e., prepare and entryPoint ). Controllers and service objects are then told to register components. For example, all ManagedObject s register themselves as a reusable schema component. After components are registered, the controllers in an application are told to create path operations that define the requests they handle. Configuration Files Because your application goes through initialization as if it were going to run the application, you must have a valid configuration file when documenting. This defaults to 'config.yaml.src', the same file you use for running tests. See aqueduct document --help to use a different file. Documenting Components Objects that register components implement APIComponentDocumenter.documentComponents . Controllers - which implement this method - automatically document their components as long as they are linked to your application's entry point. Other types of objects that implement this method will be automatically documented if they are declared as a property of your ApplicationChannel . For example, in the following code, the AuthServer , Router and PathController all automatically document their components. class MyChannel extends ApplicationChannel { AuthServer authServer ; @ override Future prepare () async { authServer = new AuthServer (...); } @ override Controller get entryPoint { final router = new Router (); router . route ( /path ). link (() = new PathController ()); return router ; } } In most applications, the automatically documented objects are the only objects that register components. If you have an object that needs to register components, but aren't automatically documented, override documentComponents in your app channel to tell that object to register components. You must call the superclass' implementation. class MyChannel extends ApplicationChannel { ... @ override void documentComponents ( APIDocumentContext context ) { super . documentComponents ( context ); objectWithComponents . documentComponents ( context ); } } You can override documentComponents in controllers and services that you create. Read the guide on component documentation for more details. Document Path Operations A path operation is the expected request and possible responses for a path (e.g., /users ) and its request method (e.g., GET ). Each operation describes how to send a request to the server, like which headers or query parameters to include. Responses describe the status code, headers and body that can be sent. Each controller implements APIOperationDocumenter.documentOperations to define this information for the requests it handles. Built-in controllers like Authorizer and ResourceController already implement this method. You typically only override this method when creating your own middleware. For more information on documenting middleware, see this guide . When creating documentation for ResourceController s, request parameters are derived from your bindings, but you still need to provide the possible responses. For more information on documenting endpoint controllers, see this guide .","title":"Creating an OpenAPI Document"},{"location":"openapi/cli/#creating-openapi-documents","text":"In this document, you'll learn how to use the aqueduct command line tool to generate an OpenAPI document for your application.","title":"Creating OpenAPI Documents"},{"location":"openapi/cli/#openapi-documents","text":"OpenAPI documents describe the details of every request and possible response your application has. These documents are JSON objects that follow a specification. This specification defines which properties the document can (or must) have. By following this specification, your application can take advantage of tools such as documentation viewers and source code generators. The two most important objects in an OpenAPI document are components and path operations. A path operation contains an expected request and possible responses. Components are reusable definitions that you can use in a path operation. For example, a 400 Bad Request response component can be reused across path operations that may send this response. Most of the documentation process revolves around registering components and creating path operations.","title":"OpenAPI Documents"},{"location":"openapi/cli/#the-aqueduct-document-command","text":"Documents can be written by hand, but it takes a lot of time and is hard to keep in sync with your code. Aqueduct analyzes your code to build (most) of a document for you. You run the aqueduct document command in your project's directory, and it prints the JSON document to your console. cd my_project/ aqueduct document -- Aqueduct CLI Version: 3 .0.0 -- Aqueduct project version: 3 .0.0 { openapi : 3.0.0 , info :... You may copy the output to use it in another tool; for example, by entering it into Swagger Editor . If you want to build a tool that runs this command, but don't want to parse the version info from the output, use the --machine flag. aqueduct document --machine { openapi : 3.0.0 , info :... Much of the metadata in an OpenAPI document - such as title or version - is derived from your application's pubspec.yaml . If you want to override the derived values, or provide values that can't be derived, use options like --title or --license-name . See aqueduct document --help for all options.","title":"The aqueduct document Command"},{"location":"openapi/cli/#how-applications-are-documented","text":"When you run the aqueduct document command, it creates an empty APIDocument that objects in your application will populate. Your application goes through its normal initialization process (i.e., prepare and entryPoint ). Controllers and service objects are then told to register components. For example, all ManagedObject s register themselves as a reusable schema component. After components are registered, the controllers in an application are told to create path operations that define the requests they handle. Configuration Files Because your application goes through initialization as if it were going to run the application, you must have a valid configuration file when documenting. This defaults to 'config.yaml.src', the same file you use for running tests. See aqueduct document --help to use a different file.","title":"How Applications are Documented"},{"location":"openapi/cli/#documenting-components","text":"Objects that register components implement APIComponentDocumenter.documentComponents . Controllers - which implement this method - automatically document their components as long as they are linked to your application's entry point. Other types of objects that implement this method will be automatically documented if they are declared as a property of your ApplicationChannel . For example, in the following code, the AuthServer , Router and PathController all automatically document their components. class MyChannel extends ApplicationChannel { AuthServer authServer ; @ override Future prepare () async { authServer = new AuthServer (...); } @ override Controller get entryPoint { final router = new Router (); router . route ( /path ). link (() = new PathController ()); return router ; } } In most applications, the automatically documented objects are the only objects that register components. If you have an object that needs to register components, but aren't automatically documented, override documentComponents in your app channel to tell that object to register components. You must call the superclass' implementation. class MyChannel extends ApplicationChannel { ... @ override void documentComponents ( APIDocumentContext context ) { super . documentComponents ( context ); objectWithComponents . documentComponents ( context ); } } You can override documentComponents in controllers and services that you create. Read the guide on component documentation for more details.","title":"Documenting Components"},{"location":"openapi/cli/#document-path-operations","text":"A path operation is the expected request and possible responses for a path (e.g., /users ) and its request method (e.g., GET ). Each operation describes how to send a request to the server, like which headers or query parameters to include. Responses describe the status code, headers and body that can be sent. Each controller implements APIOperationDocumenter.documentOperations to define this information for the requests it handles. Built-in controllers like Authorizer and ResourceController already implement this method. You typically only override this method when creating your own middleware. For more information on documenting middleware, see this guide . When creating documentation for ResourceController s, request parameters are derived from your bindings, but you still need to provide the possible responses. For more information on documenting endpoint controllers, see this guide .","title":"Document Path Operations"},{"location":"openapi/components/","text":"Document Components In this document, you'll learn how to register and use OpenAPI components in your application's documentation. Registering Components with APIDocumentContext When your application is being documented, a single instance of APIDocumentContext is created and passed to every documentation method. The context stores the document being created, but more importantly, is a container for reusable components. You may register components by implementing APIComponentDocumenter and implementing its abstract method. For example, the following code registers a reusable schema object: class SourceRepository implements APIComponentDocumenter { @ override void documentComponents ( APIDocumentContext context ) { super . documentComponents ( context ); context . schema . register ( SourceRepository , APISchemaObject . object ({ id : APISchemaObject . integer (), name : APISchemaObject . string () }); } } A \"SourceRepository\" is an object that contains two fields, \"id\" (an integer) and \"name\" (a string). This component can be used anywhere a schema object can be used. Schema objects are one type of component that document what is typically considered to be a 'model object'. You most often see schema objects in request and response bodies. By default, each of your ManagedObject s are registered as schema objects. The other types of components are: responses, request bodies, parameters, headers, security schemes, and callbacks. Components must be registered with a name, but can additionally be registered with a type. This allows users of a component to reference it by its Dart type. Including a type reference for an object is an optional argument when registering. context . schema . register ( SourceRepository , APISchemaObject . object ({ id : APISchemaObject . integer (), name : APISchemaObject . string () }, representation: SourceRepository ); The order in which components are registered and referenced does not matter. If you reference a component that is created later in the documentation process, it will be resolved prior to the document being completed. If a referenced component is never registered, an error is thrown and your document will fail to generate. Using Components Components can be used when declaring path operations, or as part of other components. For example, if you were to describe a response whose body was a component named \"SourceRepository\", it would look like this: class RepositoryController extends ResourceController { ... @ override Map String , APIResponse documentOperationResponses ( APIDocumentContext context , Operation operation ) { if ( operation . method == GET ) { return { 200 : APIResponse . schema ( context . schema [ SourceRepository ]) }; } return null ; } } If an object has been registered by its type, you may use getObjectWithType . class RepositoryController extends ResourceController { ... @ override Map String , APIResponse documentOperationResponses ( APIDocumentContext context , Operation operation ) { if ( operation . method == GET ) { return { 200 : APIResponse . schema ( context . schema . getObjectWithType ( SourceRepository )) }; } return null ; } } Component Discovery All controllers are can document components when they are linked to the entry point. Objects other than controllers will automatically document their components if they implement APIComponentDocumenter and are declared properties of your ApplicationChannel . (See this guide for other options.) Built-in Aqueduct types will register any applicable components. This includes the types that handle OAuth2 as well as all ManagedObject subclasses in your application. ManagedObject Discovery Declaring a ManagedContext as a property of your ApplicationChannel will automatically document the managed objects of your application as schema components. Serializable Discovery If a Serializable object is bound to a request body in a ResourceController , it will automatically be documented as a schema component. By default, the properties of the Serializable object are reflected on to produce this component. To override this behavior and provide your own component documentation, implement the following method in your Serializable subclass: class Person extends Serializable { String name ; Map String , dynamic asMap () = { name : name }; void readFromMap ( Map String , dynamic map ) { name = map [ name ]; } APISchemaObject documentSchema ( APIDocumentContext context ) { return APISchemaObject . object ( properties: { name : APISchemaObject . string () }); } } If you Serializable type is not bound to a resource controller operation, you must register it yourself. This typically occurs by overriding documentComponents in the controller that uses the type. class MyController extends ResourceController { ... @ override void documentComponents ( APIDocumentContext context ) { super . documentComponents ( context ); final personSchema = Person (). documentSchema ( context ); context . schema . register ( Person , personSchema , representation: Person ); } }","title":"Documenting Components"},{"location":"openapi/components/#document-components","text":"In this document, you'll learn how to register and use OpenAPI components in your application's documentation.","title":"Document Components"},{"location":"openapi/components/#registering-components-with-apidocumentcontext","text":"When your application is being documented, a single instance of APIDocumentContext is created and passed to every documentation method. The context stores the document being created, but more importantly, is a container for reusable components. You may register components by implementing APIComponentDocumenter and implementing its abstract method. For example, the following code registers a reusable schema object: class SourceRepository implements APIComponentDocumenter { @ override void documentComponents ( APIDocumentContext context ) { super . documentComponents ( context ); context . schema . register ( SourceRepository , APISchemaObject . object ({ id : APISchemaObject . integer (), name : APISchemaObject . string () }); } } A \"SourceRepository\" is an object that contains two fields, \"id\" (an integer) and \"name\" (a string). This component can be used anywhere a schema object can be used. Schema objects are one type of component that document what is typically considered to be a 'model object'. You most often see schema objects in request and response bodies. By default, each of your ManagedObject s are registered as schema objects. The other types of components are: responses, request bodies, parameters, headers, security schemes, and callbacks. Components must be registered with a name, but can additionally be registered with a type. This allows users of a component to reference it by its Dart type. Including a type reference for an object is an optional argument when registering. context . schema . register ( SourceRepository , APISchemaObject . object ({ id : APISchemaObject . integer (), name : APISchemaObject . string () }, representation: SourceRepository ); The order in which components are registered and referenced does not matter. If you reference a component that is created later in the documentation process, it will be resolved prior to the document being completed. If a referenced component is never registered, an error is thrown and your document will fail to generate.","title":"Registering Components with APIDocumentContext"},{"location":"openapi/components/#using-components","text":"Components can be used when declaring path operations, or as part of other components. For example, if you were to describe a response whose body was a component named \"SourceRepository\", it would look like this: class RepositoryController extends ResourceController { ... @ override Map String , APIResponse documentOperationResponses ( APIDocumentContext context , Operation operation ) { if ( operation . method == GET ) { return { 200 : APIResponse . schema ( context . schema [ SourceRepository ]) }; } return null ; } } If an object has been registered by its type, you may use getObjectWithType . class RepositoryController extends ResourceController { ... @ override Map String , APIResponse documentOperationResponses ( APIDocumentContext context , Operation operation ) { if ( operation . method == GET ) { return { 200 : APIResponse . schema ( context . schema . getObjectWithType ( SourceRepository )) }; } return null ; } }","title":"Using Components"},{"location":"openapi/components/#component-discovery","text":"All controllers are can document components when they are linked to the entry point. Objects other than controllers will automatically document their components if they implement APIComponentDocumenter and are declared properties of your ApplicationChannel . (See this guide for other options.) Built-in Aqueduct types will register any applicable components. This includes the types that handle OAuth2 as well as all ManagedObject subclasses in your application.","title":"Component Discovery"},{"location":"openapi/components/#managedobject-discovery","text":"Declaring a ManagedContext as a property of your ApplicationChannel will automatically document the managed objects of your application as schema components.","title":"ManagedObject Discovery"},{"location":"openapi/components/#serializable-discovery","text":"If a Serializable object is bound to a request body in a ResourceController , it will automatically be documented as a schema component. By default, the properties of the Serializable object are reflected on to produce this component. To override this behavior and provide your own component documentation, implement the following method in your Serializable subclass: class Person extends Serializable { String name ; Map String , dynamic asMap () = { name : name }; void readFromMap ( Map String , dynamic map ) { name = map [ name ]; } APISchemaObject documentSchema ( APIDocumentContext context ) { return APISchemaObject . object ( properties: { name : APISchemaObject . string () }); } } If you Serializable type is not bound to a resource controller operation, you must register it yourself. This typically occurs by overriding documentComponents in the controller that uses the type. class MyController extends ResourceController { ... @ override void documentComponents ( APIDocumentContext context ) { super . documentComponents ( context ); final personSchema = Person (). documentSchema ( context ); context . schema . register ( Person , personSchema , representation: Person ); } }","title":"Serializable Discovery"},{"location":"openapi/endpoint/","text":"Documenting Endpoint Controllers In this document, you'll learn how to document endpoint controllers. ResourceController Auto-Documentation A ResourceController does most of the heavy lifting when it comes to generating OpenAPI documents. It will reflect on the bound variables of operation methods to provide the majority of an OpenAPI document. You only need to provide the possible responses. You do this by overriding documentOperationResponses in your ResourceController subclass. The below shows a trivial example of a resource controller that returns a 200 OK with no body for every request. class MyController extends ResourceController { ... Map String , APIResponse documentOperationResponses ( APIDocumentContext context , Operation operation ) { return { 200 : APIResponse ( Successful response. )}; } } This method must return a map, where each key is a string status code and each value is an APIResponse object. An APIResponse object is highly configurable, but in most cases, you only need to declare the schema of its body. For this purpose, a convenience constructor named APIResponse.schema exists. Here is an example where the JSON response body contains a single integer field named 'id': Map String , APIResponse documentOperationResponses ( APIDocumentContext context , Operation operation ) { return { 200 : APIResponse . schema ( Successful response. , APISchemaObject . object ({ id : APISchemaObject . integer () })) }; } In practice, you'll want to have different responses depending on the request method and path variables. The operation argument tells you which operation you are documenting. Map String , APIResponse documentOperationResponses ( APIDocumentContext context , Operation operation ) { if ( operation . method == GET ) { if ( operation . pathVariables . contains ( id )) { return { 200 : APIResponse ( An object by its id. )}; } else { return { 200 : APIResponse ( All objects. )}; } } return null ; } While a resource controller derives the rest of its documentation from your code, you may at times want to override this behavior. Individual elements may be modified by overriding methods like documentOperationParameters , or you may override documentOperations to take over the whole process. If you are not using ResourceController , you must override documentOperations in your controller and provide all of the operation information yourself.","title":"Documenting Endpoint Controllers"},{"location":"openapi/endpoint/#documenting-endpoint-controllers","text":"In this document, you'll learn how to document endpoint controllers.","title":"Documenting Endpoint Controllers"},{"location":"openapi/endpoint/#resourcecontroller-auto-documentation","text":"A ResourceController does most of the heavy lifting when it comes to generating OpenAPI documents. It will reflect on the bound variables of operation methods to provide the majority of an OpenAPI document. You only need to provide the possible responses. You do this by overriding documentOperationResponses in your ResourceController subclass. The below shows a trivial example of a resource controller that returns a 200 OK with no body for every request. class MyController extends ResourceController { ... Map String , APIResponse documentOperationResponses ( APIDocumentContext context , Operation operation ) { return { 200 : APIResponse ( Successful response. )}; } } This method must return a map, where each key is a string status code and each value is an APIResponse object. An APIResponse object is highly configurable, but in most cases, you only need to declare the schema of its body. For this purpose, a convenience constructor named APIResponse.schema exists. Here is an example where the JSON response body contains a single integer field named 'id': Map String , APIResponse documentOperationResponses ( APIDocumentContext context , Operation operation ) { return { 200 : APIResponse . schema ( Successful response. , APISchemaObject . object ({ id : APISchemaObject . integer () })) }; } In practice, you'll want to have different responses depending on the request method and path variables. The operation argument tells you which operation you are documenting. Map String , APIResponse documentOperationResponses ( APIDocumentContext context , Operation operation ) { if ( operation . method == GET ) { if ( operation . pathVariables . contains ( id )) { return { 200 : APIResponse ( An object by its id. )}; } else { return { 200 : APIResponse ( All objects. )}; } } return null ; } While a resource controller derives the rest of its documentation from your code, you may at times want to override this behavior. Individual elements may be modified by overriding methods like documentOperationParameters , or you may override documentOperations to take over the whole process. If you are not using ResourceController , you must override documentOperations in your controller and provide all of the operation information yourself.","title":"ResourceController Auto-Documentation"},{"location":"openapi/middleware/","text":"Documenting Middleware Controllers In this document, you'll learn how to document middleware controllers. Adding to an Operation For the purposes of documentation, a middleware controller does not create operation request and responses. Rather, it modifies the operation details provided by its endpoint controller. When writing middleware controllers, you must override documentOperations and call the superclass' implementation. This allows the middleware's linked controller to document its operations, which will eventually reach an endpoint controller. Once the endpoint controller returns the meat of the operation document, a middleware controller can modify it. For example, a middleware that requires a query parameter named 'key' would like like so: class Middleware extends Controller { ... @ override Map String , APIOperation documentOperations ( APIDocumentContext context , String route , APIPath path ) { final ops = super . documentOperations ( context , route , path ); // ops has been filled out by an endpoint controller, // add key query parameter to each operation. ops . forEach (( method , op ) { op . addParameter ( APIParameter . query ( key , schema: APISchemaObject . string ())); }); return ops ; } } Each string key in an operations map is the lowercase name of an HTTP method, e.g. 'get' or 'post'. An APIOperation encapsulates its request parameters and responses.","title":"Documenting Middleware Controllers"},{"location":"openapi/middleware/#documenting-middleware-controllers","text":"In this document, you'll learn how to document middleware controllers.","title":"Documenting Middleware Controllers"},{"location":"openapi/middleware/#adding-to-an-operation","text":"For the purposes of documentation, a middleware controller does not create operation request and responses. Rather, it modifies the operation details provided by its endpoint controller. When writing middleware controllers, you must override documentOperations and call the superclass' implementation. This allows the middleware's linked controller to document its operations, which will eventually reach an endpoint controller. Once the endpoint controller returns the meat of the operation document, a middleware controller can modify it. For example, a middleware that requires a query parameter named 'key' would like like so: class Middleware extends Controller { ... @ override Map String , APIOperation documentOperations ( APIDocumentContext context , String route , APIPath path ) { final ops = super . documentOperations ( context , route , path ); // ops has been filled out by an endpoint controller, // add key query parameter to each operation. ops . forEach (( method , op ) { op . addParameter ( APIParameter . query ( key , schema: APISchemaObject . string ())); }); return ops ; } } Each string key in an operations map is the lowercase name of an HTTP method, e.g. 'get' or 'post'. An APIOperation encapsulates its request parameters and responses.","title":"Adding to an Operation"},{"location":"snippets/","text":"Aqueduct Snippets These snippets are quick examples of common code that you can use and modify in your application. HTTP Routing, Request and Response Snippets ORM and Database Snippets Authorization and Authentication Snippets Integration Test Snippets","title":"Overview"},{"location":"snippets/#aqueduct-snippets","text":"These snippets are quick examples of common code that you can use and modify in your application. HTTP Routing, Request and Response Snippets ORM and Database Snippets Authorization and Authentication Snippets Integration Test Snippets","title":"Aqueduct Snippets"},{"location":"snippets/auth/","text":"Aqueduct Authorization and Authentication Snippets Enable OAuth 2.0 import package:aqueduct/aqueduct.dart ; import package:aqueduct/managed_auth.dart ; class AppChannel extends ApplicationChannel { AuthServer authServer ; ManagedContext context ; @ override Future prepare () async { final dataModel = new ManagedDataModel . fromCurrentMirrorSystem (); final psc = new PostgreSQLPersistentStore ( username , password , localhost , 5432 my_app ); context = new ManagedContext ( dataModel , psc ); final delegate = new ManagedAuthDelegate User ( context ); authServer = new AuthServer ( delegate ); } @ override Controller get entryPoint { final router = Router (); router . route ( /auth/token ). link (() = AuthController ( authServer )); return router ; } } Add OAuth 2.0 Clients to Database aqueduct auth add-client \\ --id com.app.test \\ --secret supersecret \\ --allowed-scopes profile kiosk:location raw_db_access.readonly \\ --connect postgres://username:password@localhost:5432/my_app Require OAuth 2.0 Scope to Access Routes import package:aqueduct/aqueduct.dart ; import package:aqueduct/managed_auth.dart ; class AppChannel extends ApplicationChannel { AuthServer authServer ; ManagedContext context ; @ override Future prepare () async { final dataModel = ManagedDataModel . fromCurrentMirrorSystem (); final psc = PostgreSQLPersistentStore ( username , password , localhost , 5432 my_app ); context = new ManagedContext ( dataModel , psc ); final delegate = ManagedAuthDelegate User ( context ); authServer = AuthServer ( delegate ); } @ override Controller get entryPoint { router . route ( /auth/token ). link (() = AuthController ( authServer )); router . route ( /profile ) . link (() = Authorizer . bearer ( authServer , scopes: [ profile.readonly ])) . link (() = ProfileController ( context )); } } class ProfileController extends ResourceController { ProfileController ( this . context ); final ManagedContext context ; @ Operation . get () Future Response getProfile () async { final id = request . authorization . ownerID ; final query = new Query User ( context ) .. where (( u ) = u . id ). equalTo ( id ); return new Response . ok ( await query . fetchOne ()); } } Basic Authentication import package:aqueduct/aqueduct.dart ; class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = new Router (); router . route ( /profile ) . link (() = Authorizer . basic ( PasswordVerifier ())) . linkFunction (( req ) async = new Response . ok ( null )); return router ; } } class PasswordVerifier extends AuthValidator { @ override FutureOr Authorization validate T ( AuthorizationParser T parser , T authorizationData , { List AuthScope requiredScope }) {} if ( ! isPasswordCorrect ( authorizationData )) { return null ; } return Authorization ( null , authorizationData . username , this ); } } Add OAuth 2.0 Authorization Code Flow import package:aqueduct/aqueduct.dart ; import package:aqueduct/managed_auth.dart ; class AppChannel extends ApplicationChannel { AuthServer authServer ; ManagedContext context ; @ override Future prepare () async { final dataModel = ManagedDataModel . fromCurrentMirrorSystem (); final psc = PostgreSQLPersistentStore ( username , password , localhost , 5432 my_app ); context = new ManagedContext ( dataModel , psc ); final delegate = new ManagedAuthDelegate User ( context ); authServer = new AuthServer ( delegate ); } @ override Controller get entryPoint { final router = new Router (); router . route ( /auth/token ). link (() = AuthController ( authServer )); router . route ( /auth/code ). link (() = AuthCodeController ( authServer , delegate: this )); return router ; } Future String render ( AuthCodeController forController , Uri requestUri , String responseType , String clientID , String state , String scope ) async { return !DOCTYPE html html lang= en head meta charset= UTF-8 title Login /title /head body div class= container h1 Login /h1 form action= ${requestUri.path} method= POST input type= hidden name= state value= $state input type= hidden name= client_id value= $clientID input type= hidden name= response_type value= $responseType div class= form-group label for= username User Name /label input type= text class= form-control name= username placeholder= Please enter your user name /div div class= form-group label for= password Password /label input type= password class= form-control name= password placeholder= Please enter your password /div button type= submit class= btn btn-success Login /button /form /div /body /html ; } }","title":"Authentication and Authorization"},{"location":"snippets/auth/#aqueduct-authorization-and-authentication-snippets","text":"","title":"Aqueduct Authorization and Authentication Snippets"},{"location":"snippets/auth/#enable-oauth-20","text":"import package:aqueduct/aqueduct.dart ; import package:aqueduct/managed_auth.dart ; class AppChannel extends ApplicationChannel { AuthServer authServer ; ManagedContext context ; @ override Future prepare () async { final dataModel = new ManagedDataModel . fromCurrentMirrorSystem (); final psc = new PostgreSQLPersistentStore ( username , password , localhost , 5432 my_app ); context = new ManagedContext ( dataModel , psc ); final delegate = new ManagedAuthDelegate User ( context ); authServer = new AuthServer ( delegate ); } @ override Controller get entryPoint { final router = Router (); router . route ( /auth/token ). link (() = AuthController ( authServer )); return router ; } }","title":"Enable OAuth 2.0"},{"location":"snippets/auth/#add-oauth-20-clients-to-database","text":"aqueduct auth add-client \\ --id com.app.test \\ --secret supersecret \\ --allowed-scopes profile kiosk:location raw_db_access.readonly \\ --connect postgres://username:password@localhost:5432/my_app","title":"Add OAuth 2.0 Clients to Database"},{"location":"snippets/auth/#require-oauth-20-scope-to-access-routes","text":"import package:aqueduct/aqueduct.dart ; import package:aqueduct/managed_auth.dart ; class AppChannel extends ApplicationChannel { AuthServer authServer ; ManagedContext context ; @ override Future prepare () async { final dataModel = ManagedDataModel . fromCurrentMirrorSystem (); final psc = PostgreSQLPersistentStore ( username , password , localhost , 5432 my_app ); context = new ManagedContext ( dataModel , psc ); final delegate = ManagedAuthDelegate User ( context ); authServer = AuthServer ( delegate ); } @ override Controller get entryPoint { router . route ( /auth/token ). link (() = AuthController ( authServer )); router . route ( /profile ) . link (() = Authorizer . bearer ( authServer , scopes: [ profile.readonly ])) . link (() = ProfileController ( context )); } } class ProfileController extends ResourceController { ProfileController ( this . context ); final ManagedContext context ; @ Operation . get () Future Response getProfile () async { final id = request . authorization . ownerID ; final query = new Query User ( context ) .. where (( u ) = u . id ). equalTo ( id ); return new Response . ok ( await query . fetchOne ()); } }","title":"Require OAuth 2.0 Scope to Access Routes"},{"location":"snippets/auth/#basic-authentication","text":"import package:aqueduct/aqueduct.dart ; class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = new Router (); router . route ( /profile ) . link (() = Authorizer . basic ( PasswordVerifier ())) . linkFunction (( req ) async = new Response . ok ( null )); return router ; } } class PasswordVerifier extends AuthValidator { @ override FutureOr Authorization validate T ( AuthorizationParser T parser , T authorizationData , { List AuthScope requiredScope }) {} if ( ! isPasswordCorrect ( authorizationData )) { return null ; } return Authorization ( null , authorizationData . username , this ); } }","title":"Basic Authentication"},{"location":"snippets/auth/#add-oauth-20-authorization-code-flow","text":"import package:aqueduct/aqueduct.dart ; import package:aqueduct/managed_auth.dart ; class AppChannel extends ApplicationChannel { AuthServer authServer ; ManagedContext context ; @ override Future prepare () async { final dataModel = ManagedDataModel . fromCurrentMirrorSystem (); final psc = PostgreSQLPersistentStore ( username , password , localhost , 5432 my_app ); context = new ManagedContext ( dataModel , psc ); final delegate = new ManagedAuthDelegate User ( context ); authServer = new AuthServer ( delegate ); } @ override Controller get entryPoint { final router = new Router (); router . route ( /auth/token ). link (() = AuthController ( authServer )); router . route ( /auth/code ). link (() = AuthCodeController ( authServer , delegate: this )); return router ; } Future String render ( AuthCodeController forController , Uri requestUri , String responseType , String clientID , String state , String scope ) async { return !DOCTYPE html html lang= en head meta charset= UTF-8 title Login /title /head body div class= container h1 Login /h1 form action= ${requestUri.path} method= POST input type= hidden name= state value= $state input type= hidden name= client_id value= $clientID input type= hidden name= response_type value= $responseType div class= form-group label for= username User Name /label input type= text class= form-control name= username placeholder= Please enter your user name /div div class= form-group label for= password Password /label input type= password class= form-control name= password placeholder= Please enter your password /div button type= submit class= btn btn-success Login /button /form /div /body /html ; } }","title":"Add OAuth 2.0 Authorization Code Flow"},{"location":"snippets/http/","text":"Aqueduct HTTP Snippets Hello, World class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = Router (); router . route ( /hello_world ). linkFunction (( request ) async { return Response . ok ( Hello, world! ) .. contentType = ContentType . TEXT ; }); return router ; } } Route Variables class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = Router (); router . route ( /variable/[:variable] ). linkFunction (( request ) async { return Response . ok ({ method : request . raw . method , path : request . path . variables [ variable ] ?? not specified }); }); return router ; } } Grouping Routes and Binding Path Variables class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = Router (); router . route ( /users/[:id] ) . link (() = MyController ()); return router ; } } class MyController extends ResourceController { final List String things = [ thing1 , thing2 ]; @ Operation . get () Future Response getThings () async { return Response . ok ( things ); } @ Operation . get ( id ) Future Response getThing ( @ Bind . path ( id ) int id ) async { if ( id 0 || id = things . length ) { return Response . notFound (); } return Response . ok ( things [ id ]); } } Custom Middleware class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = Router (); router . route ( /rate_limit ) . link (() = RateLimiter ()) . linkFunction (( req ) async = Response . ok ({ requests_remaining : req . attachments [ remaining ] })); return router ; } } class RateLimiter extends RequestController { @ override Future RequestOrResponse handle ( Request request ) async { final apiKey = request . raw . headers . value ( x-apikey ); final requestsRemaining = await remainingRequestsForAPIKey ( apiKey ); if ( requestsRemaining = 0 ) { return Response ( 429 , null , null ); } request . addResponseModifier (( r ) { r . headers [ x-remaining-requests ] = requestsRemaining ; }); return request ; } } Application-Wide CORS Allowed Origins class AppChannel extends ApplicationChannel { @ override Future prepare () async { // All controllers will use this policy by default CORSPolicy . defaultPolicy . allowedOrigins = [ https://mywebsite.com ]; } @ override Controller get entryPoint { final router = Router (); router . route ( /things ). linkFunction (( request ) async { return Response . ok ([ Widget , Doodad , Transformer ]); }); return router ; } } Serve Files and Set Cache-Control Headers class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = Router (); router . route ( /files/* ). link (() = FileController ( web ) .. addCachePolicy ( new CachePolicy ( expirationFromNow: new Duration ( days: 365 )), ( path ) = path . endsWith ( .js ) || path . endsWith ( .css )) ); return router ; } } Streaming Responses (Server Side Events with text/event-stream) class AppChannel extends ApplicationChannel { final StreamController String controller = new StreamController String (); @ override Future prepare () async { var count = 0 ; Timer . periodic ( new Duration ( seconds: 1 ), ( _ ) { count ++ ; controller . add ( This server has been up for $ count seconds \\n ); }); } @ override Controller get entryPoint { final router = new Router (); router . route ( /stream ). linkFunction (( req ) async { return Response . ok ( controller . stream ) .. bufferOutput = false .. contentType = new ContentType ( text , event-stream , charset: utf-8 ); }); return router ; } } A websocket server class AppChannel extends ApplicationChannel { List WebSocket websockets = []; @ override Future prepare () async { // When another isolate gets a websocket message, echo it to // websockets connected on this isolate. messageHub . listen ( sendBytesToConnectedClients ); } @ override Controller get entryPoint { final router = Router (); // Allow websocket clients to connect to ws://host/connect router . route ( /connect ). linkFunction (( request ) async { var websocket = await WebSocketTransformer . upgrade ( request . raw ); websocket . listen ( echo , onDone: () { websockets . remove ( websocket ); }, cancelOnError: true ); websockets . add ( websocket ); // Take request out of channel return null ; }); return router ; } void sendBytesToConnectedClients ( List int bytes ) { websockets . forEach (( ws ) { ws . add ( bytes ); }); } void echo ( List int bytes ) { sendBytesToConnectedClients ( bytes ); // Send to other isolates messageHub . add ( bytes ); } } Setting Content-Type and Encoding a Response Body class AppChannel extends ApplicationChannel { final ContentType CSV = ContentType ( text , csv , charset: utf-8 ); @ override Future prepare () async { // CsvCodec extends dart:convert.Codec CodecRegistry . defaultInstance . add ( CSV , new CsvCodec ()); } @ override Controller get entryPoint { final router = Router (); router . route ( /csv ). linkFunction (( req ) async { // These values will get converted by CsvCodec into a comma-separated string return Response . ok ([[ 1 , 2 , 3 ], [ a , b , c ]]) .. contentType = CSV ; }); return router ; } } Proxy a File From Another Server class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = Router (); router . route ( /proxy/* ). linkFunction (( req ) async { var fileURL = https://otherserver/ ${ req . path . remainingPath } ; var fileRequest = await client . getUrl ( url ); var fileResponse = await req . close (); if ( fileResponse . statusCode != 200 ) { return new Response . notFound (); } // A dart:io.HttpResponse is a Stream List int of its body bytes. return new Response . ok ( fileResponse ) .. contentType = fileResponse . headers . contentType // let the data just pass through because it has already been encoded // according to content-type; applying encoding again would cause // an issue .. encodeBody = false ; }); return router ; } }","title":"HTTP"},{"location":"snippets/http/#aqueduct-http-snippets","text":"","title":"Aqueduct HTTP Snippets"},{"location":"snippets/http/#hello-world","text":"class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = Router (); router . route ( /hello_world ). linkFunction (( request ) async { return Response . ok ( Hello, world! ) .. contentType = ContentType . TEXT ; }); return router ; } }","title":"Hello, World"},{"location":"snippets/http/#route-variables","text":"class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = Router (); router . route ( /variable/[:variable] ). linkFunction (( request ) async { return Response . ok ({ method : request . raw . method , path : request . path . variables [ variable ] ?? not specified }); }); return router ; } }","title":"Route Variables"},{"location":"snippets/http/#grouping-routes-and-binding-path-variables","text":"class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = Router (); router . route ( /users/[:id] ) . link (() = MyController ()); return router ; } } class MyController extends ResourceController { final List String things = [ thing1 , thing2 ]; @ Operation . get () Future Response getThings () async { return Response . ok ( things ); } @ Operation . get ( id ) Future Response getThing ( @ Bind . path ( id ) int id ) async { if ( id 0 || id = things . length ) { return Response . notFound (); } return Response . ok ( things [ id ]); } }","title":"Grouping Routes and Binding Path Variables"},{"location":"snippets/http/#custom-middleware","text":"class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = Router (); router . route ( /rate_limit ) . link (() = RateLimiter ()) . linkFunction (( req ) async = Response . ok ({ requests_remaining : req . attachments [ remaining ] })); return router ; } } class RateLimiter extends RequestController { @ override Future RequestOrResponse handle ( Request request ) async { final apiKey = request . raw . headers . value ( x-apikey ); final requestsRemaining = await remainingRequestsForAPIKey ( apiKey ); if ( requestsRemaining = 0 ) { return Response ( 429 , null , null ); } request . addResponseModifier (( r ) { r . headers [ x-remaining-requests ] = requestsRemaining ; }); return request ; } }","title":"Custom Middleware"},{"location":"snippets/http/#application-wide-cors-allowed-origins","text":"class AppChannel extends ApplicationChannel { @ override Future prepare () async { // All controllers will use this policy by default CORSPolicy . defaultPolicy . allowedOrigins = [ https://mywebsite.com ]; } @ override Controller get entryPoint { final router = Router (); router . route ( /things ). linkFunction (( request ) async { return Response . ok ([ Widget , Doodad , Transformer ]); }); return router ; } }","title":"Application-Wide CORS Allowed Origins"},{"location":"snippets/http/#serve-files-and-set-cache-control-headers","text":"class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = Router (); router . route ( /files/* ). link (() = FileController ( web ) .. addCachePolicy ( new CachePolicy ( expirationFromNow: new Duration ( days: 365 )), ( path ) = path . endsWith ( .js ) || path . endsWith ( .css )) ); return router ; } }","title":"Serve Files and Set Cache-Control Headers"},{"location":"snippets/http/#streaming-responses-server-side-events-with-textevent-stream","text":"class AppChannel extends ApplicationChannel { final StreamController String controller = new StreamController String (); @ override Future prepare () async { var count = 0 ; Timer . periodic ( new Duration ( seconds: 1 ), ( _ ) { count ++ ; controller . add ( This server has been up for $ count seconds \\n ); }); } @ override Controller get entryPoint { final router = new Router (); router . route ( /stream ). linkFunction (( req ) async { return Response . ok ( controller . stream ) .. bufferOutput = false .. contentType = new ContentType ( text , event-stream , charset: utf-8 ); }); return router ; } }","title":"Streaming Responses (Server Side Events with text/event-stream)"},{"location":"snippets/http/#a-websocket-server","text":"class AppChannel extends ApplicationChannel { List WebSocket websockets = []; @ override Future prepare () async { // When another isolate gets a websocket message, echo it to // websockets connected on this isolate. messageHub . listen ( sendBytesToConnectedClients ); } @ override Controller get entryPoint { final router = Router (); // Allow websocket clients to connect to ws://host/connect router . route ( /connect ). linkFunction (( request ) async { var websocket = await WebSocketTransformer . upgrade ( request . raw ); websocket . listen ( echo , onDone: () { websockets . remove ( websocket ); }, cancelOnError: true ); websockets . add ( websocket ); // Take request out of channel return null ; }); return router ; } void sendBytesToConnectedClients ( List int bytes ) { websockets . forEach (( ws ) { ws . add ( bytes ); }); } void echo ( List int bytes ) { sendBytesToConnectedClients ( bytes ); // Send to other isolates messageHub . add ( bytes ); } }","title":"A websocket server"},{"location":"snippets/http/#setting-content-type-and-encoding-a-response-body","text":"class AppChannel extends ApplicationChannel { final ContentType CSV = ContentType ( text , csv , charset: utf-8 ); @ override Future prepare () async { // CsvCodec extends dart:convert.Codec CodecRegistry . defaultInstance . add ( CSV , new CsvCodec ()); } @ override Controller get entryPoint { final router = Router (); router . route ( /csv ). linkFunction (( req ) async { // These values will get converted by CsvCodec into a comma-separated string return Response . ok ([[ 1 , 2 , 3 ], [ a , b , c ]]) .. contentType = CSV ; }); return router ; } }","title":"Setting Content-Type and Encoding a Response Body"},{"location":"snippets/http/#proxy-a-file-from-another-server","text":"class AppChannel extends ApplicationChannel { @ override Controller get entryPoint { final router = Router (); router . route ( /proxy/* ). linkFunction (( req ) async { var fileURL = https://otherserver/ ${ req . path . remainingPath } ; var fileRequest = await client . getUrl ( url ); var fileResponse = await req . close (); if ( fileResponse . statusCode != 200 ) { return new Response . notFound (); } // A dart:io.HttpResponse is a Stream List int of its body bytes. return new Response . ok ( fileResponse ) .. contentType = fileResponse . headers . contentType // let the data just pass through because it has already been encoded // according to content-type; applying encoding again would cause // an issue .. encodeBody = false ; }); return router ; } }","title":"Proxy a File From Another Server"},{"location":"snippets/orm/","text":"Aqueduct ORM Snippets Filter Query by Column/Property (WHERE clause) var query = new Query Employee ( context ) .. where (( e ) = e . title ). equalTo ( Programmer ); var employees = await query . fetch (); Fetching Only Some Columns/Properties var query = new Query Employee ( context ) .. resultingProperties (( e ) = [ e . id , e . name ]); var employees = await query . fetch (); Sorting Rows/Objects var query = new Query Employee ( context ) .. sortBy (( e ) = e . salary , QuerySortOrder . ascending ); var employees = await query . fetch (); Fetching Only One Row/Object var query = new Query Employee ( context ) .. where (( e ) = e . id ). equalTo ( 1 ); var employee = await query . fetchOne (); Executing a Join (Has-One) var query = new Query Team ( context ) .. join ( object: ( e ) = e . league ); var teamsAndTheirLeague = await query . fetch (); Executing a Join (Has-Many) var query = new Query Team ( context ) .. join ( set : ( e ) = e . players ); var teamsAndTheirPlayers = await query . fetch (); Filtering Joined Rows/Objects var query = new Query Team ( context ); var subquery = query . join ( set : ( e ) = e . players ) .. where (( p ) = p . yearsPlayed ). lessThanOrEqualTo ( 1 ); var teamsAndTheirRookiePlayers = await query . fetch (); Filter Rows/Objects by Relationship Property var query = new Query Team ( context ) .. where (( t ) = t . players . haveAtLeastOneWhere . yearsPlayed ). lessThanOrEqualTo ( 1 ); var teamsWithRookies = await query . fetch (); Complex/Unsupported WHERE Clause (using 'OR') var query = new Query Team ( context ) .. predicate = new QueryPredicate ( name = @name1 OR name = @name2 , { name1 : Badgers , name2 : Gophers }); var badgerAndGopherTeams = await query . fetch (); Updating a Row/Object var query = new Query Team ( context ) .. where (( t ) = t . id ). equalTo ( 10 ) .. values . name = Badgers ; var team = await query . updateOne (); Configure a Database Connection from Configuration File class AppChannel extends ApplicationChannel { @ override Future prepare () async { context = contextWithConnectionInfo ( options . configurationFilePath . database ); } ManagedContext context ; @ override Controller get entryPoint { final router = new Router (); ... return router ; } ManagedContext contextWithConnectionInfo ( DatabaseConnectionConfiguration connectionInfo ) { var dataModel = new ManagedDataModel . fromCurrentMirrorSystem (); var psc = new PostgreSQLPersistentStore ( connectionInfo . username , connectionInfo . password , connectionInfo . host , connectionInfo . port , connectionInfo . databaseName ); return new ManagedContext ( dataModel , psc ); } } class MyAppConfiguration extends Configuration { MyAppConfiguration ( String fileName ) : super . fromFile ( fileName ); DatabaseConnectionConfiguration database ; }","title":"ORM"},{"location":"snippets/orm/#aqueduct-orm-snippets","text":"","title":"Aqueduct ORM Snippets"},{"location":"snippets/orm/#filter-query-by-columnproperty-where-clause","text":"var query = new Query Employee ( context ) .. where (( e ) = e . title ). equalTo ( Programmer ); var employees = await query . fetch ();","title":"Filter Query by Column/Property (WHERE clause)"},{"location":"snippets/orm/#fetching-only-some-columnsproperties","text":"var query = new Query Employee ( context ) .. resultingProperties (( e ) = [ e . id , e . name ]); var employees = await query . fetch ();","title":"Fetching Only Some Columns/Properties"},{"location":"snippets/orm/#sorting-rowsobjects","text":"var query = new Query Employee ( context ) .. sortBy (( e ) = e . salary , QuerySortOrder . ascending ); var employees = await query . fetch ();","title":"Sorting Rows/Objects"},{"location":"snippets/orm/#fetching-only-one-rowobject","text":"var query = new Query Employee ( context ) .. where (( e ) = e . id ). equalTo ( 1 ); var employee = await query . fetchOne ();","title":"Fetching Only One Row/Object"},{"location":"snippets/orm/#executing-a-join-has-one","text":"var query = new Query Team ( context ) .. join ( object: ( e ) = e . league ); var teamsAndTheirLeague = await query . fetch ();","title":"Executing a Join (Has-One)"},{"location":"snippets/orm/#executing-a-join-has-many","text":"var query = new Query Team ( context ) .. join ( set : ( e ) = e . players ); var teamsAndTheirPlayers = await query . fetch ();","title":"Executing a Join (Has-Many)"},{"location":"snippets/orm/#filtering-joined-rowsobjects","text":"var query = new Query Team ( context ); var subquery = query . join ( set : ( e ) = e . players ) .. where (( p ) = p . yearsPlayed ). lessThanOrEqualTo ( 1 ); var teamsAndTheirRookiePlayers = await query . fetch ();","title":"Filtering Joined Rows/Objects"},{"location":"snippets/orm/#filter-rowsobjects-by-relationship-property","text":"var query = new Query Team ( context ) .. where (( t ) = t . players . haveAtLeastOneWhere . yearsPlayed ). lessThanOrEqualTo ( 1 ); var teamsWithRookies = await query . fetch ();","title":"Filter Rows/Objects by Relationship Property"},{"location":"snippets/orm/#complexunsupported-where-clause-using-or","text":"var query = new Query Team ( context ) .. predicate = new QueryPredicate ( name = @name1 OR name = @name2 , { name1 : Badgers , name2 : Gophers }); var badgerAndGopherTeams = await query . fetch ();","title":"Complex/Unsupported WHERE Clause (using 'OR')"},{"location":"snippets/orm/#updating-a-rowobject","text":"var query = new Query Team ( context ) .. where (( t ) = t . id ). equalTo ( 10 ) .. values . name = Badgers ; var team = await query . updateOne ();","title":"Updating a Row/Object"},{"location":"snippets/orm/#configure-a-database-connection-from-configuration-file","text":"class AppChannel extends ApplicationChannel { @ override Future prepare () async { context = contextWithConnectionInfo ( options . configurationFilePath . database ); } ManagedContext context ; @ override Controller get entryPoint { final router = new Router (); ... return router ; } ManagedContext contextWithConnectionInfo ( DatabaseConnectionConfiguration connectionInfo ) { var dataModel = new ManagedDataModel . fromCurrentMirrorSystem (); var psc = new PostgreSQLPersistentStore ( connectionInfo . username , connectionInfo . password , connectionInfo . host , connectionInfo . port , connectionInfo . databaseName ); return new ManagedContext ( dataModel , psc ); } } class MyAppConfiguration extends Configuration { MyAppConfiguration ( String fileName ) : super . fromFile ( fileName ); DatabaseConnectionConfiguration database ; }","title":"Configure a Database Connection from Configuration File"},{"location":"snippets/test/","text":"Aqueduct Test Snippets Expect that Response Returns a JSON Object with an ID test ( that Response Returns a JSON Object , () async { expectResponse ( await app . client . request ( /endpoint ). get (), 200 , body: { id : isNumber } ); }); Expect that Response Returns a List of JSON Objects with IDs test ( that Response returns a list of JSON Objects with IDs , () async { expectResponse ( await app . client . request ( /endpoint ). get (), 200 , body: everyElement ({ id : isNumber }) ); }); Expect that Last-Modified Header Is After Date test ( that Last-Modified Header Is After Date , () async { expect ( await app . client . request ( /endpoint ). get (), hasHeaders ({ last-modified : isAfter ( new DateTime ( 2017 )) }); }); HTTP POST with JSON in Test test ( that can send JSON body , () async { var request = app . client . request ( /endpoint ) .. json = { id : 1 }; expect ( await request . post (), hasStatus ( 202 )); });","title":"Testing"},{"location":"snippets/test/#aqueduct-test-snippets","text":"","title":"Aqueduct Test Snippets"},{"location":"snippets/test/#expect-that-response-returns-a-json-object-with-an-id","text":"test ( that Response Returns a JSON Object , () async { expectResponse ( await app . client . request ( /endpoint ). get (), 200 , body: { id : isNumber } ); });","title":"Expect that Response Returns a JSON Object with an ID"},{"location":"snippets/test/#expect-that-response-returns-a-list-of-json-objects-with-ids","text":"test ( that Response returns a list of JSON Objects with IDs , () async { expectResponse ( await app . client . request ( /endpoint ). get (), 200 , body: everyElement ({ id : isNumber }) ); });","title":"Expect that Response Returns a List of JSON Objects with IDs"},{"location":"snippets/test/#expect-that-last-modified-header-is-after-date","text":"test ( that Last-Modified Header Is After Date , () async { expect ( await app . client . request ( /endpoint ). get (), hasHeaders ({ last-modified : isAfter ( new DateTime ( 2017 )) }); });","title":"Expect that Last-Modified Header Is After Date"},{"location":"snippets/test/#http-post-with-json-in-test","text":"test ( that can send JSON body , () async { var request = app . client . request ( /endpoint ) .. json = { id : 1 }; expect ( await request . post (), hasStatus ( 202 )); });","title":"HTTP POST with JSON in Test"},{"location":"testing/","text":"Tasks Aqueduct applications can be run, tested, debugged and profiled. You create a subclass of TestHarness T in your application's test/ directory. For each test suite, you install this harness to start and stop your application in 'test' mode. A test harness runs your application like a live application. You use Agent objects to send HTTP requests to your application under test. Agents add default information to all of their requests, like authorization information. You use test matchers like hasResponse or hasStatus to validate the response your application sends for a given request. You provide mock services for external services that your application communicates with. These are often driven by the contents of a configuration file. (By convention, a configuration file for tests is named config.src.yaml .) You may also create mock services with MockHTTPServer to use during testing. Guides Writing Tests with a Test Harness Testing with the ORM and OAuth 2.0 Developing Client Applications Using the Debugger and Profiling Use Mock Services","title":"Overview"},{"location":"testing/#tasks","text":"Aqueduct applications can be run, tested, debugged and profiled. You create a subclass of TestHarness T in your application's test/ directory. For each test suite, you install this harness to start and stop your application in 'test' mode. A test harness runs your application like a live application. You use Agent objects to send HTTP requests to your application under test. Agents add default information to all of their requests, like authorization information. You use test matchers like hasResponse or hasStatus to validate the response your application sends for a given request. You provide mock services for external services that your application communicates with. These are often driven by the contents of a configuration file. (By convention, a configuration file for tests is named config.src.yaml .) You may also create mock services with MockHTTPServer to use during testing.","title":"Tasks"},{"location":"testing/#guides","text":"Writing Tests with a Test Harness Testing with the ORM and OAuth 2.0 Developing Client Applications Using the Debugger and Profiling Use Mock Services","title":"Guides"},{"location":"testing/clients/","text":"Using Aqueduct when Writing Client Applications Running an Aqueduct server locally while developing client applications is an important part of the development process. Run applications through their bin/main.dart script or aqueduct serve . The former allows for debugging the application with a debugger. Enable Logging and Return Server Errors Ensure that logging is on while developing client applications by registering a listener on ApplicationChannel.logger . class MyApplicationChannel extends ApplicationChannel { @ override Future prepare () async { logger . onRecord . listen (( record ) { print ( $ record ${ record . error ?? } ${ record . stackTrace ?? } ); }); } ... } A useful feature to turn on during debugging is sending stack traces for 500 Server Error responses. Turn this flag on in a ApplicationChannel while debugging: class MyApplicationChannel extends ApplicationChannel { @ override Future prepare () async { Controller . includeErrorDetailsInServerErrorResponses = true ; } ... } When a 500 error is encountered, the server will send the stack trace back to the client so you can view it while developing the client application without having to switch terminals. This property should never be left on for production code. Avoid Port Conflicts Applications run with aqueduct serve default to port 8888. You may use the --port command-line option to pick a different port: aqueduct serve --port 4000 Provision a Database for Client Testing For applications that use the ORM, you must have a locally running database with a schema that matches your application's data model. If you are using OAuth 2.0, you must have also added client identifiers to the locally running database. You may add client identifiers with the aqueduct auth command-line tool.","title":"Developing Client Applications"},{"location":"testing/clients/#using-aqueduct-when-writing-client-applications","text":"Running an Aqueduct server locally while developing client applications is an important part of the development process. Run applications through their bin/main.dart script or aqueduct serve . The former allows for debugging the application with a debugger.","title":"Using Aqueduct when Writing Client Applications"},{"location":"testing/clients/#enable-logging-and-return-server-errors","text":"Ensure that logging is on while developing client applications by registering a listener on ApplicationChannel.logger . class MyApplicationChannel extends ApplicationChannel { @ override Future prepare () async { logger . onRecord . listen (( record ) { print ( $ record ${ record . error ?? } ${ record . stackTrace ?? } ); }); } ... } A useful feature to turn on during debugging is sending stack traces for 500 Server Error responses. Turn this flag on in a ApplicationChannel while debugging: class MyApplicationChannel extends ApplicationChannel { @ override Future prepare () async { Controller . includeErrorDetailsInServerErrorResponses = true ; } ... } When a 500 error is encountered, the server will send the stack trace back to the client so you can view it while developing the client application without having to switch terminals. This property should never be left on for production code.","title":"Enable Logging and Return Server Errors"},{"location":"testing/clients/#avoid-port-conflicts","text":"Applications run with aqueduct serve default to port 8888. You may use the --port command-line option to pick a different port: aqueduct serve --port 4000","title":"Avoid Port Conflicts"},{"location":"testing/clients/#provision-a-database-for-client-testing","text":"For applications that use the ORM, you must have a locally running database with a schema that matches your application's data model. If you are using OAuth 2.0, you must have also added client identifiers to the locally running database. You may add client identifiers with the aqueduct auth command-line tool.","title":"Provision a Database for Client Testing"},{"location":"testing/debugger/","text":"Using the IntelliJ IDE Debugger The debugger may be used when running tests or developing client applications locally. Enabling the Debugger Applications created by aqueduct create ship with a bin/main.dart script that starts the application. When developing, running this script from an IDE is often preferred to aqueduct serve because the IDE can leverage its full capabilities. One such capability is a debugger. In IntelliJ IDEA (and its suite of products), you may right-click on this file and select 'Debug' from the pop-up menu to run the application in the debugger. Setting Breakpoints A valuable feature of a debugger is the ability to set breakpoints. A breakpoint pauses execution of your application at a specific point in the code, allowing you to view variable values and monitor the code path line-by-line as execution continues. To set a breakpoint, you simply click on the gutter area next to the line of code you wish to stop at. Once a debugger stops, you can view variable values in the center pane of the debugging panel. The left pane (labeled 'Frames') shows the current stack trace. The row of buttons above the stack trace allow you to continue executing code line-by-line. Each button in this row has a slightly different behavior. From left to right: The red arrow with the stack of lines continues execution until the next breakpoint is encountered. The blue downwards arrow executes the current line and moves to the next line. The blue right/downward arrow continues execution into the function that is about to be called and stops on its first line. The red right/downward arrow is the same as above, but will also jump into dependency code. The blue right/upwards arrow completes execution of the current method and stops right after the callsite. Note that currently asynchronous invocations confuse the debugger a bit. To continue past an asynchronous method to the next line, set a breakpoint on that next line and hit the big green arrow on the left column of buttons. To jump into an asynchronous method, command-click on its definition and set a breakpoint on its first line and then click the big green arrow. Profiling with Observatory You may also use Observatory to profile applications. Profiling consists of monitoring memory usage, allocations and how much time a function spends executing relative to the rest of your application. Both aqueduct serve and bin/main.dart support starting Observatory. When running the application with aqueduct serve , add the --observe flag and Observatory will start listening on port 8181 and a web browser will automatically be opened. aqueduct serve --observe When running the application through IntelliJ, Observatory will start listening on a random port. In the run console in IntelliJ, you may click on the Observatory hyperlink to open it in your web browser.","title":"Using the Debugger"},{"location":"testing/debugger/#using-the-intellij-ide-debugger","text":"The debugger may be used when running tests or developing client applications locally.","title":"Using the IntelliJ IDE Debugger"},{"location":"testing/debugger/#enabling-the-debugger","text":"Applications created by aqueduct create ship with a bin/main.dart script that starts the application. When developing, running this script from an IDE is often preferred to aqueduct serve because the IDE can leverage its full capabilities. One such capability is a debugger. In IntelliJ IDEA (and its suite of products), you may right-click on this file and select 'Debug' from the pop-up menu to run the application in the debugger.","title":"Enabling the Debugger"},{"location":"testing/debugger/#setting-breakpoints","text":"A valuable feature of a debugger is the ability to set breakpoints. A breakpoint pauses execution of your application at a specific point in the code, allowing you to view variable values and monitor the code path line-by-line as execution continues. To set a breakpoint, you simply click on the gutter area next to the line of code you wish to stop at. Once a debugger stops, you can view variable values in the center pane of the debugging panel. The left pane (labeled 'Frames') shows the current stack trace. The row of buttons above the stack trace allow you to continue executing code line-by-line. Each button in this row has a slightly different behavior. From left to right: The red arrow with the stack of lines continues execution until the next breakpoint is encountered. The blue downwards arrow executes the current line and moves to the next line. The blue right/downward arrow continues execution into the function that is about to be called and stops on its first line. The red right/downward arrow is the same as above, but will also jump into dependency code. The blue right/upwards arrow completes execution of the current method and stops right after the callsite. Note that currently asynchronous invocations confuse the debugger a bit. To continue past an asynchronous method to the next line, set a breakpoint on that next line and hit the big green arrow on the left column of buttons. To jump into an asynchronous method, command-click on its definition and set a breakpoint on its first line and then click the big green arrow.","title":"Setting Breakpoints"},{"location":"testing/debugger/#profiling-with-observatory","text":"You may also use Observatory to profile applications. Profiling consists of monitoring memory usage, allocations and how much time a function spends executing relative to the rest of your application. Both aqueduct serve and bin/main.dart support starting Observatory. When running the application with aqueduct serve , add the --observe flag and Observatory will start listening on port 8181 and a web browser will automatically be opened. aqueduct serve --observe When running the application through IntelliJ, Observatory will start listening on a random port. In the run console in IntelliJ, you may click on the Observatory hyperlink to open it in your web browser.","title":"Profiling with Observatory"},{"location":"testing/mixins/","text":"Testing Applications That Use ORM and OAuth 2.0 This document describes how to set up your test code to test applications that use the ORM and OAuth 2.0. These types of applications require extra initialization steps, e.g. set up a test database. Testing Applications That Use the ORM Aqueduct's ORM uses PostgreSQL as its database. Before your tests run, Aqueduct will create your application's database tables in a local PostgreSQL database. After the tests complete, it will delete those tables. This allows you to start with an empty database for each test suite as well as control exactly which records are in your database while testing, but without having to manage database schemas or use an mock implementation (e.g., SQLite). You Must Install PostgreSQL Locally On macOS, Postgres.app is a simple, self-contained PostgreSQL instance that you can run as a normal application. (See PostgreSQL installation for other platforms .) Local Database for Tests The same database is reused for testing all of your applications. You only have to create this database once per development machine, or when running in a CI tool like TravisCI. From PostgreSQL's prompt, run: CREATE DATABASE dart_test ; CREATE USER dart WITH createdb ; ALTER USER dart WITH password dart ; GRANT all ON DATABASE dart_test TO dart ; A database configuration in your application's config.yaml.src must match the following: username : dart password : dart host : localhost port : 5432 databaseName : dart_test Your application, when run with a subclass of TestHarness T , will configure its database connection to connect to the local test database. You must mixin TestHarnessORMMixin with your test harness and invoke resetData by overriding onSetUp . You may also override seed to insert test data into the database. class Harness extends TestHarness AppChannel with TestHarnessORMMixin { @ override ManagedContext get context = channel . context ; @ override Future onSetUp () async { await resetData (); } @ override Future seed () async { /* insert some rows here */ } } Seeding Data You should only seed static data in the seed method; this may include things like categories or country codes that cannot be changed during runtime. Data that is manipulated for specific test cases should be invoked in a test setUp callback or the test itself. Local Database for Running an Application A database separate from the test database should be used for running an application locally. You can create a database locally by running psql to open a PostgreSQL terminal and run the following commands: CREATE DATABASE my_app_name; CREATE USER my_app_user WITH PASSWORD mypassword ; GRANT ALL ON DATABASE my_app_name TO my_app_user; Add your schema to the local database by generating and executing migration scripts: aqueduct db generate aqueduct db upgrade --connect postgres://my_app_user:mypassword@localhost:5432/my_app_name Testing Applications That Use OAuth 2.0 Applications that use OAuth 2.0 should mixin TestHarnessAuthMixin . This mixin adds methods for registering a client identifier and authenticating a user. Both methods return an Agent with default headers with authorization information for the client identifier or user. Most often, you use package:aqueduct/managed_auth for an ORM-driven OAuth2 delegate. You must also mixin TestHarnessORMMixin when using this mixin. class Harness extends TestHarness AppChannel with TestHarnessAuthMixin AppChannel , TestHarnessORMMixin { @ override ManagedContext get context = channel . context ; @ override AuthServer get authServer = channel . authServer ; Agent publicAgent ; @ override Future onSetUp () async { await resetData (); publicAgent = await addClient ( com.aqueduct.public ); } Future Agent registerUser ( User user , { Agent withClient }) async { withClient ??= publicAgent ; final req = withClient . request ( /register ) .. body = { username : user . username , password : user . password }; await req . post (); return loginUser ( withClient , user . username , user . password ); } }","title":"Testing with the ORM and OAuth 2.0"},{"location":"testing/mixins/#testing-applications-that-use-orm-and-oauth-20","text":"This document describes how to set up your test code to test applications that use the ORM and OAuth 2.0. These types of applications require extra initialization steps, e.g. set up a test database.","title":"Testing Applications That Use ORM and OAuth 2.0"},{"location":"testing/mixins/#testing-applications-that-use-the-orm","text":"Aqueduct's ORM uses PostgreSQL as its database. Before your tests run, Aqueduct will create your application's database tables in a local PostgreSQL database. After the tests complete, it will delete those tables. This allows you to start with an empty database for each test suite as well as control exactly which records are in your database while testing, but without having to manage database schemas or use an mock implementation (e.g., SQLite). You Must Install PostgreSQL Locally On macOS, Postgres.app is a simple, self-contained PostgreSQL instance that you can run as a normal application. (See PostgreSQL installation for other platforms .)","title":"Testing Applications That Use the ORM"},{"location":"testing/mixins/#local-database-for-tests","text":"The same database is reused for testing all of your applications. You only have to create this database once per development machine, or when running in a CI tool like TravisCI. From PostgreSQL's prompt, run: CREATE DATABASE dart_test ; CREATE USER dart WITH createdb ; ALTER USER dart WITH password dart ; GRANT all ON DATABASE dart_test TO dart ; A database configuration in your application's config.yaml.src must match the following: username : dart password : dart host : localhost port : 5432 databaseName : dart_test Your application, when run with a subclass of TestHarness T , will configure its database connection to connect to the local test database. You must mixin TestHarnessORMMixin with your test harness and invoke resetData by overriding onSetUp . You may also override seed to insert test data into the database. class Harness extends TestHarness AppChannel with TestHarnessORMMixin { @ override ManagedContext get context = channel . context ; @ override Future onSetUp () async { await resetData (); } @ override Future seed () async { /* insert some rows here */ } } Seeding Data You should only seed static data in the seed method; this may include things like categories or country codes that cannot be changed during runtime. Data that is manipulated for specific test cases should be invoked in a test setUp callback or the test itself.","title":"Local Database for Tests"},{"location":"testing/mixins/#local-database-for-running-an-application","text":"A database separate from the test database should be used for running an application locally. You can create a database locally by running psql to open a PostgreSQL terminal and run the following commands: CREATE DATABASE my_app_name; CREATE USER my_app_user WITH PASSWORD mypassword ; GRANT ALL ON DATABASE my_app_name TO my_app_user; Add your schema to the local database by generating and executing migration scripts: aqueduct db generate aqueduct db upgrade --connect postgres://my_app_user:mypassword@localhost:5432/my_app_name","title":"Local Database for Running an Application"},{"location":"testing/mixins/#testing-applications-that-use-oauth-20","text":"Applications that use OAuth 2.0 should mixin TestHarnessAuthMixin . This mixin adds methods for registering a client identifier and authenticating a user. Both methods return an Agent with default headers with authorization information for the client identifier or user. Most often, you use package:aqueduct/managed_auth for an ORM-driven OAuth2 delegate. You must also mixin TestHarnessORMMixin when using this mixin. class Harness extends TestHarness AppChannel with TestHarnessAuthMixin AppChannel , TestHarnessORMMixin { @ override ManagedContext get context = channel . context ; @ override AuthServer get authServer = channel . authServer ; Agent publicAgent ; @ override Future onSetUp () async { await resetData (); publicAgent = await addClient ( com.aqueduct.public ); } Future Agent registerUser ( User user , { Agent withClient }) async { withClient ??= publicAgent ; final req = withClient . request ( /register ) .. body = { username : user . username , password : user . password }; await req . post (); return loginUser ( withClient , user . username , user . password ); } }","title":"Testing Applications That Use OAuth 2.0"},{"location":"testing/mock/","text":"Mocking External Services An Aqueduct application often communicates with another server. For example, an application might make requests to the GitHub API to collect analytics about a team's workflow. When running automated tests, consuming the actual GitHub API isn't feasible - because GitHub will probably rate limit you and because the data being returned is constantly changing. To solve this problem, you can create \"mocks\" of a service during testing. Aqueduct has two testing utilities for this purpose - MockServer and MockHTTPServer - in the aqueduct/test library. Using a MockHTTPServer When testing your application, you send it requests using a TestClient . As part of the request handling logic, your application might issue requests to some other server. MockHTTPServer allows you to validate that the request your application sent was correct and gives you control what the responses are to those requests. For example, githubMock is an instance of MockHTTPServer in the following test, which ensures that the request was constructed correctly: test ( Will get correct user from GitHub , () async { var response = await app . client . authenticatedRequest ( /github_profile/fred ). get (); var requestSentByYourApplicationToGitHub = await githubMock . next (); expect ( requestSentByYourApplicationToGitHub . method , GET ); expect ( requestSentByYourApplicationToGitHub . path , /users/search?name=fred ); }); In the above code, we are expecting that anytime the request GET /github_profile/fred is sent to your application, that it turns around and searches for a user in GitHub's API. This test ensures that we have correctly translated our request to a request to be made to the GitHub API. If no request was made - because of a programmer error - this test would fail because the Future returned from githubMock.next() would never complete. There is no next request, because none was ever delivered! By default, any request sent to a MockHTTPServer is a 200 OK Response with an empty body. You may change this behavior by queuing responses in a mock server. test ( Will get correct user from GitHub , () async { githubMock . queueResponse ( new Response . ok ({ id : 1 , name : fred })); var response = await app . client . authenticatedRequest ( /github_profile/fred ). get (); expect ( response , hasResponse ( 200 , partial ({ id : 1 , name : fred }))) }); In the above code, queueResponse adds a 200 OK Response to the mock server queue with a specific body. The mock server will send that response for the next request it receives. In the implementation of /github_profile/fred , your application sends a GET /users/search?name=fred to the GitHub API - except the GitHub API is your mock server, and it returns the response you queued instead. Thus, the queued up response is the expected response of the GitHub API. After the request completes, the response is removed from the queue and subsequent responses will go back to the default. You may queue as many responses as you like. You may also simulate a failed request - one that never gets a response - like so: mockServer . queueResponse ( MockHTTPServer . mockConnectionFailureResponse ); You may also subclass MockHTTPServer and override its open method to add logic to determine the response. Please see the implementation of MockHTTPServer.open for more details. Configuring a MockHTTPServer A MockHTTPServer is created when setting up tests. It must be closed when tearing down tests. If you use the same mock server to across all tests (e.g., open it in setUpAll ), make sure to clear it after each test: import package:aqueduct/test.dart ; void main () { var mockServer = new MockHTTPServer ( 4000 ); setUpAll (() async { await mockServer . open (); }); tearDownAll (() async { await mockServer . close (); }); tearDown (() async { mockServer . clear (); }); } An instance of MockHTTPServer listens on localhost on a specific port. An application that makes testable external service requests should provide the base URI for those services in a configuration file. The URI for that service in the configuration file used during testing should point at localhost and a specific port. For example, if a deployed config.yaml file has the following key-values: github : baseURL : https :// api . github . com / Then config.src.yaml would have: github : baseURL : http :// localhost : 4000 / Your application reads this configuration file and injects the base URL into the service that will execute requests. class AppConfiguration extends Configuration { AppConfiguration ( String fileName ) : super . fromFile ( fileName ); APIConfiguration github ; } class AppApplicationChannel extends ApplicationChannel { @ override Future prepare () async { var config = new AppConfiguration ( options . configurationFilePath ); githubService = new GitHubService ( baseURL: config . github . baseURL ); } } Note that APIConfiguration is an existing type and is meant for this purpose. Also note that the testing strategy for database connections is not to use a mock but to use a temporary, local database that is set up and torn down during tests. This is possible because you own the data model generating code - whereas you probably don't have access to an external service's development API.","title":"Mocking Services"},{"location":"testing/mock/#mocking-external-services","text":"An Aqueduct application often communicates with another server. For example, an application might make requests to the GitHub API to collect analytics about a team's workflow. When running automated tests, consuming the actual GitHub API isn't feasible - because GitHub will probably rate limit you and because the data being returned is constantly changing. To solve this problem, you can create \"mocks\" of a service during testing. Aqueduct has two testing utilities for this purpose - MockServer and MockHTTPServer - in the aqueduct/test library.","title":"Mocking External Services"},{"location":"testing/mock/#using-a-mockhttpserver","text":"When testing your application, you send it requests using a TestClient . As part of the request handling logic, your application might issue requests to some other server. MockHTTPServer allows you to validate that the request your application sent was correct and gives you control what the responses are to those requests. For example, githubMock is an instance of MockHTTPServer in the following test, which ensures that the request was constructed correctly: test ( Will get correct user from GitHub , () async { var response = await app . client . authenticatedRequest ( /github_profile/fred ). get (); var requestSentByYourApplicationToGitHub = await githubMock . next (); expect ( requestSentByYourApplicationToGitHub . method , GET ); expect ( requestSentByYourApplicationToGitHub . path , /users/search?name=fred ); }); In the above code, we are expecting that anytime the request GET /github_profile/fred is sent to your application, that it turns around and searches for a user in GitHub's API. This test ensures that we have correctly translated our request to a request to be made to the GitHub API. If no request was made - because of a programmer error - this test would fail because the Future returned from githubMock.next() would never complete. There is no next request, because none was ever delivered! By default, any request sent to a MockHTTPServer is a 200 OK Response with an empty body. You may change this behavior by queuing responses in a mock server. test ( Will get correct user from GitHub , () async { githubMock . queueResponse ( new Response . ok ({ id : 1 , name : fred })); var response = await app . client . authenticatedRequest ( /github_profile/fred ). get (); expect ( response , hasResponse ( 200 , partial ({ id : 1 , name : fred }))) }); In the above code, queueResponse adds a 200 OK Response to the mock server queue with a specific body. The mock server will send that response for the next request it receives. In the implementation of /github_profile/fred , your application sends a GET /users/search?name=fred to the GitHub API - except the GitHub API is your mock server, and it returns the response you queued instead. Thus, the queued up response is the expected response of the GitHub API. After the request completes, the response is removed from the queue and subsequent responses will go back to the default. You may queue as many responses as you like. You may also simulate a failed request - one that never gets a response - like so: mockServer . queueResponse ( MockHTTPServer . mockConnectionFailureResponse ); You may also subclass MockHTTPServer and override its open method to add logic to determine the response. Please see the implementation of MockHTTPServer.open for more details.","title":"Using a MockHTTPServer"},{"location":"testing/mock/#configuring-a-mockhttpserver","text":"A MockHTTPServer is created when setting up tests. It must be closed when tearing down tests. If you use the same mock server to across all tests (e.g., open it in setUpAll ), make sure to clear it after each test: import package:aqueduct/test.dart ; void main () { var mockServer = new MockHTTPServer ( 4000 ); setUpAll (() async { await mockServer . open (); }); tearDownAll (() async { await mockServer . close (); }); tearDown (() async { mockServer . clear (); }); } An instance of MockHTTPServer listens on localhost on a specific port. An application that makes testable external service requests should provide the base URI for those services in a configuration file. The URI for that service in the configuration file used during testing should point at localhost and a specific port. For example, if a deployed config.yaml file has the following key-values: github : baseURL : https :// api . github . com / Then config.src.yaml would have: github : baseURL : http :// localhost : 4000 / Your application reads this configuration file and injects the base URL into the service that will execute requests. class AppConfiguration extends Configuration { AppConfiguration ( String fileName ) : super . fromFile ( fileName ); APIConfiguration github ; } class AppApplicationChannel extends ApplicationChannel { @ override Future prepare () async { var config = new AppConfiguration ( options . configurationFilePath ); githubService = new GitHubService ( baseURL: config . github . baseURL ); } } Note that APIConfiguration is an existing type and is meant for this purpose. Also note that the testing strategy for database connections is not to use a mock but to use a temporary, local database that is set up and torn down during tests. This is possible because you own the data model generating code - whereas you probably don't have access to an external service's development API.","title":"Configuring a MockHTTPServer"},{"location":"testing/tests/","text":"Testing in Aqueduct From the ground up, Aqueduct is built to be tested. In practice, this means two things: A deployed Aqueduct application has zero code differences from an Aqueduct application under test. There are helpful utilities for writing tests in Aqueduct. How Tests are Written An Aqueduct test suite starts your application with a configuration file specifically built for a test instance of your application. You write test cases that verify the responses of requests sent to this application. Sometimes, you might reach into your application's services to validate that an intended side-effect was triggered. For example, you might ensure that after a request was executed, a row was added to a database table. A TestHarness T is a type from package:aqueduct_test that handles the initialization of your application under test. It is often subclassed to add application-specific startup tasks, like seeding a database with test users or adding OAuth 2.0 clients. A test harness is installed at the beginning of your test's main function. void main () { final harness = new TestHarness MyApplicationChannel ().. install (); test ( GET /endpoint returns 200 and a simple object , () async { final response = await harness . agent . get ( /endpoint ); expectResponse ( response , 200 , body: { key : value }); }); }} When TestHarness.install is invoked, it installs two callbacks that will start your application in 'test mode' when the tests start, and stop it after the tests complete. An application running in 'test mode' creates a local HTTP server and instantiates your ApplicationChannel on the same isolate as your tests are running on . This allows you to reach into your application channel's services to add test expectations on the state that the services manage. When your application is started in this way, its options have some default values: the application listens on a random port the configurationFilePath is config.src.yaml The config.src.yaml file must have the same structure as your deployment configurations, but values are substituted with test control values. For example, database connection configuration will point at a local test database instead of a production database. For more details on configuring an application, see this guide . Harness Install The install method calls setUpAll and tearDownAll from package:test to start and stop your application. You can manually start and stop your application by invoking TestHarness.start and TestHarness.stop . However, this is not recommended because onSetUp and onTearDown will not be called for each test. Uncaught Exceptions when Testing A test harness configures the application the let uncaught exceptions escape so that they trigger a failure in your test. This is different than when running an application normally, where all exceptions are caught and send an error response to the HTTP client. Using a TestHarness Subclass Most applications should subclass TestHarness T to provide application customization. (Applications created through the CLI have a suclass in test/harness/app.dart .) You override callback methods for events that occur during testing, like when the application starts, and before and after each test. class Harness extends TestHarness WildfireChannel { @ override Future onSetUp () async { // called before each test } } You must invoke install on your test harness at the beginning of test suite for these callbacks to be called. See harness mixins for classes that can be mixed into your harness for testing applications that use the ORM or OAuth 2.0. Using an Agent to Execute Requests A TestHarness T has an agent property that is used to execute requests against the application being tested. An Agent has methods like get and post to execute requests and return a response object that can be validated. Its usage looks like this: test ( After POST to /thing, GET /thing/:id returns created thing , () async { final postResponse = await harness . agent . post ( /thing , body: { key : value }); expectResponse ( postResponse , 200 ); final thingId = postResponse . body . as Map ()[ id ]; final getResponse = await harness . agent . get ( /thing/ $ thingId ); expectResponse ( getResponse , 200 , body: { id : thingId , key : value }); }); Most requests can be configured and executed in methods like TestHarness.get and TestHarness.post . For additional configuration options, use TestHarness.request to create a request object that can be further customized by its properties: final request = harness . agent . request ( /endpoint ) .. headers [ X-Header ] = Value ; When a request includes a body, the body is encoded according to the content-type of the request (defaults to JSON). The encoding behavior is provided by CodecRegistry , the same type that manages encoding and decoding for your application logic. When adding a body to a test request, you provide the unencoded value (a Dart Map , for example) and it is encoded into the correct value (a JSON object, for example). On the inverse side, when validating a response body, the body is already decoded to a Dart type prior to your test code receiving the response. Codecs and CodecRegistry Your tests will run on the same isolate as your application. Whatever codecs have been registered in the codec repository by your application are automatically made available to the code that encodes and decodes your tests requests. You don't have to do anything special to opt-in to non-default codecs. Agents Add Default Values to Requests An Agent has defaults values that it applies to requests from it. These values include headers and the request body content-type. For example, you might want all requests to have an extra header value, without having to write the code to add the header for each request. The default agent of a harness creates requests that have a application/json contentType . Additional agents can be created for different sets of defaults. This is especially useful when testing endpoints that require authorization, where credentials need to be attached to each request. This is a common enough task that there are harness mixins that make this task easier. Writing Test Expectations After an agent executes a request, you write test expectations on its response. These expectations include verifying the status code, headers and body of the response are the desired values. Expectations are set by applying matchers to the properties of a response. For example: test ( GET /foo returns 200 OK , () async { final response = await harness . agent . get ( /foo ); expect ( response . statusCode , 200 ); expect ( response , hasHeaders ({ x-timestamp : greaterThan ( DateTime ( 2020 ))})); expect ( response , hasBody ( isNull )); }); Validating response headers and bodies can be more complex than validating a status code. The hasBody and hasHeaders matchers make expectations on the response headers and body easier to write. The hasHeaders matcher takes a map of header names and values, and expects that the response's headers contains a matching header for each one in the map. The value may be a String or another Matcher . The response can have more headers than expected - those headers are ignored. If you want to exactly specify all headers, there is an optional flag to pass hasHeaders . The hasBody matcher takes any object or matcher that is compared to the decoded body of the response. The body is decoded according to its content-type prior to this comparison. For example, if your response returns a JSON object {\"key\": \"value\"} , this object is first decoded into a Dart Map with the value {'key': 'value'} . The following matchers would all be true: // exact match of Dart Map expect ( response , hasBody ({ key : value })); // a map that contains a key whose value starts with v expect ( response , hasBody ({ key : startsWith ( v )})); // a map that contains the key key expect ( response , hasBody ( containsKey ( key ))); // a map with one entry expect ( response , hasBody ( hasLength ( 1 ))); For large response bodies where you have other test coverage, you may only want to set expectations for a few values. For example, you might have a map with 50 keys, but all you care about it making sure that status='pending' . For this, there is a partial map matcher. It behaves similar to hasHeaders in that it only checks the keys you provide - any other keys are ignored. For example: // Just ensure the body contains an object with at least status=pending, version 1 expect ( response , hasBody ( partial ({ status : pending , version : greaterThan ( 1 ) }))); When using partial , you can also ensure that a map doesn't have a key with the isNotPresent matcher. test ( Get 200 that at least have these keys , () async { var response = await app . client . request ( /endpoint ). get (); expect ( response , hasResponse ( 200 , partial ({ key3 : isNotPresent }))); }); This ensures that key3 is not in the map. This is different than verifying key3: null , which would be true if key3 's value was actually the null value. See the API Reference for aqueduct/test for more matchers. Verifying Side Effects For requests that are not idempotent (they change data in some way), you must also verify the state of the data has changed correctly after the request. This is often done by sending another request your application handles to get the updated data. For example, after you create an employee with POST /employees , you verify the employee was stored correctly by expecting GET /employees/:id has the same data you just sent it. Sometimes, the expected changes are not accessible through your API. For example, let's say that creating a new employee adds a record to an auditing database, but this database is not accessible through a public API. When testing, however, you would want to ensure that record was added to the database. You can access your application's services (like its database connection) in your tests through TestHarness.channel . For example, you might execute a Query T against your application's test database: test ( POST /employees adds an audit log record , () async { final response = await harness . agent . post ( /employees , body: { name : Fred }); expect ( response , hasStatus ( 202 )); final context = harness . channel . context ; final query = new Query AuditRecord ( context ) .. where (( record ) = record . user . id ). equalTo ( response . body . as Map ()[ id ]); final record = await query . fetchOne (); expect ( record , isNotNull ); }); Anything the ApplicationChannel can access, so too can the tests. Further Reading For testing applications that use OAuth 2.0 or the ORM, see the guide on mixins for important behavior.","title":"Writing Tests"},{"location":"testing/tests/#testing-in-aqueduct","text":"From the ground up, Aqueduct is built to be tested. In practice, this means two things: A deployed Aqueduct application has zero code differences from an Aqueduct application under test. There are helpful utilities for writing tests in Aqueduct.","title":"Testing in Aqueduct"},{"location":"testing/tests/#how-tests-are-written","text":"An Aqueduct test suite starts your application with a configuration file specifically built for a test instance of your application. You write test cases that verify the responses of requests sent to this application. Sometimes, you might reach into your application's services to validate that an intended side-effect was triggered. For example, you might ensure that after a request was executed, a row was added to a database table. A TestHarness T is a type from package:aqueduct_test that handles the initialization of your application under test. It is often subclassed to add application-specific startup tasks, like seeding a database with test users or adding OAuth 2.0 clients. A test harness is installed at the beginning of your test's main function. void main () { final harness = new TestHarness MyApplicationChannel ().. install (); test ( GET /endpoint returns 200 and a simple object , () async { final response = await harness . agent . get ( /endpoint ); expectResponse ( response , 200 , body: { key : value }); }); }} When TestHarness.install is invoked, it installs two callbacks that will start your application in 'test mode' when the tests start, and stop it after the tests complete. An application running in 'test mode' creates a local HTTP server and instantiates your ApplicationChannel on the same isolate as your tests are running on . This allows you to reach into your application channel's services to add test expectations on the state that the services manage. When your application is started in this way, its options have some default values: the application listens on a random port the configurationFilePath is config.src.yaml The config.src.yaml file must have the same structure as your deployment configurations, but values are substituted with test control values. For example, database connection configuration will point at a local test database instead of a production database. For more details on configuring an application, see this guide . Harness Install The install method calls setUpAll and tearDownAll from package:test to start and stop your application. You can manually start and stop your application by invoking TestHarness.start and TestHarness.stop . However, this is not recommended because onSetUp and onTearDown will not be called for each test. Uncaught Exceptions when Testing A test harness configures the application the let uncaught exceptions escape so that they trigger a failure in your test. This is different than when running an application normally, where all exceptions are caught and send an error response to the HTTP client.","title":"How Tests are Written"},{"location":"testing/tests/#using-a-testharness-subclass","text":"Most applications should subclass TestHarness T to provide application customization. (Applications created through the CLI have a suclass in test/harness/app.dart .) You override callback methods for events that occur during testing, like when the application starts, and before and after each test. class Harness extends TestHarness WildfireChannel { @ override Future onSetUp () async { // called before each test } } You must invoke install on your test harness at the beginning of test suite for these callbacks to be called. See harness mixins for classes that can be mixed into your harness for testing applications that use the ORM or OAuth 2.0.","title":"Using a TestHarness Subclass"},{"location":"testing/tests/#using-an-agent-to-execute-requests","text":"A TestHarness T has an agent property that is used to execute requests against the application being tested. An Agent has methods like get and post to execute requests and return a response object that can be validated. Its usage looks like this: test ( After POST to /thing, GET /thing/:id returns created thing , () async { final postResponse = await harness . agent . post ( /thing , body: { key : value }); expectResponse ( postResponse , 200 ); final thingId = postResponse . body . as Map ()[ id ]; final getResponse = await harness . agent . get ( /thing/ $ thingId ); expectResponse ( getResponse , 200 , body: { id : thingId , key : value }); }); Most requests can be configured and executed in methods like TestHarness.get and TestHarness.post . For additional configuration options, use TestHarness.request to create a request object that can be further customized by its properties: final request = harness . agent . request ( /endpoint ) .. headers [ X-Header ] = Value ; When a request includes a body, the body is encoded according to the content-type of the request (defaults to JSON). The encoding behavior is provided by CodecRegistry , the same type that manages encoding and decoding for your application logic. When adding a body to a test request, you provide the unencoded value (a Dart Map , for example) and it is encoded into the correct value (a JSON object, for example). On the inverse side, when validating a response body, the body is already decoded to a Dart type prior to your test code receiving the response. Codecs and CodecRegistry Your tests will run on the same isolate as your application. Whatever codecs have been registered in the codec repository by your application are automatically made available to the code that encodes and decodes your tests requests. You don't have to do anything special to opt-in to non-default codecs.","title":"Using an Agent to Execute Requests"},{"location":"testing/tests/#agents-add-default-values-to-requests","text":"An Agent has defaults values that it applies to requests from it. These values include headers and the request body content-type. For example, you might want all requests to have an extra header value, without having to write the code to add the header for each request. The default agent of a harness creates requests that have a application/json contentType . Additional agents can be created for different sets of defaults. This is especially useful when testing endpoints that require authorization, where credentials need to be attached to each request. This is a common enough task that there are harness mixins that make this task easier.","title":"Agents Add Default Values to Requests"},{"location":"testing/tests/#writing-test-expectations","text":"After an agent executes a request, you write test expectations on its response. These expectations include verifying the status code, headers and body of the response are the desired values. Expectations are set by applying matchers to the properties of a response. For example: test ( GET /foo returns 200 OK , () async { final response = await harness . agent . get ( /foo ); expect ( response . statusCode , 200 ); expect ( response , hasHeaders ({ x-timestamp : greaterThan ( DateTime ( 2020 ))})); expect ( response , hasBody ( isNull )); }); Validating response headers and bodies can be more complex than validating a status code. The hasBody and hasHeaders matchers make expectations on the response headers and body easier to write. The hasHeaders matcher takes a map of header names and values, and expects that the response's headers contains a matching header for each one in the map. The value may be a String or another Matcher . The response can have more headers than expected - those headers are ignored. If you want to exactly specify all headers, there is an optional flag to pass hasHeaders . The hasBody matcher takes any object or matcher that is compared to the decoded body of the response. The body is decoded according to its content-type prior to this comparison. For example, if your response returns a JSON object {\"key\": \"value\"} , this object is first decoded into a Dart Map with the value {'key': 'value'} . The following matchers would all be true: // exact match of Dart Map expect ( response , hasBody ({ key : value })); // a map that contains a key whose value starts with v expect ( response , hasBody ({ key : startsWith ( v )})); // a map that contains the key key expect ( response , hasBody ( containsKey ( key ))); // a map with one entry expect ( response , hasBody ( hasLength ( 1 ))); For large response bodies where you have other test coverage, you may only want to set expectations for a few values. For example, you might have a map with 50 keys, but all you care about it making sure that status='pending' . For this, there is a partial map matcher. It behaves similar to hasHeaders in that it only checks the keys you provide - any other keys are ignored. For example: // Just ensure the body contains an object with at least status=pending, version 1 expect ( response , hasBody ( partial ({ status : pending , version : greaterThan ( 1 ) }))); When using partial , you can also ensure that a map doesn't have a key with the isNotPresent matcher. test ( Get 200 that at least have these keys , () async { var response = await app . client . request ( /endpoint ). get (); expect ( response , hasResponse ( 200 , partial ({ key3 : isNotPresent }))); }); This ensures that key3 is not in the map. This is different than verifying key3: null , which would be true if key3 's value was actually the null value. See the API Reference for aqueduct/test for more matchers.","title":"Writing Test Expectations"},{"location":"testing/tests/#verifying-side-effects","text":"For requests that are not idempotent (they change data in some way), you must also verify the state of the data has changed correctly after the request. This is often done by sending another request your application handles to get the updated data. For example, after you create an employee with POST /employees , you verify the employee was stored correctly by expecting GET /employees/:id has the same data you just sent it. Sometimes, the expected changes are not accessible through your API. For example, let's say that creating a new employee adds a record to an auditing database, but this database is not accessible through a public API. When testing, however, you would want to ensure that record was added to the database. You can access your application's services (like its database connection) in your tests through TestHarness.channel . For example, you might execute a Query T against your application's test database: test ( POST /employees adds an audit log record , () async { final response = await harness . agent . post ( /employees , body: { name : Fred }); expect ( response , hasStatus ( 202 )); final context = harness . channel . context ; final query = new Query AuditRecord ( context ) .. where (( record ) = record . user . id ). equalTo ( response . body . as Map ()[ id ]); final record = await query . fetchOne (); expect ( record , isNotNull ); }); Anything the ApplicationChannel can access, so too can the tests.","title":"Verifying Side Effects"},{"location":"testing/tests/#further-reading","text":"For testing applications that use OAuth 2.0 or the ORM, see the guide on mixins for important behavior.","title":"Further Reading"},{"location":"tut/deploying-and-other-fun-things/","text":"5. Deploying an Aqueduct Application The last chapter is a quick one - we'll get our application and its database running locally. When writing tests, the harness creates temporary tables that are destroyed when the tests end. Those tables are created in a database named dart_test that is exclusively used for this purpose. All of your projects will use this same database for running tests. To run the application outside of the tests, you'll need another database. Run the psql command-line tool and enter the following SQL: CREATE DATABASE quiz ; CREATE USER quiz_user WITH createdb ; ALTER USER quiz_user WITH password quizzy ; GRANT all ON database quiz TO quiz_user ; This creates a database quiz that quiz_user has access to. Now, add quiz 's data model to this database by running the following commands in the project directory: aqueduct db generate aqueduct db upgrade --connect postgres://quiz_user:quizzy@localhost:5432/quiz The first command generates a migration file in migrations/ that adds tables _Question and _Answer , and the second command executes that migration file on the newly created database. After adding the data model to the quiz database, run the following commands in psql to insert a question and answer: \\ c quiz INSERT INTO _question ( description ) VALUES ( What is 1+1? ); INSERT INTO _answer ( description , question_index ) VALUES ( 2 , 1 ); The application is currently hard-coded to connect to the test database. We'll write a bit of code to read connection info from a YAML configuration file instead. At the bottom of quiz_sink.dart , create a Configuration subclass: class QuizConfig extends Configuration { QuizConfig ( String filename ) : super . fromFile ( filename ); DatabaseConnectionConfiguration database ; } Update QuizSink 's constructor to create its persistent store from configuration values: QuizSink ( ApplicationOptions appConfig ) : super ( appConfig ) { logger . onRecord . listen (( rec ) = print ( $ rec ${ rec . error ?? } ${ rec . stackTrace ?? } )); var dataModel = new ManagedDataModel . fromCurrentMirrorSystem (); var configValues = new QuizConfig ( appConfig . configurationFilePath ); var persistentStore = new PostgreSQLPersistentStore . fromConnectionInfo ( configValues . database . username , configValues . database . password , configValues . database . host , configValues . database . port , configValues . database . databaseName ); context = new ManagedContext ( dataModel , persistentStore ); } Finally, create the file config.yaml in the root of the project directory and add the following key-values pairs: database : username : quiz_user password : quizzy host : localhost port : 5432 databaseName : quiz Run aqueduct serve and open a browser to http://localhost:8888/questions - you'll see the question in your database. For other ways of running an Aqueduct application (and tips for running them remotely), see this guide . Test and Deployment Configuration The configurationFilePath defaults to config.yaml when using aqueduct serve . In the test harness, the configurationFilePath is set to config.src.yaml . To continue running the tests, add the database connection configuration for dart_test database to the file config.src.yaml . For more details on configuration, see this guide . Onward We've only touched on a small part of Aqueduct, but we've hit the fundamentals pretty well. The rest of the guides on this site will take you deeper on these topics, and topics we haven't covered like OAuth 2.0. It's very important that you get comfortable using the API reference in addition to these guides. If you are looking to solve a problem, start by looking at the API reference for all of the objects you have access to (including the type you are writing the method for). The properties and methods you have access to will lead you to more properties and methods that'll eventually do what you want done. Users of the documentation viewer Dash can add Aqueduct through the Preferences pane, under Downloads . There are IntelliJ IDEA file and code templates available for Aqueduct. See this guide for installation instructions and usage. It takes 10 seconds and it'll save you a ton of time overall. And lastly, remember to create a new project: aqueduct create my_next_big_idea","title":"5. Deploying an Aqueduct Application"},{"location":"tut/deploying-and-other-fun-things/#5-deploying-an-aqueduct-application","text":"The last chapter is a quick one - we'll get our application and its database running locally. When writing tests, the harness creates temporary tables that are destroyed when the tests end. Those tables are created in a database named dart_test that is exclusively used for this purpose. All of your projects will use this same database for running tests. To run the application outside of the tests, you'll need another database. Run the psql command-line tool and enter the following SQL: CREATE DATABASE quiz ; CREATE USER quiz_user WITH createdb ; ALTER USER quiz_user WITH password quizzy ; GRANT all ON database quiz TO quiz_user ; This creates a database quiz that quiz_user has access to. Now, add quiz 's data model to this database by running the following commands in the project directory: aqueduct db generate aqueduct db upgrade --connect postgres://quiz_user:quizzy@localhost:5432/quiz The first command generates a migration file in migrations/ that adds tables _Question and _Answer , and the second command executes that migration file on the newly created database. After adding the data model to the quiz database, run the following commands in psql to insert a question and answer: \\ c quiz INSERT INTO _question ( description ) VALUES ( What is 1+1? ); INSERT INTO _answer ( description , question_index ) VALUES ( 2 , 1 ); The application is currently hard-coded to connect to the test database. We'll write a bit of code to read connection info from a YAML configuration file instead. At the bottom of quiz_sink.dart , create a Configuration subclass: class QuizConfig extends Configuration { QuizConfig ( String filename ) : super . fromFile ( filename ); DatabaseConnectionConfiguration database ; } Update QuizSink 's constructor to create its persistent store from configuration values: QuizSink ( ApplicationOptions appConfig ) : super ( appConfig ) { logger . onRecord . listen (( rec ) = print ( $ rec ${ rec . error ?? } ${ rec . stackTrace ?? } )); var dataModel = new ManagedDataModel . fromCurrentMirrorSystem (); var configValues = new QuizConfig ( appConfig . configurationFilePath ); var persistentStore = new PostgreSQLPersistentStore . fromConnectionInfo ( configValues . database . username , configValues . database . password , configValues . database . host , configValues . database . port , configValues . database . databaseName ); context = new ManagedContext ( dataModel , persistentStore ); } Finally, create the file config.yaml in the root of the project directory and add the following key-values pairs: database : username : quiz_user password : quizzy host : localhost port : 5432 databaseName : quiz Run aqueduct serve and open a browser to http://localhost:8888/questions - you'll see the question in your database. For other ways of running an Aqueduct application (and tips for running them remotely), see this guide . Test and Deployment Configuration The configurationFilePath defaults to config.yaml when using aqueduct serve . In the test harness, the configurationFilePath is set to config.src.yaml . To continue running the tests, add the database connection configuration for dart_test database to the file config.src.yaml . For more details on configuration, see this guide .","title":"5. Deploying an Aqueduct Application"},{"location":"tut/deploying-and-other-fun-things/#onward","text":"We've only touched on a small part of Aqueduct, but we've hit the fundamentals pretty well. The rest of the guides on this site will take you deeper on these topics, and topics we haven't covered like OAuth 2.0. It's very important that you get comfortable using the API reference in addition to these guides. If you are looking to solve a problem, start by looking at the API reference for all of the objects you have access to (including the type you are writing the method for). The properties and methods you have access to will lead you to more properties and methods that'll eventually do what you want done. Users of the documentation viewer Dash can add Aqueduct through the Preferences pane, under Downloads . There are IntelliJ IDEA file and code templates available for Aqueduct. See this guide for installation instructions and usage. It takes 10 seconds and it'll save you a ton of time overall. And lastly, remember to create a new project: aqueduct create my_next_big_idea","title":"Onward"},{"location":"tut/executing-queries/","text":"2. Reading from a Database We will continue to build on the last chapter's project, heroes , by storing our heroes in a database. This will let us to edit our heroes and keep the changes when we restart the application. Object-Relational Mapping A relational database management system (like PostgreSQL or MySQL) stores its data in the form of tables. A table represents some sort of entity - like a person or a bank account. Each table has columns that describe the attributes of that entity - like a name or a balance. Every row in a table is an instance of that entity - like a single person named Bob or a bank account. In an object-oriented framework like Aqueduct, we have representations for tables, columns and rows. A class represents a table, its instances are rows, and instance properties are column values. An ORM translates rows in a database to and from objects in an application. Aqueduct Database Example #1 Example #2 Class Table Person Bank Account Instance Row A person named Bob Sally's Bank Account Property Column Person's Name Bank Account Balance In Aqueduct, each database table-class pairing is called an entity . Collectively, an application's entities are called its data model . Building a Data Model In our heroes application, we will have one type of entity - a \"hero\". To create a new entity, we subclass ManagedObject T . Create a new directory lib/model/ and then add a new file to this directory named hero.dart . Add the following code: import package:heroes/heroes.dart ; class Hero extends ManagedObject _Hero implements _Hero {} class _Hero { @ primaryKey int id ; @ Column ( unique: true ) String name ; } This declares a Hero entity. Entities are always made up of two classes. The _Hero class is a direct mapping of a database table. This table's name will have the same name as the class: _Hero . Every property declared in this class will have a corresponding column in this table. Therefore, the _Hero table will have two columns - id and name . The id column is this table's primary key (a unique identifier for each hero). The name of each hero must be unique. The other class, Hero , is what we work with in our code - when we fetch heroes from a database, they will be instances of Hero . The Hero class is called the instance type of the entity, because that's what we have instances of. _Hero is the table definition of the entity. You won't use the table definition for anything other than describing the database table. An instance type must implement its table definition; this gives our Hero all of the properties of _Hero . An instance type must extend ManagedObject T , where T is also the table definition. ManagedObject T has behavior for automatically transferring objects to the database and back (among other things). Transient Properties Properties declared in the instance type aren't stored in the database. This is different than properties in the table definition. For example, a database table might have a firstName and lastName , but it's useful in some places to have a fullName property. Declaring the fullName property in the instance type means we have easy access to the full name, but we still store the first and last name individually. Defining a Context Our application needs to know two things to execute database queries: What is the data model (our collection of entities)? What database are we connecting to? Both of these things are set up when an application is first started. In channel.dart , add a new property context and update prepare() : class HeroesChannel extends ApplicationChannel { ManagedContext context ; @ override Future prepare () async { logger . onRecord . listen (( rec ) = print ( $ rec ${ rec . error ?? } ${ rec . stackTrace ?? } )); final dataModel = ManagedDataModel . fromCurrentMirrorSystem (); final persistentStore = PostgreSQLPersistentStore . fromConnectionInfo ( heroes_user , password , localhost , 5432 , heroes ); context = ManagedContext ( dataModel , persistentStore ); } @ override Controller get entryPoint { ... ManagedDataModel.fromCurrentMirrorSystem() will find all of our ManagedObject T subclasses and 'compile' them into a data model. A PostgreSQLPersistentStore takes database connection information that it will use to connect and send queries to a database. Together, these objects are packaged in a ManagedContext . Configuring a Database Connection This tutorial hardcodes the information needed to connect to a database. In a future chapter, we will move these values to a configuration file so that we can change them during tests and various deployment environments. The context will coordinate with these two objects to execute queries and translate objects to and from the database. Controllers that make database queries need a reference to the context. So, we'll want HeroesController to have access to the context. In heroes_controller.dart , add a property and create a new constructor: class HeroesController extends ResourceController { HeroesController ( this . context ); final ManagedContext context ; ... Now that HeroesController requires a context in its constructor, we need to pass it the context we created in prepare() . Update entryPoint in channel.dart . @ override Controller get entryPoint { final router = Router (); router . route ( /heroes/[:id] ) . link (() = HeroesController ( context )); router . route ( /example ) . linkFunction (( request ) async { return new Response . ok ({ key : value }); }); return router ; } Now that we've 'injected' this context into our HeroesController constructor, each HeroesController can execute database queries. Service Objects and Dependency Injection Our context is an example of a service object . A service encapsulates logic and state into a single object that can be reused in multiple controllers. A typical service object accesses another server, like a database or another REST API. Some service objects may simply provide a simplified interface to a complex process, like applying transforms to an image. Services are passed in a controller's constructor; this is called dependency injection . Unlike many frameworks, Aqueduct does not require a complex dependency injection framework; this is because you write the code to create instances of your controllers and can pass whatever you like in their constructor. Executing Queries Our operation methods in HeroesController currently return heroes from an in-memory list. To fetch data from a database instead of this list, we create and execute instances of Query T in our ManagedContext . Let's start by replacing getAllHeroes in heroes_controller.dart . Make sure to import your model/hero.dart file at the top: import package:heroes/heroes.dart ; import package:heroes/model/hero.dart ; class HeroesController extends ResourceController { HeroesController ( this . context ); final ManagedContext context ; @ Operation . get () Future Response getAllHeroes () async { final heroQuery = Query Hero ( context ); final heroes = await heroQuery . fetch (); return Response . ok ( heroes ); } ... Here, we create an instance of Query Hero and then execute its fetch() method. The type argument to Query T is an instance type; it lets the query know which table to fetch rows from and the type of objects that are returned by the query. The context argument tells it which database to fetch it from. The fetch() execution method returns a List Hero . We write that list to the body of the response. Now, let's update getHeroByID to fetch a single hero from the database. @ Operation . get ( id ) Future Response getHeroByID ( @ Bind . path ( id ) int id ) async { final heroQuery = Query Hero ( context ) .. where (( h ) = h . id ). equalTo ( id ); final hero = await heroQuery . fetchOne (); if ( hero == null ) { return Response . notFound (); } return Response . ok ( hero ); } This query does two interesting things. First, it uses the where method to filter heroes that have the same id as the path variable. For example, /heroes/1 will fetch a hero with an id of 1 . This works because Query.where adds a SQL WHERE clause to the query. We'd get the following SQL: SELECT id , name FROM _question WHERE id = 1 ; The where method uses the property selector syntax. This syntax is a closure that takes an argument of the type being queried, and must return a property of that object. This creates an expression object that targets the selected property. By invoking methods like equalTo on this expression object, a boolean expression is added to the query. Property Selectors Many query configuration methods use the property selector syntax. Setting up a keyboard shortcut (called a Live Template in IntelliJ) to enter the syntax is beneficial. A downloadable settings configuration for IntelliJ exists here that includes this shortcut. The fetchOne() execution method will fetch a single object that fulfills all of the expressions applied to the query. If no database row meets the criteria, null is returned. Our controller returns a 404 Not Found response in that scenario. We have now written code that fetches heroes from a database instead of from in memory, but we don't have a database - yet. Use fetchOne() on Unique Properties If more than one database row meets the criteria of a fetchOne() , an exception is thrown. It's only safe to use fetchOne() when applying an expression to a unique property, like a primary key. Setting Up a Database For development, you'll need to install a PostgreSQL server on your local machine. If you are on macOS, use Postgres.app . This native macOS application manages starting and stopping PostgreSQL servers on your machine. For other platforms, see this page . 9.6 or Greater The minimum version of PostgreSQL needed to work with Aqueduct is 9.6. If you installed Postgres.app, open the application and select the + button on the bottom left corner of the screen to create a new database server. Choose a version (at least 9.6, but the most recent version is best), name the server whatever you like, and leave the rest of the options unchanged before clicking Create Server . Once the server has been created, click Start . A list of databases available on this server will be shown as named, database icons. Double-click on any of them to open the psql command-line tool. psql For other platforms, psql should be available in your $PATH . You can also add Postgres.app 's psql to your path with the directions here . In psql , create a new database and a user to manage it. CREATE DATABASE heroes ; CREATE USER heroes_user WITH createdb ; ALTER USER heroes_user WITH password password ; GRANT all ON database heroes TO heroes_user ; Next, we need to create the table where heroes are stored in this database. From your project directory, run the following command: aqueduct db generate This command will create a new migration file . A migration file is a Dart script that runs a series of SQL commands to alter a database's schema. It is created in a new directory in your project named migrations/ . Open migrations/00000001_initial.migration.dart , it should look like this: import package:aqueduct/aqueduct.dart ; import dart:async ; class Migration1 extends Migration { @ override Future upgrade () async { database . createTable ( SchemaTable ( _Hero , [ SchemaColumn ( id , ManagedPropertyType . bigInteger , isPrimaryKey: true , autoincrement: true , isIndexed: false , isNullable: false , isUnique: false ), SchemaColumn ( name , ManagedPropertyType . string , isPrimaryKey: false , autoincrement: false , isIndexed: false , isNullable: false , isUnique: true ), ], )); } @ override Future downgrade () async {} @ override Future seed () async {} } In a moment, we'll execute this migration file. That will create a new table named _Hero with columns for id and name . Before we run it, we should seed the database with some initial heroes. In the seed() method, add the following: @ override Future seed () async { final heroNames = [ Mr. Nice , Narco , Bombasto , Celeritas , Magneta ]; for ( final heroName in heroNames ) { await database . store . execute ( INSERT INTO _Hero (name) VALUES (@name) , substitutionValues: { name : heroName }); } } Apply this migration file to our locally running heroes database with the following command in the project directory: aqueduct db upgrade -- connect postgres: //heroes_user:password@localhost:5432/heroes Re-run your application with aqueduct serve . Then, reload http://aqueduct-tutorial.stablekernel.io . Your dashboard of heroes and detail page for each will still show up - but this time, they are sourced from a database. ManagedObjects and Migration Scripts In our migration's seed() method, we executed SQL queries instead of using the Aqueduct ORM. It is very important that you do not use Query T , ManagedObject T or other elements of the Aqueduct ORM in migration files. Migration files represent an ordered series of historical steps that describe your database schema. If you replay those steps (which is what executing a migration file does), you will end up with the same database schema every time. However, a ManagedObject T subclass changes over time - the definition of a managed object is not historical, it only represents the current point in time. Since a ManagedObject T subclass can change, using one in our migration file would mean that our migration file could change. Query Parameters and HTTP Headers In the browser application, the dashboard has a text field for searching heroes. When you enter text into it, it will send the search term to the server by appending a query parameter to GET /heroes . For example, if you entered the text abc , it'd make this request: GET /heroes?name=abc Our Aqueduct application can use this value to return a list of heroes that contains the search string. In heroes_controller.dart , modify getAllHeroes() to bind the 'name' query parameter: @ Operation . get () Future Response getAllHeroes ({ @ Bind . query ( name ) String name }) async { final heroQuery = Query Hero ( context ); if ( name != null ) { heroQuery . where (( h ) = h . name ). contains ( name , caseSensitive: false ); } final heroes = await heroQuery . fetch (); return Response . ok ( heroes ); } You can re-run your Aqueduct application and use the search bar in the client application. The @Bind.query('name') annotation will bind the value of the 'name' query parameter if it is included in the request URL. Otherwise, name will be null. Notice that name is an optional parameter (it is surrounded by curly brackets). An optional parameter in an operation method is also optional in the HTTP request. If we removed the curly brackets from this binding, the 'name' query parameter would become required and the request GET /heroes without ?name=x would fail with a 400 Bad Request. ResourceController Binding There is even more to bindings than we've shown (like automatically parsing bound values into types like int and DateTime ). For more information, see ResourceControllers . Binding query and header parameters in a operation method is a good way to make your code more intentional and avoid boilerplate parsing code. Aqueduct is able to generate better documentation when using bindings. Next: Storing Data","title":"2. Reading from a Database"},{"location":"tut/executing-queries/#2-reading-from-a-database","text":"We will continue to build on the last chapter's project, heroes , by storing our heroes in a database. This will let us to edit our heroes and keep the changes when we restart the application.","title":"2. Reading from a Database"},{"location":"tut/executing-queries/#object-relational-mapping","text":"A relational database management system (like PostgreSQL or MySQL) stores its data in the form of tables. A table represents some sort of entity - like a person or a bank account. Each table has columns that describe the attributes of that entity - like a name or a balance. Every row in a table is an instance of that entity - like a single person named Bob or a bank account. In an object-oriented framework like Aqueduct, we have representations for tables, columns and rows. A class represents a table, its instances are rows, and instance properties are column values. An ORM translates rows in a database to and from objects in an application. Aqueduct Database Example #1 Example #2 Class Table Person Bank Account Instance Row A person named Bob Sally's Bank Account Property Column Person's Name Bank Account Balance In Aqueduct, each database table-class pairing is called an entity . Collectively, an application's entities are called its data model .","title":"Object-Relational Mapping"},{"location":"tut/executing-queries/#building-a-data-model","text":"In our heroes application, we will have one type of entity - a \"hero\". To create a new entity, we subclass ManagedObject T . Create a new directory lib/model/ and then add a new file to this directory named hero.dart . Add the following code: import package:heroes/heroes.dart ; class Hero extends ManagedObject _Hero implements _Hero {} class _Hero { @ primaryKey int id ; @ Column ( unique: true ) String name ; } This declares a Hero entity. Entities are always made up of two classes. The _Hero class is a direct mapping of a database table. This table's name will have the same name as the class: _Hero . Every property declared in this class will have a corresponding column in this table. Therefore, the _Hero table will have two columns - id and name . The id column is this table's primary key (a unique identifier for each hero). The name of each hero must be unique. The other class, Hero , is what we work with in our code - when we fetch heroes from a database, they will be instances of Hero . The Hero class is called the instance type of the entity, because that's what we have instances of. _Hero is the table definition of the entity. You won't use the table definition for anything other than describing the database table. An instance type must implement its table definition; this gives our Hero all of the properties of _Hero . An instance type must extend ManagedObject T , where T is also the table definition. ManagedObject T has behavior for automatically transferring objects to the database and back (among other things). Transient Properties Properties declared in the instance type aren't stored in the database. This is different than properties in the table definition. For example, a database table might have a firstName and lastName , but it's useful in some places to have a fullName property. Declaring the fullName property in the instance type means we have easy access to the full name, but we still store the first and last name individually.","title":"Building a Data Model"},{"location":"tut/executing-queries/#defining-a-context","text":"Our application needs to know two things to execute database queries: What is the data model (our collection of entities)? What database are we connecting to? Both of these things are set up when an application is first started. In channel.dart , add a new property context and update prepare() : class HeroesChannel extends ApplicationChannel { ManagedContext context ; @ override Future prepare () async { logger . onRecord . listen (( rec ) = print ( $ rec ${ rec . error ?? } ${ rec . stackTrace ?? } )); final dataModel = ManagedDataModel . fromCurrentMirrorSystem (); final persistentStore = PostgreSQLPersistentStore . fromConnectionInfo ( heroes_user , password , localhost , 5432 , heroes ); context = ManagedContext ( dataModel , persistentStore ); } @ override Controller get entryPoint { ... ManagedDataModel.fromCurrentMirrorSystem() will find all of our ManagedObject T subclasses and 'compile' them into a data model. A PostgreSQLPersistentStore takes database connection information that it will use to connect and send queries to a database. Together, these objects are packaged in a ManagedContext . Configuring a Database Connection This tutorial hardcodes the information needed to connect to a database. In a future chapter, we will move these values to a configuration file so that we can change them during tests and various deployment environments. The context will coordinate with these two objects to execute queries and translate objects to and from the database. Controllers that make database queries need a reference to the context. So, we'll want HeroesController to have access to the context. In heroes_controller.dart , add a property and create a new constructor: class HeroesController extends ResourceController { HeroesController ( this . context ); final ManagedContext context ; ... Now that HeroesController requires a context in its constructor, we need to pass it the context we created in prepare() . Update entryPoint in channel.dart . @ override Controller get entryPoint { final router = Router (); router . route ( /heroes/[:id] ) . link (() = HeroesController ( context )); router . route ( /example ) . linkFunction (( request ) async { return new Response . ok ({ key : value }); }); return router ; } Now that we've 'injected' this context into our HeroesController constructor, each HeroesController can execute database queries. Service Objects and Dependency Injection Our context is an example of a service object . A service encapsulates logic and state into a single object that can be reused in multiple controllers. A typical service object accesses another server, like a database or another REST API. Some service objects may simply provide a simplified interface to a complex process, like applying transforms to an image. Services are passed in a controller's constructor; this is called dependency injection . Unlike many frameworks, Aqueduct does not require a complex dependency injection framework; this is because you write the code to create instances of your controllers and can pass whatever you like in their constructor.","title":"Defining a Context"},{"location":"tut/executing-queries/#executing-queries","text":"Our operation methods in HeroesController currently return heroes from an in-memory list. To fetch data from a database instead of this list, we create and execute instances of Query T in our ManagedContext . Let's start by replacing getAllHeroes in heroes_controller.dart . Make sure to import your model/hero.dart file at the top: import package:heroes/heroes.dart ; import package:heroes/model/hero.dart ; class HeroesController extends ResourceController { HeroesController ( this . context ); final ManagedContext context ; @ Operation . get () Future Response getAllHeroes () async { final heroQuery = Query Hero ( context ); final heroes = await heroQuery . fetch (); return Response . ok ( heroes ); } ... Here, we create an instance of Query Hero and then execute its fetch() method. The type argument to Query T is an instance type; it lets the query know which table to fetch rows from and the type of objects that are returned by the query. The context argument tells it which database to fetch it from. The fetch() execution method returns a List Hero . We write that list to the body of the response. Now, let's update getHeroByID to fetch a single hero from the database. @ Operation . get ( id ) Future Response getHeroByID ( @ Bind . path ( id ) int id ) async { final heroQuery = Query Hero ( context ) .. where (( h ) = h . id ). equalTo ( id ); final hero = await heroQuery . fetchOne (); if ( hero == null ) { return Response . notFound (); } return Response . ok ( hero ); } This query does two interesting things. First, it uses the where method to filter heroes that have the same id as the path variable. For example, /heroes/1 will fetch a hero with an id of 1 . This works because Query.where adds a SQL WHERE clause to the query. We'd get the following SQL: SELECT id , name FROM _question WHERE id = 1 ; The where method uses the property selector syntax. This syntax is a closure that takes an argument of the type being queried, and must return a property of that object. This creates an expression object that targets the selected property. By invoking methods like equalTo on this expression object, a boolean expression is added to the query. Property Selectors Many query configuration methods use the property selector syntax. Setting up a keyboard shortcut (called a Live Template in IntelliJ) to enter the syntax is beneficial. A downloadable settings configuration for IntelliJ exists here that includes this shortcut. The fetchOne() execution method will fetch a single object that fulfills all of the expressions applied to the query. If no database row meets the criteria, null is returned. Our controller returns a 404 Not Found response in that scenario. We have now written code that fetches heroes from a database instead of from in memory, but we don't have a database - yet. Use fetchOne() on Unique Properties If more than one database row meets the criteria of a fetchOne() , an exception is thrown. It's only safe to use fetchOne() when applying an expression to a unique property, like a primary key.","title":"Executing Queries"},{"location":"tut/executing-queries/#setting-up-a-database","text":"For development, you'll need to install a PostgreSQL server on your local machine. If you are on macOS, use Postgres.app . This native macOS application manages starting and stopping PostgreSQL servers on your machine. For other platforms, see this page . 9.6 or Greater The minimum version of PostgreSQL needed to work with Aqueduct is 9.6. If you installed Postgres.app, open the application and select the + button on the bottom left corner of the screen to create a new database server. Choose a version (at least 9.6, but the most recent version is best), name the server whatever you like, and leave the rest of the options unchanged before clicking Create Server . Once the server has been created, click Start . A list of databases available on this server will be shown as named, database icons. Double-click on any of them to open the psql command-line tool. psql For other platforms, psql should be available in your $PATH . You can also add Postgres.app 's psql to your path with the directions here . In psql , create a new database and a user to manage it. CREATE DATABASE heroes ; CREATE USER heroes_user WITH createdb ; ALTER USER heroes_user WITH password password ; GRANT all ON database heroes TO heroes_user ; Next, we need to create the table where heroes are stored in this database. From your project directory, run the following command: aqueduct db generate This command will create a new migration file . A migration file is a Dart script that runs a series of SQL commands to alter a database's schema. It is created in a new directory in your project named migrations/ . Open migrations/00000001_initial.migration.dart , it should look like this: import package:aqueduct/aqueduct.dart ; import dart:async ; class Migration1 extends Migration { @ override Future upgrade () async { database . createTable ( SchemaTable ( _Hero , [ SchemaColumn ( id , ManagedPropertyType . bigInteger , isPrimaryKey: true , autoincrement: true , isIndexed: false , isNullable: false , isUnique: false ), SchemaColumn ( name , ManagedPropertyType . string , isPrimaryKey: false , autoincrement: false , isIndexed: false , isNullable: false , isUnique: true ), ], )); } @ override Future downgrade () async {} @ override Future seed () async {} } In a moment, we'll execute this migration file. That will create a new table named _Hero with columns for id and name . Before we run it, we should seed the database with some initial heroes. In the seed() method, add the following: @ override Future seed () async { final heroNames = [ Mr. Nice , Narco , Bombasto , Celeritas , Magneta ]; for ( final heroName in heroNames ) { await database . store . execute ( INSERT INTO _Hero (name) VALUES (@name) , substitutionValues: { name : heroName }); } } Apply this migration file to our locally running heroes database with the following command in the project directory: aqueduct db upgrade -- connect postgres: //heroes_user:password@localhost:5432/heroes Re-run your application with aqueduct serve . Then, reload http://aqueduct-tutorial.stablekernel.io . Your dashboard of heroes and detail page for each will still show up - but this time, they are sourced from a database. ManagedObjects and Migration Scripts In our migration's seed() method, we executed SQL queries instead of using the Aqueduct ORM. It is very important that you do not use Query T , ManagedObject T or other elements of the Aqueduct ORM in migration files. Migration files represent an ordered series of historical steps that describe your database schema. If you replay those steps (which is what executing a migration file does), you will end up with the same database schema every time. However, a ManagedObject T subclass changes over time - the definition of a managed object is not historical, it only represents the current point in time. Since a ManagedObject T subclass can change, using one in our migration file would mean that our migration file could change.","title":"Setting Up a Database"},{"location":"tut/executing-queries/#query-parameters-and-http-headers","text":"In the browser application, the dashboard has a text field for searching heroes. When you enter text into it, it will send the search term to the server by appending a query parameter to GET /heroes . For example, if you entered the text abc , it'd make this request: GET /heroes?name=abc Our Aqueduct application can use this value to return a list of heroes that contains the search string. In heroes_controller.dart , modify getAllHeroes() to bind the 'name' query parameter: @ Operation . get () Future Response getAllHeroes ({ @ Bind . query ( name ) String name }) async { final heroQuery = Query Hero ( context ); if ( name != null ) { heroQuery . where (( h ) = h . name ). contains ( name , caseSensitive: false ); } final heroes = await heroQuery . fetch (); return Response . ok ( heroes ); } You can re-run your Aqueduct application and use the search bar in the client application. The @Bind.query('name') annotation will bind the value of the 'name' query parameter if it is included in the request URL. Otherwise, name will be null. Notice that name is an optional parameter (it is surrounded by curly brackets). An optional parameter in an operation method is also optional in the HTTP request. If we removed the curly brackets from this binding, the 'name' query parameter would become required and the request GET /heroes without ?name=x would fail with a 400 Bad Request. ResourceController Binding There is even more to bindings than we've shown (like automatically parsing bound values into types like int and DateTime ). For more information, see ResourceControllers . Binding query and header parameters in a operation method is a good way to make your code more intentional and avoid boilerplate parsing code. Aqueduct is able to generate better documentation when using bindings.","title":"Query Parameters and HTTP Headers"},{"location":"tut/executing-queries/#next-storing-data","text":"","title":"Next: Storing Data"},{"location":"tut/getting-started/","text":"1. Getting Started By the end of this tutorial, you will have created an Aqueduct application that serves fictional heroes from a PostgreSQL database. You will learn the following: Run an Aqueduct application Route HTTP requests to the appropriate handler in your code Store and retrieve database data Write automated tests for each endpoint Require authorization for HTTP requests Getting Help If at anytime you get stuck, hop on over to the Aqueduct Slack channel . You can also see a finished version of this application here . Installation To get started, make sure you have the following software installed: Dart ( Install Instructions ) IntelliJ IDEA or any other Jetbrains IDE, including the free Community Edition ( Install Instructions ) The IntelliJ IDEA Dart Plugin ( Install Instructions ) Install the aqueduct command line tool by running the following command in your shell: pub global activate aqueduct If you get warning text about your PATH , make sure to read it before moving on. Creating a Project Create a new project named heroes by entering the following in your shell: aqueduct create heroes This creates a heroes project directory. Open this directory with IntelliJ IDEA by dragging the project folder onto IntellIJ IDEA's icon. In IntelliJ's project view, locate the lib directory; this is where your project's code will go. This project has two source files - heroes.dart and channel.dart . Open the file heroes.dart . Click Enable Dart Support in the top right corner of the editor. Handling HTTP Requests In your browser, navigate to http://aqueduct-tutorial.stablekernel.io . This browser application is a 'Hero Manager' - it allows a user to view, create, delete and update heroes. (It is a slightly modified version of the AngularDart Tour of Heroes Tutorial .) It will make HTTP requests to http://localhost:8888 to fetch and manipulate hero data. The application you will build in this tutorial respond to those requests. Running the Browser Application Locally The browser application is served over HTTP so that it can access your Aqueduct application when it runs locally on your machine. Your browser may warn you about navigating to an insecure webpage, because it is in fact insecure. You can run this application locally by grabbing the source code from here . In this first chapter, you will write code to handle two requests: one to get a list of heroes, and the other to get a single hero by its identifier. Those requests are: GET /heroes to the list of heroes GET /heroes/:id to get an individual hero HTTP Operation Shorthand The term GET /heroes is called an operation. It is the combination of the HTTP method and the path of the request. Each operation is unique to an application, so your code is segmented into units for each operation. Sections with a colon, like the ':id' segment, are variable: they can be 1, 2, 3, and so on. Controller Objects Handle Requests Requests are handled by controller objects . A controller object can respond to a request. It can also take other action and let another controller respond. For example, it might check if the request is authorized, or send analytical data to some other service. Controllers are composed together, and each controller in the composition performs its logic in order. This allows for some controllers to be reused, and for better code organization. A composition of controllers is called a channel because requests flow in one direction through the controllers. Our application will link two controllers: a Router that makes sure the request path is /heroes or /heroes/:id a HeroesControllers that responds with hero objects Your application starts with a channel object called the application channel . You link the controllers in your application to this channel. Each application has a subclass of ApplicationChannel that you override methods in to set up your controllers. This type is already declared in lib/channel.dart - open this file and find ApplicationChannel.entryPoint : @ override Controller get entryPoint { final router = Router (); router . route ( /example ) . linkFunction (( request ) async { return Response . ok ({ key : value }); }); return router ; } When your application gets a request, the entryPoint controller is the first to handle it. In our case, this is a Router - a subclass of Controller . Controller Subclassing Every controller you use will be a subclass of Controller . There are some controller subclasses already in Aqueduct for common behaviors. You use the route method on a router to attach a controller to a route . A route is a string syntax that matches the path of a request. In our current implementation, the route will match every request with the path /example . When that request is received, a linked function runs and returns a 200 OK response with an example JSON object body. We need to route the path /heroes to a controller of our own, so we can control what happens. Let's create a HeroesController . Create a new file in lib/controller/heroes_controller.dart and add the following code (you will need to create the subdirectory lib/controller/ ): import package:aqueduct/aqueduct.dart ; import package:heroes/heroes.dart ; class HeroesController extends Controller { final _heroes = [ { id : 11 , name : Mr. Nice }, { id : 12 , name : Narco }, { id : 13 , name : Bombasto }, { id : 14 , name : Celeritas }, { id : 15 , name : Magneta }, ]; @ override Future RequestOrResponse handle ( Request request ) async { return Response . ok ( _heroes ); } } Notice that HeroesController is a subclass of Controller ; this is what makes it a controller object. It overrides its handle method by returning a Response object. This response object has a 200 OK status code, and it body contains a JSON-encoded list of hero objects. When a controller returns a Response object from its handle method, it is sent to the client. Right now, our HeroesController isn't hooked up to the application channel. We need to link it to the router. First, import our new file at the top of channel.dart . import controller/heroes_controller.dart ; Then link this HeroesController to the Router for the path /heroes : @ override Controller get entryPoint { final router = Router (); router . route ( /heroes ) . link (() = HeroesController ()); router . route ( /example ) . linkFunction (( request ) async { return new Response . ok ({ key : value }); }); return router ; } We now have a application that will return a list of heroes. In the project directory, run the following command from the command-line: aqueduct serve This will start your application running locally. Reload the browser page http://aqueduct-tutorial.stablekernel.io . It will make a request to http://localhost:8888/heroes and your application will serve it. You'll see your heroes in your web browser: Screenshot of Heroes Application You can also see the actual response of your request by entering the following into your shell: curl -X GET http://localhost:8888/heroes You'll get JSON output like this: [ { id : 11 , name : Mr. Nice }, { id : 12 , name : Narco }, { id : 13 , name : Bombasto }, { id : 14 , name : Celeritas }, { id : 15 , name : Magneta } ] You'll also see this request logged in the shell that you started aqueduct serve in. Linking Controllers When a controller handles a request, it can either send a response or let one of its linked controllers handle the request. By default, a Router will send a 404 Not Found response for any request. Adding a route to a Router creates an entry point to a new channel that controllers can be linked to. In our application, HeroesController is linked to the route /heroes . Controllers come in two different flavors: endpoint and middleware. Endpoint controllers, like HeroesController , always send a response. They implement the behavior that a request is seeking. Middleware controllers, like Router , handles requests before they reach an endpoint controller. A router, for example, handles a request by directing it to the right controller. Controllers like Authorizer verify the authorization of the request. You can create all kinds of controllers to provide any behavior you like. A channel can have zero or many middleware controllers, but must end in an endpoint controller. Most controllers can only have one linked controller, but a Router allows for many. For example, a larger application might look like this: @ override Controller get entryPoint { final router = Router (); router . route ( /users ) . link (() = APIKeyValidator ()) . link (() = Authorizer . bearer ()) . link (() = UsersController ()); router . route ( /posts ) . link (() = APIKeyValidator ()) . link (() = PostsController ()); return router ; } Each of these objects is a subclass of Controller , giving them the ability to be linked together to handle requests. A request goes through controllers in the order they are linked. A request for the path /users will go through an APIKeyValidator , an Authorizer and finally a UsersController . Each of these controllers has an opportunity to respond, preventing the next controller from receiving the request. Advanced Routing Right now, our application handles GET /heroes requests. The browser application uses the this list to populate its hero dashboard. If we click on an individual hero, the browser application will display an individual hero. When navigating to this page, the browser application makes a request to our server for an individual hero. This request contains the unique id of the selected hero in the path, e.g. /heroes/11 or /heroes/13 . Our server doesn't handle this request yet - it only handles requests that have exactly the path /heroes . Since a request for individual heroes will have a path that changes depending on the hero, we need our route to include a path variable . A path variable is a segment of route that matches a value for the same segment in the incoming request path. A path variable is a segment prefixed with a colon ( : ). For example, the route /heroes/:id contains a path variable named id . If the request path is /heroes/1 , /heroes/2 , and so on, the request will be sent to our HeroesController . The HeroesController will have access to the value of the path variable to determine which hero to return. There's one hiccup. The route /heroes/:id no longer matches the path /heroes . It'd be a lot easier to organize our code if both /heroes and /heroes/:id went to our HeroesController ; it does heroic stuff. For this reason, we can declare the :id portion of our route to be optional by wrapping it in square brackets. In channel.dart , modify the /heroes route: router . route ( /heroes/[:id] ) . link (() = HeroesController ()); Since the second segment of the path is optional, the path /heroes still matches the route. If the path contains a second segment, the value of that segment is bound to the path variable named id . We can access path variables through the Request object. In heroes_controller.dart , modify handle : // In just a moment, we ll replace this code with something even better, // but it s important to understand where this information comes from first! @ override Future RequestOrResponse handle ( Request request ) async { if ( request . path . variables . containsKey ( id )) { final id = int . parse ( request . path . variables [ id ]); final hero = _heroes . firstWhere (( hero ) = hero [ id ] == id , orElse: () = null ); if ( hero == null ) { return Response . notFound (); } return Response . ok ( hero ); } return Response . ok ( _heroes ); } In your shell currently running the application, hit Ctrl-C to stop the application. Then, run aqueduct serve again. In the browser application, click on a hero and you will be taken to a detail page for that hero. You can verify that your server is responding correctly by executing curl -X GET http://localhost:8888/heroes/11 to view the single hero object. You can also trigger a 404 Not Found response by getting a hero that doesn't exist. ResourceControllers and Operation Methods Our HeroesController is OK right now, but it'll soon run into a problem: what happens when we want to create a new hero? Or update an existing hero's name? Our handle method will start to get unmanageable, quickly. That's where ResourceController comes in. A ResourceController allows you to create a distinct method for each operation that we can perform on our heroes. One method will handle getting a list of heroes, another will handle getting a single hero, and so on. Each method has an annotation that identifies the HTTP method and path variables the request must have to trigger it. In heroes_controller.dart , replace HeroesController with the following: class HeroesController extends ResourceController { final _heroes = [ { id : 11 , name : Mr. Nice }, { id : 12 , name : Narco }, { id : 13 , name : Bombasto }, { id : 14 , name : Celeritas }, { id : 15 , name : Magneta }, ]; @ Operation . get () Future Response getAllHeroes () async { return Response . ok ( _heroes ); } @ Operation . get ( id ) Future Response getHeroByID () async { final id = int . parse ( request . path . variables [ id ]); final hero = _heroes . firstWhere (( hero ) = hero [ id ] == id , orElse: () = null ); if ( hero == null ) { return Response . notFound (); } return Response . ok ( hero ); } } Notice that we didn't have to override handle in ResourceController . A ResourceController implements this method to call one of our operation methods . An operation method - like getAllHeroes and getHeroByID - must have an Operation annotation. The named constructor Operation.get means these methods get called when the request's method is GET. An operation method must also return a Future Response . getHeroByID 's annotation also has an argument - the name of our path variable id . If that path variable exists in the request's path, getHeroByID will be called. If it doesn't exist, getAllHeroes will be called. Naming Operation Methods The plain English phrase for an operation - like 'get hero by id' - is a really good name for an operation method and a good name will be useful when you generate OpenAPI documentation from your code. Reload the application by hitting Ctrl-C in the terminal that ran aqueduct serve and then run aqueduct serve again. The browser application should still behave the same. Browser Clients In addition to curl , you can create a SwaggerUI browser application that executes requests against your locally running application. In your project directory, run aqueduct document client and it will generate a file named client.html . Open this file in your browser for a UI that constructs and executes requests that your application supports. Request Binding In our getHeroByID method, we make a dangerous assumption that the path variable 'id' can be parsed into an integer. If 'id' were something else, like a string, int.parse would throw an exception. When exceptions are thrown in operation methods, the controller catches it and sends a 500 Server Error response. 500s are bad, they don't tell the client what's wrong. A 404 Not Found is a better response here, but writing the code to catch that exception and create this response is cumbersome. Instead, we can rely on a feature of operation methods called request binding . An operation method can declare parameters and bind them to properties of the request. When our operation method gets called, it will be passed values from the request as arguments. Request bindings automatically parse values into the type of the parameter (and return a better error response if parsing fails). Change the method getHeroByID() : @ Operation . get ( id ) Future Response getHeroByID ( @ Bind . path ( id ) int id ) async { final hero = _heroes . firstWhere (( hero ) = hero [ id ] == id , orElse: () = null ); if ( hero == null ) { return Response . notFound (); } return Response . ok ( hero ); } The value of the path variable id will be parsed as an integer and be available to this method in the id parameter. The @Bind annotation on an operation method parameter tells Aqueduct the value from the request we want bound. Using the named constructor Bind.path binds a path variable, and the name of that variable is indicated in the argument to this constructor. You can bind path variables, headers, query parameters and bodies. When binding path variables, we have to specify which path variable with the argument to @Bind.path(pathVariableName) . Bound Parameter Names The name of a bound parameter doesn't have to match the name of the path variable. We could have declared it as @Bind.path('id') int heroID . Only the argument to Bind 's constructor must match the actual name of the path variable. This is valuable for other types of bindings, like headers, that may contain characters that aren't valid Dart variable names, e.g. X-API-Key . The More You Know: Multi-threading and Application State In this simple exercise, we used a constant list of heroes as our source of data. For a simple getting-your-feet-wet demo, this is fine. However, in a real application, you'd store this data in a database. That way you could add data to it and not risk losing it when the application was restarted. More generally, a web server should never hang on to data that can change. While previously just a best practice, stateless web servers are becoming a requirement with the prevalence of containerization and tools like Kubernetes. Aqueduct makes it a bit easier to detect violations of this rule with its multi-threading strategy. When you run an Aqueduct application, it creates multiple threads. Each of these threads has its own isolated heap in memory; meaning data that exists on one thread can't be accessed from other threads. In Dart, these isolated threads are called isolates . An instance of your application channel is created for each isolate. Each HTTP request is given to just one of the isolates to be handled. In a sense, your one application behaves the same as running your application on multiple servers behind a load balancer. (It also makes your application substantially faster.) If you are storing any data in your application, you'll find out really quick. Why? A request that changes data will only change that data in one of your application's isolates. When you make a request to get that data again, its unlikely that you'll see the changes - another isolate with different data will probably handle that request. Next Chapter: Reading from a Database","title":"1. Getting Started"},{"location":"tut/getting-started/#1-getting-started","text":"By the end of this tutorial, you will have created an Aqueduct application that serves fictional heroes from a PostgreSQL database. You will learn the following: Run an Aqueduct application Route HTTP requests to the appropriate handler in your code Store and retrieve database data Write automated tests for each endpoint Require authorization for HTTP requests Getting Help If at anytime you get stuck, hop on over to the Aqueduct Slack channel . You can also see a finished version of this application here .","title":"1. Getting Started"},{"location":"tut/getting-started/#installation","text":"To get started, make sure you have the following software installed: Dart ( Install Instructions ) IntelliJ IDEA or any other Jetbrains IDE, including the free Community Edition ( Install Instructions ) The IntelliJ IDEA Dart Plugin ( Install Instructions ) Install the aqueduct command line tool by running the following command in your shell: pub global activate aqueduct If you get warning text about your PATH , make sure to read it before moving on.","title":"Installation"},{"location":"tut/getting-started/#creating-a-project","text":"Create a new project named heroes by entering the following in your shell: aqueduct create heroes This creates a heroes project directory. Open this directory with IntelliJ IDEA by dragging the project folder onto IntellIJ IDEA's icon. In IntelliJ's project view, locate the lib directory; this is where your project's code will go. This project has two source files - heroes.dart and channel.dart . Open the file heroes.dart . Click Enable Dart Support in the top right corner of the editor.","title":"Creating a Project"},{"location":"tut/getting-started/#handling-http-requests","text":"In your browser, navigate to http://aqueduct-tutorial.stablekernel.io . This browser application is a 'Hero Manager' - it allows a user to view, create, delete and update heroes. (It is a slightly modified version of the AngularDart Tour of Heroes Tutorial .) It will make HTTP requests to http://localhost:8888 to fetch and manipulate hero data. The application you will build in this tutorial respond to those requests. Running the Browser Application Locally The browser application is served over HTTP so that it can access your Aqueduct application when it runs locally on your machine. Your browser may warn you about navigating to an insecure webpage, because it is in fact insecure. You can run this application locally by grabbing the source code from here . In this first chapter, you will write code to handle two requests: one to get a list of heroes, and the other to get a single hero by its identifier. Those requests are: GET /heroes to the list of heroes GET /heroes/:id to get an individual hero HTTP Operation Shorthand The term GET /heroes is called an operation. It is the combination of the HTTP method and the path of the request. Each operation is unique to an application, so your code is segmented into units for each operation. Sections with a colon, like the ':id' segment, are variable: they can be 1, 2, 3, and so on.","title":"Handling HTTP Requests"},{"location":"tut/getting-started/#controller-objects-handle-requests","text":"Requests are handled by controller objects . A controller object can respond to a request. It can also take other action and let another controller respond. For example, it might check if the request is authorized, or send analytical data to some other service. Controllers are composed together, and each controller in the composition performs its logic in order. This allows for some controllers to be reused, and for better code organization. A composition of controllers is called a channel because requests flow in one direction through the controllers. Our application will link two controllers: a Router that makes sure the request path is /heroes or /heroes/:id a HeroesControllers that responds with hero objects Your application starts with a channel object called the application channel . You link the controllers in your application to this channel. Each application has a subclass of ApplicationChannel that you override methods in to set up your controllers. This type is already declared in lib/channel.dart - open this file and find ApplicationChannel.entryPoint : @ override Controller get entryPoint { final router = Router (); router . route ( /example ) . linkFunction (( request ) async { return Response . ok ({ key : value }); }); return router ; } When your application gets a request, the entryPoint controller is the first to handle it. In our case, this is a Router - a subclass of Controller . Controller Subclassing Every controller you use will be a subclass of Controller . There are some controller subclasses already in Aqueduct for common behaviors. You use the route method on a router to attach a controller to a route . A route is a string syntax that matches the path of a request. In our current implementation, the route will match every request with the path /example . When that request is received, a linked function runs and returns a 200 OK response with an example JSON object body. We need to route the path /heroes to a controller of our own, so we can control what happens. Let's create a HeroesController . Create a new file in lib/controller/heroes_controller.dart and add the following code (you will need to create the subdirectory lib/controller/ ): import package:aqueduct/aqueduct.dart ; import package:heroes/heroes.dart ; class HeroesController extends Controller { final _heroes = [ { id : 11 , name : Mr. Nice }, { id : 12 , name : Narco }, { id : 13 , name : Bombasto }, { id : 14 , name : Celeritas }, { id : 15 , name : Magneta }, ]; @ override Future RequestOrResponse handle ( Request request ) async { return Response . ok ( _heroes ); } } Notice that HeroesController is a subclass of Controller ; this is what makes it a controller object. It overrides its handle method by returning a Response object. This response object has a 200 OK status code, and it body contains a JSON-encoded list of hero objects. When a controller returns a Response object from its handle method, it is sent to the client. Right now, our HeroesController isn't hooked up to the application channel. We need to link it to the router. First, import our new file at the top of channel.dart . import controller/heroes_controller.dart ; Then link this HeroesController to the Router for the path /heroes : @ override Controller get entryPoint { final router = Router (); router . route ( /heroes ) . link (() = HeroesController ()); router . route ( /example ) . linkFunction (( request ) async { return new Response . ok ({ key : value }); }); return router ; } We now have a application that will return a list of heroes. In the project directory, run the following command from the command-line: aqueduct serve This will start your application running locally. Reload the browser page http://aqueduct-tutorial.stablekernel.io . It will make a request to http://localhost:8888/heroes and your application will serve it. You'll see your heroes in your web browser:","title":"Controller Objects Handle Requests"},{"location":"tut/getting-started/#screenshot-of-heroes-application","text":"You can also see the actual response of your request by entering the following into your shell: curl -X GET http://localhost:8888/heroes You'll get JSON output like this: [ { id : 11 , name : Mr. Nice }, { id : 12 , name : Narco }, { id : 13 , name : Bombasto }, { id : 14 , name : Celeritas }, { id : 15 , name : Magneta } ] You'll also see this request logged in the shell that you started aqueduct serve in.","title":"Screenshot of Heroes Application"},{"location":"tut/getting-started/#linking-controllers","text":"When a controller handles a request, it can either send a response or let one of its linked controllers handle the request. By default, a Router will send a 404 Not Found response for any request. Adding a route to a Router creates an entry point to a new channel that controllers can be linked to. In our application, HeroesController is linked to the route /heroes . Controllers come in two different flavors: endpoint and middleware. Endpoint controllers, like HeroesController , always send a response. They implement the behavior that a request is seeking. Middleware controllers, like Router , handles requests before they reach an endpoint controller. A router, for example, handles a request by directing it to the right controller. Controllers like Authorizer verify the authorization of the request. You can create all kinds of controllers to provide any behavior you like. A channel can have zero or many middleware controllers, but must end in an endpoint controller. Most controllers can only have one linked controller, but a Router allows for many. For example, a larger application might look like this: @ override Controller get entryPoint { final router = Router (); router . route ( /users ) . link (() = APIKeyValidator ()) . link (() = Authorizer . bearer ()) . link (() = UsersController ()); router . route ( /posts ) . link (() = APIKeyValidator ()) . link (() = PostsController ()); return router ; } Each of these objects is a subclass of Controller , giving them the ability to be linked together to handle requests. A request goes through controllers in the order they are linked. A request for the path /users will go through an APIKeyValidator , an Authorizer and finally a UsersController . Each of these controllers has an opportunity to respond, preventing the next controller from receiving the request.","title":"Linking Controllers"},{"location":"tut/getting-started/#advanced-routing","text":"Right now, our application handles GET /heroes requests. The browser application uses the this list to populate its hero dashboard. If we click on an individual hero, the browser application will display an individual hero. When navigating to this page, the browser application makes a request to our server for an individual hero. This request contains the unique id of the selected hero in the path, e.g. /heroes/11 or /heroes/13 . Our server doesn't handle this request yet - it only handles requests that have exactly the path /heroes . Since a request for individual heroes will have a path that changes depending on the hero, we need our route to include a path variable . A path variable is a segment of route that matches a value for the same segment in the incoming request path. A path variable is a segment prefixed with a colon ( : ). For example, the route /heroes/:id contains a path variable named id . If the request path is /heroes/1 , /heroes/2 , and so on, the request will be sent to our HeroesController . The HeroesController will have access to the value of the path variable to determine which hero to return. There's one hiccup. The route /heroes/:id no longer matches the path /heroes . It'd be a lot easier to organize our code if both /heroes and /heroes/:id went to our HeroesController ; it does heroic stuff. For this reason, we can declare the :id portion of our route to be optional by wrapping it in square brackets. In channel.dart , modify the /heroes route: router . route ( /heroes/[:id] ) . link (() = HeroesController ()); Since the second segment of the path is optional, the path /heroes still matches the route. If the path contains a second segment, the value of that segment is bound to the path variable named id . We can access path variables through the Request object. In heroes_controller.dart , modify handle : // In just a moment, we ll replace this code with something even better, // but it s important to understand where this information comes from first! @ override Future RequestOrResponse handle ( Request request ) async { if ( request . path . variables . containsKey ( id )) { final id = int . parse ( request . path . variables [ id ]); final hero = _heroes . firstWhere (( hero ) = hero [ id ] == id , orElse: () = null ); if ( hero == null ) { return Response . notFound (); } return Response . ok ( hero ); } return Response . ok ( _heroes ); } In your shell currently running the application, hit Ctrl-C to stop the application. Then, run aqueduct serve again. In the browser application, click on a hero and you will be taken to a detail page for that hero. You can verify that your server is responding correctly by executing curl -X GET http://localhost:8888/heroes/11 to view the single hero object. You can also trigger a 404 Not Found response by getting a hero that doesn't exist.","title":"Advanced Routing"},{"location":"tut/getting-started/#resourcecontrollers-and-operation-methods","text":"Our HeroesController is OK right now, but it'll soon run into a problem: what happens when we want to create a new hero? Or update an existing hero's name? Our handle method will start to get unmanageable, quickly. That's where ResourceController comes in. A ResourceController allows you to create a distinct method for each operation that we can perform on our heroes. One method will handle getting a list of heroes, another will handle getting a single hero, and so on. Each method has an annotation that identifies the HTTP method and path variables the request must have to trigger it. In heroes_controller.dart , replace HeroesController with the following: class HeroesController extends ResourceController { final _heroes = [ { id : 11 , name : Mr. Nice }, { id : 12 , name : Narco }, { id : 13 , name : Bombasto }, { id : 14 , name : Celeritas }, { id : 15 , name : Magneta }, ]; @ Operation . get () Future Response getAllHeroes () async { return Response . ok ( _heroes ); } @ Operation . get ( id ) Future Response getHeroByID () async { final id = int . parse ( request . path . variables [ id ]); final hero = _heroes . firstWhere (( hero ) = hero [ id ] == id , orElse: () = null ); if ( hero == null ) { return Response . notFound (); } return Response . ok ( hero ); } } Notice that we didn't have to override handle in ResourceController . A ResourceController implements this method to call one of our operation methods . An operation method - like getAllHeroes and getHeroByID - must have an Operation annotation. The named constructor Operation.get means these methods get called when the request's method is GET. An operation method must also return a Future Response . getHeroByID 's annotation also has an argument - the name of our path variable id . If that path variable exists in the request's path, getHeroByID will be called. If it doesn't exist, getAllHeroes will be called. Naming Operation Methods The plain English phrase for an operation - like 'get hero by id' - is a really good name for an operation method and a good name will be useful when you generate OpenAPI documentation from your code. Reload the application by hitting Ctrl-C in the terminal that ran aqueduct serve and then run aqueduct serve again. The browser application should still behave the same. Browser Clients In addition to curl , you can create a SwaggerUI browser application that executes requests against your locally running application. In your project directory, run aqueduct document client and it will generate a file named client.html . Open this file in your browser for a UI that constructs and executes requests that your application supports.","title":"ResourceControllers and Operation Methods"},{"location":"tut/getting-started/#request-binding","text":"In our getHeroByID method, we make a dangerous assumption that the path variable 'id' can be parsed into an integer. If 'id' were something else, like a string, int.parse would throw an exception. When exceptions are thrown in operation methods, the controller catches it and sends a 500 Server Error response. 500s are bad, they don't tell the client what's wrong. A 404 Not Found is a better response here, but writing the code to catch that exception and create this response is cumbersome. Instead, we can rely on a feature of operation methods called request binding . An operation method can declare parameters and bind them to properties of the request. When our operation method gets called, it will be passed values from the request as arguments. Request bindings automatically parse values into the type of the parameter (and return a better error response if parsing fails). Change the method getHeroByID() : @ Operation . get ( id ) Future Response getHeroByID ( @ Bind . path ( id ) int id ) async { final hero = _heroes . firstWhere (( hero ) = hero [ id ] == id , orElse: () = null ); if ( hero == null ) { return Response . notFound (); } return Response . ok ( hero ); } The value of the path variable id will be parsed as an integer and be available to this method in the id parameter. The @Bind annotation on an operation method parameter tells Aqueduct the value from the request we want bound. Using the named constructor Bind.path binds a path variable, and the name of that variable is indicated in the argument to this constructor. You can bind path variables, headers, query parameters and bodies. When binding path variables, we have to specify which path variable with the argument to @Bind.path(pathVariableName) . Bound Parameter Names The name of a bound parameter doesn't have to match the name of the path variable. We could have declared it as @Bind.path('id') int heroID . Only the argument to Bind 's constructor must match the actual name of the path variable. This is valuable for other types of bindings, like headers, that may contain characters that aren't valid Dart variable names, e.g. X-API-Key .","title":"Request Binding"},{"location":"tut/getting-started/#the-more-you-know-multi-threading-and-application-state","text":"In this simple exercise, we used a constant list of heroes as our source of data. For a simple getting-your-feet-wet demo, this is fine. However, in a real application, you'd store this data in a database. That way you could add data to it and not risk losing it when the application was restarted. More generally, a web server should never hang on to data that can change. While previously just a best practice, stateless web servers are becoming a requirement with the prevalence of containerization and tools like Kubernetes. Aqueduct makes it a bit easier to detect violations of this rule with its multi-threading strategy. When you run an Aqueduct application, it creates multiple threads. Each of these threads has its own isolated heap in memory; meaning data that exists on one thread can't be accessed from other threads. In Dart, these isolated threads are called isolates . An instance of your application channel is created for each isolate. Each HTTP request is given to just one of the isolates to be handled. In a sense, your one application behaves the same as running your application on multiple servers behind a load balancer. (It also makes your application substantially faster.) If you are storing any data in your application, you'll find out really quick. Why? A request that changes data will only change that data in one of your application's isolates. When you make a request to get that data again, its unlikely that you'll see the changes - another isolate with different data will probably handle that request.","title":"The More You Know: Multi-threading and Application State"},{"location":"tut/getting-started/#next-chapter-reading-from-a-database","text":"","title":"Next Chapter: Reading from a Database"},{"location":"tut/oauth2/","text":"5. Adding Authentication and Authorization with OAuth 2.0 Our heroes application lets anyone create or view the same set of heroes. We will continue to build on the last chapter's project, heroes , requiring a user to log in before viewing or creating heroes. We're Done With the Browser App We're at the point now where using the browser application to test our Aqueduct app gets a bit cumbersome. From here on out, we'll use curl , aqueduct document client and tests. The Basics of OAuth 2.0 OAuth 2.0 is an authorization framework that also contains guidance on authentication. Authentication is the process of proving you are a particular user, typically through a username and password. Authorization is the process of ensuring that a user can access a particular resource or collection of resources. In our application, a user will have to be authenticated before being authorized to view or create heroes. In a simple authentication and authorization scheme, each HTTP request contains the username and password (credentials) of the user in an Authorization header. There are a number of security risks involved in doing this, so OAuth 2.0 takes another approach: you send your credentials once, and get a 'access token' in return. You then send this access token in each request. Because the server grants the token, it knows that you've already entered your credentials (you've authenticated ) and it remembers who the token belongs to. It's effectively the same thing as sending your credentials each time, except that the token has a time limit and can be revoked when things go wrong. Aqueduct has a built-in OAuth 2.0 implementation that leverages the ORM. This implementation is part of the aqueduct package, but it is a separate library named aqueduct/managed_auth . It takes a few steps to set up that might be difficult to understand if you are not familiar with OAuth 2.0, but you'll get a well-tested, secure authorization implementation. Alternative Implementations Using package:aqueduct/managed_auth is preferable in most cases. In some cases, you may wish to store authorization information in different database system or use token formats like JWT . This is a complex topic that requires significant testing efforts, and is outside the scope of this tutorial. Setting up OAuth 2.0: Creating a User Type Our application needs some concept of a 'user' - a person who logs into the application to manage heroes. This user will have a username and password. In a later exercise, a user will also have a list of heroes that belong to them. Create a new file model/user.dart and enter the following code: import package:aqueduct/managed_auth.dart ; import package:heroes/heroes.dart ; import package:heroes/model/hero.dart ; class User extends ManagedObject _User implements _User , ManagedAuthResourceOwner _User {} class _User extends ResourceOwnerTableDefinition {} The imported library package:aqueduct/managed_auth.dart contains types that use the ORM to store users, tokens and other OAuth 2.0 related data. One of those types is ResourceOwnerTableDefinition , the superclass of our user's table definition. This type contains all of the required fields that Aqueduct needs to implement authentication. Resource Owners A resource owner is a more general term for a 'user' that comes from the OAuth 2.0 specification. In the framework, you'll see types and variables using some variant of resource owner , but for all intents and purposes, you can consider this a 'user'. If you are curious, ResourceOwnerTableDefinition looks like this: class ResourceOwnerTableDefinition { @ primaryKey int id ; @ Column ( unique: true , indexed: true ) String username ; @ Column ( omitByDefault: true ) String hashedPassword ; @ Column ( omitByDefault: true ) String salt ; ManagedSet ManagedAuthToken tokens ; } Because these fields are in User 's table definition, our User table has all of these database columns. ManagedAuthResourceOwner Note that User implements ManagedAuthResourceOwner _User - this is a requirement of any OAuth 2.0 resource owner type when using package:aqueduct/managed_auth . Setting up OAuth 2.0: AuthServer and its Delegate Now that we have a user, we need some way to create new users and authenticate them. Authentication is fairly tricky, especially in OAuth 2.0, so there is a service object that does the hard part for us called an AuthServer . This type has all of the logic needed to authentication and authorize users. For example, an AuthServer can generate a new token if given valid user credentials. In channel.dart , add the following imports to the top of your file: import package:aqueduct/managed_auth.dart ; import package:heroes/model/user.dart ; Then, declare a new authServer property in your channel and initialize it in prepare : class HeroesChannel extends ApplicationChannel { ManagedContext context ; // Add this field AuthServer authServer ; Future prepare () async { logger . onRecord . listen (( rec ) = print ( $ rec ${ rec . error ?? } ${ rec . stackTrace ?? } )); final config = HeroConfig ( options . configurationFilePath ); final dataModel = ManagedDataModel . fromCurrentMirrorSystem (); final persistentStore = PostgreSQLPersistentStore . fromConnectionInfo ( config . database . username , config . database . password , config . database . host , config . database . port , config . database . databaseName ); context = ManagedContext ( dataModel , persistentStore ); // Add these two lines: final authStorage = ManagedAuthDelegate User ( context ); authServer = AuthServer ( authStorage ); } ... While an AuthServer handles the logic of authentication and authorization, it doesn't know how to store or fetch the data it uses for those tasks. Instead, it relies on a delegate object to handle storing and fetching data from a database. In our application, we use ManagedAuthDelegate T - from package:aqueduct/managed_auth - as the delegate. This type uses the ORM for these tasks; the type argument must be our application's user object. Delegation Delegation is a design pattern where an object has multiple callbacks that are grouped into an interface. Instead of defining a closure for each callback, a type implements methods that get called by the delegating object. It is a way of organizing large amounts of related callbacks into a tidy class. By importing aqueduct/managed_auth , we've added a few more managed objects to our application (to store tokens and other authentication data) and we also have a new User managed object. It's a good time to run a database migration. From your project directory, run the following commands: aqueduct db generate aqueduct db upgrade --connect postgres://heroes_user:password@localhost:5432/heroes Setting up OAuth 2.0: Registering Users Now that we have the concept of a user, our database and application are set up to handle authentication, we can start creating new users. Let's create a new controller for registering users. This controller will accept POST requests that contain a username and password in the body. It will insert a new user into the database and securely hash the user's password. Before we create this controller, there is something we need to consider: our registration endpoint will require the user's password, but we store the user's password as a cryptographic hash. This prevents someone with access to your database from knowing a user's password. In order to bind the body of a request to a User object, it needs a password field, but we don't want to store the password in the database without first hashing it. We can accomplish this with transient properties . A transient property is a property of a managed object that isn't stored in the database. They are declared in the managed object subclass instead of the table definition. By default, a transient property is not read from a request body or encoded into a response body; unless we add the Serialize annotation to it. Add this property to your User type: class User extends ManagedObject _User implements _User , ManagedAuthResourceOwner _User { @ Serialize ( input: true , output: false ) String password ; } This declares that a User has a transient property password that can be read on input (from a request body), but is not sent on output (to a response body). We don't have to run a database migration because transient properties are not stored in a database. Now, create the file controller/register_controller.dart and enter the following code: import dart:async ; import package:aqueduct/aqueduct.dart ; import package:heroes/model/user.dart ; class RegisterController extends ResourceController { RegisterController ( this . context , this . authServer ); final ManagedContext context ; final AuthServer authServer ; @ Operation . post () Future Response createUser ( @ Bind . body () User user ) async { // Check for required parameters before we spend time hashing if ( user . username == null || user . password == null ) { return Response . badRequest ( body: { error : username and password required. }); } user .. salt = AuthUtility . generateRandomSalt () .. hashedPassword = authServer . hashPassword ( user . password , user . salt ); return Response . ok ( await Query ( context , values: user ). insert ()); } } This controller takes POST requests that contain a user. A user has many fields (username, password, hashedPassword, salt), but we will calculate the latter two and only require that the request contain the first two. The controller generates a salt and hash of the password before storing it in the database. In channel.dart , let's link this controller - don't forget to import it! import package:heroes/controller/register_controller.dart ; ... @ override Controller get entryPoint { final router = Router (); router . route ( /heroes/[:id] ) . link (() = HeroesController ( context )); router . route ( /register ) . link (() = RegisterController ( context , authServer )); return router ; } } Let's run the application and create a new user using curl from the command-line. (We'll specify -n1 to designate using one isolate and speed up startup.) aqueduct serve -n1 Then, issue a request to your server: curl - X POST http: //localhost:8888/register -H Content-Type: application/json -d { username : bob , password : password } You'll get back the new user object and its username: { id :1, username : bob } Setting up OAuth 2.0: Authenticating Users Now that we have a user with a password, we can can create an endpoint that takes user credentials and returns an access token. The good news is that this controller already exists in Aqueduct, you just have to hook it up to a route. Update entryPoint in channel.dart to add an AuthController for the route /auth/token : @ override Controller get entryPoint { final router = Router (); // add this route router . route ( /auth/token ) . link (() = AuthController ( authServer )); router . route ( /heroes/[:id] ) . link (() = HeroesController ( context )); router . route ( /register ) . link (() = RegisterController ( context , authServer )); return router ; } An AuthController follows the OAuth 2.0 specification for granting access tokens when given valid user credentials. To understand how a request to this endpoint must be structured, we need to discuss OAuth 2.0 clients . In OAuth 2.0, a client is an application that is allowed to access your server on behalf of a user. A client can be a browser application, a mobile application, another server, a voice assistant, etc. A client always has an identifier string, typically something like 'com.stablekernel.account_app.mobile'. When authenticating, a user is always authenticated through a client. This client information must be attached to every authentication request, and the server must validate that the client had been previously registered. Therefore, we need to register a new client for our application. A client is stored in our application's database using the aqueduct auth add-client CLI. Run the following command from your project directory: aqueduct auth add-client --id com.heroes.tutorial --connect postgres://heroes_user:password@localhost:5432/heroes OAuth 2.0 Clients A client must have an identifier, but it may also have a secret, redirect URI and list of allowed scopes. See the guides on OAuth 2.0 for how these options impacts authentication. Most notably, a client identifier must have a secret to issue a refresh token . Clients are stored in an application's database. This will insert a new row into an OAuth 2.0 client table created by our last round of database migration and allow us to make authentication requests. An authentication request must meet all of the following criteria: the client identifier (and secret, if it exists) are included as a basic Authorization header. the username and password are included in the request body the key-value grant_type=password is included in the request body the request body content-type is application/x-www-form-urlencoded ; this means the request body is effectively a query string (e.g. username=bob password=pw grant_type=password ) In Dart code, this would like this: import package:http/http.dart as http ; // Must include http package in your pubspec.yaml final clientID = com.heroes.tutorial ; final body = username=bob password=password grant_type=password ; // Note the trailing colon (:) after the clientID. // A client identifier secret would follow this, but there is no secret, so it is the empty string. final clientCredentials = Base64Encoder (). convert ( $ clientID : ); final response = await http . post ( https://stablekernel.com/auth/token , headers: { Content-Type : application/x-www-form-urlencoded , Authorization : Basic $ clientCredentials }, body: body ); You can execute that code or you can use the following curl : curl -X POST http://localhost:8888/auth/token -H Authorization: Basic Y29tLmhlcm9lcy50dXRvcmlhbDo= -H Content-Type: application/x-www-form-urlencoded -d username=bob password=password grant_type=password If you were successful, you'll get the following response containing an access token: { access_token : 687PWKFHRTQ9MveQ2dKvP95D4cWie1gh , token_type : bearer , expires_in :86399} Hang on to this access token, we'll use it in a moment. Setting up OAuth 2.0: Securing Routes Now that we can create and authenticate users, we can protect our heroes from anonymous users by requiring an access token for hero requests. In channel.dart , link an Authorizer in the middle of the /heroes channel: router . route ( /heroes/[:id] ) . link (() = Authorizer . bearer ( authServer )) . link (() = HeroesController ( context )); An Authorizer protects a channel from unauthorized requests by validating the Authorization header of a request. When created with Authorizer.bearer , it ensures that the authorization header contains a valid access token. Restart your application and try and access the /heroes endpoint without including any authorization: curl -X GET --verbose http://localhost:8080/heroes You'll get a 401 Unauthorized response. Now, include your access token in a bearer authorization header (note that your token will be different): curl -X GET http://localhost:8080/heroes -H Authorization: Bearer 687PWKFHRTQ9MveQ2dKvP95D4cWie1gh You'll get back your list of heroes! Other Uses of Authorizer An Authorizer can validate access token scopes and basic authorization credentials. You'll see examples of these in a later exercise.","title":"5. Authentication and Authorization"},{"location":"tut/oauth2/#5-adding-authentication-and-authorization-with-oauth-20","text":"Our heroes application lets anyone create or view the same set of heroes. We will continue to build on the last chapter's project, heroes , requiring a user to log in before viewing or creating heroes. We're Done With the Browser App We're at the point now where using the browser application to test our Aqueduct app gets a bit cumbersome. From here on out, we'll use curl , aqueduct document client and tests.","title":"5. Adding Authentication and Authorization with OAuth 2.0"},{"location":"tut/oauth2/#the-basics-of-oauth-20","text":"OAuth 2.0 is an authorization framework that also contains guidance on authentication. Authentication is the process of proving you are a particular user, typically through a username and password. Authorization is the process of ensuring that a user can access a particular resource or collection of resources. In our application, a user will have to be authenticated before being authorized to view or create heroes. In a simple authentication and authorization scheme, each HTTP request contains the username and password (credentials) of the user in an Authorization header. There are a number of security risks involved in doing this, so OAuth 2.0 takes another approach: you send your credentials once, and get a 'access token' in return. You then send this access token in each request. Because the server grants the token, it knows that you've already entered your credentials (you've authenticated ) and it remembers who the token belongs to. It's effectively the same thing as sending your credentials each time, except that the token has a time limit and can be revoked when things go wrong. Aqueduct has a built-in OAuth 2.0 implementation that leverages the ORM. This implementation is part of the aqueduct package, but it is a separate library named aqueduct/managed_auth . It takes a few steps to set up that might be difficult to understand if you are not familiar with OAuth 2.0, but you'll get a well-tested, secure authorization implementation. Alternative Implementations Using package:aqueduct/managed_auth is preferable in most cases. In some cases, you may wish to store authorization information in different database system or use token formats like JWT . This is a complex topic that requires significant testing efforts, and is outside the scope of this tutorial.","title":"The Basics of OAuth 2.0"},{"location":"tut/oauth2/#setting-up-oauth-20-creating-a-user-type","text":"Our application needs some concept of a 'user' - a person who logs into the application to manage heroes. This user will have a username and password. In a later exercise, a user will also have a list of heroes that belong to them. Create a new file model/user.dart and enter the following code: import package:aqueduct/managed_auth.dart ; import package:heroes/heroes.dart ; import package:heroes/model/hero.dart ; class User extends ManagedObject _User implements _User , ManagedAuthResourceOwner _User {} class _User extends ResourceOwnerTableDefinition {} The imported library package:aqueduct/managed_auth.dart contains types that use the ORM to store users, tokens and other OAuth 2.0 related data. One of those types is ResourceOwnerTableDefinition , the superclass of our user's table definition. This type contains all of the required fields that Aqueduct needs to implement authentication. Resource Owners A resource owner is a more general term for a 'user' that comes from the OAuth 2.0 specification. In the framework, you'll see types and variables using some variant of resource owner , but for all intents and purposes, you can consider this a 'user'. If you are curious, ResourceOwnerTableDefinition looks like this: class ResourceOwnerTableDefinition { @ primaryKey int id ; @ Column ( unique: true , indexed: true ) String username ; @ Column ( omitByDefault: true ) String hashedPassword ; @ Column ( omitByDefault: true ) String salt ; ManagedSet ManagedAuthToken tokens ; } Because these fields are in User 's table definition, our User table has all of these database columns. ManagedAuthResourceOwner Note that User implements ManagedAuthResourceOwner _User - this is a requirement of any OAuth 2.0 resource owner type when using package:aqueduct/managed_auth .","title":"Setting up OAuth 2.0: Creating a User Type"},{"location":"tut/oauth2/#setting-up-oauth-20-authserver-and-its-delegate","text":"Now that we have a user, we need some way to create new users and authenticate them. Authentication is fairly tricky, especially in OAuth 2.0, so there is a service object that does the hard part for us called an AuthServer . This type has all of the logic needed to authentication and authorize users. For example, an AuthServer can generate a new token if given valid user credentials. In channel.dart , add the following imports to the top of your file: import package:aqueduct/managed_auth.dart ; import package:heroes/model/user.dart ; Then, declare a new authServer property in your channel and initialize it in prepare : class HeroesChannel extends ApplicationChannel { ManagedContext context ; // Add this field AuthServer authServer ; Future prepare () async { logger . onRecord . listen (( rec ) = print ( $ rec ${ rec . error ?? } ${ rec . stackTrace ?? } )); final config = HeroConfig ( options . configurationFilePath ); final dataModel = ManagedDataModel . fromCurrentMirrorSystem (); final persistentStore = PostgreSQLPersistentStore . fromConnectionInfo ( config . database . username , config . database . password , config . database . host , config . database . port , config . database . databaseName ); context = ManagedContext ( dataModel , persistentStore ); // Add these two lines: final authStorage = ManagedAuthDelegate User ( context ); authServer = AuthServer ( authStorage ); } ... While an AuthServer handles the logic of authentication and authorization, it doesn't know how to store or fetch the data it uses for those tasks. Instead, it relies on a delegate object to handle storing and fetching data from a database. In our application, we use ManagedAuthDelegate T - from package:aqueduct/managed_auth - as the delegate. This type uses the ORM for these tasks; the type argument must be our application's user object. Delegation Delegation is a design pattern where an object has multiple callbacks that are grouped into an interface. Instead of defining a closure for each callback, a type implements methods that get called by the delegating object. It is a way of organizing large amounts of related callbacks into a tidy class. By importing aqueduct/managed_auth , we've added a few more managed objects to our application (to store tokens and other authentication data) and we also have a new User managed object. It's a good time to run a database migration. From your project directory, run the following commands: aqueduct db generate aqueduct db upgrade --connect postgres://heroes_user:password@localhost:5432/heroes","title":"Setting up OAuth 2.0: AuthServer and its Delegate"},{"location":"tut/oauth2/#setting-up-oauth-20-registering-users","text":"Now that we have the concept of a user, our database and application are set up to handle authentication, we can start creating new users. Let's create a new controller for registering users. This controller will accept POST requests that contain a username and password in the body. It will insert a new user into the database and securely hash the user's password. Before we create this controller, there is something we need to consider: our registration endpoint will require the user's password, but we store the user's password as a cryptographic hash. This prevents someone with access to your database from knowing a user's password. In order to bind the body of a request to a User object, it needs a password field, but we don't want to store the password in the database without first hashing it. We can accomplish this with transient properties . A transient property is a property of a managed object that isn't stored in the database. They are declared in the managed object subclass instead of the table definition. By default, a transient property is not read from a request body or encoded into a response body; unless we add the Serialize annotation to it. Add this property to your User type: class User extends ManagedObject _User implements _User , ManagedAuthResourceOwner _User { @ Serialize ( input: true , output: false ) String password ; } This declares that a User has a transient property password that can be read on input (from a request body), but is not sent on output (to a response body). We don't have to run a database migration because transient properties are not stored in a database. Now, create the file controller/register_controller.dart and enter the following code: import dart:async ; import package:aqueduct/aqueduct.dart ; import package:heroes/model/user.dart ; class RegisterController extends ResourceController { RegisterController ( this . context , this . authServer ); final ManagedContext context ; final AuthServer authServer ; @ Operation . post () Future Response createUser ( @ Bind . body () User user ) async { // Check for required parameters before we spend time hashing if ( user . username == null || user . password == null ) { return Response . badRequest ( body: { error : username and password required. }); } user .. salt = AuthUtility . generateRandomSalt () .. hashedPassword = authServer . hashPassword ( user . password , user . salt ); return Response . ok ( await Query ( context , values: user ). insert ()); } } This controller takes POST requests that contain a user. A user has many fields (username, password, hashedPassword, salt), but we will calculate the latter two and only require that the request contain the first two. The controller generates a salt and hash of the password before storing it in the database. In channel.dart , let's link this controller - don't forget to import it! import package:heroes/controller/register_controller.dart ; ... @ override Controller get entryPoint { final router = Router (); router . route ( /heroes/[:id] ) . link (() = HeroesController ( context )); router . route ( /register ) . link (() = RegisterController ( context , authServer )); return router ; } } Let's run the application and create a new user using curl from the command-line. (We'll specify -n1 to designate using one isolate and speed up startup.) aqueduct serve -n1 Then, issue a request to your server: curl - X POST http: //localhost:8888/register -H Content-Type: application/json -d { username : bob , password : password } You'll get back the new user object and its username: { id :1, username : bob }","title":"Setting up OAuth 2.0: Registering Users"},{"location":"tut/oauth2/#setting-up-oauth-20-authenticating-users","text":"Now that we have a user with a password, we can can create an endpoint that takes user credentials and returns an access token. The good news is that this controller already exists in Aqueduct, you just have to hook it up to a route. Update entryPoint in channel.dart to add an AuthController for the route /auth/token : @ override Controller get entryPoint { final router = Router (); // add this route router . route ( /auth/token ) . link (() = AuthController ( authServer )); router . route ( /heroes/[:id] ) . link (() = HeroesController ( context )); router . route ( /register ) . link (() = RegisterController ( context , authServer )); return router ; } An AuthController follows the OAuth 2.0 specification for granting access tokens when given valid user credentials. To understand how a request to this endpoint must be structured, we need to discuss OAuth 2.0 clients . In OAuth 2.0, a client is an application that is allowed to access your server on behalf of a user. A client can be a browser application, a mobile application, another server, a voice assistant, etc. A client always has an identifier string, typically something like 'com.stablekernel.account_app.mobile'. When authenticating, a user is always authenticated through a client. This client information must be attached to every authentication request, and the server must validate that the client had been previously registered. Therefore, we need to register a new client for our application. A client is stored in our application's database using the aqueduct auth add-client CLI. Run the following command from your project directory: aqueduct auth add-client --id com.heroes.tutorial --connect postgres://heroes_user:password@localhost:5432/heroes OAuth 2.0 Clients A client must have an identifier, but it may also have a secret, redirect URI and list of allowed scopes. See the guides on OAuth 2.0 for how these options impacts authentication. Most notably, a client identifier must have a secret to issue a refresh token . Clients are stored in an application's database. This will insert a new row into an OAuth 2.0 client table created by our last round of database migration and allow us to make authentication requests. An authentication request must meet all of the following criteria: the client identifier (and secret, if it exists) are included as a basic Authorization header. the username and password are included in the request body the key-value grant_type=password is included in the request body the request body content-type is application/x-www-form-urlencoded ; this means the request body is effectively a query string (e.g. username=bob password=pw grant_type=password ) In Dart code, this would like this: import package:http/http.dart as http ; // Must include http package in your pubspec.yaml final clientID = com.heroes.tutorial ; final body = username=bob password=password grant_type=password ; // Note the trailing colon (:) after the clientID. // A client identifier secret would follow this, but there is no secret, so it is the empty string. final clientCredentials = Base64Encoder (). convert ( $ clientID : ); final response = await http . post ( https://stablekernel.com/auth/token , headers: { Content-Type : application/x-www-form-urlencoded , Authorization : Basic $ clientCredentials }, body: body ); You can execute that code or you can use the following curl : curl -X POST http://localhost:8888/auth/token -H Authorization: Basic Y29tLmhlcm9lcy50dXRvcmlhbDo= -H Content-Type: application/x-www-form-urlencoded -d username=bob password=password grant_type=password If you were successful, you'll get the following response containing an access token: { access_token : 687PWKFHRTQ9MveQ2dKvP95D4cWie1gh , token_type : bearer , expires_in :86399} Hang on to this access token, we'll use it in a moment.","title":"Setting up OAuth 2.0: Authenticating Users"},{"location":"tut/oauth2/#setting-up-oauth-20-securing-routes","text":"Now that we can create and authenticate users, we can protect our heroes from anonymous users by requiring an access token for hero requests. In channel.dart , link an Authorizer in the middle of the /heroes channel: router . route ( /heroes/[:id] ) . link (() = Authorizer . bearer ( authServer )) . link (() = HeroesController ( context )); An Authorizer protects a channel from unauthorized requests by validating the Authorization header of a request. When created with Authorizer.bearer , it ensures that the authorization header contains a valid access token. Restart your application and try and access the /heroes endpoint without including any authorization: curl -X GET --verbose http://localhost:8080/heroes You'll get a 401 Unauthorized response. Now, include your access token in a bearer authorization header (note that your token will be different): curl -X GET http://localhost:8080/heroes -H Authorization: Bearer 687PWKFHRTQ9MveQ2dKvP95D4cWie1gh You'll get back your list of heroes! Other Uses of Authorizer An Authorizer can validate access token scopes and basic authorization credentials. You'll see examples of these in a later exercise.","title":"Setting up OAuth 2.0: Securing Routes"},{"location":"tut/storing-data/","text":"3. Storing Data in a Database In the previous exercise, we loaded some heroes into the database our application reads from. Now, we will allow our application to store, delete and modify heroes in the database. Before we embark on this part of the journey, it's important that we understand how an HTTP API is intended to work. HTTP Resources and Methods The HTTP specification defines the concept of a resource . A resource can be anything - a hero, a bank account, a light switch in your home, a temperature sensor in Antarctica, etc. Some of these things are physical objects (the light switch), and some are digital - and they are all resources. An HTTP server application is an interface to these resources; a client requests that something be done with a resource, and the server finds a way to get it done. Resources are identified with a URI. A URI universally identifies a resource: it has the address of a server to connect to, and a path that identifies the resource on that server. When writing Aqueduct applications, we don't care much about the server part of a URL - the internet figures out that part. What we do care about is the path of the URL - like /heroes . An application uses the URL path to determine which resource the request wants to work with. Right now, our application works with hero resources. A request with the path /heroes/1 wants to do something with an individual hero (that is identified by the number 1 ). A request with the path /heroes will act on the entire collection of heroes. These actions are primarily described by the request method (like GET, POST, OR DELETE). Each of these methods has a general meaning that describes an action that can be applied to a resource. For example, a GET /heroes means \"get me all of the hero resources\". The meaning for each of these methods are as follows: GET: returns a collection of some resource or an individual resource POST: inserts or appends a resource to a collection of some resource; a representation of the resource is in the request body PUT: replaces a resource with the contents of the request body (or in some cases, replaces the entire collection of some resource) DELETE: deletes a resource (or in some cases, deletes the entire collection of some resource) It turns out, we can create a lot of incredible behavior by just combining these methods and a request path. More importantly, by following these specifications, client applications can use generic libraries to access any HTTP API with very little effort. This allows us to create complex systems that are easily made available to a browser, mobile phone or any other internet-connected device. Inserting Data We'll start by adding behavior that allows for new heroes to be inserted into the database. Following our previous discussion, the HTTP request must take the form POST /heroes - we are appending a new hero to the collection of heroes. This request will contain the JSON representation of a hero in its body, for example: { name : Master of Aqueducts } Our HeroesController will handle this operation. In general, a single endpoint controller should handle every operation on a resource collection and its individual resources. In heroes_controller.dart , add the following operation method: @ Operation . post () Future Response createHero () async { final Map String , dynamic body = await request . body . decode (); final query = Query Hero ( context ) .. values . name = body [ name ] as String ; final insertedHero = await query . insert (); return Response . ok ( insertedHero ); } This operation method decodes the hero from the request's body, constructs a query that inserts that hero, and then returns it in the response. Using a Query Hero to insert a row isn't very different than using one to fetch rows. When inserting a row, we execute query.insert() instead of query.fetch() . Instead of applying expressions with where , we set the properties of values . The values of a query is an empty instance of the type being inserted. Each property we set on values is sent in an INSERT command to the database. The generated SQL for the above would be something like: INSERT INTO _Hero ( name ) VALUES ( Hero Name ); The database automatically generates a value for the id property of a Hero (its @primaryKey annotation enables the \"auto-incrementing\" option). When the row has been successfully inserted, a new Hero object is returned - containing any values that were generated by the database. Most API endpoints return the created object in the response so that the client has the same information that the server has, and our application is no different. Column Attributes See the API reference for Column for column options like auto-incrementing. Re-run your application. In the browser application, click on Heroes near the top of the page. Then, enter a name into the Hero name: field and click Add . The new hero will appear. You can re-run the application and that hero will still be available, because it has been stored in the database on your machine. Sub-resources We mentioned that a single controller should handle every operation for a resource collection and its individual resources. Some resources are complex enough that they can have sub-resources. For example, an organization of heroes (like the X-Men or Fantastic Four) contains heroes, but it might also contain buildings and equipment owned by the organization. The heroes, buildings and equipment are sub-resources of an organization. Each sub-resource should have its own route and controller instead of trying to shove everything into a single route and controller. See the following code snippet for an example. @ override Controller get entryPoint { return Router () .. route ( /organizations/[:orgName] ) . link (() = OrganizationController ()); .. route ( /organizations/:orgName/heroes/[:heroID] ) . link (() = OrgHeroesController ()); .. route ( /organizations/:orgName/buildings/[:buildingID] ) . link (() = OrgBuildingController ()); } Request and Response Bodies So far, we've largely glossed over how request and response bodies are handled, and now is a good time to dig in to this topic. Response Body Encoding When we create a response, we specify its status code and optionally its headers and body. For example, the following creates a response with a status code of 200 OK with an empty list body: Response . ok ([]) The first argument to Response.ok is a body object . A body object is automatically encoded according to the contentType of its response. By default, the content type of a response is application/json - so by default, all of our response body objects are JSON-encoded in the response body. Other Response Constructors The default constructor for a Response takes a status code, map of headers and a body object: Response(200, {}, \"body\") . There are many named constructors for Response , like Response.ok or Response.notFound . These constructors set the status code and expose parameters that are intended for that type of response. For example, a 200 OK response should have a body, so Response.ok has a required body object argument. See the API reference for Response for possible constructors and properties of a response. To change the format a body object is encoded into, you set the contentType of the response. For example, Response . ok ([]) .. contentType = new ContentType ( application , xml ); The default supported content types are JSON, application/x-www-form-urlencoded and all text/* types. To encode other content-types, you must register a Codec with CodecRegistry. A body object is only valid if the codec selected by the response's content-type can encode it. If it can't, an error will be thrown and a 500 Server Error response is sent instead. Types that implement Serializable may also be body objects. Objects that implement this type provide an asMap() method that converts their properties into a Map before being passed to the encoder. This Map must be encodable for the response's content-type codec. You may also provide a List of Serializable , for which the list of each object's asMap() is passed to the encoder. ManagedObject implements the Serializable interface, and therefore all managed objects (and lists of managed objects) can be body objects. Request Body Decoding Every Request has a body property of type RequestBody . A RequestBody decodes the contents of the request body into Dart objects that you use in your application. This decoding is performed by the Codec that is associated with the request's content-type. The decoded object is determined by the format of the data - for example, a JSON array decodes into a List , a JSON object into a Map . When you write code to decode a request body, you are also validating the request body is in the expected format. For example, your HeroesController invokes decode like this: Map String , dynamic body = await request . body . decode (); The decode method has a type argument that is inferred to be a Map String, dynamic . If the decoded body is not a Map , an exception is thrown that sends an appropriate error response to the client. You may also bind the body of a request to an operation method parameter. Let's bind a Hero instance to a request body in our HeroesController . Update the code in that file to the following: @ Operation . post () Future Response createHero ( @ Bind . body () Hero inputHero ) async { final query = Query Hero ( context ) .. values = inputHero ; final insertedHero = await query . insert (); return Response . ok ( insertedHero ); } Values in the request body object are decoded into a Hero object - each key in the request body maps to a property of our Hero . For example, the value for the key 'name' is stored in the inputHero.name . If decoding the request body into a Hero instance fails for any reason, a 400 Bad Request response is sent and the operation method is not called. An object can only be bound to a request body if it implements Serializable - the good news is all ManagedObject s implement this interface. You may create your own types that implement this interface, and you may also bind a List T , where T implements the interface. Re-run your heroes application. On http://aqueduct-tutorial.stablekernel.io , click on the Heroes button on the top of the screen. In the text field, enter a new hero name and click Add . You'll see your new hero added to the list! You can shutdown your application and run it again and you'll still be able to fetch your new hero. Query Construction Properties like values and where prevent errors by type and name checking columns with the analyzer. They're also great for speeding up writing code because your IDE will autocomplete property names. There is specific behavior a query uses to decide whether it should include a value from these two properties in the SQL it generates. Next Chapter: Writing Tests","title":"3. Storing Data in a Database"},{"location":"tut/storing-data/#3-storing-data-in-a-database","text":"In the previous exercise, we loaded some heroes into the database our application reads from. Now, we will allow our application to store, delete and modify heroes in the database. Before we embark on this part of the journey, it's important that we understand how an HTTP API is intended to work.","title":"3. Storing Data in a Database"},{"location":"tut/storing-data/#http-resources-and-methods","text":"The HTTP specification defines the concept of a resource . A resource can be anything - a hero, a bank account, a light switch in your home, a temperature sensor in Antarctica, etc. Some of these things are physical objects (the light switch), and some are digital - and they are all resources. An HTTP server application is an interface to these resources; a client requests that something be done with a resource, and the server finds a way to get it done. Resources are identified with a URI. A URI universally identifies a resource: it has the address of a server to connect to, and a path that identifies the resource on that server. When writing Aqueduct applications, we don't care much about the server part of a URL - the internet figures out that part. What we do care about is the path of the URL - like /heroes . An application uses the URL path to determine which resource the request wants to work with. Right now, our application works with hero resources. A request with the path /heroes/1 wants to do something with an individual hero (that is identified by the number 1 ). A request with the path /heroes will act on the entire collection of heroes. These actions are primarily described by the request method (like GET, POST, OR DELETE). Each of these methods has a general meaning that describes an action that can be applied to a resource. For example, a GET /heroes means \"get me all of the hero resources\". The meaning for each of these methods are as follows: GET: returns a collection of some resource or an individual resource POST: inserts or appends a resource to a collection of some resource; a representation of the resource is in the request body PUT: replaces a resource with the contents of the request body (or in some cases, replaces the entire collection of some resource) DELETE: deletes a resource (or in some cases, deletes the entire collection of some resource) It turns out, we can create a lot of incredible behavior by just combining these methods and a request path. More importantly, by following these specifications, client applications can use generic libraries to access any HTTP API with very little effort. This allows us to create complex systems that are easily made available to a browser, mobile phone or any other internet-connected device.","title":"HTTP Resources and Methods"},{"location":"tut/storing-data/#inserting-data","text":"We'll start by adding behavior that allows for new heroes to be inserted into the database. Following our previous discussion, the HTTP request must take the form POST /heroes - we are appending a new hero to the collection of heroes. This request will contain the JSON representation of a hero in its body, for example: { name : Master of Aqueducts } Our HeroesController will handle this operation. In general, a single endpoint controller should handle every operation on a resource collection and its individual resources. In heroes_controller.dart , add the following operation method: @ Operation . post () Future Response createHero () async { final Map String , dynamic body = await request . body . decode (); final query = Query Hero ( context ) .. values . name = body [ name ] as String ; final insertedHero = await query . insert (); return Response . ok ( insertedHero ); } This operation method decodes the hero from the request's body, constructs a query that inserts that hero, and then returns it in the response. Using a Query Hero to insert a row isn't very different than using one to fetch rows. When inserting a row, we execute query.insert() instead of query.fetch() . Instead of applying expressions with where , we set the properties of values . The values of a query is an empty instance of the type being inserted. Each property we set on values is sent in an INSERT command to the database. The generated SQL for the above would be something like: INSERT INTO _Hero ( name ) VALUES ( Hero Name ); The database automatically generates a value for the id property of a Hero (its @primaryKey annotation enables the \"auto-incrementing\" option). When the row has been successfully inserted, a new Hero object is returned - containing any values that were generated by the database. Most API endpoints return the created object in the response so that the client has the same information that the server has, and our application is no different. Column Attributes See the API reference for Column for column options like auto-incrementing. Re-run your application. In the browser application, click on Heroes near the top of the page. Then, enter a name into the Hero name: field and click Add . The new hero will appear. You can re-run the application and that hero will still be available, because it has been stored in the database on your machine. Sub-resources We mentioned that a single controller should handle every operation for a resource collection and its individual resources. Some resources are complex enough that they can have sub-resources. For example, an organization of heroes (like the X-Men or Fantastic Four) contains heroes, but it might also contain buildings and equipment owned by the organization. The heroes, buildings and equipment are sub-resources of an organization. Each sub-resource should have its own route and controller instead of trying to shove everything into a single route and controller. See the following code snippet for an example. @ override Controller get entryPoint { return Router () .. route ( /organizations/[:orgName] ) . link (() = OrganizationController ()); .. route ( /organizations/:orgName/heroes/[:heroID] ) . link (() = OrgHeroesController ()); .. route ( /organizations/:orgName/buildings/[:buildingID] ) . link (() = OrgBuildingController ()); }","title":"Inserting Data"},{"location":"tut/storing-data/#request-and-response-bodies","text":"So far, we've largely glossed over how request and response bodies are handled, and now is a good time to dig in to this topic.","title":"Request and Response Bodies"},{"location":"tut/storing-data/#response-body-encoding","text":"When we create a response, we specify its status code and optionally its headers and body. For example, the following creates a response with a status code of 200 OK with an empty list body: Response . ok ([]) The first argument to Response.ok is a body object . A body object is automatically encoded according to the contentType of its response. By default, the content type of a response is application/json - so by default, all of our response body objects are JSON-encoded in the response body. Other Response Constructors The default constructor for a Response takes a status code, map of headers and a body object: Response(200, {}, \"body\") . There are many named constructors for Response , like Response.ok or Response.notFound . These constructors set the status code and expose parameters that are intended for that type of response. For example, a 200 OK response should have a body, so Response.ok has a required body object argument. See the API reference for Response for possible constructors and properties of a response. To change the format a body object is encoded into, you set the contentType of the response. For example, Response . ok ([]) .. contentType = new ContentType ( application , xml ); The default supported content types are JSON, application/x-www-form-urlencoded and all text/* types. To encode other content-types, you must register a Codec with CodecRegistry. A body object is only valid if the codec selected by the response's content-type can encode it. If it can't, an error will be thrown and a 500 Server Error response is sent instead. Types that implement Serializable may also be body objects. Objects that implement this type provide an asMap() method that converts their properties into a Map before being passed to the encoder. This Map must be encodable for the response's content-type codec. You may also provide a List of Serializable , for which the list of each object's asMap() is passed to the encoder. ManagedObject implements the Serializable interface, and therefore all managed objects (and lists of managed objects) can be body objects.","title":"Response Body Encoding"},{"location":"tut/storing-data/#request-body-decoding","text":"Every Request has a body property of type RequestBody . A RequestBody decodes the contents of the request body into Dart objects that you use in your application. This decoding is performed by the Codec that is associated with the request's content-type. The decoded object is determined by the format of the data - for example, a JSON array decodes into a List , a JSON object into a Map . When you write code to decode a request body, you are also validating the request body is in the expected format. For example, your HeroesController invokes decode like this: Map String , dynamic body = await request . body . decode (); The decode method has a type argument that is inferred to be a Map String, dynamic . If the decoded body is not a Map , an exception is thrown that sends an appropriate error response to the client. You may also bind the body of a request to an operation method parameter. Let's bind a Hero instance to a request body in our HeroesController . Update the code in that file to the following: @ Operation . post () Future Response createHero ( @ Bind . body () Hero inputHero ) async { final query = Query Hero ( context ) .. values = inputHero ; final insertedHero = await query . insert (); return Response . ok ( insertedHero ); } Values in the request body object are decoded into a Hero object - each key in the request body maps to a property of our Hero . For example, the value for the key 'name' is stored in the inputHero.name . If decoding the request body into a Hero instance fails for any reason, a 400 Bad Request response is sent and the operation method is not called. An object can only be bound to a request body if it implements Serializable - the good news is all ManagedObject s implement this interface. You may create your own types that implement this interface, and you may also bind a List T , where T implements the interface. Re-run your heroes application. On http://aqueduct-tutorial.stablekernel.io , click on the Heroes button on the top of the screen. In the text field, enter a new hero name and click Add . You'll see your new hero added to the list! You can shutdown your application and run it again and you'll still be able to fetch your new hero. Query Construction Properties like values and where prevent errors by type and name checking columns with the analyzer. They're also great for speeding up writing code because your IDE will autocomplete property names. There is specific behavior a query uses to decide whether it should include a value from these two properties in the SQL it generates.","title":"Request Body Decoding"},{"location":"tut/storing-data/#next-chapter-writing-tests","text":"","title":"Next Chapter: Writing Tests"},{"location":"tut/writing-tests/","text":"4. Configuration and Writing Tests We will continue to build on the last chapter's project, heroes , by writing automated tests for it. We will also set up configurable environments for our application. Application Configuration Right now, our application hardcodes its database connection information. This is bad because we want to use a different database when we're testing, running locally and running in production. It's also bad because we'd have to check our database password into version control. We can create an configuration file to store values like database connection information, and use a different configuration file for each environment. The heroes application needs to be able to configure the username, password, host port and name of the database it uses. Open the file config.yaml , which is empty, and enter the following key-value pairs: database : host : localhost port : 5432 username : heroes_user password : password databaseName : heroes These are the same values we used in our application channel. We'll want to replace the hardcoded values with whatever values are in this file. In lib/channel.dart , declare a new class at the bottom of the file: class HeroConfig extends Configuration { HeroConfig ( String path ) : super . fromFile ( File ( path )); DatabaseConfiguration database ; } A Configuration subclass declares the expected properties of a configuration file. HeroConfig has one property named database - this matches the name of our top-level key in config.yaml . A DatabaseConfiguration is a built-in configuration type that has properties for host , port , username , password and databaseName . We can load config.yaml into a HeroConfig because they have the same structure and all of the key names match the property names in our configuration types. Invalid Configuration If your configuration file and configuration object don't have a matching structure, an error will be thrown when your application starts and tell you which values are missing. Let's load config.yaml and use its values to set up our database connection by replacing the prepare method in lib/channel.dart : @ override Future prepare () async { logger . onRecord . listen ( ( rec ) = print ( $ rec ${ rec . error ?? } ${ rec . stackTrace ?? } )); final config = HeroConfig ( options . configurationFilePath ); final dataModel = ManagedDataModel . fromCurrentMirrorSystem (); final persistentStore = PostgreSQLPersistentStore . fromConnectionInfo ( config . database . username , config . database . password , config . database . host , config . database . port , config . database . databaseName ); context = ManagedContext ( dataModel , persistentStore ); } When our application starts, our channel has access to an options property that has the command-line arguments that started the application. By default, the value of configurationFilePath is config.yaml (it corresponds to --config-path in aqueduct serve ). When config.yaml is read, its values are read into a HeroConfig and are used to configure our database connection. Re-run your application and it'll work exactly the same as it did before - except now, we can substitute databases depending on how we run the application. Configuration Template You shouldn't check config.yaml into version control because it contains sensitive information. However, it is important to check in a configuration source file . A configuration source file has the same structure as HeroConfig , but it has values for your test environment - both locally and with continuous integration tools. It is also used as a template for your deployed configuration files. Sensitive Information Use a platform like Heroku or Kubernetes. You can store sensitive information in secured environment variables. You can substitute environment variables in a configuration file by using the variable's name with a $ prefix as a value, e.g. password: $DATABASE_PASSWORD . A configuration source file should be named config.src.yaml , and one currently exists as an empty file in your project. Enter the following configuration into this file: database: host: localhost port: 5432 username: dart password: dart databaseName: dart_test This file has the expected structure, but has different values for the database information (for a database that we will create shortly). In the next section, we'll use this configuration file to run our automated tests. Testing in Aqueduct So far, we've tested our application by using a web application. This isn't a good way to test an application. A better way is to write automated test cases. An automated test case not only tests the code you are working on, but makes sure the code you've worked on the past continues to work as you make changes. A good development practice is to configure TravisCI to run all of your tests for every code change. Because testing is so important, there is a package for writing Aqueduct application tests. In this chapter, we will use this package to make sure our hero endpoints are working correctly. package:aqueduct_test The package aqueduct_test and test was already added to your pubspec.yaml file as a test dependency by the template generator. In all Dart applications, a test suite is a Dart script with a main function. In this function, the test function is called multiple times to register expectations. A test passes if all of your expectations are met. An example Dart test looks like this: import package:test/test.dart ; void main () { test ( 1+1 = 2 , () { // Expect that 1 + 1 = 2 expect ( 1 + 1 , equals ( 2 )); }); } Setting up your Development Environment In config.src.yaml , we target the database dart:dart@localhost:5432/dart_test . This is a 'special' database that is used by all Aqueduct applications for automated testing (by default). When your application is tested, its tables are temporarily added to this database and then discarded after tests complete. This means that no data is stored in between test runs. Create this database by running psql and enter the following SQL: CREATE DATABASE dart_test ; CREATE USER dart WITH createdb ; ALTER USER dart WITH password dart ; GRANT all ON database dart_test TO dart ; dart_test Database You only have to create this database once per machine, and in any continuous integration scripts. All of your Aqueduct applications will use this database for automated testing. Fun fact - you can run multiple application's tests simultaneously using this database because the tables only exist for the database connection that created them. Writing Your First Test We will create a test suite to make sure that all hero endpoints return the right data, and make the right changes. Create a new file named test/hero_controller_test.dart . Test Files Names and Locations A test file must end in _test.dart and must be in the test/ directory of your project, or it won't be run. At the top of this file, import your application's test harness and enter the following main function: import harness/app.dart ; void main () { final harness = Harness ().. install (); } A test harness is an object that starts and stops your application when running a test suite, as long as you call its install method. This harness can then send requests to your application, and you can expect that the response is correct. Add a test to the main function that makes sure we get back a 200 OK when we call GET /heroes : void main () { final harness = Harness ().. install (); test ( GET /heroes returns 200 OK , () async { final response = await harness . agent . get ( /heroes ); expectResponse ( response , 200 ); }); } A harness has an Agent that can send requests to the application it started. Methods like get and post take a path (and optionally headers and a body) and return a response object. This object is used in expectResponse to validate the status code and other values. Tests in Aqueduct are written in this way: make a request, expect that the response is intended. Because our application makes database queries, we have to to upload our database schema to the test database before each test. Fortunately, this is something our test harness can also do. In test/harness/app.dart , mixin TestHarnessORMMixin and override two methods: class Harness extends TestHarness HeroesChannel with TestHarnessORMMixin { @ override ManagedContext get context = channel . context ; @ override Future onSetUp () async { await resetData (); } } The mixin gives our harness the method resetData . This method deletes everything from the test database and uploads the schema in a pristine state. By calling this method in onSetUp , our test harness will reset data before each test. New Project Templates Using the -t command-line argument with aqueduct create allows you to select a template. Templates like db and db_and_auth have a test harness that already mixes in TestHarnessORMMixin . Now, we can run this test by right-clicking on the main function in hero_controller_test.dart and selecting Run tests in 'hero_controller_test.dart' . A panel will appear that shows the results of your tests. You'll see a green checkmark next to the test in this panel to show that your test succeeded. If your test did not succeed, the reason will be printed to the console. If your test failed because of an error in your code, you will also be able to see the stack trace of the error. Running Tests You can also run all of your tests for an application by running pub run test from your project's directory. You can re-run a test with the green play button at the top right corner of the screen, or the keyboard shortcut associated with it (this shortcut varies depending on your installation). We should expect that more than just the status code is correct. Let's verify that the body is a list, where every element is an object that contains an id and name. Update your test: test ( GET /heroes returns 200 OK , () async { final response = await harness . agent . get ( /heroes ); expectResponse ( response , 200 , body: everyElement ({ id : greaterThan ( 0 ), name : isString , })); }); This expectation ensures that the body is a list and that every element is an object with a id greater than 0, and a name that is a string. When expecting a body value, the body is first decoded from its content-type before the expectation. In practice, this means that your JSON response body is deserialized into an object or list. Your expectations of the body are built from Dart objects like List and Object that deserialized from JSON. Matchers The function everyElement is a Matcher from package:matcher . There are many types of matchers for all kinds of scenarios, and package:aqueduct_test includes Aqueduct-specific matchers. See the aqueduct_test API Reference for all Aqueduct matchers. This test actually has an error that we will fix in it by using another matcher. Right now, this endpoint returns an empty list because there are no heroes in the database! Let's insert a hero before we make this request, and also expect that there is at least one element in the body. Make sure to import hero.dart at the top of the file! import package:heroes/model/hero.dart ; import harness/app.dart ; void main () { final harness = Harness ().. install (); test ( GET /heroes returns 200 OK , () async { final query = Query Hero ( harness . application . channel . context ) .. values . name = Bob ; await query . insert (); final response = await harness . agent . get ( /heroes ); expectResponse ( response , 200 , body: allOf ([ hasLength ( greaterThan ( 0 )), everyElement ({ id : greaterThan ( 0 ), name : isString , }) ])); }); } This test first inserts a hero named 'Bob' before getting all heroes. We compose a matcher where each element has to match the expected list, but also have a length greater than 0. Re-run your tests, and they should still pass. Writing More Tests Let's write a few more tests for when we POST /heroes . In the first test, we'll make a mistake on purpose to see how tests fail. Add the following test: test ( POST /heroes returns 200 OK , () async { final response = await harness . agent . post ( /heroes , body: { name : Fred }); expectResponse ( response , 200 , body: { id : greaterThan ( 0 ), name : Bob }); }); This test creates a hero named 'Fred', but expects that the returned hero has the name 'Bob'. When we run the test, we see this test failure: Expected : --- HTTP Response --- - Status code must be 200 - Headers can be anything - Body after decoding must be : { id : a value greater than 0 , name : Bob } --------------------- Actual : TestResponse : ----------- - Status code is 200 - Headers are the following : - content-encoding : gzip - content-length : 42 - x-frame-options : SAMEORIGIN - content-type : application / json ; charset = utf-8 - x-xss-protection : 1 ; mode = block - x-content-type-options : nosniff - server : aqueduct / 1 Decoded body is : { id : 1 , name : Fred } ------------------------- Which : the body differs for the following reasons : was Fred instead of Bob at location [ name ] The 'Expected' value tells us the response we expected - that it has a status code of 200, any headers and the body must have a certain structure. The 'Actual' value tells us what the actual response was - a 200 OK, a bunch of headers, and a body a hero named 'Fred'. 'Which' tells us exactly what went wrong - we were expected 'Bob', not 'Fred'. Let's update our test to expect 'Fred'. test ( POST /heroes returns 200 OK , () async { final response = await harness . agent . post ( /heroes , body: { name : Fred }); expectResponse ( response , 200 , body: { id : greaterThan ( 0 ), name : Fred }); }); We shouldn't just test success cases. Let's also expect that if we try and insert a hero with the same name, we get a 409 error response. test ( POST /heroes returns 200 OK , () async { await harness . agent . post ( /heroes , body: { name : Fred }); final badResponse = await harness . agent . post ( /heroes , body: { name : Fred }); expectResponse ( badResponse , 409 ); }); In this test, we request two 'Fred' heroes be created, and the second request fails with a 409 because name is a unique property of a hero. Notice that the first request didn't fail, even though we had created a 'Fred' hero in the previous test - that's because we reset the database for each test in our harness. Next Chapter: Authentication and Authorization","title":"4. Configuration and Testing"},{"location":"tut/writing-tests/#4-configuration-and-writing-tests","text":"We will continue to build on the last chapter's project, heroes , by writing automated tests for it. We will also set up configurable environments for our application.","title":"4. Configuration and Writing Tests"},{"location":"tut/writing-tests/#application-configuration","text":"Right now, our application hardcodes its database connection information. This is bad because we want to use a different database when we're testing, running locally and running in production. It's also bad because we'd have to check our database password into version control. We can create an configuration file to store values like database connection information, and use a different configuration file for each environment. The heroes application needs to be able to configure the username, password, host port and name of the database it uses. Open the file config.yaml , which is empty, and enter the following key-value pairs: database : host : localhost port : 5432 username : heroes_user password : password databaseName : heroes These are the same values we used in our application channel. We'll want to replace the hardcoded values with whatever values are in this file. In lib/channel.dart , declare a new class at the bottom of the file: class HeroConfig extends Configuration { HeroConfig ( String path ) : super . fromFile ( File ( path )); DatabaseConfiguration database ; } A Configuration subclass declares the expected properties of a configuration file. HeroConfig has one property named database - this matches the name of our top-level key in config.yaml . A DatabaseConfiguration is a built-in configuration type that has properties for host , port , username , password and databaseName . We can load config.yaml into a HeroConfig because they have the same structure and all of the key names match the property names in our configuration types. Invalid Configuration If your configuration file and configuration object don't have a matching structure, an error will be thrown when your application starts and tell you which values are missing. Let's load config.yaml and use its values to set up our database connection by replacing the prepare method in lib/channel.dart : @ override Future prepare () async { logger . onRecord . listen ( ( rec ) = print ( $ rec ${ rec . error ?? } ${ rec . stackTrace ?? } )); final config = HeroConfig ( options . configurationFilePath ); final dataModel = ManagedDataModel . fromCurrentMirrorSystem (); final persistentStore = PostgreSQLPersistentStore . fromConnectionInfo ( config . database . username , config . database . password , config . database . host , config . database . port , config . database . databaseName ); context = ManagedContext ( dataModel , persistentStore ); } When our application starts, our channel has access to an options property that has the command-line arguments that started the application. By default, the value of configurationFilePath is config.yaml (it corresponds to --config-path in aqueduct serve ). When config.yaml is read, its values are read into a HeroConfig and are used to configure our database connection. Re-run your application and it'll work exactly the same as it did before - except now, we can substitute databases depending on how we run the application.","title":"Application Configuration"},{"location":"tut/writing-tests/#configuration-template","text":"You shouldn't check config.yaml into version control because it contains sensitive information. However, it is important to check in a configuration source file . A configuration source file has the same structure as HeroConfig , but it has values for your test environment - both locally and with continuous integration tools. It is also used as a template for your deployed configuration files. Sensitive Information Use a platform like Heroku or Kubernetes. You can store sensitive information in secured environment variables. You can substitute environment variables in a configuration file by using the variable's name with a $ prefix as a value, e.g. password: $DATABASE_PASSWORD . A configuration source file should be named config.src.yaml , and one currently exists as an empty file in your project. Enter the following configuration into this file: database: host: localhost port: 5432 username: dart password: dart databaseName: dart_test This file has the expected structure, but has different values for the database information (for a database that we will create shortly). In the next section, we'll use this configuration file to run our automated tests.","title":"Configuration Template"},{"location":"tut/writing-tests/#testing-in-aqueduct","text":"So far, we've tested our application by using a web application. This isn't a good way to test an application. A better way is to write automated test cases. An automated test case not only tests the code you are working on, but makes sure the code you've worked on the past continues to work as you make changes. A good development practice is to configure TravisCI to run all of your tests for every code change. Because testing is so important, there is a package for writing Aqueduct application tests. In this chapter, we will use this package to make sure our hero endpoints are working correctly. package:aqueduct_test The package aqueduct_test and test was already added to your pubspec.yaml file as a test dependency by the template generator. In all Dart applications, a test suite is a Dart script with a main function. In this function, the test function is called multiple times to register expectations. A test passes if all of your expectations are met. An example Dart test looks like this: import package:test/test.dart ; void main () { test ( 1+1 = 2 , () { // Expect that 1 + 1 = 2 expect ( 1 + 1 , equals ( 2 )); }); }","title":"Testing in Aqueduct"},{"location":"tut/writing-tests/#setting-up-your-development-environment","text":"In config.src.yaml , we target the database dart:dart@localhost:5432/dart_test . This is a 'special' database that is used by all Aqueduct applications for automated testing (by default). When your application is tested, its tables are temporarily added to this database and then discarded after tests complete. This means that no data is stored in between test runs. Create this database by running psql and enter the following SQL: CREATE DATABASE dart_test ; CREATE USER dart WITH createdb ; ALTER USER dart WITH password dart ; GRANT all ON database dart_test TO dart ; dart_test Database You only have to create this database once per machine, and in any continuous integration scripts. All of your Aqueduct applications will use this database for automated testing. Fun fact - you can run multiple application's tests simultaneously using this database because the tables only exist for the database connection that created them.","title":"Setting up your Development Environment"},{"location":"tut/writing-tests/#writing-your-first-test","text":"We will create a test suite to make sure that all hero endpoints return the right data, and make the right changes. Create a new file named test/hero_controller_test.dart . Test Files Names and Locations A test file must end in _test.dart and must be in the test/ directory of your project, or it won't be run. At the top of this file, import your application's test harness and enter the following main function: import harness/app.dart ; void main () { final harness = Harness ().. install (); } A test harness is an object that starts and stops your application when running a test suite, as long as you call its install method. This harness can then send requests to your application, and you can expect that the response is correct. Add a test to the main function that makes sure we get back a 200 OK when we call GET /heroes : void main () { final harness = Harness ().. install (); test ( GET /heroes returns 200 OK , () async { final response = await harness . agent . get ( /heroes ); expectResponse ( response , 200 ); }); } A harness has an Agent that can send requests to the application it started. Methods like get and post take a path (and optionally headers and a body) and return a response object. This object is used in expectResponse to validate the status code and other values. Tests in Aqueduct are written in this way: make a request, expect that the response is intended. Because our application makes database queries, we have to to upload our database schema to the test database before each test. Fortunately, this is something our test harness can also do. In test/harness/app.dart , mixin TestHarnessORMMixin and override two methods: class Harness extends TestHarness HeroesChannel with TestHarnessORMMixin { @ override ManagedContext get context = channel . context ; @ override Future onSetUp () async { await resetData (); } } The mixin gives our harness the method resetData . This method deletes everything from the test database and uploads the schema in a pristine state. By calling this method in onSetUp , our test harness will reset data before each test. New Project Templates Using the -t command-line argument with aqueduct create allows you to select a template. Templates like db and db_and_auth have a test harness that already mixes in TestHarnessORMMixin . Now, we can run this test by right-clicking on the main function in hero_controller_test.dart and selecting Run tests in 'hero_controller_test.dart' . A panel will appear that shows the results of your tests. You'll see a green checkmark next to the test in this panel to show that your test succeeded. If your test did not succeed, the reason will be printed to the console. If your test failed because of an error in your code, you will also be able to see the stack trace of the error. Running Tests You can also run all of your tests for an application by running pub run test from your project's directory. You can re-run a test with the green play button at the top right corner of the screen, or the keyboard shortcut associated with it (this shortcut varies depending on your installation). We should expect that more than just the status code is correct. Let's verify that the body is a list, where every element is an object that contains an id and name. Update your test: test ( GET /heroes returns 200 OK , () async { final response = await harness . agent . get ( /heroes ); expectResponse ( response , 200 , body: everyElement ({ id : greaterThan ( 0 ), name : isString , })); }); This expectation ensures that the body is a list and that every element is an object with a id greater than 0, and a name that is a string. When expecting a body value, the body is first decoded from its content-type before the expectation. In practice, this means that your JSON response body is deserialized into an object or list. Your expectations of the body are built from Dart objects like List and Object that deserialized from JSON. Matchers The function everyElement is a Matcher from package:matcher . There are many types of matchers for all kinds of scenarios, and package:aqueduct_test includes Aqueduct-specific matchers. See the aqueduct_test API Reference for all Aqueduct matchers. This test actually has an error that we will fix in it by using another matcher. Right now, this endpoint returns an empty list because there are no heroes in the database! Let's insert a hero before we make this request, and also expect that there is at least one element in the body. Make sure to import hero.dart at the top of the file! import package:heroes/model/hero.dart ; import harness/app.dart ; void main () { final harness = Harness ().. install (); test ( GET /heroes returns 200 OK , () async { final query = Query Hero ( harness . application . channel . context ) .. values . name = Bob ; await query . insert (); final response = await harness . agent . get ( /heroes ); expectResponse ( response , 200 , body: allOf ([ hasLength ( greaterThan ( 0 )), everyElement ({ id : greaterThan ( 0 ), name : isString , }) ])); }); } This test first inserts a hero named 'Bob' before getting all heroes. We compose a matcher where each element has to match the expected list, but also have a length greater than 0. Re-run your tests, and they should still pass.","title":"Writing Your First Test"},{"location":"tut/writing-tests/#writing-more-tests","text":"Let's write a few more tests for when we POST /heroes . In the first test, we'll make a mistake on purpose to see how tests fail. Add the following test: test ( POST /heroes returns 200 OK , () async { final response = await harness . agent . post ( /heroes , body: { name : Fred }); expectResponse ( response , 200 , body: { id : greaterThan ( 0 ), name : Bob }); }); This test creates a hero named 'Fred', but expects that the returned hero has the name 'Bob'. When we run the test, we see this test failure: Expected : --- HTTP Response --- - Status code must be 200 - Headers can be anything - Body after decoding must be : { id : a value greater than 0 , name : Bob } --------------------- Actual : TestResponse : ----------- - Status code is 200 - Headers are the following : - content-encoding : gzip - content-length : 42 - x-frame-options : SAMEORIGIN - content-type : application / json ; charset = utf-8 - x-xss-protection : 1 ; mode = block - x-content-type-options : nosniff - server : aqueduct / 1 Decoded body is : { id : 1 , name : Fred } ------------------------- Which : the body differs for the following reasons : was Fred instead of Bob at location [ name ] The 'Expected' value tells us the response we expected - that it has a status code of 200, any headers and the body must have a certain structure. The 'Actual' value tells us what the actual response was - a 200 OK, a bunch of headers, and a body a hero named 'Fred'. 'Which' tells us exactly what went wrong - we were expected 'Bob', not 'Fred'. Let's update our test to expect 'Fred'. test ( POST /heroes returns 200 OK , () async { final response = await harness . agent . post ( /heroes , body: { name : Fred }); expectResponse ( response , 200 , body: { id : greaterThan ( 0 ), name : Fred }); }); We shouldn't just test success cases. Let's also expect that if we try and insert a hero with the same name, we get a 409 error response. test ( POST /heroes returns 200 OK , () async { await harness . agent . post ( /heroes , body: { name : Fred }); final badResponse = await harness . agent . post ( /heroes , body: { name : Fred }); expectResponse ( badResponse , 409 ); }); In this test, we request two 'Fred' heroes be created, and the second request fails with a 409 because name is a unique property of a hero. Notice that the first request didn't fail, even though we had created a 'Fred' hero in the previous test - that's because we reset the database for each test in our harness.","title":"Writing More Tests"},{"location":"tut/writing-tests/#next-chapter-authentication-and-authorization","text":"","title":"Next Chapter: Authentication and Authorization"}]}