{
    "docs": [
        {
            "location": "/", 
            "text": "Aqueduct is a productive server-side framework written in Dart.\n\n\n \n\n\nGetting Started\n\n\nMake sure to check out the tutorial in the navigation menu.\n\n\n\n\nInstall Dart\n.\n\n\n\n\nActivate the Aqueduct Command-Line Tool\n\n\npub global activate aqueduct\n\n\n\n\n\n\n\n\n\nRun first time setup (this prompts you to setup a local PostgreSQL database for testing).\n\n\naqueduct setup\n\n\n\n\n\n\n\n\n\nCreate a new project.\n\n\naqueduct create my_project\n\n\n\n\n\n\n\n\n\nThe recommended IDE is \nIntelliJ IDEA CE\n (or any other IntelliJ platform, like Webstorm) with the \nDart Plugin\n. (The plugin can be installed directly from the IntelliJ IDEA plugin preference pane.)\n\n\nOther editors with good Dart plugins are \nAtom\n and \nVisual Studio Code\n.\n\n\nIn any of these editors, open the project directory created by \naqueduct create\n.\n\n\nOther Important References\n\n\nDeeper dives into the framework are available under the Guides in the sidebar.\n\n\nAqueduct API Reference\n.\n\n\nAqueduct on Github\n.\n\n\nTour\n\n\nTake a tour of Aqueduct.\n\n\nInitialization\n\n\nCreate applications with the command line tool:\n\n\naqueduct create my_app\n\n\n\n\n\nAnd subclass a \nRequestSink\n to declare routes:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\n\nclass\n \nAppRequestSink\n \nextends\n \nRequestSink\n \n{\n\n  \nManagedContext\n \ndatabaseContext\n;\n\n\n  \nAppRequestSink\n(\nApplicationConfig\n \nconfig\n)\n \n:\n \nsuper\n(\nconfig\n)\n \n{\n\n    \ndatabaseContext\n \n=\n \ncontextFrom\n(\nconfig\n);\n\n  \n}\n\n\n  \n@\noverride\n\n  \nvoid\n \nsetupRouter\n(\nRouter\n \nrouter\n)\n \n{\n\n    \nrouter\n\n      \n.\nroute\n(\n/resource\n)\n\n      \n.\ngenerate\n(()\n \n=\n \nnew\n \nResourceController\n(\ndatabaseContext\n));\n\n  \n}\n\n\n}\n\n\n\n\n\n\nRouting\n\n\nBuild complex routes with path variables, create route groups via optional path segments:\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/users/[:id]\n)\n\n    \n.\ngenerate\n(()\n \n=\n \nnew\n \nUserController\n());\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/file/*\n)\n\n    \n.\ngenerate\n(()\n \n=\n \nnew\n \nStaticFileController\n());\n\n\n\n\n\n\nControllers\n\n\nThe class most often used to respond to a request is \nHTTPController\n. \nHTTPController\ns must be subclassed and are declared in their own file. An \nHTTPController\n handles all HTTP requests for a resource; e.g. POST /users, GET /users and GET /users/1 all go to the same controller.\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n\n\n\nclass\n \nResourceController\n \nextends\n \nHTTPController\n \n{\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetAllResources\n()\n \nasync\n \n{\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nawait\n \nfetchResources\n())\n;\n\n  \n}\n\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetResourceByID\n(\n@\nHTTPPath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nawait\n \nfetchResource\n(\nid\n));\n\n  \n}\n\n\n}\n\n\n\n\n\n\nUse \nManagedObjectController\nT\ns that map a REST interface to database queries without writing any code:\n\n\nrouter\n\n  \n.\nroute\n(\n/users/[:id]\n)\n\n  \n.\ngenerate\n(()\n \n=\n \nnew\n \nManagedObjectController\nUser\n());\n\n\n\n\n\n\nControllers catch exceptions and translate them to the appropriate status code response.\n\n\nConfiguration\n\n\nRead YAML configuration data into type-safe and name-safe structures at startup:\n\n\n// config.yaml\ndatabase:\n  host: ...\n  port: 5432\n  databaseName: foo\notherOption: hello\nnumberOfDoodads: 3  \n\n\n\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\n\nclass\n \nAppRequestSink\n \nextends\n \nRequestSink\n \n{\n\n  \nAppRequestSink\n(\nApplicationConfig\n \nconfig\n)\n \n:\n \nsuper\n(\nconfig\n)\n \n{\n\n    \nvar\n \noptions\n \n=\n \nnew\n \nAppOptions\n(\nconfig\n.\nconfigurationFilePath\n);\n\n    \n...\n\n  \n}\n\n\n}\n\n\n\nclass\n \nAppOptions\n \nextends\n \nConfigurationItem\n \n{\n\n  \nDatabaseConnectionInfo\n \ndatabase\n;\n\n  \nString\n \notherOption\n;\n\n  \nint\n \nnumberOfDoodads\n;\n\n\n}\n\n\n\n\n\n\nRunning and Concurrency\n\n\nAqueduct applications are run with a command line tool, which can also open debugging and instrumentation tools and specify how many threads the application should run on:\n\n\naqueduct serve --observe --isolates 5\n\n\n\n\n\nRun applications detached or still connected to the shell (how a tool like Heroku expects):\n\n\naqueduct serve --detached --port $PORT\n\n\n\n\n\nAqueduct applications threads are isolated - they share no memory with other threads - and each runs a replica of the same web server. Pooling resources is effectively achieved through this mechanism.\n\n\nQuerying a Database\n\n\nMuch of the time, a request is handled by sending one or more commands to a database to either get data or send data. This is done with \nQuery\nT\n objects.\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n\n\n\nclass\n \nResourceController\n \nextends\n \nHTTPController\n \n{\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetAllResources\n()\n \nasync\n \n{\n\n    \nvar\n \nquery\n \n=\n \nnew\n \nQuery\nResource\n()\n;\n\n\n    \nvar\n \nresults\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nresults\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe results of a \nQuery\nT\n can be filtered by configuring its \nQuery.where\n property, which uses Dart's powerful, real-time static analyzer to avoid mistakes and offer code completion.\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nEmployee\n()\n\n  \n..\nwhere\n.\nname\n \n=\n \nwhereStartsWith\n(\nSa\n)\n\n  \n..\nwhere\n.\nsalary\n \n=\n \nwhereGreaterThan\n(\n50000\n);\n\n\nvar\n \nresults\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nBuilding queries to insert or update values into the database uses the similar \nvalues\n property of a \nQuery\nT\n.\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nEmployee\n()\n\n  \n..\nvalues\n.\nname\n \n=\n \nBob\n\n  \n..\nvalues\n.\nsalary\n \n=\n \n50000\n;\n\n\n\nvar\n \nbob\n \n=\n \nawait\n \nquery\n.\ninsert\n();\n  \n\n\nvar\n \nupdateQuery\n \n=\n \nnew\n \nQuery\nEmployee\n()\n\n  \n..\nwhere\n.\nid\n \n=\n \nbob\n.\nid\n\n  \n..\nvalues\n.\nname\n \n=\n \nBobby\n;\n\n\nbob\n \n=\n \nawait\n \nupdateQuery\n.\nupdateOne\n();\n  \n\n\n\n\n\nQuery\nT\ns can sort and page on a result set. It can also join tables and return objects and their relationships:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nEmployee\n()\n\n  \n..\nwhere\n.\nname\n \n=\n \nSue Gallagher\n\n  \n..\njoinOne\n((\ne\n)\n \n=\n \ne\n.\nmanager\n)\n\n  \n..\njoinMany\n((\ne\n)\n \n=\n \ne\n.\ndirectReports\n);\n\n\n\nvar\n \nherAndHerManagerAndHerDirectReports\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\n\n\n\n\nExceptions thrown for queries are caught by the controller and translated into the appropriate status code. Unique constraint conflicts return 409,\nmissing required properties return 400, database connection failure returns 503, etc. You can change this by try-catching \nQuery\nT\n methods.\n\n\nDefining a Data Model\n\n\nFor each database table, there is a \nManagedObject\nT\n subclass. These subclasses are the type argument to \nQuery\nT\n. They are made up of two classes: a persistent type that declares a property for each database column in the table, and the subclass of \nManagedObject\nT\n that you work with in your code.\n\n\nclass\n \nEmployee\n \nextends\n \nManagedObject\n_Employee\n \nimplements\n \n_Employee\n \n{\n\n  \nbool\n \nget\n \nwasRecentlyHired\n \n=\n \nhireDate\n.\ndifference\n(\nnew\n \nDateTime\n.\nnow\n()).\ninDays\n \n \n30\n;\n\n\n}\n\n\nclass\n \n_Employee\n  \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nindex\n;\n\n\n  \n@\nManagedColumnAttributes\n(\nindexed:\n \ntrue\n)\n\n  \nString\n \nname\n;\n\n\n  \nDateTime\n \nhireDate\n;\n\n  \nint\n \nsalary\n;\n\n\n}\n\n\n\n\n\n\nManagedObject\nT\ns have relationship properties - references to other \nManagedObject\nT\ns. The property with \nManagedRelationship\n metadata is a foreign key column.\n\n\nclass\n \nEmployee\n \nextends\n \nManagedObject\n_Employee\n \nimplements\n \n_Employee\n \n{}\n\n\nclass\n \n_Employee\n \n{\n\n  \nManagedSet\nInitiative\n \ninitiatives\n;\n\n\n  \n...\n\n\n}\n\n\n\nclass\n \nInitiative\n \nextends\n \nManagedObject\n_Initiative\n \nimplements\n \n_Initiative\n \n{}\n\n\nclass\n \n_Initiative\n \n{\n\n  \n@\nManagedRelationship\n(\n#\ninitiatives\n)\n\n  \nEmployee\n \nleader\n;\n\n\n  \n...\n\n\n}\n\n\n\n\n\n\nManagedObject\nT\ns are easily read from and written to JSON (or any other format):\n\n\nclass\n \nUserController\n \nextends\n \nHTTPController\n \n{\n\n  \n@\nhttpPut\n\n  \nFuture\nResponse\n \nupdateUser\n(\n@\nHTTPPath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n    \nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n      \n..\nwhere\n.\nid\n \n=\n \nid\n\n      \n..\nvalues\n \n=\n \n(\nnew\n \nUser\n()..\nreadMap\n(\nrequest\n.\nbody\n.\nasMap\n());\n\n\n    \nvar\n \nupdatedUser\n \n=\n \nawait\n \nquery\n.\nupdateOne\n();\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nupdatedUser\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nAutomatic Database Migration\n\n\nGenerate and run database migrations with the \naqueduct db\n tool:\n\n\naqueduct db generate\naqueduct db validate\naqueduct db upgrade --connect postgres@://...\n\n\n\n\n\nOAuth 2.0\n\n\nAuthentication and authorization are enabled at application startup by creating an \nAuthServer\n with \nManagedAuthStorage\n:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\n\nclass\n \nAppRequestSink\n \nextends\n \nRequestSink\n \n{\n\n  \nAppRequestSink\n(\nApplicationConfig\n \nconfig\n)\n \n:\n \nsuper\n(\nconfig\n)\n \n{\n\n    \nvar\n \nstorage\n \n=\n \nnew\n \nManagedAuthStorage\nUser\n(\nManagedContext\n.\ndefaultContext\n);\n\n    \nauthServer\n \n=\n \nnew\n \nAuthServer\n(\nstorage\n);\n\n  \n}\n\n\n  \nAuthServer\n \nauthServer\n;\n\n\n}\n\n\n\n\n\n\nSet up routes to exchange credentials for tokens using \nAuthController\n and \nAuthCodeController\n. Add \nAuthorizer\ns between routes and their controller to restrict access to authorized resource owners only:\n\n\nvoid\n \nsetupRouter\n(\nRouter\n \nrouter\n)\n \n{\n\n  \nrouter\n\n    \n.\nroute\n(\n/auth/token\n)\n\n    \n.\ngenerate\n(()\n \n=\n \nnew\n \nAuthController\n(\nauthServer\n));\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/auth/code\n)\n\n    \n.\ngenerate\n(()\n \n=\n \nnew\n \nAuthCodeController\n(\nauthServer\n));\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/protected\n)\n\n    \n.\npipe\n(\nnew\n \nAuthorizer\n.\nbearer\n(\nauthServer\n))\n\n    \n.\ngenerate\n(()\n \n=\n \nnew\n \nProtectedController\n());\n\n\n}\n\n\n\n\n\n\nInsert OAuth 2.0 clients into a database:\n\n\naqueduct auth add-client --id com.app.mobile --secret foobar --redirect-uri https://somewhereoutthere.com\n\n\n\n\n\nLogging\n\n\nLogging can write to stdout or a rotating log file. Logging runs on its own thread; API threads send messages to the logging thread which handles I/O.\n\n\nclass\n \nWildfireSink\n \nextends\n \nRequestSink\n \n{\n\n  \nstatic\n \nString\n \nLoggingTargetKey\n \n=\n \nlogging\n;\n\n\n  \nstatic\n \nFuture\n \ninitializeApplication\n(\nApplicationConfiguration\n \nconfig\n)\n \nasync\n \n{\n    \n    \n...\n\n    \nvar\n \nloggingServer\n \n=\n \nnew\n \nLoggingServer\n([\nnew\n \nConsoleBackend\n()]);\n\n    \nawait\n \nloggingServer\n?\n.\nstart\n();\n\n    \nconfig\n.\noptions\n[\nLoggingTargetKey\n]\n \n=\n \nloggingServer\n?\n.\ngetNewTarget\n();\n\n  \n}\n\n\n  \nWildfireSink\n(\nApplicationConfiguration\n \nconfig\n)\n \n:\n \nsuper\n(\nconfig\n)\n \n{\n\n    \nvar\n \ntarget\n \n=\n \nconfig\n.\noptions\n[\nLoggingTargetKey\n];\n\n    \ntarget\n?\n.\nbind\n(\nlogger\n);\n\n\n    \nlogger\n.\ninfo\n(\nWe\nre up!\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nTesting\n\n\nBecause Aqueduct can generate database migration files, it can generate your application data model on the fly, too. Starting a test instance of an application will connect to a temporary database and create tables that are destroyed when the database connection closes. Endpoints are validated with specialized matchers in the Hamcrest matcher style:\n\n\ntest\n(\n/users/1 returns a user\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \ntestClient\n.\nauthenticatedRequest\n(\n/users/1\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \npartial\n({\n\n    \nid\n:\n \n1\n,\n\n    \nname\n:\n \nisString\n\n  \n})));\n\n\n});\n\n\n\n\n\n\nUse the template project's test harness to quickly set up tests:\n\n\nimport\n \npackage:test/test.dart\n;\n\n\nimport\n \npackage:my_app/my_app.dart\n;\n\n\n\nvoid\n \nmain\n()\n \n{\n\n  \nvar\n \napp\n \n=\n \nnew\n \nTestApplication\n();\n\n\n  \nsetUpAll\n(()\n \nasync\n \n{\n\n    \nawait\n \napp\n.\nstart\n();\n\n  \n});\n\n\n  \ntest\n(\n...\n,\n \n()\n \nasync\n \n{\n\n    \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n();\n\n    \n...\n\n  \n});\n\n\n}\n\n\n\n\n\n\nDocumentation\n\n\nGenerate OpenAPI specifications automatically:\n\n\naqueduct document", 
            "title": "Home"
        }, 
        {
            "location": "/#getting-started", 
            "text": "Make sure to check out the tutorial in the navigation menu.   Install Dart .   Activate the Aqueduct Command-Line Tool  pub global activate aqueduct    Run first time setup (this prompts you to setup a local PostgreSQL database for testing).  aqueduct setup    Create a new project.  aqueduct create my_project    The recommended IDE is  IntelliJ IDEA CE  (or any other IntelliJ platform, like Webstorm) with the  Dart Plugin . (The plugin can be installed directly from the IntelliJ IDEA plugin preference pane.)  Other editors with good Dart plugins are  Atom  and  Visual Studio Code .  In any of these editors, open the project directory created by  aqueduct create .", 
            "title": "Getting Started"
        }, 
        {
            "location": "/#other-important-references", 
            "text": "Deeper dives into the framework are available under the Guides in the sidebar.  Aqueduct API Reference .  Aqueduct on Github .", 
            "title": "Other Important References"
        }, 
        {
            "location": "/#tour", 
            "text": "Take a tour of Aqueduct.", 
            "title": "Tour"
        }, 
        {
            "location": "/#initialization", 
            "text": "Create applications with the command line tool:  aqueduct create my_app  And subclass a  RequestSink  to declare routes:  import   package:aqueduct/aqueduct.dart ;  class   AppRequestSink   extends   RequestSink   { \n   ManagedContext   databaseContext ; \n\n   AppRequestSink ( ApplicationConfig   config )   :   super ( config )   { \n     databaseContext   =   contextFrom ( config ); \n   } \n\n   @ override \n   void   setupRouter ( Router   router )   { \n     router \n       . route ( /resource ) \n       . generate (()   =   new   ResourceController ( databaseContext )); \n   }  }", 
            "title": "Initialization"
        }, 
        {
            "location": "/#routing", 
            "text": "Build complex routes with path variables, create route groups via optional path segments:     router \n     . route ( /users/[:id] ) \n     . generate (()   =   new   UserController ()); \n\n   router \n     . route ( /file/* ) \n     . generate (()   =   new   StaticFileController ());", 
            "title": "Routing"
        }, 
        {
            "location": "/#controllers", 
            "text": "The class most often used to respond to a request is  HTTPController .  HTTPController s must be subclassed and are declared in their own file. An  HTTPController  handles all HTTP requests for a resource; e.g. POST /users, GET /users and GET /users/1 all go to the same controller.  import   package:aqueduct/aqueduct.dart  class   ResourceController   extends   HTTPController   { \n   @ httpGet \n   Future Response   getAllResources ()   async   { \n     return   new   Response . ok ( await   fetchResources ()) ; \n   } \n\n   @ httpGet \n   Future Response   getResourceByID ( @ HTTPPath ( id )   int   id )   async   { \n     return   new   Response . ok ( await   fetchResource ( id )); \n   }  }   Use  ManagedObjectController T s that map a REST interface to database queries without writing any code:  router \n   . route ( /users/[:id] ) \n   . generate (()   =   new   ManagedObjectController User ());   Controllers catch exceptions and translate them to the appropriate status code response.", 
            "title": "Controllers"
        }, 
        {
            "location": "/#configuration", 
            "text": "Read YAML configuration data into type-safe and name-safe structures at startup:  // config.yaml\ndatabase:\n  host: ...\n  port: 5432\n  databaseName: foo\notherOption: hello\nnumberOfDoodads: 3    import   package:aqueduct/aqueduct.dart ;  class   AppRequestSink   extends   RequestSink   { \n   AppRequestSink ( ApplicationConfig   config )   :   super ( config )   { \n     var   options   =   new   AppOptions ( config . configurationFilePath ); \n     ... \n   }  }  class   AppOptions   extends   ConfigurationItem   { \n   DatabaseConnectionInfo   database ; \n   String   otherOption ; \n   int   numberOfDoodads ;  }", 
            "title": "Configuration"
        }, 
        {
            "location": "/#running-and-concurrency", 
            "text": "Aqueduct applications are run with a command line tool, which can also open debugging and instrumentation tools and specify how many threads the application should run on:  aqueduct serve --observe --isolates 5  Run applications detached or still connected to the shell (how a tool like Heroku expects):  aqueduct serve --detached --port $PORT  Aqueduct applications threads are isolated - they share no memory with other threads - and each runs a replica of the same web server. Pooling resources is effectively achieved through this mechanism.", 
            "title": "Running and Concurrency"
        }, 
        {
            "location": "/#querying-a-database", 
            "text": "Much of the time, a request is handled by sending one or more commands to a database to either get data or send data. This is done with  Query T  objects.  import   package:aqueduct/aqueduct.dart  class   ResourceController   extends   HTTPController   { \n   @ httpGet \n   Future Response   getAllResources ()   async   { \n     var   query   =   new   Query Resource () ; \n\n     var   results   =   await   query . fetch (); \n\n     return   new   Response . ok ( results ); \n   }  }   The results of a  Query T  can be filtered by configuring its  Query.where  property, which uses Dart's powerful, real-time static analyzer to avoid mistakes and offer code completion.  var   query   =   new   Query Employee () \n   .. where . name   =   whereStartsWith ( Sa ) \n   .. where . salary   =   whereGreaterThan ( 50000 );  var   results   =   await   query . fetch ();   Building queries to insert or update values into the database uses the similar  values  property of a  Query T .  var   query   =   new   Query Employee () \n   .. values . name   =   Bob \n   .. values . salary   =   50000 ;  var   bob   =   await   query . insert ();    var   updateQuery   =   new   Query Employee () \n   .. where . id   =   bob . id \n   .. values . name   =   Bobby ;  bob   =   await   updateQuery . updateOne ();     Query T s can sort and page on a result set. It can also join tables and return objects and their relationships:  var   query   =   new   Query Employee () \n   .. where . name   =   Sue Gallagher \n   .. joinOne (( e )   =   e . manager ) \n   .. joinMany (( e )   =   e . directReports );  var   herAndHerManagerAndHerDirectReports   =   await   query . fetchOne ();   Exceptions thrown for queries are caught by the controller and translated into the appropriate status code. Unique constraint conflicts return 409,\nmissing required properties return 400, database connection failure returns 503, etc. You can change this by try-catching  Query T  methods.", 
            "title": "Querying a Database"
        }, 
        {
            "location": "/#defining-a-data-model", 
            "text": "For each database table, there is a  ManagedObject T  subclass. These subclasses are the type argument to  Query T . They are made up of two classes: a persistent type that declares a property for each database column in the table, and the subclass of  ManagedObject T  that you work with in your code.  class   Employee   extends   ManagedObject _Employee   implements   _Employee   { \n   bool   get   wasRecentlyHired   =   hireDate . difference ( new   DateTime . now ()). inDays     30 ;  }  class   _Employee    { \n   @ managedPrimaryKey \n   int   index ; \n\n   @ ManagedColumnAttributes ( indexed:   true ) \n   String   name ; \n\n   DateTime   hireDate ; \n   int   salary ;  }   ManagedObject T s have relationship properties - references to other  ManagedObject T s. The property with  ManagedRelationship  metadata is a foreign key column.  class   Employee   extends   ManagedObject _Employee   implements   _Employee   {}  class   _Employee   { \n   ManagedSet Initiative   initiatives ; \n\n   ...  }  class   Initiative   extends   ManagedObject _Initiative   implements   _Initiative   {}  class   _Initiative   { \n   @ ManagedRelationship ( # initiatives ) \n   Employee   leader ; \n\n   ...  }   ManagedObject T s are easily read from and written to JSON (or any other format):  class   UserController   extends   HTTPController   { \n   @ httpPut \n   Future Response   updateUser ( @ HTTPPath ( id )   int   id )   async   { \n     var   query   =   new   Query User () \n       .. where . id   =   id \n       .. values   =   ( new   User ().. readMap ( request . body . asMap ()); \n\n     var   updatedUser   =   await   query . updateOne (); \n\n     return   new   Response . ok ( updatedUser ); \n   }  }", 
            "title": "Defining a Data Model"
        }, 
        {
            "location": "/#automatic-database-migration", 
            "text": "Generate and run database migrations with the  aqueduct db  tool:  aqueduct db generate\naqueduct db validate\naqueduct db upgrade --connect postgres@://...", 
            "title": "Automatic Database Migration"
        }, 
        {
            "location": "/#oauth-20", 
            "text": "Authentication and authorization are enabled at application startup by creating an  AuthServer  with  ManagedAuthStorage :  import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  class   AppRequestSink   extends   RequestSink   { \n   AppRequestSink ( ApplicationConfig   config )   :   super ( config )   { \n     var   storage   =   new   ManagedAuthStorage User ( ManagedContext . defaultContext ); \n     authServer   =   new   AuthServer ( storage ); \n   } \n\n   AuthServer   authServer ;  }   Set up routes to exchange credentials for tokens using  AuthController  and  AuthCodeController . Add  Authorizer s between routes and their controller to restrict access to authorized resource owners only:  void   setupRouter ( Router   router )   { \n   router \n     . route ( /auth/token ) \n     . generate (()   =   new   AuthController ( authServer )); \n\n   router \n     . route ( /auth/code ) \n     . generate (()   =   new   AuthCodeController ( authServer )); \n\n   router \n     . route ( /protected ) \n     . pipe ( new   Authorizer . bearer ( authServer )) \n     . generate (()   =   new   ProtectedController ());  }   Insert OAuth 2.0 clients into a database:  aqueduct auth add-client --id com.app.mobile --secret foobar --redirect-uri https://somewhereoutthere.com", 
            "title": "OAuth 2.0"
        }, 
        {
            "location": "/#logging", 
            "text": "Logging can write to stdout or a rotating log file. Logging runs on its own thread; API threads send messages to the logging thread which handles I/O.  class   WildfireSink   extends   RequestSink   { \n   static   String   LoggingTargetKey   =   logging ; \n\n   static   Future   initializeApplication ( ApplicationConfiguration   config )   async   {     \n     ... \n     var   loggingServer   =   new   LoggingServer ([ new   ConsoleBackend ()]); \n     await   loggingServer ? . start (); \n     config . options [ LoggingTargetKey ]   =   loggingServer ? . getNewTarget (); \n   } \n\n   WildfireSink ( ApplicationConfiguration   config )   :   super ( config )   { \n     var   target   =   config . options [ LoggingTargetKey ]; \n     target ? . bind ( logger ); \n\n     logger . info ( We re up! ); \n   }  }", 
            "title": "Logging"
        }, 
        {
            "location": "/#testing", 
            "text": "Because Aqueduct can generate database migration files, it can generate your application data model on the fly, too. Starting a test instance of an application will connect to a temporary database and create tables that are destroyed when the database connection closes. Endpoints are validated with specialized matchers in the Hamcrest matcher style:  test ( /users/1 returns a user ,   ()   async   { \n   var   response   =   await   testClient . authenticatedRequest ( /users/1 ). get (); \n   expect ( response ,   hasResponse ( 200 ,   partial ({ \n     id :   1 , \n     name :   isString \n   })));  });   Use the template project's test harness to quickly set up tests:  import   package:test/test.dart ;  import   package:my_app/my_app.dart ;  void   main ()   { \n   var   app   =   new   TestApplication (); \n\n   setUpAll (()   async   { \n     await   app . start (); \n   }); \n\n   test ( ... ,   ()   async   { \n     var   response   =   await   app . client . request ( /endpoint ). get (); \n     ... \n   });  }", 
            "title": "Testing"
        }, 
        {
            "location": "/#documentation", 
            "text": "Generate OpenAPI specifications automatically:  aqueduct document", 
            "title": "Documentation"
        }, 
        {
            "location": "/tut/getting-started/", 
            "text": "Purpose\n\n\nThe purpose of this tutorial series is to become familiar with how Aqueduct works. That means this tutorial will take a less efficient approach than a normal work flow so that the fundamentals are covered. For example, you will create a new project manually, but in a real work flow you would use the \naqueduct\n command line tool.\n\n\nThis tutorial will use Atom for editing code. It has the lowest barrier to entry and is easy to install. For heavy duty work, we recommend IntelliJ IDEA Community Edition with the Dart plugin. The IntelliJ Dart plugin is an official plugin.\n\n\nInstalling Dart\n\n\nIf you have Homebrew installed, run these commands from terminal:\n\n\nbrew tap dart-lang/dart\nbrew install dart\n\n\n\n\n\nIf you don't have Homebrew installed or you are on another platform, visit \nhttps://www.dartlang.org/install\n. It'll be quick, promise.\n\n\nYou should install Atom for editing your Dart code. You can get it from \nhttps://atom.io\n. Once Atom is installed, install the 'dartlang' package from 'dart-atom' (not any of the other ones that have a similar name).  \n\n\nCreating a Project\n\n\nCreate a new directory named \nquiz\n (ensure that it is lowercase). In this directory, create a new file named \npubspec.yaml\n. Dart uses this file to define your project and its dependencies (like iOS' \nInfo.plist\n or Android's \nAndroidManifest.xml\n).\n\n\nIn the pubspec, enter the following markup:\n\n\nname\n:\n \nquiz\n\n\ndescription\n:\n \nA\n \nquiz\n \nweb\n \nserver\n\n\nversion\n:\n \n0.0\n.\n1\n\n\nauthor\n:\n \nThor\n \nOdinson\n \nthor\n@\nasgard\n.\nyg\n\n\n\nenvironment\n:\n\n  \nsdk\n:\n \n=1.20.0 \n2.0.0\n\n\n\ndependencies\n:\n\n  \naqueduct\n:\n \nany\n  \n\n\n\n\n\nThis pubspec declares an application named \nquiz\n (all Dart files, directories and application identifiers are snake_case), indicates that it can use a version of the Dart SDK between 1.20 and 2.0, and depends on the \naqueduct\n package.\n\n\nNext, you will fetch the dependencies of the \nquiz\n project - this will fetch the source for \naqueduct\n from Dart's hosted package manager. If you are using Atom, you'll get a popup that tells you to do this and you can just click the button. (You may also right-click on file in Atom and select 'Pub Get'). If you aren't using Atom, from the command line, run the following from inside the \nquiz\n directory:\n\n\npub get\n\n\n\n\n\nDependencies get stored in the global cache directory, \n~/.pub-cache\n. Dependencies are referenced by files in your project's directory. These files are automatically generated by the previous command. You won't have to worry about that, though, since you'll never have to deal with it directly. Sometimes, it's just nice to know where things are. (There is one other file, called \npubspec.lock\n that you do care about, but we'll chat about it later.)\n\n\nWith this dependency installed, your project can use Aqueduct. For this simple getting started guide, we won't structure a full project and just focus on getting an Aqueduct web server up and running. Create a new directory named \nlib\n and add a file to it named \nquiz.dart\n. The project should now look like this on the filesystem:\n\n\nquiz/\n  pubspec.yaml\n  pubspec.lock\n  lib/\n    quiz.dart\n\n\n\n\n\nAt the top of this file, import the Aqueduct package and the \nasync\n standard library:\n\n\nimport\n \ndart:async\n;\n\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\n\n\n\n\nHandling Requests\n\n\nThe structure of Aqueduct is like most server-side frameworks: a new request comes in and gets routed to code that will respond to it. At its core, Aqueduct request handling is made up of three types of objects: \nRequest\ns, \nResponse\ns and \nRequestController\ns. When an Aqueduct application receives an HTTP request, it creates a \nRequest\n object. For every \nRequest\n, a \nResponse\n must be created and sent back. \nRequestController\ns handle the logic of taking a \nRequest\ns and creating a \nResponse\ns.\n\n\nExamples of \nRequestController\n subclasses are \nRouter\n and \nHTTPController\n. A router figures out the right \nRequestController\n to handle a request by inspecting the request's path. An \nHTTPController\n takes a request - after it's been through a \nRouter\n - and calls one its methods depending on the request's HTTP method (e.g., GET, POST). That method returns a \nResponse\n and the request is completed.\n\n\nThe \nquiz\n application will have a \nRouter\n that will send requests with the path \n/questions\n to an instance of \nQuestionController\n. \nQuestionController\n is an \nHTTPController\n subclass that you will write - it will respond with a list of JSON questions. In \nquiz.dart\n, create this new type:\n\n\nclass\n \nQuestionController\n \nextends\n \nHTTPController\n \n{\n\n  \nvar\n \nquestions\n \n=\n \n[\n\n    \nHow much wood can a woodchuck chuck?\n,\n\n    \nWhat\ns the tallest mountain in the world?\n\n  \n];\n\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetAllQuestions\n()\n \nasync\n \n{\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nquestions\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe \nQuestionController\n class has a list of strings named \nquestions\n and a method called \ngetAllQuestions\n. The metadata above the method - \nhttpGet\n - is important. This metadata tells the \nQuestionController\n to invoke \ngetAllQuestions\n when it receives a GET request. Likewise, if this metadata were \nhttpPut\n or \nhttpPost\n, this controller would invoke this method for PUT or POST requests.\n\n\nMethods declared in \nHTTPController\n subclasses with this metadata are called \nresponder methods\n, because they respond to HTTP requests. This is the primary job of an \nHTTPController\n - to map requests to a responder method based on their HTTP method. A responder method must return an instance of \nFuture\nResponse\n. There are convenience constructors for common response status codes. In this example, \nResponse.ok\n creates a \nResponse\n with status code 200. The first argument to \nResponse.ok\n is an object that will be encoded as the HTTP response body.\n\n\nNow, we must create a \nRouter\n. A \nRouter\n will receive all requests in an application. During initialization, a router is given \nroutes\n - patterns that look for matches in the path of an HTTP request - and \nRequestController\ns registered to receive requests for those routes. In your application, the \nRouter\n will have instances of \nQuestionController\n registered for the route \n/questions\n. All initialization for Aqueduct applications happens in a \nRequestSink\n.\n\n\nAn application subclasses \nRequestSink\n and overrides a few of methods to handle initializing the application. The one required override is \nsetupRouter\n. This method, as the name suggests, is where you set up the application's routes and \nRequestController\ns. The tools that run an Aqueduct application know how to find and create your \nRequestSink\n subclass in your application.\n\n\nAt the bottom of \nquiz.dart\n, create a \nRequestSink\n subclass:\n\n\nclass\n \nQuizRequestSink\n \nextends\n \nRequestSink\n \n{\n\n  \nQuizRequestSink\n(\nApplicationConfiguration\n \noptions\n)\n \n:\n \nsuper\n \n(\noptions\n);\n\n\n  \n@\noverride\n\n  \nvoid\n \nsetupRouter\n(\nRouter\n \nrouter\n)\n \n{\n\n    \nrouter\n\n      \n.\nroute\n(\n/questions\n)\n\n      \n.\ngenerate\n(()\n \n=\n \nnew\n \nQuestionController\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nA \nRequestSink\n subclass must have a constructor that takes an \nApplicationConfiguration\n instance and forward it on to its superclass' constructor. These values are provided by a configuration file and are typically used to configure a \nRequestSink\n's properties - like a database connection. Since the \nquiz\n app doesn't do much right now, we simply forward the configuration options on to the \nsuper\n's constructor as required.\n\n\nRoutes are registered through the \nroute\n method. When a router matches the path of an HTTP request to one of its registered routes, the \nRequest\n is sent to the next \nRequestController\n for that route. If no registered route matches the path of the request, the \nRouter\n responds to the \nRequest\n with a 404 status code and drops the \nRequest\n event.\n\n\nIn this example, the \"next controller\" for \n/questions\n is added with the \ngenerate\n method. The \ngenerate\n method takes a closure that returns an instance of some \nRequestController\n. Each time the router passes a \nRequest\n a generator, the closure is called, creating a new instance of that \nRequestController\n, and the \nRequest\n is delivered to that new instance. Here, that new instance is an instance of our \nQuestionController\n.\n\n\nWe'll get to the specifics of all of that in a moment, but we're at the point that we can run this web server, and that seems more exciting. First, activate the \naqueduct\n executable:\n\n\npub global activate aqueduct\n\n\n\n\n\nThis command might tell you that \n~/.pub-cache/bin\n (or some other directory) is not in your \nPATH\n variable. If that's the case, add it according to the instructions emitted by the command. (For example, if you are on macOS, you'd add \nexport PATH=$PATH:\"~/pub-cache/bin\"\n to your \n~/.bash_profile\n and then reload your terminal.)\n\n\nIn the project directory, run the following command to start the application:\n\n\naqueduct serve\n\n\n\n\n\nIn a browser, open the URL \nhttp://localhost:8081/questions\n. You'll see the list of questions! (You can shut down the server by hitting Ctrl-C in the terminal where you ran \naqueduct serve\n.)\n\n\nRouting and Another Route\n\n\nSo far, we've added a route that matches the constant string \n/questions\n. Routers can do more than match a constant string, they can also include path variables, optional path components, regular expression matching and the wildcard character. We'll add to the existing \n/questions\n route by allowing requests to get a specific question.\n\n\nIn \nquiz.dart\n, modify the code in the \nQuizRequestSink.setupRouter\n by adding \"/[:index]\" to the route.\n\n\n  \n@\noverride\n\n  \nvoid\n \nsetupRouter\n(\nRouter\n \nrouter\n)\n \n{\n\n    \nrouter\n\n        \n.\nroute\n(\n/questions/[:index]\n)\n\n        \n.\ngenerate\n(()\n \n=\n \nnew\n \nQuestionController\n());\n\n  \n}\n\n\n\n\n\n\nThe square brackets indicate that part of the path is optional, and the colon indicates that it is a path variable. A path variable matches anything. Therefore, this route will match if the path is \n/questions\n or \n/questions/2\n or \n/questions/foo\n.\n\n\nWhen using path variables, you may optionally restrict which values they match with a regular expression. The regular expression syntax goes into parentheses after the path variable name. Let's restrict the \nindex\n path variable to only numbers:\n\n\n  \n@\noverride\n\n  \nvoid\n \nsetupRouter\n(\nRouter\n \nrouter\n)\n \n{\n\n    \nrouter\n\n        \n.\nroute\n(\n/questions/[:index(\n\\\\\nd+)]\n)\n\n        \n.\ngenerate\n(()\n \n=\n \nnew\n \nQuestionController\n());\n\n  \n}\n\n\n\n\n\n\nNow, there are two types of requests that will get forwarded to a \nQuestionController\n - a request for all questions (\n/questions\n) and and a request for a specific question at some index (\n/questions/1\n). We need to add a new responder method to \nQuestionController\n that gets called when the latter request is made:\n\n\nclass\n \nQuestionController\n \nextends\n \nHTTPController\n \n{\n\n  \nvar\n \nquestions\n \n=\n \n[\n\n    \nHow much wood can a woodchuck chuck?\n,\n\n    \nWhat\ns the tallest mountain in the world?\n\n  \n];\n\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetAllQuestions\n()\n \nasync\n \n{\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nquestions\n);\n\n  \n}\n\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetQuestionAtIndex\n(\n@\nHTTPPath\n(\nindex\n)\n \nint\n \nindex\n)\n \nasync\n \n{\n\n    \nif\n \n(\nindex\n \n \n0\n \n||\n \nindex\n \n=\n \nquestions\n.\nlength\n)\n \n{\n\n      \nreturn\n \nnew\n \nResponse\n.\nnotFound\n();\n\n    \n}\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nquestions\n[\nindex\n]);\n  \n  \n}\n\n\n}\n\n\n\n\n\n\nReload the application by hitting Ctrl-C and then running \naqueduct serve\n again. In your browser, enter \nhttp://localhost:8081/questions\n and you'll get the list of questions. Then, enter \nhttp://localhost:8081/questions/0\n and you'll get the first question. If you enter an index not within the list of questions or something other than an integer, you'll get a 404.\n\n\nWhen a \nRequest\n is sent to an \nHTTPController\n, it evaluates the HTTP method of the request and matches it against every declared responder method. In this case, the \nHTTPController\n will have two possible choices: \ngetQuestions\n and \ngetQuestionAtIndex\n. From here, it looks at the parameters for each of the methods and the path variables in the \nRequest\n.\n\n\nParameters with \nHTTPPath\n metadata are used to match path variables from the \nRequest\n. If there are no path variables, the no-argument \ngetAllQuestions\n is invoked. If there is one \nHTTPPath\n argument \nand\n the name of the path variable is named \nindex\n (the \nString\n argument to \nHTTPPath\n), then \ngetQuestionAtIndex\n is called. The name of the path variable is defined by the name of the variable declared in \nRouter\n's \nroute\n method.\n\n\nIf neither of those scenarios are true, the \nHTTPController\n responds with 404 and doesn't call any of your responder methods. Because the route is declared to also evaluate a regular expression that restricts \nindex\n to only numeric values, non-numeric values in the \nindex\n portion of the route will also yield a 404. You can try that be hitting \nhttp://localhost:8081/questions/foo\n from your browser.\n\n\nThis HTTP method and path variable matching behavior is specific to \nHTTPController\n.\n\n\nThe More You Know: Multi-threading and Application State\n\n\nIn this simple exercise, we used a constant list of question as the source of data for the questions endpoint. For a simple getting-your-feet-wet demo, this is fine.\n\n\nHowever, in a real application, it is important that we don't keep any mutable state in a \nRequestSink\n or any \nRequestController\ns. This is for three reasons. First, it's just bad practice - web servers should be stateless. They are facilitators between a client and a repository of data, not a repository of data themselves. A repository of data is typically a database.\n\n\nSecond, the way Aqueduct applications are structured makes it really difficult to keep state. For example, \nHTTPController\n is instantiated each time a new request comes in. Any state they have is discarded after the request is finished processing. This is intentional - you won't run into an issue when scaling to multiple server instances in the future, because the code is already structured to be stateless.\n\n\nFinally, isolates. Aqueduct applications are set up to run on multiple isolates (the \n--isolates\n option for the in \naqueduct serve\n). An isolate is effectively a thread that shares no memory with other threads. If we were to keep track of state in some way, that state would not be reflected across all of the isolates running on this web server. So depending on which isolate grabbed a request, it may have different state than you might expect. Again, Aqueduct forces you into this model on purpose.\n\n\nIsolates will spread themselves out across CPUs on the host machine. Each isolate will have its own instance of your \nRequestSink\n subclass. Having multiple isolates running the same stateless web server on one machine allows for faster request handling. Each isolate also maintains its own set of resources, like database connections.\n\n\nNext Chapter: Writing Tests", 
            "title": "1. Getting Started"
        }, 
        {
            "location": "/tut/getting-started/#purpose", 
            "text": "The purpose of this tutorial series is to become familiar with how Aqueduct works. That means this tutorial will take a less efficient approach than a normal work flow so that the fundamentals are covered. For example, you will create a new project manually, but in a real work flow you would use the  aqueduct  command line tool.  This tutorial will use Atom for editing code. It has the lowest barrier to entry and is easy to install. For heavy duty work, we recommend IntelliJ IDEA Community Edition with the Dart plugin. The IntelliJ Dart plugin is an official plugin.", 
            "title": "Purpose"
        }, 
        {
            "location": "/tut/getting-started/#installing-dart", 
            "text": "If you have Homebrew installed, run these commands from terminal:  brew tap dart-lang/dart\nbrew install dart  If you don't have Homebrew installed or you are on another platform, visit  https://www.dartlang.org/install . It'll be quick, promise.  You should install Atom for editing your Dart code. You can get it from  https://atom.io . Once Atom is installed, install the 'dartlang' package from 'dart-atom' (not any of the other ones that have a similar name).", 
            "title": "Installing Dart"
        }, 
        {
            "location": "/tut/getting-started/#creating-a-project", 
            "text": "Create a new directory named  quiz  (ensure that it is lowercase). In this directory, create a new file named  pubspec.yaml . Dart uses this file to define your project and its dependencies (like iOS'  Info.plist  or Android's  AndroidManifest.xml ).  In the pubspec, enter the following markup:  name :   quiz  description :   A   quiz   web   server  version :   0.0 . 1  author :   Thor   Odinson   thor @ asgard . yg  environment : \n   sdk :   =1.20.0  2.0.0  dependencies : \n   aqueduct :   any     This pubspec declares an application named  quiz  (all Dart files, directories and application identifiers are snake_case), indicates that it can use a version of the Dart SDK between 1.20 and 2.0, and depends on the  aqueduct  package.  Next, you will fetch the dependencies of the  quiz  project - this will fetch the source for  aqueduct  from Dart's hosted package manager. If you are using Atom, you'll get a popup that tells you to do this and you can just click the button. (You may also right-click on file in Atom and select 'Pub Get'). If you aren't using Atom, from the command line, run the following from inside the  quiz  directory:  pub get  Dependencies get stored in the global cache directory,  ~/.pub-cache . Dependencies are referenced by files in your project's directory. These files are automatically generated by the previous command. You won't have to worry about that, though, since you'll never have to deal with it directly. Sometimes, it's just nice to know where things are. (There is one other file, called  pubspec.lock  that you do care about, but we'll chat about it later.)  With this dependency installed, your project can use Aqueduct. For this simple getting started guide, we won't structure a full project and just focus on getting an Aqueduct web server up and running. Create a new directory named  lib  and add a file to it named  quiz.dart . The project should now look like this on the filesystem:  quiz/\n  pubspec.yaml\n  pubspec.lock\n  lib/\n    quiz.dart  At the top of this file, import the Aqueduct package and the  async  standard library:  import   dart:async ;  import   package:aqueduct/aqueduct.dart ;", 
            "title": "Creating a Project"
        }, 
        {
            "location": "/tut/getting-started/#handling-requests", 
            "text": "The structure of Aqueduct is like most server-side frameworks: a new request comes in and gets routed to code that will respond to it. At its core, Aqueduct request handling is made up of three types of objects:  Request s,  Response s and  RequestController s. When an Aqueduct application receives an HTTP request, it creates a  Request  object. For every  Request , a  Response  must be created and sent back.  RequestController s handle the logic of taking a  Request s and creating a  Response s.  Examples of  RequestController  subclasses are  Router  and  HTTPController . A router figures out the right  RequestController  to handle a request by inspecting the request's path. An  HTTPController  takes a request - after it's been through a  Router  - and calls one its methods depending on the request's HTTP method (e.g., GET, POST). That method returns a  Response  and the request is completed.  The  quiz  application will have a  Router  that will send requests with the path  /questions  to an instance of  QuestionController .  QuestionController  is an  HTTPController  subclass that you will write - it will respond with a list of JSON questions. In  quiz.dart , create this new type:  class   QuestionController   extends   HTTPController   { \n   var   questions   =   [ \n     How much wood can a woodchuck chuck? , \n     What s the tallest mountain in the world? \n   ]; \n\n   @ httpGet \n   Future Response   getAllQuestions ()   async   { \n     return   new   Response . ok ( questions ); \n   }  }   The  QuestionController  class has a list of strings named  questions  and a method called  getAllQuestions . The metadata above the method -  httpGet  - is important. This metadata tells the  QuestionController  to invoke  getAllQuestions  when it receives a GET request. Likewise, if this metadata were  httpPut  or  httpPost , this controller would invoke this method for PUT or POST requests.  Methods declared in  HTTPController  subclasses with this metadata are called  responder methods , because they respond to HTTP requests. This is the primary job of an  HTTPController  - to map requests to a responder method based on their HTTP method. A responder method must return an instance of  Future Response . There are convenience constructors for common response status codes. In this example,  Response.ok  creates a  Response  with status code 200. The first argument to  Response.ok  is an object that will be encoded as the HTTP response body.  Now, we must create a  Router . A  Router  will receive all requests in an application. During initialization, a router is given  routes  - patterns that look for matches in the path of an HTTP request - and  RequestController s registered to receive requests for those routes. In your application, the  Router  will have instances of  QuestionController  registered for the route  /questions . All initialization for Aqueduct applications happens in a  RequestSink .  An application subclasses  RequestSink  and overrides a few of methods to handle initializing the application. The one required override is  setupRouter . This method, as the name suggests, is where you set up the application's routes and  RequestController s. The tools that run an Aqueduct application know how to find and create your  RequestSink  subclass in your application.  At the bottom of  quiz.dart , create a  RequestSink  subclass:  class   QuizRequestSink   extends   RequestSink   { \n   QuizRequestSink ( ApplicationConfiguration   options )   :   super   ( options ); \n\n   @ override \n   void   setupRouter ( Router   router )   { \n     router \n       . route ( /questions ) \n       . generate (()   =   new   QuestionController ()); \n   }  }   A  RequestSink  subclass must have a constructor that takes an  ApplicationConfiguration  instance and forward it on to its superclass' constructor. These values are provided by a configuration file and are typically used to configure a  RequestSink 's properties - like a database connection. Since the  quiz  app doesn't do much right now, we simply forward the configuration options on to the  super 's constructor as required.  Routes are registered through the  route  method. When a router matches the path of an HTTP request to one of its registered routes, the  Request  is sent to the next  RequestController  for that route. If no registered route matches the path of the request, the  Router  responds to the  Request  with a 404 status code and drops the  Request  event.  In this example, the \"next controller\" for  /questions  is added with the  generate  method. The  generate  method takes a closure that returns an instance of some  RequestController . Each time the router passes a  Request  a generator, the closure is called, creating a new instance of that  RequestController , and the  Request  is delivered to that new instance. Here, that new instance is an instance of our  QuestionController .  We'll get to the specifics of all of that in a moment, but we're at the point that we can run this web server, and that seems more exciting. First, activate the  aqueduct  executable:  pub global activate aqueduct  This command might tell you that  ~/.pub-cache/bin  (or some other directory) is not in your  PATH  variable. If that's the case, add it according to the instructions emitted by the command. (For example, if you are on macOS, you'd add  export PATH=$PATH:\"~/pub-cache/bin\"  to your  ~/.bash_profile  and then reload your terminal.)  In the project directory, run the following command to start the application:  aqueduct serve  In a browser, open the URL  http://localhost:8081/questions . You'll see the list of questions! (You can shut down the server by hitting Ctrl-C in the terminal where you ran  aqueduct serve .)", 
            "title": "Handling Requests"
        }, 
        {
            "location": "/tut/getting-started/#routing-and-another-route", 
            "text": "So far, we've added a route that matches the constant string  /questions . Routers can do more than match a constant string, they can also include path variables, optional path components, regular expression matching and the wildcard character. We'll add to the existing  /questions  route by allowing requests to get a specific question.  In  quiz.dart , modify the code in the  QuizRequestSink.setupRouter  by adding \"/[:index]\" to the route.     @ override \n   void   setupRouter ( Router   router )   { \n     router \n         . route ( /questions/[:index] ) \n         . generate (()   =   new   QuestionController ()); \n   }   The square brackets indicate that part of the path is optional, and the colon indicates that it is a path variable. A path variable matches anything. Therefore, this route will match if the path is  /questions  or  /questions/2  or  /questions/foo .  When using path variables, you may optionally restrict which values they match with a regular expression. The regular expression syntax goes into parentheses after the path variable name. Let's restrict the  index  path variable to only numbers:     @ override \n   void   setupRouter ( Router   router )   { \n     router \n         . route ( /questions/[:index( \\\\ d+)] ) \n         . generate (()   =   new   QuestionController ()); \n   }   Now, there are two types of requests that will get forwarded to a  QuestionController  - a request for all questions ( /questions ) and and a request for a specific question at some index ( /questions/1 ). We need to add a new responder method to  QuestionController  that gets called when the latter request is made:  class   QuestionController   extends   HTTPController   { \n   var   questions   =   [ \n     How much wood can a woodchuck chuck? , \n     What s the tallest mountain in the world? \n   ]; \n\n   @ httpGet \n   Future Response   getAllQuestions ()   async   { \n     return   new   Response . ok ( questions ); \n   } \n\n   @ httpGet \n   Future Response   getQuestionAtIndex ( @ HTTPPath ( index )   int   index )   async   { \n     if   ( index     0   ||   index   =   questions . length )   { \n       return   new   Response . notFound (); \n     } \n\n     return   new   Response . ok ( questions [ index ]);   \n   }  }   Reload the application by hitting Ctrl-C and then running  aqueduct serve  again. In your browser, enter  http://localhost:8081/questions  and you'll get the list of questions. Then, enter  http://localhost:8081/questions/0  and you'll get the first question. If you enter an index not within the list of questions or something other than an integer, you'll get a 404.  When a  Request  is sent to an  HTTPController , it evaluates the HTTP method of the request and matches it against every declared responder method. In this case, the  HTTPController  will have two possible choices:  getQuestions  and  getQuestionAtIndex . From here, it looks at the parameters for each of the methods and the path variables in the  Request .  Parameters with  HTTPPath  metadata are used to match path variables from the  Request . If there are no path variables, the no-argument  getAllQuestions  is invoked. If there is one  HTTPPath  argument  and  the name of the path variable is named  index  (the  String  argument to  HTTPPath ), then  getQuestionAtIndex  is called. The name of the path variable is defined by the name of the variable declared in  Router 's  route  method.  If neither of those scenarios are true, the  HTTPController  responds with 404 and doesn't call any of your responder methods. Because the route is declared to also evaluate a regular expression that restricts  index  to only numeric values, non-numeric values in the  index  portion of the route will also yield a 404. You can try that be hitting  http://localhost:8081/questions/foo  from your browser.  This HTTP method and path variable matching behavior is specific to  HTTPController .", 
            "title": "Routing and Another Route"
        }, 
        {
            "location": "/tut/getting-started/#the-more-you-know-multi-threading-and-application-state", 
            "text": "In this simple exercise, we used a constant list of question as the source of data for the questions endpoint. For a simple getting-your-feet-wet demo, this is fine.  However, in a real application, it is important that we don't keep any mutable state in a  RequestSink  or any  RequestController s. This is for three reasons. First, it's just bad practice - web servers should be stateless. They are facilitators between a client and a repository of data, not a repository of data themselves. A repository of data is typically a database.  Second, the way Aqueduct applications are structured makes it really difficult to keep state. For example,  HTTPController  is instantiated each time a new request comes in. Any state they have is discarded after the request is finished processing. This is intentional - you won't run into an issue when scaling to multiple server instances in the future, because the code is already structured to be stateless.  Finally, isolates. Aqueduct applications are set up to run on multiple isolates (the  --isolates  option for the in  aqueduct serve ). An isolate is effectively a thread that shares no memory with other threads. If we were to keep track of state in some way, that state would not be reflected across all of the isolates running on this web server. So depending on which isolate grabbed a request, it may have different state than you might expect. Again, Aqueduct forces you into this model on purpose.  Isolates will spread themselves out across CPUs on the host machine. Each isolate will have its own instance of your  RequestSink  subclass. Having multiple isolates running the same stateless web server on one machine allows for faster request handling. Each isolate also maintains its own set of resources, like database connections.", 
            "title": "The More You Know: Multi-threading and Application State"
        }, 
        {
            "location": "/tut/getting-started/#next-chapter-writing-tests", 
            "text": "", 
            "title": "Next Chapter: Writing Tests"
        }, 
        {
            "location": "/tut/writing-tests/", 
            "text": "Testing Aqueduct Applications\n\n\nOne of the core principles of Aqueduct is efficient testing. While opening up your browser and typing in a URL can verify the code you just wrote succeeds, it's not a very reliable way of testing software. We'll also run into some dead-ends when we test HTTP requests that use an HTTP method other than GET. Therefore, there are some helpful utilities for writing tests built into Aqueduct.\n\n\n(As a note, testing Dart in Atom is not well supported - yet. Once you get past this tutorial, it is highly recommended you download IntelliJ IDEA Community Edition for better test support. Most importantly, Aqueduct's style of testing requires that test files are not run in parallel - and Atom only runs them in parallel. In the meantime, you can use the command line and run the tests serially using the command \npub run test -j 1\n.)\n\n\nIn general, testing in Dart is simple: in a file that ends with \n_test.dart\n, you write a \nmain\n function and use the \ntest\n function register a test. Each test is a closure that runs some code and has expectations. For example, this code would test that 1 + 1 = 2:\n\n\nimport\n \npackage:test/test.dart\n;\n\n\n\nvoid\n \nmain\n()\n \n{\n\n  \ntest\n(\n1+1 = 2\n,\n \n()\n \n{\n\n    \nexpect\n(\n1\n \n+\n \n1\n,\n \nequals\n(\n2\n));\n\n  \n});\n\n\n}\n\n\n\n\n\n\nTests are made possible by the \ntest\n package which you'll need to claim as a dependency. In \nquiz/pubspec.yaml\n, add it as a development dependency by adding the following two lines to the end of the file:\n\n\ndev_dependencies\n:\n\n  \ntest\n:\n \nany\n\n\n\n\n\n\nNow, get the dependencies again by right-clicking on any project file and selecting 'Pub Get'. (Or run \npub get\n from the command line in the \nquiz\n directory.)\n\n\nRestructuring quiz\n\n\nLast chapter, we just threw everything in a single file to get started. We should really get things structured a bit more. The suggested approach is to separate \nRequestController\ns into their own files. These files should live in \nlib/controller\n. The \nRequestSink\n subclass should be in its own file, too, but directly under \nlib\n.\n\n\nCreate a new directory, \nlib/controller\n and add a new file \nquestion_controller.dart\n to it. Create a new file in \nlib\n named \nsink.dart\n.\n\n\nNow, we'll move some code around. The full contents of each file will be listed here to make sure nothing gets lost. There are three total source files in the project. Change the file \nquiz.dart\n to only contain:\n\n\nexport\n \ndart:async\n;\n\n\nexport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\n\nexport\n \nsink.dart\n;\n\n\n\n\n\n\nMove the implementation of \nQuestionController\n to \ncontroller/question_controller.dart\n and import the top-level file:\n\n\nimport\n \npackage:quiz/quiz.dart\n;\n\n\n\nclass\n \nQuestionController\n \nextends\n \nHTTPController\n \n{\n\n  \nvar\n \nquestions\n \n=\n \n[\n\n    \nHow much wood can a woodchuck chuck?\n,\n\n    \nWhat\ns the tallest mountain in the world?\n\n  \n];\n\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetAllQuestions\n()\n \nasync\n \n{\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nquestions\n);\n\n  \n}\n\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetQuestionAtIndex\n(\n@\nHTTPPath\n(\nindex\n)\n \nint\n \nindex\n)\n \nasync\n \n{\n\n    \nif\n \n(\nindex\n \n \n0\n \n||\n \nindex\n \n=\n \nquestions\n.\nlength\n)\n \n{\n\n      \nreturn\n \nnew\n \nResponse\n.\nnotFound\n();\n\n    \n}\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nquestions\n[\nindex\n]);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nMove \nQuizRequestSink\n to \nsink.dart\n:\n\n\nimport\n \npackage:quiz/quiz.dart\n;\n\n\nimport\n \ncontroller/question_controller.dart\n;\n\n\n\nclass\n \nQuizRequestSink\n \nextends\n \nRequestSink\n \n{\n\n  \nQuizRequestSink\n(\nApplicationConfiguration\n \noptions\n)\n \n:\n \nsuper\n \n(\noptions\n);\n\n\n  \n@\noverride\n\n  \nvoid\n \nsetupRouter\n(\nRouter\n \nrouter\n)\n \n{\n\n    \nrouter\n\n      \n.\nroute\n(\n/questions/[:index(\n\\\\\nd+)]\n)\n\n      \n.\ngenerate\n(()\n \n=\n \nnew\n \nQuestionController\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIt is important that there is a top-level library file (\nquiz.dart\n) that exports the file that contains the \nRequestSink\n subclass, otherwise, the \naqueduct\n executable won't be able to find it and start your application. Files that declare \nRequestController\n subclasses should be imported in \nsink.dart\n, since that's the only place they'll get used.\n\n\nAdditionally, the top-level library file \nmust\n be named the same as the project - here, \nquiz.dart\n. The name of the project is is \nname\n key in \npubspec.yaml\n.\n\n\nYou can double-check that your changes worked by running \naqueduct serve\n from the project directory. The full project structure should be:\n\n\npubspec.yaml\nlib/\n  quiz.dart\n  sink.dart\n  controller/\n    question_controller.dart\n\n\n\n\n\nWriting Tests\n\n\nWe'd like to ensure that when we hit the \n/questions\n endpoint, we get a response with questions. What does that mean? Well, that is up to us. But, let's say that 'questions' means 'a list of strings that all end in a question mark'.\n\n\nIn Dart, tests are stored in a top-level \ntest\n directory. Create that directory in \nquiz\n. Then, add a new file to it named \nquestion_controller_test.dart\n. (Tests must end in \n_test.dart\n and live in the \ntest\n directory for the tools to find them without you having to specify their path.) In this file, import the following:\n\n\nimport\n \npackage:quiz/quiz.dart\n;\n\n\nimport\n \npackage:test/test.dart\n;\n\n\nimport\n \npackage:aqueduct/test.dart\n;\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\n\n\n\n\nThe way Aqueduct accomplishes testing is by starting an entire application, running the tests, then stopping the application. The library \naqueduct/test\n has helpful utilities for testing Aqueduct applications. Declare a \nsetUp\n and \ntearDown\n method to run before and after each test. After the import statements, add a \nmain\n function with the appropriate setup and teardown code:\n\n\nvoid\n \nmain\n()\n \n{\n\n  \nvar\n \napp\n \n=\n \nnew\n \nApplication\nQuizRequestSink\n();\n\n  \nTestClient\n \nclient\n;\n\n\n  \nsetUp\n(()\n \nasync\n \n{\n\n    \nawait\n \napp\n.\nstart\n(\nrunOnMainIsolate:\n \ntrue\n);\n\n    \nclient\n \n=\n \nnew\n \nTestClient\n(\napp\n);\n\n  \n});\n\n\n  \ntearDown\n(()\n \nasync\n \n{\n\n    \nawait\n \napp\n.\nstop\n();\n\n  \n});\n\n\n}\n\n\n\n\n\n\nThe \nApplication\n type has a type argument that must be a subclass of \nRequestSink\n - specifically, the \nRequestSink\n of your project. When running the application through \naqueduct serve\n, an instance of \nApplication\nT\n is created for you. Running tests, you create it and start it yourself in \nsetup\n and stop it \ntearDown\n. (In order for your tests to shut down properly, the application must be stopped in \ntearDown\n.)\n\n\nNotice also that \nstart\n takes an optional argument, \nrunOnMainIsolate\n. When this argument is true, an instance of your \nRequestSink\n is created on the main isolate and requests are received on the same isolate running the tests. This behavior is different than when using \naqueduct serve\n, where one or more additional isolates are created and each has an instance of the \nRequestSink\n that is accepting requests.\n\n\nDuring testing, running the application on the main isolate is very important. We'll see why a bit later, but the general idea is that your tests have access to the properties of a \nRequestSink\n if and only if it is running on the main isolate.\n\n\nNow, we need to add a test to verify that hitting the \n/questions\n endpoint does return our definition of 'questions'. A \nTestClient\n will execute HTTP requests on your behalf, and is configured to point at the running application. Testing an Aqueduct application is generally two steps: make a request and then verify you got the response you wanted. Let's create a new test and do the first step. Near the end of main, add the following test:\n\n\nvoid\n \nmain\n()\n \n{\n\n  \n...\n\n\n  \ntest\n(\n/questions returns list of questions\n,\n \n()\n \nasync\n \n{\n\n    \nvar\n \nresponse\n \n=\n \nawait\n \nclient\n.\nrequest\n(\n/questions\n).\nget\n();\n\n    \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \neveryElement\n(\nendsWith\n(\n?\n))));\n\n  \n});\n\n\n}\n\n\n\n\n\n\nThis test executes the request \nGET http://localhost:8081/questions\n and ensures that the response's status code is 200 and the body is a list of strings that all end in '?'.\n\n\nThe value of \nresponse\n in the previous code snippet is an instance of \nTestResponse\n. Dart tests use the Hamcrest style matchers in their expectations. There are built-in matchers in Aqueduct for setting up and matching expectations on \nTestResponse\n instances. For example, if we wanted to verify that we got a 404 back, we'd do this:\n\n\n  \nexpect\n(\nresponse\n,\n \nhasStatus\n(\n404\n));\n\n\n\n\n\n\nNow, make sure you shut down your application if you were running it from a previous chapter. To run a test file in Atom, you can do two things: manually hit Cmd-Shift-P and type in run test or use the keyboard shortcut, Cmd-Option-Ctrl-T. The test results will appear in a panel. (Make sure you save your test file first!  Atom currently isn't great at displaying test results. A more powerful option is IntelliJ IDEA Community Edition, but Atom is a lot friendlier for a tutorial.)\n\n\nYou should see the string 'All tests passed!' in your test results panel.\n\n\nThere's one little issue here: the \neveryElement\n matcher ensures each element passes the inner matcher (\nendsWith\n). However, if this response returned an empty list of questions, the inner matcher would never run and the test would pass. Let's also verify that there is at least one question, too:\n\n\ntest\n(\n/questions returns list of questions\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \nclient\n.\nrequest\n(\n/questions\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \neveryElement\n(\nendsWith\n(\n?\n))));\n\n  \nexpect\n(\nresponse\n.\ndecodedBody\n,\n \nhasLength\n(\ngreaterThan\n(\n0\n)));\n\n\n});\n\n\n\n\n\n\nWhat sort of wizardry is this?\n\n\nThe \nhasResponse\n matcher takes two arguments: a status code and a 'body matcher'. If the response's status code matches the first argument of \nhasResponse\n - 200 in this case - the matcher will move on to the body. The response's HTTP body will be decoded according to its \nContent-Type\n header. In this example, the body is a JSON list of strings, and therefore it will be decoded into a Dart list of strings.\n\n\nNext, the decoded body is matched against the body matcher. There are a lot of built-in matchers - see the documentation for the test package \nhere\n - and \neveryElement\n and \nendsWith\n are two examples. \neveryElement\n verifies that the decoded body is a list, and then runs the \nendsWith\n matcher on every string in that list. Since every string ends with ?, this matcher as a whole will succeed.\n\n\nLet's write two more tests - first, that getting a specific question returns a question (a string with a question mark at the end) and then a test that ensures a question outside of the range of questions will return a 404. Add the following two tests inside the main function:\n\n\ntest\n(\n/questions/index returns a single question\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \nclient\n.\nrequest\n(\n/questions/1\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \nendsWith\n(\n?\n)));\n\n\n});\n\n\n\ntest\n(\n/questions/index out of range returns 404\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \nclient\n.\nrequest\n(\n/questions/100\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasStatus\n(\n404\n));\n\n\n});\n\n\n\n\n\n\nRun the tests against, and they should all pass.\n\n\nNext Chapter: Executing Database Queries", 
            "title": "2. Writing Tests"
        }, 
        {
            "location": "/tut/writing-tests/#testing-aqueduct-applications", 
            "text": "One of the core principles of Aqueduct is efficient testing. While opening up your browser and typing in a URL can verify the code you just wrote succeeds, it's not a very reliable way of testing software. We'll also run into some dead-ends when we test HTTP requests that use an HTTP method other than GET. Therefore, there are some helpful utilities for writing tests built into Aqueduct.  (As a note, testing Dart in Atom is not well supported - yet. Once you get past this tutorial, it is highly recommended you download IntelliJ IDEA Community Edition for better test support. Most importantly, Aqueduct's style of testing requires that test files are not run in parallel - and Atom only runs them in parallel. In the meantime, you can use the command line and run the tests serially using the command  pub run test -j 1 .)  In general, testing in Dart is simple: in a file that ends with  _test.dart , you write a  main  function and use the  test  function register a test. Each test is a closure that runs some code and has expectations. For example, this code would test that 1 + 1 = 2:  import   package:test/test.dart ;  void   main ()   { \n   test ( 1+1 = 2 ,   ()   { \n     expect ( 1   +   1 ,   equals ( 2 )); \n   });  }   Tests are made possible by the  test  package which you'll need to claim as a dependency. In  quiz/pubspec.yaml , add it as a development dependency by adding the following two lines to the end of the file:  dev_dependencies : \n   test :   any   Now, get the dependencies again by right-clicking on any project file and selecting 'Pub Get'. (Or run  pub get  from the command line in the  quiz  directory.)", 
            "title": "Testing Aqueduct Applications"
        }, 
        {
            "location": "/tut/writing-tests/#restructuring-quiz", 
            "text": "Last chapter, we just threw everything in a single file to get started. We should really get things structured a bit more. The suggested approach is to separate  RequestController s into their own files. These files should live in  lib/controller . The  RequestSink  subclass should be in its own file, too, but directly under  lib .  Create a new directory,  lib/controller  and add a new file  question_controller.dart  to it. Create a new file in  lib  named  sink.dart .  Now, we'll move some code around. The full contents of each file will be listed here to make sure nothing gets lost. There are three total source files in the project. Change the file  quiz.dart  to only contain:  export   dart:async ;  export   package:aqueduct/aqueduct.dart ;  export   sink.dart ;   Move the implementation of  QuestionController  to  controller/question_controller.dart  and import the top-level file:  import   package:quiz/quiz.dart ;  class   QuestionController   extends   HTTPController   { \n   var   questions   =   [ \n     How much wood can a woodchuck chuck? , \n     What s the tallest mountain in the world? \n   ]; \n\n   @ httpGet \n   Future Response   getAllQuestions ()   async   { \n     return   new   Response . ok ( questions ); \n   } \n\n   @ httpGet \n   Future Response   getQuestionAtIndex ( @ HTTPPath ( index )   int   index )   async   { \n     if   ( index     0   ||   index   =   questions . length )   { \n       return   new   Response . notFound (); \n     } \n\n     return   new   Response . ok ( questions [ index ]); \n   }  }   Move  QuizRequestSink  to  sink.dart :  import   package:quiz/quiz.dart ;  import   controller/question_controller.dart ;  class   QuizRequestSink   extends   RequestSink   { \n   QuizRequestSink ( ApplicationConfiguration   options )   :   super   ( options ); \n\n   @ override \n   void   setupRouter ( Router   router )   { \n     router \n       . route ( /questions/[:index( \\\\ d+)] ) \n       . generate (()   =   new   QuestionController ()); \n   }  }   It is important that there is a top-level library file ( quiz.dart ) that exports the file that contains the  RequestSink  subclass, otherwise, the  aqueduct  executable won't be able to find it and start your application. Files that declare  RequestController  subclasses should be imported in  sink.dart , since that's the only place they'll get used.  Additionally, the top-level library file  must  be named the same as the project - here,  quiz.dart . The name of the project is is  name  key in  pubspec.yaml .  You can double-check that your changes worked by running  aqueduct serve  from the project directory. The full project structure should be:  pubspec.yaml\nlib/\n  quiz.dart\n  sink.dart\n  controller/\n    question_controller.dart", 
            "title": "Restructuring quiz"
        }, 
        {
            "location": "/tut/writing-tests/#writing-tests", 
            "text": "We'd like to ensure that when we hit the  /questions  endpoint, we get a response with questions. What does that mean? Well, that is up to us. But, let's say that 'questions' means 'a list of strings that all end in a question mark'.  In Dart, tests are stored in a top-level  test  directory. Create that directory in  quiz . Then, add a new file to it named  question_controller_test.dart . (Tests must end in  _test.dart  and live in the  test  directory for the tools to find them without you having to specify their path.) In this file, import the following:  import   package:quiz/quiz.dart ;  import   package:test/test.dart ;  import   package:aqueduct/test.dart ;  import   package:aqueduct/aqueduct.dart ;   The way Aqueduct accomplishes testing is by starting an entire application, running the tests, then stopping the application. The library  aqueduct/test  has helpful utilities for testing Aqueduct applications. Declare a  setUp  and  tearDown  method to run before and after each test. After the import statements, add a  main  function with the appropriate setup and teardown code:  void   main ()   { \n   var   app   =   new   Application QuizRequestSink (); \n   TestClient   client ; \n\n   setUp (()   async   { \n     await   app . start ( runOnMainIsolate:   true ); \n     client   =   new   TestClient ( app ); \n   }); \n\n   tearDown (()   async   { \n     await   app . stop (); \n   });  }   The  Application  type has a type argument that must be a subclass of  RequestSink  - specifically, the  RequestSink  of your project. When running the application through  aqueduct serve , an instance of  Application T  is created for you. Running tests, you create it and start it yourself in  setup  and stop it  tearDown . (In order for your tests to shut down properly, the application must be stopped in  tearDown .)  Notice also that  start  takes an optional argument,  runOnMainIsolate . When this argument is true, an instance of your  RequestSink  is created on the main isolate and requests are received on the same isolate running the tests. This behavior is different than when using  aqueduct serve , where one or more additional isolates are created and each has an instance of the  RequestSink  that is accepting requests.  During testing, running the application on the main isolate is very important. We'll see why a bit later, but the general idea is that your tests have access to the properties of a  RequestSink  if and only if it is running on the main isolate.  Now, we need to add a test to verify that hitting the  /questions  endpoint does return our definition of 'questions'. A  TestClient  will execute HTTP requests on your behalf, and is configured to point at the running application. Testing an Aqueduct application is generally two steps: make a request and then verify you got the response you wanted. Let's create a new test and do the first step. Near the end of main, add the following test:  void   main ()   { \n   ... \n\n   test ( /questions returns list of questions ,   ()   async   { \n     var   response   =   await   client . request ( /questions ). get (); \n     expect ( response ,   hasResponse ( 200 ,   everyElement ( endsWith ( ? )))); \n   });  }   This test executes the request  GET http://localhost:8081/questions  and ensures that the response's status code is 200 and the body is a list of strings that all end in '?'.  The value of  response  in the previous code snippet is an instance of  TestResponse . Dart tests use the Hamcrest style matchers in their expectations. There are built-in matchers in Aqueduct for setting up and matching expectations on  TestResponse  instances. For example, if we wanted to verify that we got a 404 back, we'd do this:     expect ( response ,   hasStatus ( 404 ));   Now, make sure you shut down your application if you were running it from a previous chapter. To run a test file in Atom, you can do two things: manually hit Cmd-Shift-P and type in run test or use the keyboard shortcut, Cmd-Option-Ctrl-T. The test results will appear in a panel. (Make sure you save your test file first!  Atom currently isn't great at displaying test results. A more powerful option is IntelliJ IDEA Community Edition, but Atom is a lot friendlier for a tutorial.)  You should see the string 'All tests passed!' in your test results panel.  There's one little issue here: the  everyElement  matcher ensures each element passes the inner matcher ( endsWith ). However, if this response returned an empty list of questions, the inner matcher would never run and the test would pass. Let's also verify that there is at least one question, too:  test ( /questions returns list of questions ,   ()   async   { \n   var   response   =   await   client . request ( /questions ). get (); \n   expect ( response ,   hasResponse ( 200 ,   everyElement ( endsWith ( ? )))); \n   expect ( response . decodedBody ,   hasLength ( greaterThan ( 0 )));  });", 
            "title": "Writing Tests"
        }, 
        {
            "location": "/tut/writing-tests/#what-sort-of-wizardry-is-this", 
            "text": "The  hasResponse  matcher takes two arguments: a status code and a 'body matcher'. If the response's status code matches the first argument of  hasResponse  - 200 in this case - the matcher will move on to the body. The response's HTTP body will be decoded according to its  Content-Type  header. In this example, the body is a JSON list of strings, and therefore it will be decoded into a Dart list of strings.  Next, the decoded body is matched against the body matcher. There are a lot of built-in matchers - see the documentation for the test package  here  - and  everyElement  and  endsWith  are two examples.  everyElement  verifies that the decoded body is a list, and then runs the  endsWith  matcher on every string in that list. Since every string ends with ?, this matcher as a whole will succeed.  Let's write two more tests - first, that getting a specific question returns a question (a string with a question mark at the end) and then a test that ensures a question outside of the range of questions will return a 404. Add the following two tests inside the main function:  test ( /questions/index returns a single question ,   ()   async   { \n   var   response   =   await   client . request ( /questions/1 ). get (); \n   expect ( response ,   hasResponse ( 200 ,   endsWith ( ? )));  });  test ( /questions/index out of range returns 404 ,   ()   async   { \n   var   response   =   await   client . request ( /questions/100 ). get (); \n   expect ( response ,   hasStatus ( 404 ));  });   Run the tests against, and they should all pass.", 
            "title": "What sort of wizardry is this?"
        }, 
        {
            "location": "/tut/writing-tests/#next-chapter-executing-database-queries", 
            "text": "", 
            "title": "Next Chapter: Executing Database Queries"
        }, 
        {
            "location": "/tut/executing-queries/", 
            "text": "Executing Queries\n\n\nNow that you've seen how to route HTTP requests and respond to them, we'll do something useful with those requests: like interacting with a database. We will continue to build on the last chapter project, \nquiz\n, by storing the questions in a database and retrieving them from the database.\n\n\nBuilding a Data Model\n\n\nAqueduct has a built-in ORM (some of which is modeled after the iOS/macOS Core Data framework). Like all ORMs, rows of a database are mapped to objects. In Aqueduct, these objects are of type \nManagedObject\nT\n. Let's define a managed object that represents a 'question'. Create a new directory in \nlib\n named \nmodel\n, and then add a new file to it named \nquestion.dart\n (thus, \nlib/model/question.dart\n).\n\n\nA managed object is a subclass of \nManagedObject\nT\n, where \nT\n is a \npersistent type\n. A persistent type is a simple Dart class that maps to a database table. Each of its properties maps to a column in that table. By convention, but not required, persistent types are prefixed with '_'. In \nquestion.dart\n, let's define a persistent type for a question:\n\n\nimport\n \npackage:quiz/quiz.dart\n;\n\n\n\nclass\n \n_Question\n \n{\n\n  \n@\nManagedColumnAttributes\n(\nprimaryKey:\n \ntrue\n,\n \ndatabaseType:\n \nPropertyType\n.\nbigInteger\n,\n \nautoincrement:\n \ntrue\n)\n\n  \nint\n \nindex\n;\n\n\n  \nString\n \ndescription\n;\n\n\n}\n\n\n\n\n\n\nEach property in a persistent type can be marked with \nManagedColumnAttributes\n metadata that defines how the underlying database column is defined. The \nindex\n property of \n_Question\n is the primary key column and a \"big\" integer. The autoincrement flag lets the database generate this value when a new question is inserted. Because it is quite common to have a primary key that is a big integer and autoincrementing, there is shorthand for it. Replace the metadata with the \nmanagedPrimaryKey\n shorthand:\n\n\nclass\n \n_Question\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nindex\n;\n\n\n  \nString\n \ndescription\n;\n\n\n}\n\n\n\n\n\n\nAll managed objects must have exactly one property with \nprimaryKey\n set to true.\n Other interesting flags for \nManagedColumnAttributes\n are \nindexed\n, \nnullable\n and \ndefaultValue\n. If a property does not have \nManagedColumnAttributes\n, it is still a persistent property. All of the , it's just a normal column and its database type is inferred from its Dart type. Supported Dart types are \nint\n, \ndouble\n, \nString\n, \nDateTime\n and \nbool\n.\n\n\nOnce a persistent type has been defined, you must also declare a corresponding subclass of \nManagedObject\n. At the top of \nquestion.dart\n, but underneath the import, add the following:\n\n\nimport\n \npackage:quiz/quiz.dart\n;\n\n\n\nclass\n \nQuestion\n \nextends\n \nManagedObject\n_Question\n \nimplements\n \n_Question\n \n{}\n\n\nclass\n \n_Question\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nindex\n;\n\n\n  \nString\n \ndescription\n;\n\n\n}\n\n\n\n\n\n\nThis dual-class setup is important and necessary for using Aqueduct's ORM. The persistent type - the plain Dart class that starts with an underscore - represents a database table. Each property of the persistent type is a column in that database table. The name of the database table matches the name of the class (here, \n_Question\n).\n\n\nThe \nManagedObject\n subclass is the type you work with in your code. Its associated persistent type appears twice in its declaration: as the type argument to \nManagedObject\n (\nManagedObject\n_Question\n) and as an interface (\nimplements _Question\n). A \nManagedObject\n may have properties and methods of its own, but those are \nnot\n backed by a database column.\n\n\nImporting ManagedObjects\n\n\nAs your code progresses, those \nManagedObject\nT\ns will have relationships with other \nManagedObject\nT\ns and be used in your request handling code. Additionally, the tools that generate database schemas and 'compile' the declarations of \nManagedObject\nT\n also need to see the definitions. Therefore, \nManagedObject\n declarations must be visible to the rest of your application.\n\n\nThe best practice is to declare each \nManagedObject\nT\n in its own file and create a file that exports all \nManagedObject\nT\ns. Create a new file in \nlib\n named \nmodel.dart\n. In this file, export \nmodel/question.dart\n:\n\n\nexport\n \nmodel/question.dart\n;\n\n\n\n\n\n\nThe \nmodel.dart\n file exports all of your \nManagedObject\n declarations. Now, to make all of your managed objects visible, export \nmodel.dart\n in \nquiz.dart\n:\n\n\nexport\n \ndart:async\n;\n\n\nexport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\n\nexport\n \nsink.dart\n;\n\n\n\n// Add this export:\n\n\nexport\n \nmodel.dart\n;\n\n\n\n\n\n\nNow, every file in your application that import the application package will see the managed object declarations - and more importantly, the tools will see those declarations, too.\n\n\nDefining a Context\n\n\nIn order for an application to work with a database, it needs a \nManagedContext\n. A \nManagedContext\n is the facilitator between your code and a database. It is made up of two components, a \nManagedDataModel\n (the thing that keeps track of all of your managed object types) and \nPersistentStore\n (the thing that talks to the database). These objects are set up in a \nRequestSink\n. In \nsink.dart\n, add the following code to the constructor for \nQuizRequestSink\n and define a new property:\n\n\nclass\n \nQuizRequestSink\n \nextends\n \nRequestSink\n \n{\n\n  \nQuizRequestSink\n(\nMap\nString\n,\n \ndynamic\n \noptions\n)\n \n:\n \nsuper\n(\noptions\n)\n \n{\n\n    \nvar\n \ndataModel\n \n=\n \nnew\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nvar\n \npersistentStore\n \n=\n \nnew\n \nPostgreSQLPersistentStore\n.\nfromConnectionInfo\n(\n\n      \ndart\n,\n \ndart\n,\n \nlocalhost\n,\n \n5432\n,\n \ndart_test\n);\n\n    \ncontext\n \n=\n \nnew\n \nManagedContext\n(\ndataModel\n,\n \npersistentStore\n);\n\n  \n}\n\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n...\n\n\n\n\n\n\n(In the future, we'll allow this information to be passed from a configuration file. But for now, we'll do it manually.)\n\n\nA \nManagedDataModel\n is initialized with its named constructor \nfromCurrentMirrorSystem\n. This constructor uses reflection to find every \nManagedObject\nT\n subclass in your application and compile a data model from them. (This is why it is important to export managed objects the way it was done in the previous section.)\n\n\nThe persistent store is a specific implementation of a persistent store, \nPostgreSQLPersistentStore\n. It is initialized with information necessary to connect to a database. A \nManagedContext\n simply ties those two things together.\n\n\n(By the way, the interface for \nPersistentStore\n can be implemented for different flavors of SQL and even non-SQL databases. We just so happen to prefer PostgreSQL, so we've already built that one.)\n\n\nWhen a \nManagedContext\n is created, it becomes the \ndefault context\n of your application. When we execute database queries, they run on the default context (by default). If we have multiple databases, we can create more \nManagedContext\ns and pass them around to make sure we hit the right database. For now, we can ignore this, just know that it exists.\n\n\nExecuting Queries\n\n\nNow that we have a context - which can establish a connection to a database, talk to the database and map rows to managed objects - we can execute queries in our \nRequestController\ns. In \nquestion_controller.dart\n, replace the code for \ngetAllQuestions\n (we'll work on \ngetQuestionAtIndex\n soon):\n\n\nclass\n \nQuestionController\n \nextends\n \nHttpController\n \n{\n\n  \nvar\n \nquestions\n \n=\n \n[\n\n    \nHow much wood can a woodchuck chuck?\n,\n\n    \nWhat\ns the tallest mountain in the world?\n\n  \n];\n\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetAllQuestions\n()\n \nasync\n \n{\n\n    \nvar\n \nquestionQuery\n \n=\n \nnew\n \nQuery\nQuestion\n();\n\n    \nvar\n \ndatabaseQuestions\n \n=\n \nawait\n \nquestionQuery\n.\nfetch\n();\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\ndatabaseQuestions\n);\n\n  \n}\n\n\n\n...\n\n\n\n\n\n\nWhen this responder method is executed, it'll create a new \nQuery\nT\n for \nQuestion\n (as indicated by the type parameter). A query has a handful of execution methods on it - \nfetch\n, \nfetchOne\n, \ninsert\n, \nupdate\n, \nupdateOne\n and \ndelete\n. By executing a \nfetch\n on a vanilla \nQuery\nQuestion\n, this will return a list of \nQuestion\ns, one for each row in the database's question table.\n\n\nNow, we need an actual database to fetch data from.\n\n\nConfiguring a Database\n\n\nAs we've mentioned a few times, a key facet to Aqueduct is efficient automated testing. The scheme for testing is to create a 'test' database that all of your Aqueduct projects run against. When you run tests against that database, the tests create \ntemporary\n tables prior to executing. The good news is that the \nManagedDataModel\n in your application can drive this table creation, so you don't need to do anything special. The tests are run against the current version of the schema defined by your code.\n\n\nTherefore, on any machine you're going to test on, you need to install PostgreSQL and configure a test database. You'll only need to set this up once on - all Aqueduct project tests run against the same database.\n\n\nOn macOS, the best way to do this locally is download \nPostgres.app\n. This has a self-contained instance of Postgres that you start by opening up the application itself. Download this application and run it.\n\n\nOnce running, run the command \naqueduct setup\n from anywhere. It will give you some additional instructions to follow to make sure everything is OK. It just runs the following SQL:\n\n\ncreate\n \ndatabase\n \ndart_test\n;\n\n\ncreate\n \nuser\n \ndart\n \nwith\n \ncreatedb\n;\n\n\nalter\n \nuser\n \ndart\n \nwith\n \npassword\n \ndart\n;\n\n\ngrant\n \nall\n \non\n \ndatabase\n \ndart_test\n \nto\n \ndart\n;\n\n\n\n\n\n\nIf you are on another operating system or this command fails for your installation of PostgreSQL, you may run the above commands through the \npsql\n command-line utility.\n\n\nYou'll notice in your \nRequestSink\n, the configuration parameters for the \nPostgreSQLPersistentStore\n match those that you have just added to your local instance of Postgres, so your application will run against that instance. However, if you were to run your code now, the table backing \nQuestion\ns would not exist. When running tests, we need to create a temporary table for \nQuestion\ns before the tests start. Go to the \nsetUp\n method in \nquestion_controller_test.dart\n, and enter the following code after the application is started:\n\n\n  \nsetUp\n(()\n \nasync\n \n{\n\n    \nawait\n \napp\n.\nstart\n(\nrunOnMainIsolate:\n \ntrue\n);\n\n    \nclient\n \n=\n \nnew\n \nTestClient\n(\napp\n);\n\n\n    \nvar\n \nctx\n \n=\n \nManagedContext\n.\ndefaultContext\n;\n\n    \nvar\n \nbuilder\n \n=\n \nnew\n \nSchemaBuilder\n.\ntoSchema\n(\n\n      \nctx\n.\npersistentStore\n,\n \nnew\n \nSchema\n.\nfromDataModel\n(\nctx\n.\ndataModel\n),\n \nisTemporary:\n \ntrue\n);\n\n\n    \nfor\n \n(\nvar\n \ncmd\n \nin\n \nbuilder\n.\ncommands\n)\n \n{\n\n      \nawait\n \nctx\n.\npersistentStore\n.\nexecute\n(\ncmd\n);\n\n    \n}\n\n  \n});\n\n\n\n\n\n\nAfter the application is started, we know that it creates a \nManagedContext\n in the constructor of \nQuizRequestSink\n. The default context can be accessed through \nManagedContext.defaultContext\n. We also know that this context has a \nManagedDataModel\n containing \nQuestion\n. The class \nSchemaBuilder\n will create a series of SQL commands from the data model, translated by the \nPostgreSQLPersistentStore\n. (Note that the \nisTemporary\n parameter makes all of the tables temporary and therefore they disappear when the database connection in the context's persistent store closes. This prevents changes to the database from leaking into subsequent tests.)\n\n\nThe database connection is automatically closed when the tests complete by the existing \ntearDown\n method that stops the application. Note that when the databsae connection is closed, the tables and data in the database created by this test are discarded.\n\n\nWe now need questions in the database (you can run your tests and see the they fail because there are no questions). Let's first seed the database with some questions using an insert query at the end of \nsetUp\n.\n\n\n  \nsetUp\n(()\n \nasync\n \n{\n\n    \nawait\n \napp\n.\nstart\n(\nrunOnMainIsolate:\n \ntrue\n);\n\n    \nclient\n \n=\n \nnew\n \nTestClient\n(\napp\n);\n\n\n    \nvar\n \nctx\n \n=\n \nManagedContext\n.\ndefaultContext\n;\n\n    \nvar\n \nbuilder\n \n=\n \nnew\n \nSchemaBuilder\n.\ntoSchema\n(\nctx\n.\npersistentStore\n,\n \nnew\n \nSchema\n.\nfromDataModel\n(\nctx\n.\ndataModel\n),\n \nisTemporary:\n \ntrue\n);\n\n\n    \nfor\n \n(\nvar\n \ncmd\n \nin\n \nbuilder\n.\ncommands\n)\n \n{\n\n      \nawait\n \nctx\n.\npersistentStore\n.\nexecute\n(\ncmd\n);\n\n    \n}\n\n\n    \nvar\n \nquestions\n \n=\n \n[\n\n      \nHow much wood can a woodchuck chuck?\n,\n\n      \nWhat\ns the tallest mountain in the world?\n\n    \n];\n\n\n    \nfor\n \n(\nvar\n \nquestion\n \nin\n \nquestions\n)\n \n{\n\n      \nvar\n \ninsertQuery\n \n=\n \nnew\n \nQuery\nQuestion\n()\n\n        \n..\nvalues\n.\ndescription\n \n=\n \nquestion\n;\n\n      \nawait\n \ninsertQuery\n.\ninsert\n();\n\n    \n}\n\n  \n});\n\n\n\n\n\n\nNow, this is also a lesson in insert queries. \nQuery\nT\n has a property named \nvalues\n, an instance of the type being queried. In this case, \nvalues\n is a \nQuestion\n because the query is created as \nQuery\nQuestion\n. When the \nQuery\nT\n is inserted, all of the values that have been set on \nvalues\n property are inserted into the database. (If you don't set a value, it isn't sent in the insert query at all. A \nQuery\nT\n does not send \nnull\n unless you explicitly set a property to \nnull\n.)\n\n\nIn our seeded test database, there will be two questions. If you re-run the tests, the first one should pa... wait, no it fails. The test results says this:\n\n\nExpected\n:\n\n  \nStatus\n \nCode\n:\n \n200\n\n  \nBody\n:\n \nevery\n \nelement\n(\na\n \nstring\n \nending\n \nwith\n \n?\n)\n\n  \nActual\n:\n \nTestResponse\n:\n\n  \nStatus\n \nCode\n:\n \n200\n\n  \nHeaders\n:\n \ntransfer\n-\nencoding\n:\n \nchunked\n\n       \ncontent\n-\nencoding\n:\n \ngzip\n\n       \nx\n-\nframe\n-\noptions\n:\n \nSAMEORIGIN\n\n       \ncontent\n-\ntype\n:\n \napplication\n/\njson\n;\n \ncharset\n=\nutf\n-\n8\n\n       \nx\n-\nxss\n-\nprotection\n:\n \n1\n;\n \nmode\n=\nblock\n\n       \nx\n-\ncontent\n-\ntype\n-\noptions\n:\n \nnosniff\n\n       \nserver\n:\n \naqueduct\n/\n1\n\n  \nBody\n:\n \n[{\nindex\n:\n1\n,\ndescription\n:\nHow much wood can a woodchuck chuck?\n},{\nindex\n:\n2\n,\ndescription\n:\nWhat\ns the tallest mountain in the world?\n}]\n\n\n\n\n\n\nWhen a \nhasResponse\n matcher fails, it prints out what you expected and what the \nTestResponse\n actually was. The expectation was that every element is a string ending with '?'. Instead, the bottom of the test result says that the body is actually a list of maps, for which there is a index and a description. This is the list of JSON-encoded \nQuestion\n objects, and they are obviously not \nString\ns like they previously were.\n\n\nThis is because a \nManagedObject\n like \nQuestion\n is serialized into a \nMap\nString, dynamic\n when returned in a \nResponse\n. Each key in the map is a property of the managed object. Since \nQuestion\n declares two properties - \nindex\n and \ndescription\n - each question in the response body JSON is a map of those two values. Let's update this test to reflect that change:\n\n\n  \ntest\n(\n/questions returns list of questions\n,\n \n()\n \nasync\n \n{\n\n    \nvar\n \nresponse\n \n=\n \nawait\n \nclient\n.\nrequest\n(\n/questions\n).\nget\n();\n\n    \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \neveryElement\n({\n\n        \nindex\n \n:\n \ngreaterThan\n(\n0\n),\n\n        \ndescription\n \n:\n \nendsWith\n(\n?\n)\n\n    \n})));\n\n    \nexpect\n(\nresponse\n.\ndecodedBody\n,\n \nhasLength\n(\ngreaterThan\n(\n0\n)));\n\n  \n});\n\n\n\n\n\n\nNow, the expectation is that every element in the response body is a \nMap\n, for which it has an \nindex\n greater than or equal to \n0\n and and a \ndescription\n that ends with \n?\n. Run these tests again and the tests will pass.\n\n\nNow, our \nQuestionController\n reads from a database when fetching all questions through the \n/questions\n endpoint. However, it is still reading from the list of static questions when fetching a single question with \n/questions/:id\n.\n\n\nModify \ngetQuestionAtIndex\n in \nquestion_controller.dart\n to fetch a single question from the database. You may also delete the property \nquestions\n from \nQuestionController\n.\n\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetQuestionAtIndex\n(\n@\nHTTPPath\n(\nindex\n)\n \nint\n \nindex\n)\n \nasync\n \n{\n\n    \nvar\n \nquestionQuery\n \n=\n \nnew\n \nQuery\nQuestion\n()\n\n      \n..\nwhere\n.\nindex\n \n=\n \nwhereEqualTo\n(\nindex\n);\n    \n\n    \nvar\n \nquestion\n \n=\n \nawait\n \nquestionQuery\n.\nfetchOne\n();\n\n\n    \nif\n \n(\nquestion\n \n==\n \nnull\n)\n \n{\n\n      \nreturn\n \nnew\n \nResponse\n.\nnotFound\n();\n\n    \n}\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nquestion\n);\n\n  \n}\n\n\n\n\n\n\nIn this query, a 'where' is being applied to the query. The \nQuery.where\n property allows you to restrict the results returned from a query to those that match the conditions applied to it. \nQuery.where\n is also an instance of \nQuestion\n, like \nvalues\n, so its properties like \nindex\n are accessible. When setting a property of \nQuery.where\n, you must use a \nmatcher\n. There are many available matchers and all of them begin with the word 'where'. This particular query only fetches questions where the index is equal to the argument \nindex\n. (Check the \nAqueduct API reference\n to see all of the matchers.)\n\n\nNow, we must update the second test in \nquestion_controller_test.dart\n now that this endpoint is returning a JSON object that represents a question:\n\n\n  \ntest\n(\n/questions/index returns a single question\n,\n \n()\n \nasync\n \n{\n\n    \nvar\n \nresponse\n \n=\n \nawait\n \nclient\n.\nrequest\n(\n/questions/1\n).\nget\n();\n\n    \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \n{\n\n        \nindex\n \n:\n \ngreaterThanOrEqualTo\n(\n0\n),\n\n        \ndescription\n \n:\n \nendsWith\n(\n?\n)\n\n    \n}));\n\n  \n});\n\n\n\n\n\n\nThat's fetch and insert. Delete works the same way - you specify \nwhere\n values and invoke \ndelete\n on the query. If you want to update database rows, you specify both \nvalues\n and \nwhere\n.\n\n\nThe more you know: Query Parameters and HTTP Headers\n\n\nYou can specify that a \nHTTPController\n responder method extract HTTP query parameters and headers and supply them as arguments to the method. We'll allow the \ngetAllQuestions\n method to take a query parameter named \ncontains\n. If this query parameter is part of the request, we'll filter the questions on whether or not that question contains some substring. In \nquestion_controller.dart\n, update this method:\n\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetAllQuestions\n({\n@\nHTTPQuery\n(\ncontains\n)\n \nString\n \ncontainsSubstring:\n \nnull\n})\n \nasync\n \n{\n\n    \nvar\n \nquestionQuery\n \n=\n \nnew\n \nQuery\nQuestion\n();\n\n    \nif\n \n(\ncontainsSubstring\n \n!=\n \nnull\n)\n \n{\n\n      \nquestionQuery\n.\nwhere\n.\ndescription\n \n=\n \nwhereContainsString\n(\ncontainsSubstring\n);\n\n    \n}\n\n    \nvar\n \nquestions\n \n=\n \nawait\n \nquestionQuery\n.\nfetch\n();\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nquestions\n);\n\n  \n}\n\n\n\n\n\n\nIf an HTTP request has a \ncontains\n query parameter, that value will be passed as the \ncontainsSubstring\n parameter. As you can see, you may name the parameter whatever you like, it doesn't have to match the name of query parameter. Also, note that we first check \ncontainsSubstring\n to make sure it is not-null. If we simply assigned \nnull\n to \ndescription\n, we'd be creating a matcher that checked to see if the \ndescription\n \ncontained\n \nnull\n.\n\n\nUsing HTTP header values as parameters is accomplished in the same way, except using the \nHTTPHeader\n metadata. Query parameters are case sensitive, where header parameters are not.\n\n\nThen, add a new test in \nquestion_controller_test.dart\n:\n\n\n  \ntest\n(\n/questions returns list of questions filtered by contains\n,\n \n()\n \nasync\n \n{\n\n    \nvar\n \nresponse\n \n=\n \nawait\n \nclient\n.\nrequest\n(\n/questions?contains=mountain\n).\nget\n();\n\n    \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \n[{\n\n        \nindex\n \n:\n \ngreaterThanOrEqualTo\n(\n0\n),\n\n        \ndescription\n \n:\n \nWhat\ns the tallest mountain in the world?\n\n    \n}]));\n\n    \nexpect\n(\nresponse\n.\ndecodedBody\n,\n \nhasLength\n(\n1\n));\n\n  \n});\n\n\n\n\n\n\nThis test will pass, along with the rest of them. It's important to note that GET \n/questions\n without a \ncontains\n query still yields the correct results. That is because the \nHTTPQuery\n argument was declared in the optional parameters portion of the responder method. If the parameter were in the required, positional set of parameters and the query string was not included, this request would respond with a 400. (The same positional vs. optional behavior is true of \nHTTPHeader\ns as well.) For example, if we wanted to make a 'X-Client-ID' header that had to be included on this request, we'd do the following:\n\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetAllQuestions\n(\n\n    \n@\nHTTPHeader\n(\nX-Client-ID\n)\n \nint\n \nclientID\n,\n\n    \n{\n@\nHTTPQuery\n(\ncontains\n)\n \nString\n \ncontainsSubstring\n \n=\n \nnull\n}\n\n  \n)\n \nasync\n \n{\n\n    \nif\n \n(\nclientID\n \n!=\n \n12345\n)\n \n{\n\n      \nreturn\n \nnew\n \nResponse\n.\nunauthorized\n();\n\n    \n}\n\n\n    \nvar\n \nquestionQuery\n \n=\n \nnew\n \nQuery\nQuestion\n();\n\n    \nif\n \n(\ncontainsSubstring\n \n!=\n \nnull\n)\n \n{\n\n      \nquestionQuery\n.\nwhere\n.\ndescription\n \n=\n \nwhereContainsString\n(\ncontainsSubstring\n);\n\n    \n}\n\n\n    \nvar\n \nquestions\n \n=\n \nawait\n \nquestionQuery\n.\nfetch\n();\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nquestions\n);\n\n  \n}\n\n\n\n\n\n\nNote that in this case, the \nclientID\n will be parsed as an integer before being sent as an argument to \ngetAllQuestions\n. If the value cannot be parsed as an integer or is omitted, a 400 status code will be returned before your responder method gets called.\n\n\nSpecifying query and header parameters in a responder method is a good way to make your code more intentional and avoid boilerplate parsing code. Additionally, Aqueduct is able to generate documentation from method signatures - by specifying these types of parameters, the documentation generator can add that information to the documentation.\n\n\nNext: Relationships and Joins", 
            "title": "3. Executing Database Queries"
        }, 
        {
            "location": "/tut/executing-queries/#executing-queries", 
            "text": "Now that you've seen how to route HTTP requests and respond to them, we'll do something useful with those requests: like interacting with a database. We will continue to build on the last chapter project,  quiz , by storing the questions in a database and retrieving them from the database.", 
            "title": "Executing Queries"
        }, 
        {
            "location": "/tut/executing-queries/#building-a-data-model", 
            "text": "Aqueduct has a built-in ORM (some of which is modeled after the iOS/macOS Core Data framework). Like all ORMs, rows of a database are mapped to objects. In Aqueduct, these objects are of type  ManagedObject T . Let's define a managed object that represents a 'question'. Create a new directory in  lib  named  model , and then add a new file to it named  question.dart  (thus,  lib/model/question.dart ).  A managed object is a subclass of  ManagedObject T , where  T  is a  persistent type . A persistent type is a simple Dart class that maps to a database table. Each of its properties maps to a column in that table. By convention, but not required, persistent types are prefixed with '_'. In  question.dart , let's define a persistent type for a question:  import   package:quiz/quiz.dart ;  class   _Question   { \n   @ ManagedColumnAttributes ( primaryKey:   true ,   databaseType:   PropertyType . bigInteger ,   autoincrement:   true ) \n   int   index ; \n\n   String   description ;  }   Each property in a persistent type can be marked with  ManagedColumnAttributes  metadata that defines how the underlying database column is defined. The  index  property of  _Question  is the primary key column and a \"big\" integer. The autoincrement flag lets the database generate this value when a new question is inserted. Because it is quite common to have a primary key that is a big integer and autoincrementing, there is shorthand for it. Replace the metadata with the  managedPrimaryKey  shorthand:  class   _Question   { \n   @ managedPrimaryKey \n   int   index ; \n\n   String   description ;  }   All managed objects must have exactly one property with  primaryKey  set to true.  Other interesting flags for  ManagedColumnAttributes  are  indexed ,  nullable  and  defaultValue . If a property does not have  ManagedColumnAttributes , it is still a persistent property. All of the , it's just a normal column and its database type is inferred from its Dart type. Supported Dart types are  int ,  double ,  String ,  DateTime  and  bool .  Once a persistent type has been defined, you must also declare a corresponding subclass of  ManagedObject . At the top of  question.dart , but underneath the import, add the following:  import   package:quiz/quiz.dart ;  class   Question   extends   ManagedObject _Question   implements   _Question   {}  class   _Question   { \n   @ managedPrimaryKey \n   int   index ; \n\n   String   description ;  }   This dual-class setup is important and necessary for using Aqueduct's ORM. The persistent type - the plain Dart class that starts with an underscore - represents a database table. Each property of the persistent type is a column in that database table. The name of the database table matches the name of the class (here,  _Question ).  The  ManagedObject  subclass is the type you work with in your code. Its associated persistent type appears twice in its declaration: as the type argument to  ManagedObject  ( ManagedObject _Question ) and as an interface ( implements _Question ). A  ManagedObject  may have properties and methods of its own, but those are  not  backed by a database column.", 
            "title": "Building a Data Model"
        }, 
        {
            "location": "/tut/executing-queries/#importing-managedobjects", 
            "text": "As your code progresses, those  ManagedObject T s will have relationships with other  ManagedObject T s and be used in your request handling code. Additionally, the tools that generate database schemas and 'compile' the declarations of  ManagedObject T  also need to see the definitions. Therefore,  ManagedObject  declarations must be visible to the rest of your application.  The best practice is to declare each  ManagedObject T  in its own file and create a file that exports all  ManagedObject T s. Create a new file in  lib  named  model.dart . In this file, export  model/question.dart :  export   model/question.dart ;   The  model.dart  file exports all of your  ManagedObject  declarations. Now, to make all of your managed objects visible, export  model.dart  in  quiz.dart :  export   dart:async ;  export   package:aqueduct/aqueduct.dart ;  export   sink.dart ;  // Add this export:  export   model.dart ;   Now, every file in your application that import the application package will see the managed object declarations - and more importantly, the tools will see those declarations, too.", 
            "title": "Importing ManagedObjects"
        }, 
        {
            "location": "/tut/executing-queries/#defining-a-context", 
            "text": "In order for an application to work with a database, it needs a  ManagedContext . A  ManagedContext  is the facilitator between your code and a database. It is made up of two components, a  ManagedDataModel  (the thing that keeps track of all of your managed object types) and  PersistentStore  (the thing that talks to the database). These objects are set up in a  RequestSink . In  sink.dart , add the following code to the constructor for  QuizRequestSink  and define a new property:  class   QuizRequestSink   extends   RequestSink   { \n   QuizRequestSink ( Map String ,   dynamic   options )   :   super ( options )   { \n     var   dataModel   =   new   ManagedDataModel . fromCurrentMirrorSystem (); \n     var   persistentStore   =   new   PostgreSQLPersistentStore . fromConnectionInfo ( \n       dart ,   dart ,   localhost ,   5432 ,   dart_test ); \n     context   =   new   ManagedContext ( dataModel ,   persistentStore ); \n   } \n\n   ManagedContext   context ; \n\n   ...   (In the future, we'll allow this information to be passed from a configuration file. But for now, we'll do it manually.)  A  ManagedDataModel  is initialized with its named constructor  fromCurrentMirrorSystem . This constructor uses reflection to find every  ManagedObject T  subclass in your application and compile a data model from them. (This is why it is important to export managed objects the way it was done in the previous section.)  The persistent store is a specific implementation of a persistent store,  PostgreSQLPersistentStore . It is initialized with information necessary to connect to a database. A  ManagedContext  simply ties those two things together.  (By the way, the interface for  PersistentStore  can be implemented for different flavors of SQL and even non-SQL databases. We just so happen to prefer PostgreSQL, so we've already built that one.)  When a  ManagedContext  is created, it becomes the  default context  of your application. When we execute database queries, they run on the default context (by default). If we have multiple databases, we can create more  ManagedContext s and pass them around to make sure we hit the right database. For now, we can ignore this, just know that it exists.", 
            "title": "Defining a Context"
        }, 
        {
            "location": "/tut/executing-queries/#executing-queries_1", 
            "text": "Now that we have a context - which can establish a connection to a database, talk to the database and map rows to managed objects - we can execute queries in our  RequestController s. In  question_controller.dart , replace the code for  getAllQuestions  (we'll work on  getQuestionAtIndex  soon):  class   QuestionController   extends   HttpController   { \n   var   questions   =   [ \n     How much wood can a woodchuck chuck? , \n     What s the tallest mountain in the world? \n   ]; \n\n   @ httpGet \n   Future Response   getAllQuestions ()   async   { \n     var   questionQuery   =   new   Query Question (); \n     var   databaseQuestions   =   await   questionQuery . fetch (); \n     return   new   Response . ok ( databaseQuestions ); \n   }  ...   When this responder method is executed, it'll create a new  Query T  for  Question  (as indicated by the type parameter). A query has a handful of execution methods on it -  fetch ,  fetchOne ,  insert ,  update ,  updateOne  and  delete . By executing a  fetch  on a vanilla  Query Question , this will return a list of  Question s, one for each row in the database's question table.  Now, we need an actual database to fetch data from.", 
            "title": "Executing Queries"
        }, 
        {
            "location": "/tut/executing-queries/#configuring-a-database", 
            "text": "As we've mentioned a few times, a key facet to Aqueduct is efficient automated testing. The scheme for testing is to create a 'test' database that all of your Aqueduct projects run against. When you run tests against that database, the tests create  temporary  tables prior to executing. The good news is that the  ManagedDataModel  in your application can drive this table creation, so you don't need to do anything special. The tests are run against the current version of the schema defined by your code.  Therefore, on any machine you're going to test on, you need to install PostgreSQL and configure a test database. You'll only need to set this up once on - all Aqueduct project tests run against the same database.  On macOS, the best way to do this locally is download  Postgres.app . This has a self-contained instance of Postgres that you start by opening up the application itself. Download this application and run it.  Once running, run the command  aqueduct setup  from anywhere. It will give you some additional instructions to follow to make sure everything is OK. It just runs the following SQL:  create   database   dart_test ;  create   user   dart   with   createdb ;  alter   user   dart   with   password   dart ;  grant   all   on   database   dart_test   to   dart ;   If you are on another operating system or this command fails for your installation of PostgreSQL, you may run the above commands through the  psql  command-line utility.  You'll notice in your  RequestSink , the configuration parameters for the  PostgreSQLPersistentStore  match those that you have just added to your local instance of Postgres, so your application will run against that instance. However, if you were to run your code now, the table backing  Question s would not exist. When running tests, we need to create a temporary table for  Question s before the tests start. Go to the  setUp  method in  question_controller_test.dart , and enter the following code after the application is started:     setUp (()   async   { \n     await   app . start ( runOnMainIsolate:   true ); \n     client   =   new   TestClient ( app ); \n\n     var   ctx   =   ManagedContext . defaultContext ; \n     var   builder   =   new   SchemaBuilder . toSchema ( \n       ctx . persistentStore ,   new   Schema . fromDataModel ( ctx . dataModel ),   isTemporary:   true ); \n\n     for   ( var   cmd   in   builder . commands )   { \n       await   ctx . persistentStore . execute ( cmd ); \n     } \n   });   After the application is started, we know that it creates a  ManagedContext  in the constructor of  QuizRequestSink . The default context can be accessed through  ManagedContext.defaultContext . We also know that this context has a  ManagedDataModel  containing  Question . The class  SchemaBuilder  will create a series of SQL commands from the data model, translated by the  PostgreSQLPersistentStore . (Note that the  isTemporary  parameter makes all of the tables temporary and therefore they disappear when the database connection in the context's persistent store closes. This prevents changes to the database from leaking into subsequent tests.)  The database connection is automatically closed when the tests complete by the existing  tearDown  method that stops the application. Note that when the databsae connection is closed, the tables and data in the database created by this test are discarded.  We now need questions in the database (you can run your tests and see the they fail because there are no questions). Let's first seed the database with some questions using an insert query at the end of  setUp .     setUp (()   async   { \n     await   app . start ( runOnMainIsolate:   true ); \n     client   =   new   TestClient ( app ); \n\n     var   ctx   =   ManagedContext . defaultContext ; \n     var   builder   =   new   SchemaBuilder . toSchema ( ctx . persistentStore ,   new   Schema . fromDataModel ( ctx . dataModel ),   isTemporary:   true ); \n\n     for   ( var   cmd   in   builder . commands )   { \n       await   ctx . persistentStore . execute ( cmd ); \n     } \n\n     var   questions   =   [ \n       How much wood can a woodchuck chuck? , \n       What s the tallest mountain in the world? \n     ]; \n\n     for   ( var   question   in   questions )   { \n       var   insertQuery   =   new   Query Question () \n         .. values . description   =   question ; \n       await   insertQuery . insert (); \n     } \n   });   Now, this is also a lesson in insert queries.  Query T  has a property named  values , an instance of the type being queried. In this case,  values  is a  Question  because the query is created as  Query Question . When the  Query T  is inserted, all of the values that have been set on  values  property are inserted into the database. (If you don't set a value, it isn't sent in the insert query at all. A  Query T  does not send  null  unless you explicitly set a property to  null .)  In our seeded test database, there will be two questions. If you re-run the tests, the first one should pa... wait, no it fails. The test results says this:  Expected : \n   Status   Code :   200 \n   Body :   every   element ( a   string   ending   with   ? ) \n   Actual :   TestResponse : \n   Status   Code :   200 \n   Headers :   transfer - encoding :   chunked \n        content - encoding :   gzip \n        x - frame - options :   SAMEORIGIN \n        content - type :   application / json ;   charset = utf - 8 \n        x - xss - protection :   1 ;   mode = block \n        x - content - type - options :   nosniff \n        server :   aqueduct / 1 \n   Body :   [{ index : 1 , description : How much wood can a woodchuck chuck? },{ index : 2 , description : What s the tallest mountain in the world? }]   When a  hasResponse  matcher fails, it prints out what you expected and what the  TestResponse  actually was. The expectation was that every element is a string ending with '?'. Instead, the bottom of the test result says that the body is actually a list of maps, for which there is a index and a description. This is the list of JSON-encoded  Question  objects, and they are obviously not  String s like they previously were.  This is because a  ManagedObject  like  Question  is serialized into a  Map String, dynamic  when returned in a  Response . Each key in the map is a property of the managed object. Since  Question  declares two properties -  index  and  description  - each question in the response body JSON is a map of those two values. Let's update this test to reflect that change:     test ( /questions returns list of questions ,   ()   async   { \n     var   response   =   await   client . request ( /questions ). get (); \n     expect ( response ,   hasResponse ( 200 ,   everyElement ({ \n         index   :   greaterThan ( 0 ), \n         description   :   endsWith ( ? ) \n     }))); \n     expect ( response . decodedBody ,   hasLength ( greaterThan ( 0 ))); \n   });   Now, the expectation is that every element in the response body is a  Map , for which it has an  index  greater than or equal to  0  and and a  description  that ends with  ? . Run these tests again and the tests will pass.  Now, our  QuestionController  reads from a database when fetching all questions through the  /questions  endpoint. However, it is still reading from the list of static questions when fetching a single question with  /questions/:id .  Modify  getQuestionAtIndex  in  question_controller.dart  to fetch a single question from the database. You may also delete the property  questions  from  QuestionController .     @ httpGet \n   Future Response   getQuestionAtIndex ( @ HTTPPath ( index )   int   index )   async   { \n     var   questionQuery   =   new   Query Question () \n       .. where . index   =   whereEqualTo ( index );     \n\n     var   question   =   await   questionQuery . fetchOne (); \n\n     if   ( question   ==   null )   { \n       return   new   Response . notFound (); \n     } \n     return   new   Response . ok ( question ); \n   }   In this query, a 'where' is being applied to the query. The  Query.where  property allows you to restrict the results returned from a query to those that match the conditions applied to it.  Query.where  is also an instance of  Question , like  values , so its properties like  index  are accessible. When setting a property of  Query.where , you must use a  matcher . There are many available matchers and all of them begin with the word 'where'. This particular query only fetches questions where the index is equal to the argument  index . (Check the  Aqueduct API reference  to see all of the matchers.)  Now, we must update the second test in  question_controller_test.dart  now that this endpoint is returning a JSON object that represents a question:     test ( /questions/index returns a single question ,   ()   async   { \n     var   response   =   await   client . request ( /questions/1 ). get (); \n     expect ( response ,   hasResponse ( 200 ,   { \n         index   :   greaterThanOrEqualTo ( 0 ), \n         description   :   endsWith ( ? ) \n     })); \n   });   That's fetch and insert. Delete works the same way - you specify  where  values and invoke  delete  on the query. If you want to update database rows, you specify both  values  and  where .", 
            "title": "Configuring a Database"
        }, 
        {
            "location": "/tut/executing-queries/#the-more-you-know-query-parameters-and-http-headers", 
            "text": "You can specify that a  HTTPController  responder method extract HTTP query parameters and headers and supply them as arguments to the method. We'll allow the  getAllQuestions  method to take a query parameter named  contains . If this query parameter is part of the request, we'll filter the questions on whether or not that question contains some substring. In  question_controller.dart , update this method:     @ httpGet \n   Future Response   getAllQuestions ({ @ HTTPQuery ( contains )   String   containsSubstring:   null })   async   { \n     var   questionQuery   =   new   Query Question (); \n     if   ( containsSubstring   !=   null )   { \n       questionQuery . where . description   =   whereContainsString ( containsSubstring ); \n     } \n     var   questions   =   await   questionQuery . fetch (); \n     return   new   Response . ok ( questions ); \n   }   If an HTTP request has a  contains  query parameter, that value will be passed as the  containsSubstring  parameter. As you can see, you may name the parameter whatever you like, it doesn't have to match the name of query parameter. Also, note that we first check  containsSubstring  to make sure it is not-null. If we simply assigned  null  to  description , we'd be creating a matcher that checked to see if the  description   contained   null .  Using HTTP header values as parameters is accomplished in the same way, except using the  HTTPHeader  metadata. Query parameters are case sensitive, where header parameters are not.  Then, add a new test in  question_controller_test.dart :     test ( /questions returns list of questions filtered by contains ,   ()   async   { \n     var   response   =   await   client . request ( /questions?contains=mountain ). get (); \n     expect ( response ,   hasResponse ( 200 ,   [{ \n         index   :   greaterThanOrEqualTo ( 0 ), \n         description   :   What s the tallest mountain in the world? \n     }])); \n     expect ( response . decodedBody ,   hasLength ( 1 )); \n   });   This test will pass, along with the rest of them. It's important to note that GET  /questions  without a  contains  query still yields the correct results. That is because the  HTTPQuery  argument was declared in the optional parameters portion of the responder method. If the parameter were in the required, positional set of parameters and the query string was not included, this request would respond with a 400. (The same positional vs. optional behavior is true of  HTTPHeader s as well.) For example, if we wanted to make a 'X-Client-ID' header that had to be included on this request, we'd do the following:     @ httpGet \n   Future Response   getAllQuestions ( \n     @ HTTPHeader ( X-Client-ID )   int   clientID , \n     { @ HTTPQuery ( contains )   String   containsSubstring   =   null } \n   )   async   { \n     if   ( clientID   !=   12345 )   { \n       return   new   Response . unauthorized (); \n     } \n\n     var   questionQuery   =   new   Query Question (); \n     if   ( containsSubstring   !=   null )   { \n       questionQuery . where . description   =   whereContainsString ( containsSubstring ); \n     } \n\n     var   questions   =   await   questionQuery . fetch (); \n     return   new   Response . ok ( questions ); \n   }   Note that in this case, the  clientID  will be parsed as an integer before being sent as an argument to  getAllQuestions . If the value cannot be parsed as an integer or is omitted, a 400 status code will be returned before your responder method gets called.  Specifying query and header parameters in a responder method is a good way to make your code more intentional and avoid boilerplate parsing code. Additionally, Aqueduct is able to generate documentation from method signatures - by specifying these types of parameters, the documentation generator can add that information to the documentation.", 
            "title": "The more you know: Query Parameters and HTTP Headers"
        }, 
        {
            "location": "/tut/executing-queries/#next-relationships-and-joins", 
            "text": "", 
            "title": "Next: Relationships and Joins"
        }, 
        {
            "location": "/tut/model-relationships-and-joins/", 
            "text": "ManagedObject Relationships\n\n\nManaged objects can also have relationships to other managed objects. There are two types of relationships: to-one and to-many. Let's add an answer for each \nQuestion\n in the form of a to-one relationship. First, create a new file \nlib/model/answer.dart\n and define a new managed object to represent an answer:\n\n\nimport\n \npackage:quiz/quiz.dart\n;\n\n\n\nclass\n \nAnswer\n \nextends\n \nManagedObject\n_Answer\n \nimplements\n \n_Answer\n \n{}\n\n\nclass\n \n_Answer\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nid\n;\n\n  \nString\n \ndescription\n;\n\n\n}\n\n\n\n\n\n\nNotice we created the persistent type and subclass of \nManagedObject\n. Export this file to the library from \nmodel.dart\n so everything that needs to see it can:\n\n\nexport\n \nmodel/answer.dart\n;\n\n\n\n\n\n\nNow that we have a managed object that represents both a question and answer, we will set up a relationship between them. It logically makes sense that a 'question \nhas an\n answer', so let's add that property to \n_Question\n, the persistent type of \nQuestion\n:\n\n\nclass\n \n_Question\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nindex\n;\n\n\n  \nString\n \ndescription\n;\n\n  \nAnswer\n \nanswer\n;\n\n\n}\n\n\n\n\n\n\nFor all relationships, we also must specify the \ninverse relationship\n. The inverse will be a property on \n_Answer\n that points back to the \nQuestion\n it is the answer for. In \n_Answer\n, add the inverse:\n\n\nclass\n \n_Answer\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nid\n;\n\n  \nString\n \ndescription\n;\n\n\n  \n@\nManagedRelationship\n(\n#\nanswer\n)\n\n  \nQuestion\n \nquestion\n;\n\n\n}\n\n\n\n\n\n\nNotice that we added \nManagedRelationship\n metadata to \nquestion\n. Since relationships are two-sided, only one side needs to have this metadata (and in fact, only one side \ncan\n have this metadata). The first argument is the name of the property on the other side of the relationship; this is what links the relationship together.\n\n\nThe property with \nManagedRelationship\n metadata is actually a column in the database. More specifically, it is a foreign key column. So in this case, the \n_Answer\n table has a foreign key column named \nquestion_index\n. (The name is derived by taking the name of the relationship property and name of the primary key property on the other side and joining it with a \n_\n.) The \n_Answer\n table now has three columns: \nid\n, \ndescription\n and \nquestion_index\n.\n\n\nThe relationship property \nwithout\n \nManagedRelationship\n metadata is \nnot\n a column in the database. Instead, it represents an \nentire row\n in the database. Thus, the table \n_Question\n only has two columns: \nindex\n and \ndescription\n.\n\n\nManagedRelationship\n also allows you to specify a delete rule and whether or not the property is required, i.e., not nullable. By default, the delete rule is \nManagedRelationshipDeleteRule.nullify\n and not required - this is the least destructive action. But, in this case, we want every question to always have an answer and if we delete the question, the answer gets deleted along with it:\n\n\nclass\n \n_Answer\n \n{\n\n  \n@\nprimaryKey\n \nint\n \nid\n;\n\n  \nString\n \ndescription\n;\n\n\n  \n@\nManagedRelationship\n(\n\n    \n#\nanswer\n,\n \nonDelete:\n \nManagedRelationshipDeleteRule\n.\ncascade\n,\n \nisRequired:\n \ntrue\n)\n\n  \nQuestion\n \nquestion\n;\n\n\n}\n\n\n\n\n\n\nNow that we have defined this relationship, we can associate answers with questions and return them in our \n/questions\n endpoint. In \nquestion_controller.dart\n, let's update the queries to fetch the \nAnswer\n for each \nQuestion\n and include it in the response JSON. First, for \ngetAllQuestions\n, use \njoinOne()\n to connect to \nquestion.answer\n for \nwhere\n's \nanswer\n:\n\n\n@\nhttpGet\n\n\nFuture\nResponse\n \ngetAllQuestions\n({\n@\nHTTPQuery\n(\ncontains\n)\n \nString\n \ncontainsSubstring:\n \nnull\n})\n \nasync\n \n{\n\n  \nvar\n \nquestionQuery\n \n=\n \nnew\n \nQuery\nQuestion\n()\n\n    \n..\njoinOne\n((\nquestion\n)\n \n=\n \nquestion\n.\nanswer\n);\n\n\n  \nif\n \n(\ncontainsSubstring\n \n!=\n \nnull\n)\n \n{\n\n    \nquestionQuery\n.\nwhere\n.\ndescription\n \n=\n \nwhereContainsString\n(\ncontainsSubstring\n);\n\n  \n}\n\n\n  \nvar\n \nquestions\n \n=\n \nawait\n \nquestionQuery\n.\nfetch\n();\n\n  \nreturn\n \nnew\n \nResponse\n.\nok\n(\nquestions\n);\n\n\n}\n\n\n\n\n\n\nYeah, that was it. The SQL that gets built for this \nQuery\nT\n will join on the underlying \n_Answer\n table. Therefore, each \nanswer\n property of every \nQuestion\n returned will have a valid \nAnswer\n instance from the database. Managed objects also know how to serialize their relationship properties, so you'll get the following JSON when fetching a question that has been joined with its answer:\n\n\n{\n\n  \nindex\n \n:\n \n1\n,\n\n  \ndescription\n \n:\n \nA question?\n,\n\n  \nanswer\n \n:\n \n{\n\n      \nid\n \n:\n \n1\n,\n\n      \ndescription\n \n:\n \nAn answer\n\n  \n}\n\n\n}\n\n\n\n\n\n\nLet's update our tests to ensure this works correctly. If you run your tests now, the two tests that get a list of \nQuestion\ns will fail because they don't expect an answer key in the JSON. Now, we don't really care about the 'id' of the answer at all, just its 'description'. Therefore, when we add to the HTTP body matcher to match the inner 'answer' object, it'd be great if we could just ignore it. That's why there is the \npartial\n matcher. A \npartial\n matcher will match a \nMap\n, but will only verify the values for the specified keys. Any other key-value pairs are just ignored. Let's try that out by updating the first test for getting all questions:\n\n\ntest\n(\n/questions returns list of questions\n,\n \n()\n \nasync\n \n{\n\n    \nvar\n \nresponse\n \n=\n \nawait\n \nclient\n.\nrequest\n(\n/questions\n).\nget\n();\n\n    \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \neveryElement\n({\n\n        \nindex\n \n:\n \ngreaterThanOrEqualTo\n(\n0\n),\n\n        \ndescription\n \n:\n \nendsWith\n(\n?\n),\n\n        \nanswer\n \n:\n \npartial\n({\n\n          \ndescription\n \n:\n \nisString\n\n        \n})\n\n    \n})));\n\n    \nexpect\n(\nresponse\n.\ndecodedBody\n,\n \nhasLength\n(\ngreaterThan\n(\n0\n)));\n\n  \n});\n\n\n\n\n\n\nThe partial matcher here will just check to see if the 'answer' key is a map that contains a \nString\n 'description' value. The extraneous 'id' key won't cause a failure. If you run the tests now, this test will still fail - 'answer' in the JSON is null because there are no answers in the database. Let's insert some by replacing \nsetUp\n in \nquestion_controller_test.dart\n:\n\n\nsetUp\n(()\n \nasync\n \n{\n\n  \nawait\n \napp\n.\nstart\n(\nrunOnMainIsolate:\n \ntrue\n);\n\n  \nclient\n \n=\n \nnew\n \nTestClient\n(\napp\n);\n\n\n  \nvar\n \nctx\n \n=\n \nManagedContext\n.\ndefaultContext\n;\n\n  \nvar\n \nbuilder\n \n=\n \nnew\n \nSchemaBuilder\n.\ntoSchema\n(\nctx\n.\npersistentStore\n,\n \nnew\n \nSchema\n.\nfromDataModel\n(\nctx\n.\ndataModel\n),\n \nisTemporary:\n \ntrue\n);\n\n\n  \nfor\n \n(\nvar\n \ncmd\n \nin\n \nbuilder\n.\ncommands\n)\n \n{\n\n    \nawait\n \nctx\n.\npersistentStore\n.\nexecute\n(\ncmd\n);\n\n  \n}\n\n\n  \nvar\n \nquestions\n \n=\n \n[\n\n    \nnew\n \nQuestion\n()\n\n      \n..\ndescription\n \n=\n \nHow much wood can a woodchuck chuck?\n\n      \n..\nanswer\n \n=\n \n(\nnew\n \nAnswer\n()..\ndescription\n \n=\n \nDepends\n),\n\n    \nnew\n \nQuestion\n()\n\n      \n..\ndescription\n \n=\n \nWhat\ns the tallest mountain in the world?\n\n      \n..\nanswer\n \n=\n \n(\nnew\n \nAnswer\n()..\ndescription\n \n=\n \nMount Everest\n)\n\n  \n];\n\n\n  \nfor\n \n(\nvar\n \nquestion\n \nin\n \nquestions\n)\n \n{\n\n    \nvar\n \nquestionInsert\n \n=\n \nnew\n \nQuery\nQuestion\n()\n\n        \n..\nvalues\n \n=\n \nquestion\n;\n\n    \nvar\n \ninsertedQuestion\n \n=\n \nawait\n \nquestionInsert\n.\ninsert\n();\n\n\n    \nvar\n \nanswerInsert\n \n=\n \nnew\n \nQuery\nAnswer\n()\n\n      \n..\nvalues\n.\ndescription\n \n=\n \nquestion\n.\nanswer\n.\ndescription\n\n      \n..\nvalues\n.\nquestion\n \n=\n \ninsertedQuestion\n;\n\n    \nawait\n \nanswerInsert\n.\ninsert\n();\n\n  \n}\n\n\n});\n\n\n\n\n\n\nNotice that we accumulated all of the questions and answers into a list of questions where each has an answer (\nquestions\n). Managed objects can be used just like normal objects, too.\n\n\nThen, for each question, we inserted it and got a reference to the \ninsertedQuestion\n back. The difference between each \nQuestion\n in \nquestions\n and \ninsertedQuestion\n is that the \ninsertedQuestion\n will have its primary key value (\nindex\n) set by the database. This allows the \nAnswer\ns - which have to be inserted separately, because they are different tables - to specify which question they are the answer for.\n\n\nAt the time the answer is being inserted, the question in the database \ninsertedQuestion\n does not yet have an answer - so asking it for its \nanswer.description\n would yield null. Therefore, the \nvalues.description\n is set from the source of data created in \nquestions\n, but the \nquestion\n must be set from \ninsertedQuestion\n - which contains the actual \nindex\n of the question.\n\n\nRecall that a property with \nManagedRelationship\n - like \nAnswer.question\n - is actually a foreign key column. When setting this property with a \nManagedObject\nT\n, the primary key value of that instance is sent as the value for the foreign key column. In this case, the \ninsertedQuestion\n has valid values for both \ndescription\n and \nindex\n. Setting the query's \nvalues.question\n to this instance ignores the \ndescription\n - it's not going to store it anyway - and sets the \nindex\n of the answer being inserted.\n\n\nNote, also, that the query to insert a question has \nvalues\n that contain an answer. These answers will be ignored during that insertion, because only the question is being inserted. Inserting or updating values will only operate on one table at a table - this is intentional explicit to avoid unintended consequences.\n\n\nYou could also set the answer's question with the following code:\n\n\ninsertQuery\n \n=\n \nnew\n \nQuery\nAnswer\n()\n\n  \n..\nvalues\n.\ndescription\n \n=\n \nanswersIterator\n.\ncurrent\n\n  \n..\nvalues\n.\nquestion\n \n=\n \n(\nnew\n \nQuestion\n()..\nindex\n \n=\n \n1\n);\n\n\n\n\n\n\nBut you couldn't do this, because \nvalues.question\n is null:\n\n\ninsertQuery\n \n=\n \nnew\n \nQuery\nAnswer\n()\n\n  \n..\nvalues\n.\ndescription\n \n=\n \nanswersIterator\n.\ncurrent\n\n  \n..\nvalues\n.\nquestion\n.\nid\n \n=\n \n1\n;\n\n\n\n\n\n\nNow, running the tests against, the first one will succeed again. We'll leave it as an exercise to the user to update the remaining failing tests to check for an answer.\n\n\nMore on Joins and Relationships\n\n\nHas-many relationships are also available. For example, if you wanted many answers for a question, it'd be declared like so:\n\n\nclass\n \n_Question\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nindex\n;\n\n\n  \nString\n \ndescription\n;\n\n  \nManagedSet\nAnswer\n \nanswers\n;\n\n\n}\n\n\n\n\n\n\nThe inverse relationship doesn't have to be updated - whether it is has-one or has-many is determined by whether or not property is a \nManagedSet\nT\n or a subclass of \nManagedObject\nT\n. For \nManagedSet\nT\n, \nT\n must be a subclass of \nManagedObject\nT\n. A \nManagedSet\n acts just like a \nList\n - it has methods like \nmap\n and \nwhere\n - but also has special behavior that allows it to be used in building \nQuery\nT\ns. If you wish to join on \nManagedSet\nT\n properties, the syntax is the same:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nQuestion\n()\n\n  \n..\njoinMany\n((\nquestion\n)\n \n=\n \nquestion\n.\nanswers\n);\n  \n\n\n\n\n\nEach returned \nQuestion\n would also have a \nManagedSet\n of \nAnswer\ns in its \nanswers\n property. You may also filter which answers are returned for each \nQuestion\n. A \njoinMany\n or \njoinOne\n creates a new \nQuery\nT\n that has its own \nwhere\n property.\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nQuestion\n();\n\n\nvar\n \njoin\n \n=\n \nquery\n.\njoinMany\n((\nquestion\n)\n \n=\n \nquestion\n.\nanswers\n)\n\n  \n..\nwhere\n.\nisCorrect\n \n=\n \nwhereEqualTo\n(\ntrue\n);\n  \n\n\n\n\n\nAn \nManagedSet\n is serialized into a \nList\n of \nMap\ns, and therefore the encoded JSON will be an array of objects.\n\n\nNext: Deployment", 
            "title": "4. Advanced Database Queries"
        }, 
        {
            "location": "/tut/model-relationships-and-joins/#managedobject-relationships", 
            "text": "Managed objects can also have relationships to other managed objects. There are two types of relationships: to-one and to-many. Let's add an answer for each  Question  in the form of a to-one relationship. First, create a new file  lib/model/answer.dart  and define a new managed object to represent an answer:  import   package:quiz/quiz.dart ;  class   Answer   extends   ManagedObject _Answer   implements   _Answer   {}  class   _Answer   { \n   @ managedPrimaryKey \n   int   id ; \n   String   description ;  }   Notice we created the persistent type and subclass of  ManagedObject . Export this file to the library from  model.dart  so everything that needs to see it can:  export   model/answer.dart ;   Now that we have a managed object that represents both a question and answer, we will set up a relationship between them. It logically makes sense that a 'question  has an  answer', so let's add that property to  _Question , the persistent type of  Question :  class   _Question   { \n   @ managedPrimaryKey \n   int   index ; \n\n   String   description ; \n   Answer   answer ;  }   For all relationships, we also must specify the  inverse relationship . The inverse will be a property on  _Answer  that points back to the  Question  it is the answer for. In  _Answer , add the inverse:  class   _Answer   { \n   @ managedPrimaryKey \n   int   id ; \n   String   description ; \n\n   @ ManagedRelationship ( # answer ) \n   Question   question ;  }   Notice that we added  ManagedRelationship  metadata to  question . Since relationships are two-sided, only one side needs to have this metadata (and in fact, only one side  can  have this metadata). The first argument is the name of the property on the other side of the relationship; this is what links the relationship together.  The property with  ManagedRelationship  metadata is actually a column in the database. More specifically, it is a foreign key column. So in this case, the  _Answer  table has a foreign key column named  question_index . (The name is derived by taking the name of the relationship property and name of the primary key property on the other side and joining it with a  _ .) The  _Answer  table now has three columns:  id ,  description  and  question_index .  The relationship property  without   ManagedRelationship  metadata is  not  a column in the database. Instead, it represents an  entire row  in the database. Thus, the table  _Question  only has two columns:  index  and  description .  ManagedRelationship  also allows you to specify a delete rule and whether or not the property is required, i.e., not nullable. By default, the delete rule is  ManagedRelationshipDeleteRule.nullify  and not required - this is the least destructive action. But, in this case, we want every question to always have an answer and if we delete the question, the answer gets deleted along with it:  class   _Answer   { \n   @ primaryKey   int   id ; \n   String   description ; \n\n   @ ManagedRelationship ( \n     # answer ,   onDelete:   ManagedRelationshipDeleteRule . cascade ,   isRequired:   true ) \n   Question   question ;  }   Now that we have defined this relationship, we can associate answers with questions and return them in our  /questions  endpoint. In  question_controller.dart , let's update the queries to fetch the  Answer  for each  Question  and include it in the response JSON. First, for  getAllQuestions , use  joinOne()  to connect to  question.answer  for  where 's  answer :  @ httpGet  Future Response   getAllQuestions ({ @ HTTPQuery ( contains )   String   containsSubstring:   null })   async   { \n   var   questionQuery   =   new   Query Question () \n     .. joinOne (( question )   =   question . answer ); \n\n   if   ( containsSubstring   !=   null )   { \n     questionQuery . where . description   =   whereContainsString ( containsSubstring ); \n   } \n\n   var   questions   =   await   questionQuery . fetch (); \n   return   new   Response . ok ( questions );  }   Yeah, that was it. The SQL that gets built for this  Query T  will join on the underlying  _Answer  table. Therefore, each  answer  property of every  Question  returned will have a valid  Answer  instance from the database. Managed objects also know how to serialize their relationship properties, so you'll get the following JSON when fetching a question that has been joined with its answer:  { \n   index   :   1 , \n   description   :   A question? , \n   answer   :   { \n       id   :   1 , \n       description   :   An answer \n   }  }   Let's update our tests to ensure this works correctly. If you run your tests now, the two tests that get a list of  Question s will fail because they don't expect an answer key in the JSON. Now, we don't really care about the 'id' of the answer at all, just its 'description'. Therefore, when we add to the HTTP body matcher to match the inner 'answer' object, it'd be great if we could just ignore it. That's why there is the  partial  matcher. A  partial  matcher will match a  Map , but will only verify the values for the specified keys. Any other key-value pairs are just ignored. Let's try that out by updating the first test for getting all questions:  test ( /questions returns list of questions ,   ()   async   { \n     var   response   =   await   client . request ( /questions ). get (); \n     expect ( response ,   hasResponse ( 200 ,   everyElement ({ \n         index   :   greaterThanOrEqualTo ( 0 ), \n         description   :   endsWith ( ? ), \n         answer   :   partial ({ \n           description   :   isString \n         }) \n     }))); \n     expect ( response . decodedBody ,   hasLength ( greaterThan ( 0 ))); \n   });   The partial matcher here will just check to see if the 'answer' key is a map that contains a  String  'description' value. The extraneous 'id' key won't cause a failure. If you run the tests now, this test will still fail - 'answer' in the JSON is null because there are no answers in the database. Let's insert some by replacing  setUp  in  question_controller_test.dart :  setUp (()   async   { \n   await   app . start ( runOnMainIsolate:   true ); \n   client   =   new   TestClient ( app ); \n\n   var   ctx   =   ManagedContext . defaultContext ; \n   var   builder   =   new   SchemaBuilder . toSchema ( ctx . persistentStore ,   new   Schema . fromDataModel ( ctx . dataModel ),   isTemporary:   true ); \n\n   for   ( var   cmd   in   builder . commands )   { \n     await   ctx . persistentStore . execute ( cmd ); \n   } \n\n   var   questions   =   [ \n     new   Question () \n       .. description   =   How much wood can a woodchuck chuck? \n       .. answer   =   ( new   Answer ().. description   =   Depends ), \n     new   Question () \n       .. description   =   What s the tallest mountain in the world? \n       .. answer   =   ( new   Answer ().. description   =   Mount Everest ) \n   ]; \n\n   for   ( var   question   in   questions )   { \n     var   questionInsert   =   new   Query Question () \n         .. values   =   question ; \n     var   insertedQuestion   =   await   questionInsert . insert (); \n\n     var   answerInsert   =   new   Query Answer () \n       .. values . description   =   question . answer . description \n       .. values . question   =   insertedQuestion ; \n     await   answerInsert . insert (); \n   }  });   Notice that we accumulated all of the questions and answers into a list of questions where each has an answer ( questions ). Managed objects can be used just like normal objects, too.  Then, for each question, we inserted it and got a reference to the  insertedQuestion  back. The difference between each  Question  in  questions  and  insertedQuestion  is that the  insertedQuestion  will have its primary key value ( index ) set by the database. This allows the  Answer s - which have to be inserted separately, because they are different tables - to specify which question they are the answer for.  At the time the answer is being inserted, the question in the database  insertedQuestion  does not yet have an answer - so asking it for its  answer.description  would yield null. Therefore, the  values.description  is set from the source of data created in  questions , but the  question  must be set from  insertedQuestion  - which contains the actual  index  of the question.  Recall that a property with  ManagedRelationship  - like  Answer.question  - is actually a foreign key column. When setting this property with a  ManagedObject T , the primary key value of that instance is sent as the value for the foreign key column. In this case, the  insertedQuestion  has valid values for both  description  and  index . Setting the query's  values.question  to this instance ignores the  description  - it's not going to store it anyway - and sets the  index  of the answer being inserted.  Note, also, that the query to insert a question has  values  that contain an answer. These answers will be ignored during that insertion, because only the question is being inserted. Inserting or updating values will only operate on one table at a table - this is intentional explicit to avoid unintended consequences.  You could also set the answer's question with the following code:  insertQuery   =   new   Query Answer () \n   .. values . description   =   answersIterator . current \n   .. values . question   =   ( new   Question ().. index   =   1 );   But you couldn't do this, because  values.question  is null:  insertQuery   =   new   Query Answer () \n   .. values . description   =   answersIterator . current \n   .. values . question . id   =   1 ;   Now, running the tests against, the first one will succeed again. We'll leave it as an exercise to the user to update the remaining failing tests to check for an answer.", 
            "title": "ManagedObject Relationships"
        }, 
        {
            "location": "/tut/model-relationships-and-joins/#more-on-joins-and-relationships", 
            "text": "Has-many relationships are also available. For example, if you wanted many answers for a question, it'd be declared like so:  class   _Question   { \n   @ managedPrimaryKey \n   int   index ; \n\n   String   description ; \n   ManagedSet Answer   answers ;  }   The inverse relationship doesn't have to be updated - whether it is has-one or has-many is determined by whether or not property is a  ManagedSet T  or a subclass of  ManagedObject T . For  ManagedSet T ,  T  must be a subclass of  ManagedObject T . A  ManagedSet  acts just like a  List  - it has methods like  map  and  where  - but also has special behavior that allows it to be used in building  Query T s. If you wish to join on  ManagedSet T  properties, the syntax is the same:  var   query   =   new   Query Question () \n   .. joinMany (( question )   =   question . answers );     Each returned  Question  would also have a  ManagedSet  of  Answer s in its  answers  property. You may also filter which answers are returned for each  Question . A  joinMany  or  joinOne  creates a new  Query T  that has its own  where  property.  var   query   =   new   Query Question ();  var   join   =   query . joinMany (( question )   =   question . answers ) \n   .. where . isCorrect   =   whereEqualTo ( true );     An  ManagedSet  is serialized into a  List  of  Map s, and therefore the encoded JSON will be an array of objects.", 
            "title": "More on Joins and Relationships"
        }, 
        {
            "location": "/tut/model-relationships-and-joins/#next-deployment", 
            "text": "", 
            "title": "Next: Deployment"
        }, 
        {
            "location": "/tut/deploying-and-other-fun-things/", 
            "text": "Deploying an Aqueduct Application\n\n\nWe've only touched on a small part of Aqueduct, but we've hit the fundamentals pretty well. The rest of the documentation should lead you towards more specific features, in a less hand-holding way. A lot of the code you have written throughout the tutorial is part of the templates that ship with Aqueduct. So it's likely that this is the last time you'll write the 'setup code' you wrote throughout this tutorial. To create a project from the templates, run:\n\n\naqueduct create my_project\n\n\n\n\n\nDeploying Aqueduct applications involves using the \naqueduct serve\n command to run the web server, and \naqueduct db\n to upload your application's database schema to a live database. See the \nDeployment Guide\n for detailed instructions.", 
            "title": "5. Deploying"
        }, 
        {
            "location": "/tut/deploying-and-other-fun-things/#deploying-an-aqueduct-application", 
            "text": "We've only touched on a small part of Aqueduct, but we've hit the fundamentals pretty well. The rest of the documentation should lead you towards more specific features, in a less hand-holding way. A lot of the code you have written throughout the tutorial is part of the templates that ship with Aqueduct. So it's likely that this is the last time you'll write the 'setup code' you wrote throughout this tutorial. To create a project from the templates, run:  aqueduct create my_project  Deploying Aqueduct applications involves using the  aqueduct serve  command to run the web server, and  aqueduct db  to upload your application's database schema to a live database. See the  Deployment Guide  for detailed instructions.", 
            "title": "Deploying an Aqueduct Application"
        }, 
        {
            "location": "/http/overview/", 
            "text": "Tasks\n\n\nAqueduct responds to HTTP requests. The main concepts and tasks are:\n\n\n\n\nUsing a \nRouter\n to dispatch \nRequest\ns to a \nRequestController\n\n\nUsing \nRequestController\ns to process, modify and respond to \nRequest\ns\n\n\nSubclassing \nRequestSink\n to handle application initialization\n\n\nRunning Aqueduct Applications with \naqueduct serve\n\n\nSubclassing \nHTTPController\n to group routes and create responses\n\n\nUsing helpful controllers like \nQueryController\nT\n and \nManagedObjectController\nT\n.\n\n\nDecoding HTTP request bodies with \nHTTPBody\n and encoding objects into HTTP response bodies with \nResponse\n\n\nHandling CORS requests with \nCORSPolicy\n\n\n\n\nGuides\n\n\n\n\nStructure of Aqueduct Application\n\n\nRequest and Response Objects\n\n\nHandling Requests\n\n\nThe RequestSink\n\n\nRouting\n\n\nHTTPControllers\n\n\nConfiguration Files, CORS and SSL", 
            "title": "Overview"
        }, 
        {
            "location": "/http/overview/#tasks", 
            "text": "Aqueduct responds to HTTP requests. The main concepts and tasks are:   Using a  Router  to dispatch  Request s to a  RequestController  Using  RequestController s to process, modify and respond to  Request s  Subclassing  RequestSink  to handle application initialization  Running Aqueduct Applications with  aqueduct serve  Subclassing  HTTPController  to group routes and create responses  Using helpful controllers like  QueryController T  and  ManagedObjectController T .  Decoding HTTP request bodies with  HTTPBody  and encoding objects into HTTP response bodies with  Response  Handling CORS requests with  CORSPolicy", 
            "title": "Tasks"
        }, 
        {
            "location": "/http/overview/#guides", 
            "text": "Structure of Aqueduct Application  Request and Response Objects  Handling Requests  The RequestSink  Routing  HTTPControllers  Configuration Files, CORS and SSL", 
            "title": "Guides"
        }, 
        {
            "location": "/http/structure/", 
            "text": "Aqueduct Application Structure\n\n\nAn Aqueduct application created with the command-line tool \naqueduct create\n will create an application with the structure discussed in this document. See \nGetting Started\n for installation and usage.\n\n\nAn Aqueduct application is a tree of \nRequestController\ns. A \nRequestController\n takes a \nRequest\n and either creates a \nResponse\n or passes the \nRequest\n to another \nRequestController\n in the tree. More often than not, \nRequestController\n is subclassed to create reusable components to build a request processing pipeline. Some commonly used \nRequestController\ns are \nRequestSink\n, \nAuthorizer\n, \nRouter\n and \nHTTPController\n.\n\n\nThe root of the \nRequestController\n tree is always an application-specific subclass of \nRequestSink\n. The only requirement of an Aqueduct application is that a subclass of this type is declared in an application package and is visible from its top-level library file. A \nRequestSink\n is not only the first \nRequestController\n that receives requests, its initialization process creates all of the other \nRequestController\ns in an application. See \nRequest Sink\n for more details.\n\n\nA \nRequestSink\n sends all \nRequest\ns to its \nRouter\n. A \nRouter\n figures out which \nRequestController\n to send a \nRequest\n to based on the HTTP request path. Setting up which \nRequestController\n receives requests for a particular path (or paths) is called routing. Routing is done by overriding \nRequestSink\n's \nsetupRouter\n method. If no \nRequestController\n has matches the path of the request, the \nRouter\n responds with a 404 and dumps the request. See \nRouting\n for more details.\n\n\nOnce past a router, a \nRequest\n typically goes through an \nAuthorizer\n then an \nHTTPController\n subclass. An \nAuthorizer\n validates the Authorization header of a request, and attaches authorization information to the request so that the next controller can use it. If an \nAuthorizer\n rejects a request, it responds to it with a 401 and does not pass it to the next controller. See \nAuthorization\n for more details.\n\n\nAn \nHTTPController\n subclass handles all of the operations for an HTTP resource collection (or single resource in that collection). For example, a subclass of \nHTTPController\n named \nUserController\n would likely be able to list users, show a single user, create a new user, delete a user or update an existing user. An \nHTTPController\n always responds to any request it receives. See \nHTTPControllers\n for more details.\n\n\nFilesystem Structure\n\n\nThe directory structure of an Aqueduct application typically looks like this:\n\n\napplication_name/\n  application_name.dart\n  application_name_request_sink.dart\n  controllers/\n    user_controller.dart\n\n\n\n\n\nAqueduct applications are run by running \naqueduct serve\n in project directory (here, \napplication_name\n). The top-level library file, \napplication_name/application_name.dart\n, must at least import \napplication_name_request_sink.dart\n so that \naqueduct\n serve can see it. See \nDeploying\n for more details on this command.", 
            "title": "Application Structure"
        }, 
        {
            "location": "/http/structure/#aqueduct-application-structure", 
            "text": "An Aqueduct application created with the command-line tool  aqueduct create  will create an application with the structure discussed in this document. See  Getting Started  for installation and usage.  An Aqueduct application is a tree of  RequestController s. A  RequestController  takes a  Request  and either creates a  Response  or passes the  Request  to another  RequestController  in the tree. More often than not,  RequestController  is subclassed to create reusable components to build a request processing pipeline. Some commonly used  RequestController s are  RequestSink ,  Authorizer ,  Router  and  HTTPController .  The root of the  RequestController  tree is always an application-specific subclass of  RequestSink . The only requirement of an Aqueduct application is that a subclass of this type is declared in an application package and is visible from its top-level library file. A  RequestSink  is not only the first  RequestController  that receives requests, its initialization process creates all of the other  RequestController s in an application. See  Request Sink  for more details.  A  RequestSink  sends all  Request s to its  Router . A  Router  figures out which  RequestController  to send a  Request  to based on the HTTP request path. Setting up which  RequestController  receives requests for a particular path (or paths) is called routing. Routing is done by overriding  RequestSink 's  setupRouter  method. If no  RequestController  has matches the path of the request, the  Router  responds with a 404 and dumps the request. See  Routing  for more details.  Once past a router, a  Request  typically goes through an  Authorizer  then an  HTTPController  subclass. An  Authorizer  validates the Authorization header of a request, and attaches authorization information to the request so that the next controller can use it. If an  Authorizer  rejects a request, it responds to it with a 401 and does not pass it to the next controller. See  Authorization  for more details.  An  HTTPController  subclass handles all of the operations for an HTTP resource collection (or single resource in that collection). For example, a subclass of  HTTPController  named  UserController  would likely be able to list users, show a single user, create a new user, delete a user or update an existing user. An  HTTPController  always responds to any request it receives. See  HTTPControllers  for more details.", 
            "title": "Aqueduct Application Structure"
        }, 
        {
            "location": "/http/structure/#filesystem-structure", 
            "text": "The directory structure of an Aqueduct application typically looks like this:  application_name/\n  application_name.dart\n  application_name_request_sink.dart\n  controllers/\n    user_controller.dart  Aqueduct applications are run by running  aqueduct serve  in project directory (here,  application_name ). The top-level library file,  application_name/application_name.dart , must at least import  application_name_request_sink.dart  so that  aqueduct  serve can see it. See  Deploying  for more details on this command.", 
            "title": "Filesystem Structure"
        }, 
        {
            "location": "/http/request_and_response/", 
            "text": "Request and Response Objects\n\n\nIn Aqueduct, HTTP requests and responses are instances of \nRequest\n and \nResponse\n, respectively. For every HTTP request an application receives, an instance of \nRequest\n is created. A \nResponse\n must be created for each \nRequest\n. Requests pass through a series of \nRequestControllers\n to be validated, modified and finally responded to.\n\n\nThe Request Object\n\n\nAn instance of \nRequest\n has the information in an HTTP request. They are automatically created when the application receives an HTTP request and are passed to your application's \nRequestSink\n. A \nRequest\n also has additional storage to collect information as it passes through \nRequestController\ns. A \nRequest\n is a wrapper around the Dart standard library \nHttpRequest\n and its values - such as headers - can be accessed through its \ninnerRequest\n. (Just don't write to its \nResponse\n - Aqueduct does that.)\n\n\nA \nRequest\n has an \nHTTPBody\n property, \nbody\n. This property contains the HTTP request body. An \nHTTPBody\n decodes the contents of a request body from a transmission format like JSON or XML into Dart objects, like \nMap\n, \nString\n and \nList\n. The mechanism to decode the body is determined by decoders available in \nHTTPBody\n. By default, decoders exist for text, JSON and form data. New decoders can be added with \nHTTPBody.addDecoder()\n.\n\n\nA \nRequest\n may go through many \nRequestController\ns before it is finally responded to. These \nRequestController\ns may validate or add more information to the request as it passes through. For example, an \nAuthorizer\n - a subclass of \nRequestController\n - will validate the Authorization header of a request. Once validated, it will add authorization info to the request and pass it to the next \nRequestController\n. The next controller then has access to the request's authorization info.\n\n\nThese additional values are added to a \nRequest\n's \nattachments\n property. A \nRequest\n also has two built-in attachments, \nauthorization\n and \npath\n. \nauthorization\n contains authorization information created by an \nAuthorizer\n and \npath\n has request path information created by a \nRouter\n.\n\n\nRequest\ns are responded to by invoking \nrespond\n on them. Instances of \nRequestController\n invoke this method as part of their  on your behalf (see \nRequestControllers\n). Once a request has been responded to, it \ncannot\n be responded to again. Because \nRequestController\ns invoke \nrespond\n on your behalf, it is important that you never invoke \nrespond\n explicitly - otherwise a request controller will try responding to an already responded to request.\n\n\nResponse Objects and HTTP Body Encoding\n\n\nAn instance of \nResponse\n represents all of the information needed to send a response to a client: a status code, HTTP headers and an HTTP body. There are a number of convenience constructors for \nResponse\n for commonly used status codes. For example, \nResponse.ok\n creates a 200 OK status code response.\n\n\nvar\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n({\nkey\n:\n \nvalue\n});\n\n\n\n\n\n\nResponse\ns are returned from a \nRequestController\n's \nprocessRequest\n and Aqueduct manages sending that response back to the client.  Therefore, subclasses of \nRequestController\n must override \nprocessRequest\n to create a \nResponse\n. Some subclasses of \nRequestController\n, like \nHTTPController\n, override this method and allow \nResponse\ns to be created in more meaningful ways.\n\n\nA \nResponse\n's body gets encoded according to its Content-Type. The \nResponse\n class has a set of encoders that will take Dart objects and encode them to data that will be the HTTP response body. By default, JSON and text are supported encoders, but new ones can be added with \nResponse.addEncoder\n.\n\n\nThe type of the \nbody\n property of a \nResponse\n depends the content type of the response. More often than not, the content type is JSON and the \nbody\n can be anything that can be passed to \nJSON.encode\n. This means \nMap\ns and \nList\ns that contain only \nString\n, \nint\n, \ndouble\n, \nbool\n or other \nMap\ns and \nList\ns that contain only these types, too.\n\n\nValues that implement \nHTTPSerializable\n (or are a \nList\nHTTPSerializable\n) can also be used as the \nbody\n of a \nResponse\n. This interface allows any Dart object to be represented as a \nMap\n.\n\n\nThe content type of a \nResponse\n is set through its \ncontentType\n property.\n\n\nvar object = new ObjectThatImplementsHTTPSerializable();\nvar response = new Response.ok(object)\n  ..contentType = ContentType.JSON;\n\n\n\n\n\nIf the body cannot be encoded, an exception is thrown and a 500 status code is returned to the HTTP client.", 
            "title": "Request and Response Objects"
        }, 
        {
            "location": "/http/request_and_response/#request-and-response-objects", 
            "text": "In Aqueduct, HTTP requests and responses are instances of  Request  and  Response , respectively. For every HTTP request an application receives, an instance of  Request  is created. A  Response  must be created for each  Request . Requests pass through a series of  RequestControllers  to be validated, modified and finally responded to.", 
            "title": "Request and Response Objects"
        }, 
        {
            "location": "/http/request_and_response/#the-request-object", 
            "text": "An instance of  Request  has the information in an HTTP request. They are automatically created when the application receives an HTTP request and are passed to your application's  RequestSink . A  Request  also has additional storage to collect information as it passes through  RequestController s. A  Request  is a wrapper around the Dart standard library  HttpRequest  and its values - such as headers - can be accessed through its  innerRequest . (Just don't write to its  Response  - Aqueduct does that.)  A  Request  has an  HTTPBody  property,  body . This property contains the HTTP request body. An  HTTPBody  decodes the contents of a request body from a transmission format like JSON or XML into Dart objects, like  Map ,  String  and  List . The mechanism to decode the body is determined by decoders available in  HTTPBody . By default, decoders exist for text, JSON and form data. New decoders can be added with  HTTPBody.addDecoder() .  A  Request  may go through many  RequestController s before it is finally responded to. These  RequestController s may validate or add more information to the request as it passes through. For example, an  Authorizer  - a subclass of  RequestController  - will validate the Authorization header of a request. Once validated, it will add authorization info to the request and pass it to the next  RequestController . The next controller then has access to the request's authorization info.  These additional values are added to a  Request 's  attachments  property. A  Request  also has two built-in attachments,  authorization  and  path .  authorization  contains authorization information created by an  Authorizer  and  path  has request path information created by a  Router .  Request s are responded to by invoking  respond  on them. Instances of  RequestController  invoke this method as part of their  on your behalf (see  RequestControllers ). Once a request has been responded to, it  cannot  be responded to again. Because  RequestController s invoke  respond  on your behalf, it is important that you never invoke  respond  explicitly - otherwise a request controller will try responding to an already responded to request.", 
            "title": "The Request Object"
        }, 
        {
            "location": "/http/request_and_response/#response-objects-and-http-body-encoding", 
            "text": "An instance of  Response  represents all of the information needed to send a response to a client: a status code, HTTP headers and an HTTP body. There are a number of convenience constructors for  Response  for commonly used status codes. For example,  Response.ok  creates a 200 OK status code response.  var   response   =   new   Response . ok ({ key :   value });   Response s are returned from a  RequestController 's  processRequest  and Aqueduct manages sending that response back to the client.  Therefore, subclasses of  RequestController  must override  processRequest  to create a  Response . Some subclasses of  RequestController , like  HTTPController , override this method and allow  Response s to be created in more meaningful ways.  A  Response 's body gets encoded according to its Content-Type. The  Response  class has a set of encoders that will take Dart objects and encode them to data that will be the HTTP response body. By default, JSON and text are supported encoders, but new ones can be added with  Response.addEncoder .  The type of the  body  property of a  Response  depends the content type of the response. More often than not, the content type is JSON and the  body  can be anything that can be passed to  JSON.encode . This means  Map s and  List s that contain only  String ,  int ,  double ,  bool  or other  Map s and  List s that contain only these types, too.  Values that implement  HTTPSerializable  (or are a  List HTTPSerializable ) can also be used as the  body  of a  Response . This interface allows any Dart object to be represented as a  Map .  The content type of a  Response  is set through its  contentType  property.  var object = new ObjectThatImplementsHTTPSerializable();\nvar response = new Response.ok(object)\n  ..contentType = ContentType.JSON;  If the body cannot be encoded, an exception is thrown and a 500 status code is returned to the HTTP client.", 
            "title": "Response Objects and HTTP Body Encoding"
        }, 
        {
            "location": "/http/request_controller/", 
            "text": "Handling Requests\n\n\nFor every HTTP request, an instance of \nRequest\n is created. A \nRequestController\n creates a \nResponse\n for a request. Sometimes. Other times, a controller does something with the request and then passes it on to another.\n\n\nAqueduct applications are just a bunch of \nRequestController\ns strung together like a real life assembly line. In an assembly line of cars, the body of a car gets put on a conveyor belt. The first worker puts on a steering wheel, the next puts on tires and the last one paints the car a color. The car is then removed from the conveyor belt and sold. Each worker has a specific job in a specific order - they rely on the rest of the assembly line to complete the car, but their job is isolated.\n\n\nThis conveyor belt is built by chaining together \nRequestController\ns with methods like \npipe\n and \ngenerate\n. Here's an example of some common Aqueduct code:\n\n\nvar\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\nrouter\n\n  \n.\nroute\n(\n/users\n)\n\n  \n.\npipe\n(\nnew\n \nAuthorizer\n(\nauthServer\n))\n\n  \n.\ngenerate\n(()\n \n=\n \nnew\n \nUserController\n());\n\n\n\n\n\n\nThis chains together a \nRouter\n, an \nAuthorizer\n and a \nUserController\n - all subclasses of \nRequestController\n. So, let's say this router gets a request - if the path matches \n/users\n, it goes to the \nAuthorizer\n, and if its authorized, it goes to a \nUserController\n, which responds to the request.\n\n\nA request can drop out of the assembly line before it reaches the end. If the request's path didn't match \n/users\n, a 404 response would be created and the request would never get to the \nAuthorizer\n. If the request wasn't authorized, a 401 response would be created and the request would never get to the \nUserController\n.\n\n\nMore generally, \nRequestController\ns take a \nRequest\n as input. If they want to respond to the request, they create a response. Otherwise, they send the request to the next controller in line.\n\n\nBoth \npipe\n and \ngenerate\n set up this relationship between controllers; difference being that \ngenerate\n creates a new instance of the controller each time a request comes through and \npipe\n just reuses the same one. (That's why the argument is a closure that creates a new \nUserController\n in this example, not just a \nUserController\n instance.)\n\n\nThe reason this distinction exists is because some controllers will have properties that reference the request they are currently processing. Since Aqueduct applications handle multiple \nRequest\ns at a time, these controllers would get their properties changed while waiting for an asynchronous operation to complete if there were only one instance.\n\n\nThe most commonly used controller - \nHTTPController\n - must be generated, whereas an \nAuthorizer\n holds no state and does not. \nRequestController\n subclasses that require generation have \n@cannotBeReused\n metadata and will throw an exception immediately at startup if not.\n\n\nThere's also a \nlisten\n method that takes a closure to process the request instead of an object (that closure still gets wrapped in a \nRequestController\n under the hood):\n\n\nvar\n \nrouter\n \n=\n \nnew\n \nRouter\n();\n\n\nrouter\n\n  \n.\nroute\n(\n/health\n)\n\n  \n.\nlisten\n((\nreq\n)\n \nasync\n \n=\n \nnew\n \nResponse\n.\nok\n(\nnull\n));\n\n\n\n\n\n\nThe \nroute\n method is unique to a \nRouter\n, but allows for multiple controllers to be chained to the router based on their request path. There's a whole section on \nRouting\n.\n\n\nRequestController\ns serve as the building blocks of an Aqueduct application, but they are rarely used directly. More often than not, an Aqueduct application is built entirely out of \nRouter\n, \nAuthorizer\n and \nHTTPController\n subclasses.\n\n\nException Handling\n\n\nIf an exception is thrown while processing a request, it will be caught by the \nRequestController\n doing the processing. The controller will respond with an appropriate status code and the request is discarded so no more controllers will see it.\n\n\nThere are two types of exceptions that a \nRequestController\n will interpret to return a meaningful status code: \nHTTPResponseException\n and \nQueryException\n. Any other uncaught exceptions will result in a 500 status code error.\n\n\nQueryException\ns are generated by the Aqueduct ORM. A request controller interprets these types of exceptions to return a suitable status code. The following reasons for the exception generate the following status codes:\n\n\n\n\n\n\n\n\nReason\n\n\nStatus Code\n\n\n\n\n\n\n\n\n\n\nA programmer error (bad query syntax)\n\n\n500\n\n\n\n\n\n\nUnique constraint violated\n\n\n409\n\n\n\n\n\n\nInvalid input\n\n\n400\n\n\n\n\n\n\nDatabase can't be reached\n\n\n503\n\n\n\n\n\n\n\n\nAn \nHTTPResponseException\n can be thrown at anytime to escape early from processing and return a response. Exceptions of these type allow you to specify the status code and a message. The message is encoded in a JSON object for the key \"error\". Some classes in Aqueduct will throw an exception of this kind if some precondition isn't met. You may add your own try-catch blocks to request processing code to either catch and reinterpret the behavior of \nHTTPResponseException\n and \nQueryException\n, or for any other reason.\n\n\nOther than \nHTTPResponseException\ns, exceptions are always logged along with some details of the request that generated the exception. \nHTTPResponseException\ns are not logged, as they are used for control flow and are considered \"normal\" operation.\n\n\nSubclassing RequestController\n\n\nUsing existing subclasses of \nRequestController\n like \nRouter\n, \nAuthorizer\n and \nHTTPController\n cover the majority of Aqueduct use cases. There are times where creating your own \nRequestController\n subclass may make sense.\n\n\nSubclassing \nRequestController\n usually involves overriding its \nprocessRequest\n method. This method takes a \nRequest\n as input and returns either a \nResponse\n or \nRequest\n wrapped in a \nFuture\n.\n\n\nclass\n \nController\n \nextends\n \nRequestController\n \n{\n\n  \n@\noverride\n\n  \nFuture\nRequestOrResponse\n \nprocessRequest\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n      \n...\n \nreturn\n \neither\n \nrequest\n \nor\n \na\n \nnew\n \nResponse\n \n...\n\n  \n}\n\n\n}\n\n\n\n\n\n\nA controller receives \nRequest\ns in this method. If this method returns a \nResponse\n, that response is sent to the HTTP client and no more processing occurs. If this method returns a \nRequest\n, the next controller in the assembly line has this method invoked.\n\n\nA controller must return the same instance of \nRequest\n it receives, but it may attach additional information by adding key-value pairs to the request's \nattachments\n.\n\n\nFor example, an \nAuthorizer\n's pseudo code looks like this:\n\n\nFuture\nRequestOrResponse\n \nprocessRequest\n(\nRequest\n \nrequest\n)\n \nasync\n \n{\n\n    \nif\n \n(\n!\nisAuthorized\n(\nrequest\n))\n \n{\n\n      \nreturn\n \nnew\n \nResponse\n.\nunauthorized\n();\n\n    \n}\n\n\n    \nrequest\n.\nattachments\n[\nauthInfo\n]\n \n=\n \nauthInfoFromRequest\n(\nrequest\n);\n\n    \nreturn\n \nrequest\n;\n\n\n}\n\n\n\n\n\n\nIt's important that the last controller in the assembly line always responds to a request. Typically, this is an instance of an \nHTTPController\n subclass.\n\n\nAqueduct automatically invokes \nprocessRequest\n on controllers inside a try-catch block. This allows uncaught errors to always send a response to the HTTP client and attaches things like CORS headers.", 
            "title": "Handling Requests: Fundamentals"
        }, 
        {
            "location": "/http/request_controller/#handling-requests", 
            "text": "For every HTTP request, an instance of  Request  is created. A  RequestController  creates a  Response  for a request. Sometimes. Other times, a controller does something with the request and then passes it on to another.  Aqueduct applications are just a bunch of  RequestController s strung together like a real life assembly line. In an assembly line of cars, the body of a car gets put on a conveyor belt. The first worker puts on a steering wheel, the next puts on tires and the last one paints the car a color. The car is then removed from the conveyor belt and sold. Each worker has a specific job in a specific order - they rely on the rest of the assembly line to complete the car, but their job is isolated.  This conveyor belt is built by chaining together  RequestController s with methods like  pipe  and  generate . Here's an example of some common Aqueduct code:  var   router   =   new   Router ();  router \n   . route ( /users ) \n   . pipe ( new   Authorizer ( authServer )) \n   . generate (()   =   new   UserController ());   This chains together a  Router , an  Authorizer  and a  UserController  - all subclasses of  RequestController . So, let's say this router gets a request - if the path matches  /users , it goes to the  Authorizer , and if its authorized, it goes to a  UserController , which responds to the request.  A request can drop out of the assembly line before it reaches the end. If the request's path didn't match  /users , a 404 response would be created and the request would never get to the  Authorizer . If the request wasn't authorized, a 401 response would be created and the request would never get to the  UserController .  More generally,  RequestController s take a  Request  as input. If they want to respond to the request, they create a response. Otherwise, they send the request to the next controller in line.  Both  pipe  and  generate  set up this relationship between controllers; difference being that  generate  creates a new instance of the controller each time a request comes through and  pipe  just reuses the same one. (That's why the argument is a closure that creates a new  UserController  in this example, not just a  UserController  instance.)  The reason this distinction exists is because some controllers will have properties that reference the request they are currently processing. Since Aqueduct applications handle multiple  Request s at a time, these controllers would get their properties changed while waiting for an asynchronous operation to complete if there were only one instance.  The most commonly used controller -  HTTPController  - must be generated, whereas an  Authorizer  holds no state and does not.  RequestController  subclasses that require generation have  @cannotBeReused  metadata and will throw an exception immediately at startup if not.  There's also a  listen  method that takes a closure to process the request instead of an object (that closure still gets wrapped in a  RequestController  under the hood):  var   router   =   new   Router ();  router \n   . route ( /health ) \n   . listen (( req )   async   =   new   Response . ok ( null ));   The  route  method is unique to a  Router , but allows for multiple controllers to be chained to the router based on their request path. There's a whole section on  Routing .  RequestController s serve as the building blocks of an Aqueduct application, but they are rarely used directly. More often than not, an Aqueduct application is built entirely out of  Router ,  Authorizer  and  HTTPController  subclasses.", 
            "title": "Handling Requests"
        }, 
        {
            "location": "/http/request_controller/#exception-handling", 
            "text": "If an exception is thrown while processing a request, it will be caught by the  RequestController  doing the processing. The controller will respond with an appropriate status code and the request is discarded so no more controllers will see it.  There are two types of exceptions that a  RequestController  will interpret to return a meaningful status code:  HTTPResponseException  and  QueryException . Any other uncaught exceptions will result in a 500 status code error.  QueryException s are generated by the Aqueduct ORM. A request controller interprets these types of exceptions to return a suitable status code. The following reasons for the exception generate the following status codes:     Reason  Status Code      A programmer error (bad query syntax)  500    Unique constraint violated  409    Invalid input  400    Database can't be reached  503     An  HTTPResponseException  can be thrown at anytime to escape early from processing and return a response. Exceptions of these type allow you to specify the status code and a message. The message is encoded in a JSON object for the key \"error\". Some classes in Aqueduct will throw an exception of this kind if some precondition isn't met. You may add your own try-catch blocks to request processing code to either catch and reinterpret the behavior of  HTTPResponseException  and  QueryException , or for any other reason.  Other than  HTTPResponseException s, exceptions are always logged along with some details of the request that generated the exception.  HTTPResponseException s are not logged, as they are used for control flow and are considered \"normal\" operation.", 
            "title": "Exception Handling"
        }, 
        {
            "location": "/http/request_controller/#subclassing-requestcontroller", 
            "text": "Using existing subclasses of  RequestController  like  Router ,  Authorizer  and  HTTPController  cover the majority of Aqueduct use cases. There are times where creating your own  RequestController  subclass may make sense.  Subclassing  RequestController  usually involves overriding its  processRequest  method. This method takes a  Request  as input and returns either a  Response  or  Request  wrapped in a  Future .  class   Controller   extends   RequestController   { \n   @ override \n   Future RequestOrResponse   processRequest ( Request   request )   async   { \n       ...   return   either   request   or   a   new   Response   ... \n   }  }   A controller receives  Request s in this method. If this method returns a  Response , that response is sent to the HTTP client and no more processing occurs. If this method returns a  Request , the next controller in the assembly line has this method invoked.  A controller must return the same instance of  Request  it receives, but it may attach additional information by adding key-value pairs to the request's  attachments .  For example, an  Authorizer 's pseudo code looks like this:  Future RequestOrResponse   processRequest ( Request   request )   async   { \n     if   ( ! isAuthorized ( request ))   { \n       return   new   Response . unauthorized (); \n     } \n\n     request . attachments [ authInfo ]   =   authInfoFromRequest ( request ); \n     return   request ;  }   It's important that the last controller in the assembly line always responds to a request. Typically, this is an instance of an  HTTPController  subclass.  Aqueduct automatically invokes  processRequest  on controllers inside a try-catch block. This allows uncaught errors to always send a response to the HTTP client and attaches things like CORS headers.", 
            "title": "Subclassing RequestController"
        }, 
        {
            "location": "/http/routing/", 
            "text": "Routing\n\n\nEvery HTTP request has a URL. A URL identifies a \nresource\n on a computer. In the early days of the Internet, a resource was a file. For example, the URL \nhttp://www.geocities.com/my_page/image.jpg\n would return the file \nimage.jpg\n from the folder \nmy_page\n on the webserver located at \nwww.geocities.com\n. In a web application today, resources come from many other sources of data, like a database or a connected device. The job of a web application is to provide a resource for a URL, wherever that resource might come from.\n\n\nA URL is made up of many parts, some of which are optional. The typical URL we see as humans looks like this: \nhttp://stablekernel.com/about\n. Most people recognize that typing this URL into a browser would take them to our company's \"About\" page. In other words, our \"About\" page is a resource and the URL identifies it.\n\n\nMore generally, the \"About\" page URL has the three required components of a URL: a \nscheme\n (\nhttp\n), a \nhost\n (\nstablekernel.com\n) and a \npath\n (\n/about\n). The host specifies the computer responsible for providing the resource, the path indicates the 'name' of the resource and the scheme lets both the requester and the host know how they should exchange information.\n\n\nAn Aqueduct application receives requests when the scheme is \nhttp\n (or \nhttps\n) and the host refers to a machine where the application is running. Therefore, once the application gets the request, it only cares about the remaining component: the path.\n\n\nIn Aqueduct, a \nRouter\n splits a stream of \nRequest\ns coming into the application based on their path. This process is known as \nrouting\n. When an application starts up, routes are registered in a subclass of \nRequestSink\n. Each registered route creates a new stream of requests that \nRequestController\ns can listen to.\n\n\nWhen an incoming request's path matches a route, the router will send the request to the next listener for that route. Typically, routing is the first processing step a request goes through in an Aqueduct application.\n\n\nRoute Specifications Match HTTP Request Paths\n\n\nA route is registered by invoking \nRouter.route\n. This method takes a \nroute specification\n - a \nString\n with some syntax rules that will match the path of a request. This registration occurs when an application first starts by overriding \nRequestSink.setupRouter\n. For example:\n\n\nclass\n \nMyRequestSink\n \nextends\n \nRequestSink\n \n{\n\n  \nMyRequestSink\n(\nApplicationConfiguration\n \nconfig\n)\n:\n \nsuper\n(\nconfig\n);\n\n\n  \n@\noverride\n\n  \nvoid\n \nsetupRouter\n(\nRouter\n \nrouter\n)\n \n{\n\n    \nrouter\n\n      \n.\nroute\n(\n/users\n)\n\n      \n.\nlisten\n((\nreq\n)\n \n{...});\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe argument to \nroute\n is the route specification string. This particular route matches the path \n/users\n. That is, a request for the URL \nhttp://myserver.com/users\n will be sent to the \nlisten\n closure. (Leading and trailing slashes are stripped out when routes are compiled, so including them has no effect, but it is good style to show a leading slash.)\n\n\nA path can have multiple segments (the characters between slashes). For example, the path \n/users/foo\n has two path segments: \nusers\n and \nfoo\n. Routes, too, have segments. A router matches each segment of a path against each segment of a route specification. The path and the route must also have the same number of segments. Thus, the route specification \n/users/foo\n would match the path \n/users/foo\n, but not \n/users\n, \n/users/7\n or \n/users/foo/1\n.\n\n\nA route specification can have \npath variables\n. A path variable is a route segment that always succeeds in matching a path segment, and that segment is stored so that later controllers can use its value. In a route specification, a path variable starts with a colon (\n:\n). The name of the variable follows this colon. For example, consider the following route that declares a path variable named \nuserID\n:\n\n\nrouter\n.\nroute\n(\n/users/:userID\n)\n\n\n\n\n\n\nThis route specification will match \n/users/1\n, \n/users/2\n, \n/users/foo\n, etc. The value of \nuserID\n is \n1\n, \n2\n and \nfoo\n, respectively. This route won't match \n/users\n or \n/users/1/2\n.\n\n\nRoutes may have optional path segments. This allows a group of routes that all refer to the same resource collection to go to the same controller. For example, the requests \n/users\n and \n/users/1\n can both be covered by a single route specification.\n\n\nAn optional path segment has square brackets (\n[]\n) around it. The brackets can go before or after slashes. For example, the following two syntaxes register a route that accepts both \n/users\n and \n/users/:userID\n:\n\n\nroute\n(\n/users/[:userID]\n)\n\n\nroute\n(\n/users[/:userID]\n)\n\n\n\n\n\n\nConceptually, a request with a path of \n/users/1\n identifies a single user, where \n/users\n identifies all users. Optional segments are used to create better code structure by forwarding requests that deal with a specific type of resource to the same request controller. Therefore, the code to handle one user or multiple users is written in the same place.\n\n\nYou may have any number of optional segments in a route specification. Each optional segment must be nested. The following route would match \n/a\n, \n/a/b\n and \n/a/b/c\n (but not \n/a/c\n):\n\n\nroute\n(\n/a/[b/[c]]\n)\n\n\n\n\n\n\nIt's pretty rare to have more than one optional segment in a route. In most circumstances, a good API has routes with just one optional segment. The first segment is the type of the resource and the second segment is an optional unique identifier for a specific resource of that type. More generally, a typical route is \n/type/[:id]\n. It is also fairly rare to have an optional literal segment - optionals are typically used for path variables only.\n\n\nPath variables may restrict their possible values with a regular expression. The expression comes in parentheses following the path variable name. For example, the following route specification limits \nuserID\n to numbers only:\n\n\nroute\n(\n/users/:userID([0-9]+)\n)\n\n\n\n\n\n\nThis regular expression would only apply to the \n:userID\n segment. Note that capture groups and parentheses in general can't be included in a route's regular expression.\n\n\nEverything in between the parentheses is evaluated as the regular expression. Therefore, any additional spaces or characters will be a part of the regular expression. Since spaces aren't valid in a URL, you don't want spaces in a regular expression.\n\n\nFinally, a route specification may have a special 'match-all' token, the asterisk (\n*\n). This token allows for any remaining request path to be matched, regardless of its contents or length. For example, the route specification \n/users/*\n would match the following paths:\n\n\n/users\n/users/1\n/users/foo\n/users/foo/bar\n/users/foo/bar/something/else/and/this/goes/on/forever\n\n\n\n\n\nThis token is used when another medium is going to interpret the URL. For example, a request controller that reads a file might have a route \n/file/*\n. It uses everything after \n/file\n to figure out the path on the filesystem.\n\n\nAccessing Path Variables\n\n\nInformation that a router parses from a request path - like path variables - are stored in a \nRequest\n's \npath\n. As a \nRequest\n passes through a \nRouter\n, its \npath\n is set to an instance of this type. Later controllers access the \npath\n of a \nRequest\n to help determine which resource the request is referring to. The \npath\n is an instance of \nHTTPRequestPath\n.\n\n\nThe \nvariables\n of an \nHTTPRequestPath\n are a \nMap\nString, String\n, where the key is the name of the variable in the route specification and the value is the matching path segment in an incoming request. For example, consider a route specification \n/users/:id\n. When a request with path \n/users/1\n is routed, this specification will match. So, a controller would access it like so:\n\n\nvar\n \nidentifier\n \n=\n \nrequest\n.\npath\n.\nvariables\n[\nid\n];\n\n\n// identifier = \n1\n\n\n\n\n\n\nThe values in \nvariables\n are always \nString\ns, since a request path is a \nString\n. \nRequestController\ns may parse path variables into types like \nint\n.\n\n\nHTTPController\n uses path variables to select a responder method to handle a request.\n\n\nFailed Matches Return 404\n\n\nA \nRouter\n will return a \nResponse.notFound\n - a response with status code 404 - if it receives a request that no route is registered for. The router will not send this request downstream to further listeners. This behavior may be overridden by providing a closure to \nRouter.unhandledRequestController\n, but the use-case is rare.", 
            "title": "Routing"
        }, 
        {
            "location": "/http/routing/#routing", 
            "text": "Every HTTP request has a URL. A URL identifies a  resource  on a computer. In the early days of the Internet, a resource was a file. For example, the URL  http://www.geocities.com/my_page/image.jpg  would return the file  image.jpg  from the folder  my_page  on the webserver located at  www.geocities.com . In a web application today, resources come from many other sources of data, like a database or a connected device. The job of a web application is to provide a resource for a URL, wherever that resource might come from.  A URL is made up of many parts, some of which are optional. The typical URL we see as humans looks like this:  http://stablekernel.com/about . Most people recognize that typing this URL into a browser would take them to our company's \"About\" page. In other words, our \"About\" page is a resource and the URL identifies it.  More generally, the \"About\" page URL has the three required components of a URL: a  scheme  ( http ), a  host  ( stablekernel.com ) and a  path  ( /about ). The host specifies the computer responsible for providing the resource, the path indicates the 'name' of the resource and the scheme lets both the requester and the host know how they should exchange information.  An Aqueduct application receives requests when the scheme is  http  (or  https ) and the host refers to a machine where the application is running. Therefore, once the application gets the request, it only cares about the remaining component: the path.  In Aqueduct, a  Router  splits a stream of  Request s coming into the application based on their path. This process is known as  routing . When an application starts up, routes are registered in a subclass of  RequestSink . Each registered route creates a new stream of requests that  RequestController s can listen to.  When an incoming request's path matches a route, the router will send the request to the next listener for that route. Typically, routing is the first processing step a request goes through in an Aqueduct application.", 
            "title": "Routing"
        }, 
        {
            "location": "/http/routing/#route-specifications-match-http-request-paths", 
            "text": "A route is registered by invoking  Router.route . This method takes a  route specification  - a  String  with some syntax rules that will match the path of a request. This registration occurs when an application first starts by overriding  RequestSink.setupRouter . For example:  class   MyRequestSink   extends   RequestSink   { \n   MyRequestSink ( ApplicationConfiguration   config ) :   super ( config ); \n\n   @ override \n   void   setupRouter ( Router   router )   { \n     router \n       . route ( /users ) \n       . listen (( req )   {...}); \n   }  }   The argument to  route  is the route specification string. This particular route matches the path  /users . That is, a request for the URL  http://myserver.com/users  will be sent to the  listen  closure. (Leading and trailing slashes are stripped out when routes are compiled, so including them has no effect, but it is good style to show a leading slash.)  A path can have multiple segments (the characters between slashes). For example, the path  /users/foo  has two path segments:  users  and  foo . Routes, too, have segments. A router matches each segment of a path against each segment of a route specification. The path and the route must also have the same number of segments. Thus, the route specification  /users/foo  would match the path  /users/foo , but not  /users ,  /users/7  or  /users/foo/1 .  A route specification can have  path variables . A path variable is a route segment that always succeeds in matching a path segment, and that segment is stored so that later controllers can use its value. In a route specification, a path variable starts with a colon ( : ). The name of the variable follows this colon. For example, consider the following route that declares a path variable named  userID :  router . route ( /users/:userID )   This route specification will match  /users/1 ,  /users/2 ,  /users/foo , etc. The value of  userID  is  1 ,  2  and  foo , respectively. This route won't match  /users  or  /users/1/2 .  Routes may have optional path segments. This allows a group of routes that all refer to the same resource collection to go to the same controller. For example, the requests  /users  and  /users/1  can both be covered by a single route specification.  An optional path segment has square brackets ( [] ) around it. The brackets can go before or after slashes. For example, the following two syntaxes register a route that accepts both  /users  and  /users/:userID :  route ( /users/[:userID] )  route ( /users[/:userID] )   Conceptually, a request with a path of  /users/1  identifies a single user, where  /users  identifies all users. Optional segments are used to create better code structure by forwarding requests that deal with a specific type of resource to the same request controller. Therefore, the code to handle one user or multiple users is written in the same place.  You may have any number of optional segments in a route specification. Each optional segment must be nested. The following route would match  /a ,  /a/b  and  /a/b/c  (but not  /a/c ):  route ( /a/[b/[c]] )   It's pretty rare to have more than one optional segment in a route. In most circumstances, a good API has routes with just one optional segment. The first segment is the type of the resource and the second segment is an optional unique identifier for a specific resource of that type. More generally, a typical route is  /type/[:id] . It is also fairly rare to have an optional literal segment - optionals are typically used for path variables only.  Path variables may restrict their possible values with a regular expression. The expression comes in parentheses following the path variable name. For example, the following route specification limits  userID  to numbers only:  route ( /users/:userID([0-9]+) )   This regular expression would only apply to the  :userID  segment. Note that capture groups and parentheses in general can't be included in a route's regular expression.  Everything in between the parentheses is evaluated as the regular expression. Therefore, any additional spaces or characters will be a part of the regular expression. Since spaces aren't valid in a URL, you don't want spaces in a regular expression.  Finally, a route specification may have a special 'match-all' token, the asterisk ( * ). This token allows for any remaining request path to be matched, regardless of its contents or length. For example, the route specification  /users/*  would match the following paths:  /users\n/users/1\n/users/foo\n/users/foo/bar\n/users/foo/bar/something/else/and/this/goes/on/forever  This token is used when another medium is going to interpret the URL. For example, a request controller that reads a file might have a route  /file/* . It uses everything after  /file  to figure out the path on the filesystem.", 
            "title": "Route Specifications Match HTTP Request Paths"
        }, 
        {
            "location": "/http/routing/#accessing-path-variables", 
            "text": "Information that a router parses from a request path - like path variables - are stored in a  Request 's  path . As a  Request  passes through a  Router , its  path  is set to an instance of this type. Later controllers access the  path  of a  Request  to help determine which resource the request is referring to. The  path  is an instance of  HTTPRequestPath .  The  variables  of an  HTTPRequestPath  are a  Map String, String , where the key is the name of the variable in the route specification and the value is the matching path segment in an incoming request. For example, consider a route specification  /users/:id . When a request with path  /users/1  is routed, this specification will match. So, a controller would access it like so:  var   identifier   =   request . path . variables [ id ];  // identifier =  1   The values in  variables  are always  String s, since a request path is a  String .  RequestController s may parse path variables into types like  int .  HTTPController  uses path variables to select a responder method to handle a request.", 
            "title": "Accessing Path Variables"
        }, 
        {
            "location": "/http/routing/#failed-matches-return-404", 
            "text": "A  Router  will return a  Response.notFound  - a response with status code 404 - if it receives a request that no route is registered for. The router will not send this request downstream to further listeners. This behavior may be overridden by providing a closure to  Router.unhandledRequestController , but the use-case is rare.", 
            "title": "Failed Matches Return 404"
        }, 
        {
            "location": "/http/request_sink/", 
            "text": "Application Initialization and the RequestSink\n\n\nThe only requirement of an Aqueduct application is that it has exactly one \nRequestSink\n subclass. This subclass handles the initialization of an application, including setting up routes, authorization and database connections.\n\n\nBy convention, a \nRequestSink\n subclass is declared in its own file named \nlib/\napplication_name\n_request_sink.dart\n. This file must visible to the application library file. (In an application named \nfoo\n, the library file is \nlib/foo.dart\n.) An example directory structure:\n\n\nwildfire/\n  lib/\n    wildfire.dart\n    wildfire_request_sink.dart\n    controllers/\n      user_controller.dart      \n    ...\n\n\n\n\n\nTo make the \nRequestSink\n subclass visible, the file \nwildfire.dart\n imports \nwildfire_request_sink.dart\n:\n\n\nimport\n \nwildfire_request_sink.dart\n;\n\n\n\n\n\n\nApplications are run with the command line tool \naqueduct serve\n. This tool finds the subclass of \nRequestSink\n visible to the application library file.\n\n\nAn Aqueduct application will create multiple instances of a \nRequestSink\n subclass. Each instance has its own \nIsolate\n - Dart's version of a thread - that it will process requests on. This behavior allows an application's code to be replicated across a number of threads.\n\n\nSubclassing RequestSink\n\n\nThe responsibility of a \nRequestSink\n is to set up routes and initialize resources it will use to fulfill requests. There are five initialization methods in \nRequestSink\n, each with its own purpose. The methods and the order they are executed in are as follows:\n\n\n\n\nRequestSink.initializeApplication\n: this \nstatic\n method is called once at the very beginning of an application's startup, before any instances of \nRequestSink\n are created.\n\n\nAn instance of \nRequestSink\n is created with its default constructor.\n\n\nThe method \nsetupRouter\n is invoked on the \nRequestSink\n instance; initialized properties from the constructor are injected into controllers created here.\n\n\nThe method \nwillOpen\n is invoked on the \nRequestSink\n instance.\n\n\nThe method \ndidOpen\n is invoked on the \nRequestSink\n instance.\n\n\n\n\nOnly \nsetupRouter\n is required, but it is extremely common to provide a constructor and implement \nRequestSink.initializeApplication\n. It is rare to use \nwillOpen\n and rarer still to use \ndidOpen\n.\n\n\nAqueduct applications will create more than one instance of \nRequestSink\n and repeat steps 2-5 for each instance. See a later section on multi-threading in Aqueduct applications.\n\n\nThe usage and details for each of these initialization methods is detailed in the following sections.\n\n\nUse RequestSink.initializeApplication for One-Time Initialization\n\n\nSince many instances of \nRequestSink\n will be created in an Aqueduct application, its instance methods and constructor will be called multiple times. An Aqueduct application may often have to execute one-time startup tasks that must not occur more than once. For this purpose, you may implement a \nstatic\n method with the following name and signature in an application's \nRequestSink\n:\n\n\nstatic\n \nFuture\n \ninitializeApplication\n(\nApplicationConfiguration\n \nconfig\n)\n \nasync\n \n{\n\n  \n...\n \ndo\n \none\n \ntime\n \nsetup\n \n...\n\n\n}\n\n\n\n\n\n\nA common use of this method is to set up resources that will be shared across isolates or unique persistent connections to remote services. This method can modify \nApplicationConfiguration\n prior to \nRequestSink\n instances being created. This allows resources allocated during this one-time setup method can be accessible by each \nRequestSink\n instance.\n\n\nIn its simplest form, \ninitializeApplication\n will often read values from a \nconfiguration file\n and set them in the \nApplicationConfiguration.options\n map. That looks like this:\n\n\nstatic\n \nFuture\n \ninitializeApplication\n(\nApplicationConfiguration\n \nconfig\n)\n \nasync\n \n{\n        \n  \nconfig\n.\noptions\n[\nConfiguration Values\n]\n \n=\n \nnew\n \nConfiguration\n(\nconfig\n.\nconfigurationFilePath\n);;\n\n\n}\n  \n\n\nRequestSink\n(\nApplicationConfiguration\n \nconfig\n)\n \n{\n\n  \nvar\n \nparsedConfigValues\n \n=\n \nconfig\n.\noptions\n[\nConfiguration Values\n];\n\n\n}\n\n\n\n\n\n\nIn a more complex example, Aqueduct applications that use \nscribe\n will implement \ninitializeApplication\n to optimize logging. \nscribe\n works by spawning a new isolate that writes log statements to disk or the console. Other isolates that do work send their log messages to \nscribe\n's logging isolate so that they can move on to more important things. The logging isolate is spawned in \ninitializeApplication\n, and a communication port to that isolate is added to the \nApplicationConfiguration\n. Each \nRequestSink\n grabs that communication port so that it can send messages to the logging isolate later.\n\n\nIt is important to note the behavior of isolates as it relates to Aqueduct and the initialization process. Each isolate has its own heap. \ninitializeApplication\n is executed in the main isolate, whereas each \nRequestSink\n is instantiated in its own isolate. This means that any values stored in \nApplicationConfiguration\n must be safe to pass across isolates - i.e., they can't contain references to closures.\n\n\nAdditionally, any static or global variables that are set in the main isolate \nwill not be set\n in other isolates. Static properties like the encoder and decoder maps created by \nResponse.addEncoder\n and \nHTTPBody.addDecoder\n must not be modified in \ninitializeApplication\n, since these changes will not occur in other isolates. For initialization that is isolate-specific, see later sections.\n\n\nAlso, because static methods cannot be overridden in Dart, it is important that you ensure the name and signature of \ninitializeApplication\n exactly matches what is shown in these code samples. The analyzer can't help you here, unfortunately.\n\n\nUse RequestSink's Constructor to Initialize Resources and Isolate-Specific Configurations\n\n\nA resource, in this context, is something your application will use to fulfill requests. A database connection is an example of a resource. Resources should be created the constructor of a \nRequestSink\n and stored as properties.\n\n\nThe constructor of a \nRequestSink\n must be unnamed and take a single argument of type \nApplicationConfiguration\n. This instance of \nApplicationConfiguration\n will have the same values as the instance in the previous initialization step (\ninitializeApplication\n) and will retain any values this step applied to the configuration. The values in \nApplicationConfiguration\n often contain the details for the resources that should be created - like database connection information. Here is an example:\n\n\nclass\n \nMySink\n \nextends\n \nRequestSink\n \n{\n\n  \nMySink\n(\nApplicationConfiguration\n \nconfig\n)\n \n:\n \nsuper\n(\nconfig\n)\n \n{\n\n    \nvar\n \ndatabaseConnectionInfo\n \n=\n \nconfig\n[\nDatabase Connection Info\n];\n\n    \nvar\n \ndatabaseConnection\n \n=\n \nnew\n \nDatabaseConnection\n()\n\n      \n..\nconnectionInfo\n \n=\n \ndatabaseConnectionInfo\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIsolate specific initialization should also be set in this method.\n\n\nclass\n \nMySink\n \nextends\n \nRequestSink\n \n{\n\n  \nMySink\n(\nApplicationConfiguration\n \nconfig\n)\n \n:\n \nsuper\n(\nconfig\n)\n \n{\n\n    \nResponse\n.\naddEncoder\n(\nnew\n \nContentType\n(\napplication\n,\n \nxml\n),\n \nxmlEncoder\n);\n\n  \n}\n\n\n}\n  \n\n\n\n\n\nAll of the properties of a \nRequestSink\n should be initialized in its constructor. This allows the next phase of initialization - setting up routes - to inject these resources into controllers. For example, a typical \nRequestSink\n will have some property that holds a database connection; this property should be initialized in the constructor.\n\n\nA constructor for a \nRequestSink\n may look like this:\n\n\nclass\n \nWildfireSink\n \nextends\n \nRequestSink\n \n{\n\n  \nstatic\n \nString\n \nConfigurationKey\n \n=\n \nconfig\n;\n\n\n  \nstatic\n \nFuture\n \ninitializeApplication\n(\nApplicationConfiguration\n \nconfig\n)\n \nasync\n \n{\n        \n    \nconfig\n.\noptions\n[\nConfigurationKey\n]\n \n=\n \nnew\n \nConfiguration\n(\nconfig\n.\nconfigurationFilePath\n);\n\n  \n}\n  \n\n  \nWildfireSink\n(\nMap\nString\n,\n \ndynamic\n \nopts\n)\n \n:\n \nsuper\n(\nopts\n)\n \n{\n\n    \nWildfireConfiguration\n \nconfiguration\n \n=\n \nopts\n[\nConfigurationKey\n];\n\n\n    \ncontext\n \n=\n \ncontextWithConnectionInfo\n(\nconfiguration\n.\ndatabase\n);\n\n\n    \nauthServer\n \n=\n \nnew\n \nAuthServer\nUser\n,\n \nToken\n,\n \nAuthCode\n(\nnew\n \nWildfireAuthDelegate\n());\n\n  \n}\n\n\n  \nManagedContext\n \ncontext\n;\n\n  \nAuthServer\n \nauthServer\n;\n\n\n}\n\n\n\n\n\n\nA constructor should never call asynchronous functions. Some resources require asynchronous initialization - e.g., a database connection has to connect to a database - but those must be fully initialized later. (See a later section on Lazy Resources.)\n\n\nSetting up Routes in setupRouter\n\n\nOnce a \nRequestSink\n is instantiated, its \nsetupRouter\n method is invoked. This method takes a \nRouter\n that you must configure with all of the routes your application will respond to. (See \nRouting\n for more details.)\n\n\nWhen setting up routes, you will create many instances of \nRequestController\n. Any resources these controllers need should be injected in their constructor. For example, \nAuthorizer\ns need an instance of \nAuthServer\n to validate a request. The following code is an example of this:\n\n\nclass\n \nMySink\n \nextends\n \nRequestSink\n \n{\n\n  \nMySink\n(\nApplicationConfiguration\n \nconfig\n)\n \n:\n \nsuper\n(\nconfig\n)\n \n{\n  \n    \nauthServer\n \n=\n \nnew\n \nAuthServer\n(...);\n\n  \n}\n\n\n  \nAuthServer\n \nauthServer\n;\n\n\n  \n@\noverride\n\n  \nvoid\n \nsetupRouter\n(\nRouter\n \nrouter\n)\n \n{\n\n    \nrouter\n\n        \n.\nroute\n(\n/path\n)\n\n        \n.\npipe\n(\nnew\n \nAuthorizer\n(\nauthServer\n))\n\n        \n.\nlisten\n((\nreq\n)\n \n=\n \nnew\n \nResponse\n.\nok\n(\nAuthorized!\n));\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThis is the only time routes may be set up in an application, as the \nRouter\n will restructure its registered routes into an optimized, immutable collection after this method is invoked.\n\n\nYou may not call any asynchronous functions in this this method and you should not alter the state of any properties.\n\n\nAfter \nsetupRouter\n has completed, the \nRequestSink.router\n property is set to the router this method configured.\n\n\nPerform Asynchronous Initialization with willOpen\n\n\nFor any initialization that needs to occur asynchronously, you may override \nRequestSink.willOpen\n. This method is asynchronous, and the application will wait for this method to complete before sending any HTTP requests to the request sink. In general, you should avoid using this method and read the later section on Lazy Resources.\n\n\nStart Receiving Requests\n\n\nOnce an \nRequestSink\n sets up its routes and performs asynchronous initialization, the application will hook up the stream of HTTP requests to the \nRequestSink\n and data will start flowing. Just prior to this, one last method is invoked on \nRequestSink\n, \ndidOpen\n. This method is a final callback to the \nRequestSink\n that indicates all initialization has completed.\n\n\nLazy Resources\n\n\nAn Aqueduct application will probably communicate to other servers and databases. A \nRequestSink\n will have properties to represent these connections. Resources like these must open a persistent network connection, a process that is asynchronous by nature. Following the initialization process of a \nRequestSink\n, it may then make sense to create the resources in a constructor and then open them in \nwillOpen\n. And while this could be true, resources like this should manage the opening and closing of their underlying network connection internally.\n\n\nFor example, an object that has a database connection should open it when it goes to execute a query, but doesn't have a valid connection. This is how \nPersistentStore\ns work - they store properties that have all of the information they need to connect to a database when initialized, but do not immediately open a connection. The first time the \nPersistentStore\n has to fulfill a query, it executes a function that opens the database connection. This defers fully loading the resource until it is needed, but there is actually a much more important behavior here.\n\n\nAn Aqueduct application (ideally) will run for a long time. During that time, the servers and databases it connects to may not always be reachable - perhaps they went down to be upgraded or there was an outage of some kind. An Aqueduct application must be able to recover from this. If opening an external connection only happened during startup, an application would not reopen a connection if it went down for some reason. This would be bad.\n\n\nIn the general case, a resource of this nature will have methods that use the underlying connection. These methods must be responsible for ensuring the underlying connection is valid and reopen it (or report failure) if that is not the case. For example, a simple database connection class might implement its \nexecute\n method like so:\n\n\nFuture\n \nexecute\n(\nString\n \nsql\n)\n \nasync\n \n{\n\n  \nif\n \n(\nconnection\n \n==\n \nnull\n \n||\n \n!\nconnection\n.\nisAvailable\n)\n \n{\n\n    \nconnection\n \n=\n \nnew\n \nConnection\n(...);\n\n    \nawait\n \nconnection\n.\nopen\n();\n\n  \n}\n\n\n  \nreturn\n \nawait\n \nconnection\n.\nexecuteSQL\n(\nsql\n);\n\n\n}\n\n\n\n\n\n\nFrom the perspective of a \nRequestController\n, it doesn't care about the underlying connection. It invokes \nexecute\n, and the connection object figures out if it needs to establish a connection first:\n\n\n@\nhttpGet\n \ngetThings\n()\n \nasync\n \n{\n\n  \n// May or may not create a new connection, but will either return\n\n  \n// some things or throw an error.\n\n  \nvar\n \nthings\n \n=\n \nawait\n \nconnection\n.\nexecute\n(\nselect * from things\n);\n\n\n  \n...\n\n\n}\n\n\n\n\n\n\nMulti-threaded Aqueduct Applications\n\n\nAqueduct applications can - and should - be spread across a number of threads. This allows an application to take advantage of multiple CPUs and serve requests faster. In Dart, threads are called \nisolates\n (and have some slight nuances to them that makes the different than a traditional thread). Spreading requests across isolates is an architectural tenet of Aqueduct applications.\n\n\nWhen an application is started with \naqueduct serve\n, a flag indicates how many isolates the application should run on. This defaults to 3. An application will spawn that many isolates and create an instance of \nRequestSink\n for each. When an HTTP request is received, one of the isolates - and its \nRequestSink\n - will receive the request while the others will never see it. Each isolate works independently of each other, running as their own \"web server\" within a web server. Because a \nRequestSink\n initializes itself in the exact same way on each isolate, each isolate behaves exactly the same way.\n\n\nAn isolate can't share memory with another isolate. Therefore, each \nRequestSink\n instance has its own set of resources, like database connections. This behavior also makes connection pooling a non-issue - the connections are effectively pooled by the fact that there is a pool of \nRequestSink\ns. If a \nRequestSink\n creates a database connection and an application is started with four isolates, there will be four database connections total.\n\n\nHowever, there are times where you want your own pool or you want to share a single resource across multiple isolates. For example, an API that must register with some other server (like in a system with an event bus) or must maintain a single persistent connection (like the error pipe to Apple's Push Notification Service or a streaming connection to Nest). These types of resources should be instantiated in \ninitializeApplication\n.\n\n\nPreprocessing Requests and initialHandler\n\n\nBy default, when a \nRequestSink\n receives an HTTP request, it immediately forwards it to its \nrouter\n. However, if an application wishes to take some action prior to routing, use another router or forego routing altogether, the \nRouter\n can be skipped. Every \nRequestSink\n has an \ninitialHandler\n property that it forwards all requests to. This property defaults to the request sink's \nrouter\n, but can be overridden to return something else.\n\n\nIf you only wish to preprocess a request, you may instead override \nRequestSink.willReceiveRequest\n. This asynchronous method takes the incoming \nRequest\n as an argument, but can't respond to it.\n\n\nThe Application Object\n\n\nHidden in all of this discussion is the \nApplication\nT\n object. Because the \naqueduct serve\n command manages creating \nApplication\nT\n instances, your code rarely concerns itself with this type.\n\n\nAn \nApplication\nT\n is the top-level object in an Aqueduct application; it setups up HTTP listeners and channels their requests to \nRequestSink\n instances. The \nApplication\nT\n itself is just a generic container for \nRequestSink\ns; it doesn't do much other than kick everything off.\n\n\nThe application's \nstart\n method will initialize at least one instance of the application's \nRequestSink\n. If something goes wrong during this initialization process, the application will throw an exception and halt starting the server. For example, setting up an invalid route in a \nRequestSink\n subclass would trigger this type of startup exception.\n\n\nAn \nApplication\nT\n has a number of options that determine how it will listen for HTTP requests, such as which port it is listening on or the SSL certificate it will use. These values are available in the application's \nconfiguration\n property, an instance of \nApplicationConfiguration\n.\n\n\nAn application will likely have other kinds of configurable options that are specific to the application, like connection information for a database. For this purpose, \nApplicationConfiguration\n has a \noptions\n property - a \nMap\n - that takes dynamic data. This type of information usually comes from a configuration file or environment variables. This information is simply forwarded to every \nRequestSink\n during their initialization.\n\n\nProperties of an \nApplicationConfiguration\n and \nApplication\nT\n are provided through the \naqueduct serve\n command.", 
            "title": "Initialization and the RequestSink"
        }, 
        {
            "location": "/http/request_sink/#application-initialization-and-the-requestsink", 
            "text": "The only requirement of an Aqueduct application is that it has exactly one  RequestSink  subclass. This subclass handles the initialization of an application, including setting up routes, authorization and database connections.  By convention, a  RequestSink  subclass is declared in its own file named  lib/ application_name _request_sink.dart . This file must visible to the application library file. (In an application named  foo , the library file is  lib/foo.dart .) An example directory structure:  wildfire/\n  lib/\n    wildfire.dart\n    wildfire_request_sink.dart\n    controllers/\n      user_controller.dart      \n    ...  To make the  RequestSink  subclass visible, the file  wildfire.dart  imports  wildfire_request_sink.dart :  import   wildfire_request_sink.dart ;   Applications are run with the command line tool  aqueduct serve . This tool finds the subclass of  RequestSink  visible to the application library file.  An Aqueduct application will create multiple instances of a  RequestSink  subclass. Each instance has its own  Isolate  - Dart's version of a thread - that it will process requests on. This behavior allows an application's code to be replicated across a number of threads.", 
            "title": "Application Initialization and the RequestSink"
        }, 
        {
            "location": "/http/request_sink/#subclassing-requestsink", 
            "text": "The responsibility of a  RequestSink  is to set up routes and initialize resources it will use to fulfill requests. There are five initialization methods in  RequestSink , each with its own purpose. The methods and the order they are executed in are as follows:   RequestSink.initializeApplication : this  static  method is called once at the very beginning of an application's startup, before any instances of  RequestSink  are created.  An instance of  RequestSink  is created with its default constructor.  The method  setupRouter  is invoked on the  RequestSink  instance; initialized properties from the constructor are injected into controllers created here.  The method  willOpen  is invoked on the  RequestSink  instance.  The method  didOpen  is invoked on the  RequestSink  instance.   Only  setupRouter  is required, but it is extremely common to provide a constructor and implement  RequestSink.initializeApplication . It is rare to use  willOpen  and rarer still to use  didOpen .  Aqueduct applications will create more than one instance of  RequestSink  and repeat steps 2-5 for each instance. See a later section on multi-threading in Aqueduct applications.  The usage and details for each of these initialization methods is detailed in the following sections.", 
            "title": "Subclassing RequestSink"
        }, 
        {
            "location": "/http/request_sink/#use-requestsinkinitializeapplication-for-one-time-initialization", 
            "text": "Since many instances of  RequestSink  will be created in an Aqueduct application, its instance methods and constructor will be called multiple times. An Aqueduct application may often have to execute one-time startup tasks that must not occur more than once. For this purpose, you may implement a  static  method with the following name and signature in an application's  RequestSink :  static   Future   initializeApplication ( ApplicationConfiguration   config )   async   { \n   ...   do   one   time   setup   ...  }   A common use of this method is to set up resources that will be shared across isolates or unique persistent connections to remote services. This method can modify  ApplicationConfiguration  prior to  RequestSink  instances being created. This allows resources allocated during this one-time setup method can be accessible by each  RequestSink  instance.  In its simplest form,  initializeApplication  will often read values from a  configuration file  and set them in the  ApplicationConfiguration.options  map. That looks like this:  static   Future   initializeApplication ( ApplicationConfiguration   config )   async   {         \n   config . options [ Configuration Values ]   =   new   Configuration ( config . configurationFilePath );;  }    RequestSink ( ApplicationConfiguration   config )   { \n   var   parsedConfigValues   =   config . options [ Configuration Values ];  }   In a more complex example, Aqueduct applications that use  scribe  will implement  initializeApplication  to optimize logging.  scribe  works by spawning a new isolate that writes log statements to disk or the console. Other isolates that do work send their log messages to  scribe 's logging isolate so that they can move on to more important things. The logging isolate is spawned in  initializeApplication , and a communication port to that isolate is added to the  ApplicationConfiguration . Each  RequestSink  grabs that communication port so that it can send messages to the logging isolate later.  It is important to note the behavior of isolates as it relates to Aqueduct and the initialization process. Each isolate has its own heap.  initializeApplication  is executed in the main isolate, whereas each  RequestSink  is instantiated in its own isolate. This means that any values stored in  ApplicationConfiguration  must be safe to pass across isolates - i.e., they can't contain references to closures.  Additionally, any static or global variables that are set in the main isolate  will not be set  in other isolates. Static properties like the encoder and decoder maps created by  Response.addEncoder  and  HTTPBody.addDecoder  must not be modified in  initializeApplication , since these changes will not occur in other isolates. For initialization that is isolate-specific, see later sections.  Also, because static methods cannot be overridden in Dart, it is important that you ensure the name and signature of  initializeApplication  exactly matches what is shown in these code samples. The analyzer can't help you here, unfortunately.", 
            "title": "Use RequestSink.initializeApplication for One-Time Initialization"
        }, 
        {
            "location": "/http/request_sink/#use-requestsinks-constructor-to-initialize-resources-and-isolate-specific-configurations", 
            "text": "A resource, in this context, is something your application will use to fulfill requests. A database connection is an example of a resource. Resources should be created the constructor of a  RequestSink  and stored as properties.  The constructor of a  RequestSink  must be unnamed and take a single argument of type  ApplicationConfiguration . This instance of  ApplicationConfiguration  will have the same values as the instance in the previous initialization step ( initializeApplication ) and will retain any values this step applied to the configuration. The values in  ApplicationConfiguration  often contain the details for the resources that should be created - like database connection information. Here is an example:  class   MySink   extends   RequestSink   { \n   MySink ( ApplicationConfiguration   config )   :   super ( config )   { \n     var   databaseConnectionInfo   =   config [ Database Connection Info ]; \n     var   databaseConnection   =   new   DatabaseConnection () \n       .. connectionInfo   =   databaseConnectionInfo ; \n   }  }   Isolate specific initialization should also be set in this method.  class   MySink   extends   RequestSink   { \n   MySink ( ApplicationConfiguration   config )   :   super ( config )   { \n     Response . addEncoder ( new   ContentType ( application ,   xml ),   xmlEncoder ); \n   }  }     All of the properties of a  RequestSink  should be initialized in its constructor. This allows the next phase of initialization - setting up routes - to inject these resources into controllers. For example, a typical  RequestSink  will have some property that holds a database connection; this property should be initialized in the constructor.  A constructor for a  RequestSink  may look like this:  class   WildfireSink   extends   RequestSink   { \n   static   String   ConfigurationKey   =   config ; \n\n   static   Future   initializeApplication ( ApplicationConfiguration   config )   async   {         \n     config . options [ ConfigurationKey ]   =   new   Configuration ( config . configurationFilePath ); \n   }   \n\n   WildfireSink ( Map String ,   dynamic   opts )   :   super ( opts )   { \n     WildfireConfiguration   configuration   =   opts [ ConfigurationKey ]; \n\n     context   =   contextWithConnectionInfo ( configuration . database ); \n\n     authServer   =   new   AuthServer User ,   Token ,   AuthCode ( new   WildfireAuthDelegate ()); \n   } \n\n   ManagedContext   context ; \n   AuthServer   authServer ;  }   A constructor should never call asynchronous functions. Some resources require asynchronous initialization - e.g., a database connection has to connect to a database - but those must be fully initialized later. (See a later section on Lazy Resources.)", 
            "title": "Use RequestSink's Constructor to Initialize Resources and Isolate-Specific Configurations"
        }, 
        {
            "location": "/http/request_sink/#setting-up-routes-in-setuprouter", 
            "text": "Once a  RequestSink  is instantiated, its  setupRouter  method is invoked. This method takes a  Router  that you must configure with all of the routes your application will respond to. (See  Routing  for more details.)  When setting up routes, you will create many instances of  RequestController . Any resources these controllers need should be injected in their constructor. For example,  Authorizer s need an instance of  AuthServer  to validate a request. The following code is an example of this:  class   MySink   extends   RequestSink   { \n   MySink ( ApplicationConfiguration   config )   :   super ( config )   {   \n     authServer   =   new   AuthServer (...); \n   } \n\n   AuthServer   authServer ; \n\n   @ override \n   void   setupRouter ( Router   router )   { \n     router \n         . route ( /path ) \n         . pipe ( new   Authorizer ( authServer )) \n         . listen (( req )   =   new   Response . ok ( Authorized! )); \n   }  }   This is the only time routes may be set up in an application, as the  Router  will restructure its registered routes into an optimized, immutable collection after this method is invoked.  You may not call any asynchronous functions in this this method and you should not alter the state of any properties.  After  setupRouter  has completed, the  RequestSink.router  property is set to the router this method configured.", 
            "title": "Setting up Routes in setupRouter"
        }, 
        {
            "location": "/http/request_sink/#perform-asynchronous-initialization-with-willopen", 
            "text": "For any initialization that needs to occur asynchronously, you may override  RequestSink.willOpen . This method is asynchronous, and the application will wait for this method to complete before sending any HTTP requests to the request sink. In general, you should avoid using this method and read the later section on Lazy Resources.", 
            "title": "Perform Asynchronous Initialization with willOpen"
        }, 
        {
            "location": "/http/request_sink/#start-receiving-requests", 
            "text": "Once an  RequestSink  sets up its routes and performs asynchronous initialization, the application will hook up the stream of HTTP requests to the  RequestSink  and data will start flowing. Just prior to this, one last method is invoked on  RequestSink ,  didOpen . This method is a final callback to the  RequestSink  that indicates all initialization has completed.", 
            "title": "Start Receiving Requests"
        }, 
        {
            "location": "/http/request_sink/#lazy-resources", 
            "text": "An Aqueduct application will probably communicate to other servers and databases. A  RequestSink  will have properties to represent these connections. Resources like these must open a persistent network connection, a process that is asynchronous by nature. Following the initialization process of a  RequestSink , it may then make sense to create the resources in a constructor and then open them in  willOpen . And while this could be true, resources like this should manage the opening and closing of their underlying network connection internally.  For example, an object that has a database connection should open it when it goes to execute a query, but doesn't have a valid connection. This is how  PersistentStore s work - they store properties that have all of the information they need to connect to a database when initialized, but do not immediately open a connection. The first time the  PersistentStore  has to fulfill a query, it executes a function that opens the database connection. This defers fully loading the resource until it is needed, but there is actually a much more important behavior here.  An Aqueduct application (ideally) will run for a long time. During that time, the servers and databases it connects to may not always be reachable - perhaps they went down to be upgraded or there was an outage of some kind. An Aqueduct application must be able to recover from this. If opening an external connection only happened during startup, an application would not reopen a connection if it went down for some reason. This would be bad.  In the general case, a resource of this nature will have methods that use the underlying connection. These methods must be responsible for ensuring the underlying connection is valid and reopen it (or report failure) if that is not the case. For example, a simple database connection class might implement its  execute  method like so:  Future   execute ( String   sql )   async   { \n   if   ( connection   ==   null   ||   ! connection . isAvailable )   { \n     connection   =   new   Connection (...); \n     await   connection . open (); \n   } \n\n   return   await   connection . executeSQL ( sql );  }   From the perspective of a  RequestController , it doesn't care about the underlying connection. It invokes  execute , and the connection object figures out if it needs to establish a connection first:  @ httpGet   getThings ()   async   { \n   // May or may not create a new connection, but will either return \n   // some things or throw an error. \n   var   things   =   await   connection . execute ( select * from things ); \n\n   ...  }", 
            "title": "Lazy Resources"
        }, 
        {
            "location": "/http/request_sink/#multi-threaded-aqueduct-applications", 
            "text": "Aqueduct applications can - and should - be spread across a number of threads. This allows an application to take advantage of multiple CPUs and serve requests faster. In Dart, threads are called  isolates  (and have some slight nuances to them that makes the different than a traditional thread). Spreading requests across isolates is an architectural tenet of Aqueduct applications.  When an application is started with  aqueduct serve , a flag indicates how many isolates the application should run on. This defaults to 3. An application will spawn that many isolates and create an instance of  RequestSink  for each. When an HTTP request is received, one of the isolates - and its  RequestSink  - will receive the request while the others will never see it. Each isolate works independently of each other, running as their own \"web server\" within a web server. Because a  RequestSink  initializes itself in the exact same way on each isolate, each isolate behaves exactly the same way.  An isolate can't share memory with another isolate. Therefore, each  RequestSink  instance has its own set of resources, like database connections. This behavior also makes connection pooling a non-issue - the connections are effectively pooled by the fact that there is a pool of  RequestSink s. If a  RequestSink  creates a database connection and an application is started with four isolates, there will be four database connections total.  However, there are times where you want your own pool or you want to share a single resource across multiple isolates. For example, an API that must register with some other server (like in a system with an event bus) or must maintain a single persistent connection (like the error pipe to Apple's Push Notification Service or a streaming connection to Nest). These types of resources should be instantiated in  initializeApplication .", 
            "title": "Multi-threaded Aqueduct Applications"
        }, 
        {
            "location": "/http/request_sink/#preprocessing-requests-and-initialhandler", 
            "text": "By default, when a  RequestSink  receives an HTTP request, it immediately forwards it to its  router . However, if an application wishes to take some action prior to routing, use another router or forego routing altogether, the  Router  can be skipped. Every  RequestSink  has an  initialHandler  property that it forwards all requests to. This property defaults to the request sink's  router , but can be overridden to return something else.  If you only wish to preprocess a request, you may instead override  RequestSink.willReceiveRequest . This asynchronous method takes the incoming  Request  as an argument, but can't respond to it.", 
            "title": "Preprocessing Requests and initialHandler"
        }, 
        {
            "location": "/http/request_sink/#the-application-object", 
            "text": "Hidden in all of this discussion is the  Application T  object. Because the  aqueduct serve  command manages creating  Application T  instances, your code rarely concerns itself with this type.  An  Application T  is the top-level object in an Aqueduct application; it setups up HTTP listeners and channels their requests to  RequestSink  instances. The  Application T  itself is just a generic container for  RequestSink s; it doesn't do much other than kick everything off.  The application's  start  method will initialize at least one instance of the application's  RequestSink . If something goes wrong during this initialization process, the application will throw an exception and halt starting the server. For example, setting up an invalid route in a  RequestSink  subclass would trigger this type of startup exception.  An  Application T  has a number of options that determine how it will listen for HTTP requests, such as which port it is listening on or the SSL certificate it will use. These values are available in the application's  configuration  property, an instance of  ApplicationConfiguration .  An application will likely have other kinds of configurable options that are specific to the application, like connection information for a database. For this purpose,  ApplicationConfiguration  has a  options  property - a  Map  - that takes dynamic data. This type of information usually comes from a configuration file or environment variables. This information is simply forwarded to every  RequestSink  during their initialization.  Properties of an  ApplicationConfiguration  and  Application T  are provided through the  aqueduct serve  command.", 
            "title": "The Application Object"
        }, 
        {
            "location": "/http/http_controller/", 
            "text": "HTTPController\n\n\nThe overwhelming majority of Aqueduct code is written in subclasses of \nHTTPController\n. Instances of this class receive requests for a particular resource. For example, an \nHTTPController\n might handle requests to create, update, delete, read and list users.\n\n\nAn \nHTTPController\n works by selecting one of its methods to respond to a request. This selection is based on the HTTP method and path variables of the request. For example, a \nPOST /users\n would trigger a \ncreateUser\n method to be invoked, whereas a \nGET /users/1\n would trigger its \ngetUserByID\n method. The names of these methods are up to you; the method that gets called is determined by metadata on the method and its parameters.\n\n\nResponder Methods\n\n\nA method that handles a request in an \nHTTPController\n subclass is called a \nresponder method\n. To be a responder method, a method must return a \nFuture\nResponse\n and have \nHTTPMethod\n metadata. Here's an example:\n\n\nclass\n \nUserController\n \nextends\n \nHTTPController\n \n{\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetAllUsers\n()\n \nasync\n \n{\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nawait\n \ngetUsersFromDatabase\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe constant \nhttpGet\n is an instance of \nHTTPMethod\n. When a \nGET\n request is sent to an instance of \nUserController\n, this method is invoked and the \nResponse\n it returns is sent to the HTTP client. There exist \nHTTPMethod\n constants for the major HTTP methods: \nhttpPut\n, \nhttpGet\n, \nhttpPost\n and \nhttpDelete\n. You may use \nHTTPMethod\n for other types of HTTP methods:\n\n\n@\nHTTPMethod\n(\nPATCH\n)\n\n\nFuture\nResponse\n \npatch\n()\n \nasync\n \n{\n \n...\n \n}\n\n\n\n\n\n\nA responder method may have parameters that further qualify its selection based on the path of the HTTP request. For example, the following controller may respond to both \nGET /users\n and \nGET /users/1\n:\n\n\nclass\n \nUserController\n \nextends\n \nHTTPController\n \n{\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetAllUsers\n()\n \nasync\n \n{\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nawait\n \ngetUsersFromDatabase\n());\n\n  \n}\n\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetOneUser\n(\n@\nHTTPPath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nawait\n \ngetAUserFromDatabaseByID\n(\nid\n));\n\n  \n}\n\n\n}\n\n\n\n\n\n\nFor this controller to work correctly, it must be hooked up to a route with an optional \nid\n path variable:\n\n\nrouter\n\n  \n.\nroute\n(\n/users/[:id]\n)\n\n  \n.\ngenerate\n(()\n \n=\n \nnew\n \nUserController\n());\n\n\n\n\n\n\nNotice that the \nid\n parameter in \ngetOneUser\n has \nHTTPPath\n metadata. The argument to \nHTTPPath\n must be the name of the path variable in the route. In this example, the path variable is \nid\n and the argument to \nHTTPPath\n is the same. When a \nGET\n request is delivered to the controller in this example, it is checked for the path variable \nid\n: if it exists, \ngetOneUser\n is invoked, otherwise \ngetAllUsers\n is invoked.\n\n\nThe value of an \nHTTPPath\n parameter will be equal to value of the variable in the incoming request path. A path variable is a \nString\n, but an \nHTTPPath\n parameter can be another type and the value will be parsed into that type. Any type that has a static \nparse(String)\n method can be used as a path variable. If the \nHTTPPath\n parameter is a \nString\n, no parsing occurs.\n\n\nA responder method may have multiple \nHTTPPath\n parameters and the order does not matter. If no responder method exists for the incoming HTTP method, a 405 status code is returned. An \nHTTPController\n will always respond to a request.\n\n\nRequest and Response Bodies\n\n\nAn \nHTTPController\n limits the content type of HTTP request bodies it accepts. By default, an \nHTTPController\n will accept both \napplication/json\n and \napplication/x-www-form-urlencoded\n request bodies for its \nPOST\n and \nPUT\n methods. This can be modified by setting the \nacceptedContentTypes\n property in the constructor.\n\n\nclass\n \nUserController\n \nextends\n \nHTTPController\n \n{\n\n  \nUserController\n()\n \n{\n\n    \nacceptedContentTypes\n \n=\n \n[\nContentType\n.\nJSON\n,\n \nContentType\n.\nXML\n];\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIf a request is made with a content type other than the accepted content types, the controller automatically responds with a unsupported media type (status code 415) response.\n\n\nThe body of an HTTP request is decoded if the content type is supported and there exists a responder method to handle the request. This means two things. First, the body is not decoded if the request is going to be discarded because no responder method was found.\n\n\nSecond, methods on \nHTTPBody\n have two flavors: those that return the contents as a \nFuture\n or those that return the already decoded body. Responder methods can access the already decoded body without awaiting on the \nFuture\n-flavored variants of \nHTTPBody\n:\n\n\n@\nhttpPost\n\n\nFuture\nResponse\n \ncreateThing\n()\n \nasync\n \n{\n\n  \n// do this:\n\n  \nvar\n \nbodyMap\n \n=\n \nrequest\n.\nbody\n.\nasMap\n();\n\n\n  \n// no need to do this:\n\n  \nvar\n \nbodyMap\n \n=\n \nawait\n \nrequest\n.\nbody\n.\ndecodeAsMap\n();\n\n\n  \nreturn\n \n...;\n\n\n}\n\n\n\n\n\n\nAn \nHTTPController\n can also have a default content type for its response bodies. By default, this is \napplication/json\n - any response body is encoded to JSON. This default can be changed by changing \nresponseContentType\n in the constructor:\n\n\nclass\n \nUserController\n \nextends\n \nHTTPController\n \n{\n\n  \nUserController\n()\n \n{\n\n    \nresponseContentType\n \n=\n \nContentType\n.\nXML\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe \nresponseContentType\n is the \ndefault\n response content type. An individual \nResponse\n may set its own \ncontentType\n, which takes precedence over the \nresponseContentType\n. For example, the following controller returns JSON by default, but if the request specifically asks for XML, that's what it will return:\n\n\nclass\n \nUserController\n \nextends\n \nHTTPController\n \n{\n\n  \nUserController\n()\n \n{\n\n    \nresponseContentType\n \n=\n \nContentType\n.\nJSON\n;\n\n  \n}\n\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetUserByID\n(\n@\nHTTPPath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n    \nvar\n \nresponse\n \n=\n \nnew\n \nResponse\n.\nok\n(...);\n\n\n    \nif\n \n(\nrequest\n.\nheaders\n.\nvalue\n(\nHttpHeaders\n.\nACCEPT\n).\nstartsWith\n(\napplication/xml\n))\n \n{\n\n      \nresponse\n.\ncontentType\n \n=\n \nContentType\n.\nXML\n;\n\n    \n}\n\n\n    \nreturn\n \nresponse\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nQuery and Header Values\n\n\nThe \nRequest\n being processed can always be accessed through the \nrequest\n property of a controller. For example, if you want to check for a particular header:\n\n\n@\nhttpGet\n\n\nFuture\nResponse\n \ngetThing\n()\n \nasync\n \n{\n\n  \nif\n \n(\nrequest\n.\ninnerRequest\n.\nheaders\n.\nvalue\n(\nX-Header\n)\n \n!=\n \nnull\n)\n \n{\n\n    \n...\n\n  \n}\n\n\n  \nreturn\n \nnew\n \nResponse\n.\nok\n(...);\n\n\n}\n\n\n\n\n\n\nHTTPController\ns can help when reading header and query parameter values from a request. A responder method can have additional parameters with either \nHTTPQuery\n or \nHTTPHeader\n metadata. For example:\n\n\nFuture\nResponse\n \ngetThing\n(\n\n  \n@\nHTTPQuery\n(\nlimit\n)\n \nint\n \nnumberOfThings\n,\n\n  \n@\nHTTPQuery\n(\noffset\n)\n \nint\n \noffset\n)\n \nasync\n \n{\n\n    \nvar\n \nthings\n \n=\n \nawait\n \ngetThingsBetween\n(\noffset\n,\n \noffset\n \n+\n \nnumberOfThings\n);\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nthings\n);\n\n\n}\n\n\n\n\n\n\nIf the request \n/things?limit=10\noffset=20\n is handled by this method, \nnumberOfThings\n will be 10 and \noffset\n will be 20. \nHTTPQuery\n and \nHTTPHeader\n parameters, like \nHTTPPath\n parameters, are always strings but can be parsed into types that implement \nparse\n. \nHTTPHeader\n metadata on parameters works the same, but read values from headers. \nHTTPQuery\n parameter names are case sensitive, whereas \nHTTPHeader\n parameter names are not.\n\n\nThe position of a parameter with \nHTTPQuery\n or \nHTTPMethod\n metadata in an parameter list matters. In the above example, both \nlimit\n and \noffset\n are \nrequired\n in the request. If these parameters were optional parameters, the they are optional:\n\n\nFuture\nResponse\n \ngetThing\n(\n\n  \n{\n@\nHTTPQuery\n(\nlimit\n)\n \nint\n \nnumberOfThings\n,\n\n  \n@\nHTTPQuery\n(\noffset\n)\n \nint\n \noffset\n})\n \nasync\n \n{\n\n    \noffset\n \n??=\n \n0\n;\n\n    \nnumberOfThings\n \n??=\n \n10\n;\n\n\n    \nvar\n \nthings\n \n=\n \nawait\n \ngetThingsBetween\n(\noffset\n,\n \noffset\n \n+\n \nnumberOfThings\n);\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nthings\n);\n\n\n}\n\n\n\n\n\n\nIn the above example - with curly brackets (\n{}\n) to indicate optional - the request can omit both \nlimit\n and \noffset\n. If omitted, their values are null and the controller can provide defaults. This optional vs. required behavior is true for both \nHTTPQuery\n and \nHTTPHeader\n parameters, but not for \nHTTPPath\n.\n\n\nIf a method has required query or header parameters that are not met by a request, the controller responds with a 400 status code, listing the required parameters that were missing, and \ndoes not\n invoke the responder method.\n\n\nControllers can also declare properties with \nHTTPQuery\n or \nHTTPHeader\n metadata. For example, the following controller will set its \nversion\n property to the header \nX-Version\n for all requests it receives:\n\n\nclass\n \nVersionedController\n \nextends\n \nHTTPController\n \n{\n\n  \n@\nHTTPHeader\n(\nx-version\n)\n\n  \nString\n \nversion\n;\n\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetThings\n()\n \nasync\n \n{\n\n    \n// version = X-Version header from request\n\n    \n...\n\n  \n}\n\n\n}\n\n\n\n\n\n\nProperties that are declared with this metadata default to optional. To make them required, add additional metadata:\n\n\nclass\n \nVersionedController\n \nextends\n \nHTTPController\n \n{\n\n  \n@\nrequiredHTTPParameter\n\n  \n@\nHTTPHeader\n(\nx-version\n)\n\n  \nString\n \nversion\n;\n\n  \n...\n\n\n}\n\n\n\n\n\n\nIf a required property has no value in the request, a 400 is returned and no responder method is called. If the property is optional and not in the request, the value is null.\n\n\nHTTPQuery\n parameters will also assign values from request bodies if the content type is \napplication/x-www-form-urlencoded\n. For example, a \nPOST /endpoint?param=1\n sends \nparam=1\n in the HTTP body, but it is conceptually a query string. Therefore, the following responder method would have the value \n1\n in its \nparam\n parameter:\n\n\n@\nhttpPost\n\n\nFuture\nResponse\n \ncreateThing\n(\n@\nHTTPQuery\n(\nparam\n)\n \nint\n \nparam\n)\n \nasync\n \n{\n\n  \n...\n\n\n}\n\n\n\n\n\n\nMore Specialized HTTPControllers\n\n\nBecause many \nHTTPController\n subclasses will execute \nQueries\n, there are helpful \nHTTPController\n subclasses for reducing boilerplate code.\n\n\nA \nQueryController\nT\n builds a \nQuery\nT\n based on the incoming request. If the request has a body, this \nQuery\nT\n's \nvalues\n property is read from that body. If the request has a path variable, the \nQuery\nT\n assigns a matcher to the primary key value of its \nwhere\n. For example, in a normal \nHTTPController\n that responds to a PUT request, you might write the following:\n\n\n@\nhttpPut\n\n\nFuture\nResponse\n \nupdateUser\n(\n@\nHTTPPath\n(\nid\n)\n \nint\n \nid\n)\n \nasync\n \n{\n\n  \nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n    \n..\nwhere\n.\nid\n \n=\n \nwhereEqualTo\n(\nid\n)\n\n    \n..\nvalues\n \n=\n \n(\nnew\n \nUser\n()..\nreadMap\n(\nrequest\n.\nbody\n.\nasMap\n());\n\n\n  \nreturn\n \nnew\n \nResponse\n.\nok\n(\nawait\n \nquery\n.\nupdateOne\n());\n\n\n}\n\n\n\n\n\n\nA \nQueryController\nT\n builds this query for you. The \nManagedObject\nT\n subclass is the type argument to \nQueryController\nT\n, which has an additional \nquery\n property that is read from the request.\n\n\nclass\n \nUserController\n \nextends\n \nQueryController\nUser\n \n{\n\n  \n// query already exists and is identical to the snippet above\n\n  \nreturn\n \nnew\n \nResponse\n.\nok\n(\nawait\n \nquery\n.\nupdateOne\n());\n\n\n}\n\n\n\n\n\n\nA \nManagedObjectController\nT\n is significantly more powerful; you don't even need to subclass it. It does all the things a CRUD endpoint does without any code. Here's an example usage:\n\n\nrouter\n\n  \n.\nroute\n(\n/users/[:id]\n)\n\n  \n.\ngenerate\n(()\n \n=\n \nnew\n \nManagedObjectController\nUser\n());\n\n\n\n\n\n\nThis controller has the following behavior:\n\n\n\n\n\n\n\n\nRequest\n\n\nAction\n\n\n\n\n\n\n\n\n\n\nPOST /users\n\n\nInserts a user into the database with values from the request body\n\n\n\n\n\n\nGET /users\n\n\nFetches all users in the database\n\n\n\n\n\n\nGET /users/:id\n\n\nFetches a single user by id\n\n\n\n\n\n\nDELETE /users/:id\n\n\nDeletes a single user by id\n\n\n\n\n\n\nPUT /users/:id\n\n\nUpdated a single user by id, using values from the request body\n\n\n\n\n\n\n\n\nThe objects returned from getting the collection - e.g, \nGET /users\n - can be modified with query parameters. For example, the following request will return the users sorted by their name in ascending order:\n\n\nGET /users?sortBy=name,asc\n\n\n\n\n\n\nThe results can be paged (see \nPaging in Advanced Queries\n) with query parameters \noffset\n, \ncount\n, \npageBy\n, \npageAfter\n and \npagePrior\n.\n\n\nA \nManagedObjectController\nT\n can also be subclassed. A subclass allows for callbacks to be overridden to adjust the query before execution, or the results before sending the respond. Each operation - fetch, update, delete, etc. - has a pair of methods to do this. For example, the following subclass alters the query and results before any update via \nPUT\n:\n\n\nclass\n \nUserController\n \nextends\n \nManagedObjectController\nUser\n \n{\n\n  \nFuture\nQuery\nUser\n \nwillUpdateObjectWithQuery\n(\n\n      \nQuery\nUser\n \nquery\n)\n \nasync\n \n{\n\n    \nquery\n.\nvalues\n.\nlastUpdatedAt\n \n=\n \nnew\n \nDateTime\n.\nnow\n().\ntoUtc\n();\n\n    \nreturn\n \nquery\n;\n\n  \n}\n\n\n  \nFuture\nResponse\n \ndidUpdateObject\n(\nUser\n \nobject\n)\n \nasync\n \n{\n\n    \nobject\n.\nremovePropertyFromBackingMap\n(\nprivate\n);\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nobject\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nAccessing the Request\n\n\nRecall that any value from the request itself can be accessed through the \nrequest\n property of a controller.\n\n\nThis also means that an \nHTTPController\n instance cannot be reused to handle multiple requests; if it awaited on an asynchronous method, a new request could be assigned to the \nrequest\n property. Therefore, all \nHTTPController\ns must be added to a request processing pipeline with \ngenerate\n. If you add a controller with \npipe\n, an exception will be thrown immediately at startup.", 
            "title": "Handling Requests: HTTPController"
        }, 
        {
            "location": "/http/http_controller/#httpcontroller", 
            "text": "The overwhelming majority of Aqueduct code is written in subclasses of  HTTPController . Instances of this class receive requests for a particular resource. For example, an  HTTPController  might handle requests to create, update, delete, read and list users.  An  HTTPController  works by selecting one of its methods to respond to a request. This selection is based on the HTTP method and path variables of the request. For example, a  POST /users  would trigger a  createUser  method to be invoked, whereas a  GET /users/1  would trigger its  getUserByID  method. The names of these methods are up to you; the method that gets called is determined by metadata on the method and its parameters.", 
            "title": "HTTPController"
        }, 
        {
            "location": "/http/http_controller/#responder-methods", 
            "text": "A method that handles a request in an  HTTPController  subclass is called a  responder method . To be a responder method, a method must return a  Future Response  and have  HTTPMethod  metadata. Here's an example:  class   UserController   extends   HTTPController   { \n   @ httpGet \n   Future Response   getAllUsers ()   async   { \n     return   new   Response . ok ( await   getUsersFromDatabase ()); \n   }  }   The constant  httpGet  is an instance of  HTTPMethod . When a  GET  request is sent to an instance of  UserController , this method is invoked and the  Response  it returns is sent to the HTTP client. There exist  HTTPMethod  constants for the major HTTP methods:  httpPut ,  httpGet ,  httpPost  and  httpDelete . You may use  HTTPMethod  for other types of HTTP methods:  @ HTTPMethod ( PATCH )  Future Response   patch ()   async   {   ...   }   A responder method may have parameters that further qualify its selection based on the path of the HTTP request. For example, the following controller may respond to both  GET /users  and  GET /users/1 :  class   UserController   extends   HTTPController   { \n   @ httpGet \n   Future Response   getAllUsers ()   async   { \n     return   new   Response . ok ( await   getUsersFromDatabase ()); \n   } \n\n   @ httpGet \n   Future Response   getOneUser ( @ HTTPPath ( id )   int   id )   async   { \n     return   new   Response . ok ( await   getAUserFromDatabaseByID ( id )); \n   }  }   For this controller to work correctly, it must be hooked up to a route with an optional  id  path variable:  router \n   . route ( /users/[:id] ) \n   . generate (()   =   new   UserController ());   Notice that the  id  parameter in  getOneUser  has  HTTPPath  metadata. The argument to  HTTPPath  must be the name of the path variable in the route. In this example, the path variable is  id  and the argument to  HTTPPath  is the same. When a  GET  request is delivered to the controller in this example, it is checked for the path variable  id : if it exists,  getOneUser  is invoked, otherwise  getAllUsers  is invoked.  The value of an  HTTPPath  parameter will be equal to value of the variable in the incoming request path. A path variable is a  String , but an  HTTPPath  parameter can be another type and the value will be parsed into that type. Any type that has a static  parse(String)  method can be used as a path variable. If the  HTTPPath  parameter is a  String , no parsing occurs.  A responder method may have multiple  HTTPPath  parameters and the order does not matter. If no responder method exists for the incoming HTTP method, a 405 status code is returned. An  HTTPController  will always respond to a request.", 
            "title": "Responder Methods"
        }, 
        {
            "location": "/http/http_controller/#request-and-response-bodies", 
            "text": "An  HTTPController  limits the content type of HTTP request bodies it accepts. By default, an  HTTPController  will accept both  application/json  and  application/x-www-form-urlencoded  request bodies for its  POST  and  PUT  methods. This can be modified by setting the  acceptedContentTypes  property in the constructor.  class   UserController   extends   HTTPController   { \n   UserController ()   { \n     acceptedContentTypes   =   [ ContentType . JSON ,   ContentType . XML ]; \n   }  }   If a request is made with a content type other than the accepted content types, the controller automatically responds with a unsupported media type (status code 415) response.  The body of an HTTP request is decoded if the content type is supported and there exists a responder method to handle the request. This means two things. First, the body is not decoded if the request is going to be discarded because no responder method was found.  Second, methods on  HTTPBody  have two flavors: those that return the contents as a  Future  or those that return the already decoded body. Responder methods can access the already decoded body without awaiting on the  Future -flavored variants of  HTTPBody :  @ httpPost  Future Response   createThing ()   async   { \n   // do this: \n   var   bodyMap   =   request . body . asMap (); \n\n   // no need to do this: \n   var   bodyMap   =   await   request . body . decodeAsMap (); \n\n   return   ...;  }   An  HTTPController  can also have a default content type for its response bodies. By default, this is  application/json  - any response body is encoded to JSON. This default can be changed by changing  responseContentType  in the constructor:  class   UserController   extends   HTTPController   { \n   UserController ()   { \n     responseContentType   =   ContentType . XML ; \n   }  }   The  responseContentType  is the  default  response content type. An individual  Response  may set its own  contentType , which takes precedence over the  responseContentType . For example, the following controller returns JSON by default, but if the request specifically asks for XML, that's what it will return:  class   UserController   extends   HTTPController   { \n   UserController ()   { \n     responseContentType   =   ContentType . JSON ; \n   } \n\n   @ httpGet \n   Future Response   getUserByID ( @ HTTPPath ( id )   int   id )   async   { \n     var   response   =   new   Response . ok (...); \n\n     if   ( request . headers . value ( HttpHeaders . ACCEPT ). startsWith ( application/xml ))   { \n       response . contentType   =   ContentType . XML ; \n     } \n\n     return   response ; \n   }  }", 
            "title": "Request and Response Bodies"
        }, 
        {
            "location": "/http/http_controller/#query-and-header-values", 
            "text": "The  Request  being processed can always be accessed through the  request  property of a controller. For example, if you want to check for a particular header:  @ httpGet  Future Response   getThing ()   async   { \n   if   ( request . innerRequest . headers . value ( X-Header )   !=   null )   { \n     ... \n   } \n\n   return   new   Response . ok (...);  }   HTTPController s can help when reading header and query parameter values from a request. A responder method can have additional parameters with either  HTTPQuery  or  HTTPHeader  metadata. For example:  Future Response   getThing ( \n   @ HTTPQuery ( limit )   int   numberOfThings , \n   @ HTTPQuery ( offset )   int   offset )   async   { \n     var   things   =   await   getThingsBetween ( offset ,   offset   +   numberOfThings ); \n     return   new   Response . ok ( things );  }   If the request  /things?limit=10 offset=20  is handled by this method,  numberOfThings  will be 10 and  offset  will be 20.  HTTPQuery  and  HTTPHeader  parameters, like  HTTPPath  parameters, are always strings but can be parsed into types that implement  parse .  HTTPHeader  metadata on parameters works the same, but read values from headers.  HTTPQuery  parameter names are case sensitive, whereas  HTTPHeader  parameter names are not.  The position of a parameter with  HTTPQuery  or  HTTPMethod  metadata in an parameter list matters. In the above example, both  limit  and  offset  are  required  in the request. If these parameters were optional parameters, the they are optional:  Future Response   getThing ( \n   { @ HTTPQuery ( limit )   int   numberOfThings , \n   @ HTTPQuery ( offset )   int   offset })   async   { \n     offset   ??=   0 ; \n     numberOfThings   ??=   10 ; \n\n     var   things   =   await   getThingsBetween ( offset ,   offset   +   numberOfThings ); \n     return   new   Response . ok ( things );  }   In the above example - with curly brackets ( {} ) to indicate optional - the request can omit both  limit  and  offset . If omitted, their values are null and the controller can provide defaults. This optional vs. required behavior is true for both  HTTPQuery  and  HTTPHeader  parameters, but not for  HTTPPath .  If a method has required query or header parameters that are not met by a request, the controller responds with a 400 status code, listing the required parameters that were missing, and  does not  invoke the responder method.  Controllers can also declare properties with  HTTPQuery  or  HTTPHeader  metadata. For example, the following controller will set its  version  property to the header  X-Version  for all requests it receives:  class   VersionedController   extends   HTTPController   { \n   @ HTTPHeader ( x-version ) \n   String   version ; \n\n   @ httpGet \n   Future Response   getThings ()   async   { \n     // version = X-Version header from request \n     ... \n   }  }   Properties that are declared with this metadata default to optional. To make them required, add additional metadata:  class   VersionedController   extends   HTTPController   { \n   @ requiredHTTPParameter \n   @ HTTPHeader ( x-version ) \n   String   version ; \n   ...  }   If a required property has no value in the request, a 400 is returned and no responder method is called. If the property is optional and not in the request, the value is null.  HTTPQuery  parameters will also assign values from request bodies if the content type is  application/x-www-form-urlencoded . For example, a  POST /endpoint?param=1  sends  param=1  in the HTTP body, but it is conceptually a query string. Therefore, the following responder method would have the value  1  in its  param  parameter:  @ httpPost  Future Response   createThing ( @ HTTPQuery ( param )   int   param )   async   { \n   ...  }", 
            "title": "Query and Header Values"
        }, 
        {
            "location": "/http/http_controller/#more-specialized-httpcontrollers", 
            "text": "Because many  HTTPController  subclasses will execute  Queries , there are helpful  HTTPController  subclasses for reducing boilerplate code.  A  QueryController T  builds a  Query T  based on the incoming request. If the request has a body, this  Query T 's  values  property is read from that body. If the request has a path variable, the  Query T  assigns a matcher to the primary key value of its  where . For example, in a normal  HTTPController  that responds to a PUT request, you might write the following:  @ httpPut  Future Response   updateUser ( @ HTTPPath ( id )   int   id )   async   { \n   var   query   =   new   Query User () \n     .. where . id   =   whereEqualTo ( id ) \n     .. values   =   ( new   User ().. readMap ( request . body . asMap ()); \n\n   return   new   Response . ok ( await   query . updateOne ());  }   A  QueryController T  builds this query for you. The  ManagedObject T  subclass is the type argument to  QueryController T , which has an additional  query  property that is read from the request.  class   UserController   extends   QueryController User   { \n   // query already exists and is identical to the snippet above \n   return   new   Response . ok ( await   query . updateOne ());  }   A  ManagedObjectController T  is significantly more powerful; you don't even need to subclass it. It does all the things a CRUD endpoint does without any code. Here's an example usage:  router \n   . route ( /users/[:id] ) \n   . generate (()   =   new   ManagedObjectController User ());   This controller has the following behavior:     Request  Action      POST /users  Inserts a user into the database with values from the request body    GET /users  Fetches all users in the database    GET /users/:id  Fetches a single user by id    DELETE /users/:id  Deletes a single user by id    PUT /users/:id  Updated a single user by id, using values from the request body     The objects returned from getting the collection - e.g,  GET /users  - can be modified with query parameters. For example, the following request will return the users sorted by their name in ascending order:  GET /users?sortBy=name,asc   The results can be paged (see  Paging in Advanced Queries ) with query parameters  offset ,  count ,  pageBy ,  pageAfter  and  pagePrior .  A  ManagedObjectController T  can also be subclassed. A subclass allows for callbacks to be overridden to adjust the query before execution, or the results before sending the respond. Each operation - fetch, update, delete, etc. - has a pair of methods to do this. For example, the following subclass alters the query and results before any update via  PUT :  class   UserController   extends   ManagedObjectController User   { \n   Future Query User   willUpdateObjectWithQuery ( \n       Query User   query )   async   { \n     query . values . lastUpdatedAt   =   new   DateTime . now (). toUtc (); \n     return   query ; \n   } \n\n   Future Response   didUpdateObject ( User   object )   async   { \n     object . removePropertyFromBackingMap ( private ); \n     return   new   Response . ok ( object ); \n   }  }", 
            "title": "More Specialized HTTPControllers"
        }, 
        {
            "location": "/http/http_controller/#accessing-the-request", 
            "text": "Recall that any value from the request itself can be accessed through the  request  property of a controller.  This also means that an  HTTPController  instance cannot be reused to handle multiple requests; if it awaited on an asynchronous method, a new request could be assigned to the  request  property. Therefore, all  HTTPController s must be added to a request processing pipeline with  generate . If you add a controller with  pipe , an exception will be thrown immediately at startup.", 
            "title": "Accessing the Request"
        }, 
        {
            "location": "/http/configure/", 
            "text": "Configuring an Aqueduct Application\n\n\nThis guide covers configuring an Aqueduct application.\n\n\nConfiguration Files\n\n\nAqueduct applications will likely use a YAML configuration file to provide environment-specific values like database connection information. Configuration is managed by the \naqueduct serve\n command and your \nRequestSink\n subclass.\n\n\nThe path to a configuration file may be passed to \naqueduct serve\n with the \n--config\n option. This value defaults to \nconfig.yaml\n. When your application starts, the path to the configuration file is available in \nApplicationConfiguration.configurationFilePath\n.\n\n\nThe best practice for using a configuration file is to load its contents with \nsafe_config\n, which is automatically included as a dependency of Aqueduct applications. The documentation for this package is available at the link above, but the basic premise is to map a configuration file to a Dart object.\n\n\nIn \nRequestSink.initializeApplication\n, the contents of the configuration file are read into an application-specific \nConfigurationItem\n.\n\n\nclass\n \nMyRequestSink\n \nextends\n \nRequestSink\n \n{\n\n  \nstatic\n \nFuture\n \ninitializeApplication\n(\nApplicationConfiguration\n \nconfig\n)\n \nasync\n \n{\n    \n    \nvar\n \nconfigFileValues\n \n=\n \nnew\n \nMyConfiguration\n(\nconfig\n.\nconfigurationFilePath\n);\n\n    \nconfig\n.\noptions\n[\nConfigurationValuesKey\n]\n \n=\n \nconfigFileValues\n;\n    \n  \n}\n\n\n}\n\n\n\nclass\n \nMyConfiguration\n \nextends\n \nConfigurationItem\n \n{\n\n  \nMyConfiguration\n(\nString\n \nfileName\n)\n \n:\n \nsuper\n.\nfromFile\n(\nfileName\n);\n\n\n  \nString\n \nusername\n;\n\n  \nString\n \npassword\n;\n\n  \nString\n \nhost\n;\n\n  \nString\n \nname\n;\n\n\n}\n\n\n\n\n\n\nEach property of a \nConfigurationItem\n must be a key in the loaded YAML configuration file. Thus, the above requires a YAML file like so:\n\n\nusername\n:\n \nabcdef\n\n\npassword\n:\n \nfoobar\n\n\nhost\n:\n \nlocalhost\n\n\nname\n:\n \nappDB\n\n\n\n\n\n\nIn \ninitializeApplication\n, the configuration file is parsed and added to \nApplicationConfiguration.options\n. When each \nRequestSink\n isolate starts, the configuration item is available in the options passed to its constructor:\n\n\nclass\n \nMyRequestSink\n \nextends\n \nRequestSink\n \n{\n\n  \nstatic\n \nFuture\n \ninitializeApplication\n(\nApplicationConfiguration\n \nconfig\n)\n \nasync\n \n{\n    \n    \nvar\n \nconfigFileValues\n \n=\n \nnew\n \nMyConfiguration\n(\nconfig\n.\nconfigurationFilePath\n);\n\n    \nconfig\n.\noptions\n[\nappOptions\n]\n \n=\n \nconfigFileValues\n;\n    \n  \n}\n\n\n  \nMyRequestSink\n(\nApplicationConfiguration\n \nconfig\n)\n \n:\n \nsuper\n(\nconfig\n)\n \n{\n\n    \nvar\n \noptions\n \n=\n \nconfig\n[\nappOptions\n];\n\n    \nvar\n \nstore\n \n=\n \nnew\n \nPostgreSQLPersistentStore\n.\nfromConnectionInfo\n(\n\n      \noptions\n.\nusername\n,\n \noptions\n.\npassword\n,\n \noptions\n.\nhost\n,\n \n5432\n,\n \noptions\n.\nname\n);\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe \nsafe_config\n package has instructions for more complex configuration patterns and some built-in configuration types for things like database connections.\n\n\nPreventing Resource Leaks\n\n\nWhen an Aqueduct application starts, the application and its \nRequestSink\ns will likely open connections and streams that they use to respond to requests. In order for application tests to complete successfully, these connections and streams must be closed when the application stops. For built-in connections and streams, like \nPostgreSQLPersistentStore\n, this happens automatically when \nApplication.stop()\n is invoked.\n\n\nObjects that need to be closed can be registered with \nResourceRegistry\n to automatically be closed when the application is stopped. Registration looks like this:\n\n\nvar\n \nconnection\n \n=\n \nnew\n \nConnectionOfSomeKind\n();\n\n\nawait\n \nconnection\n.\nopen\n();\n\n\nResourceRegistry\n.\nadd\nConnectionOfSomeKind\n(\nconnection\n,\n \n(\nc\n)\n \n=\n \nc\n.\nclose\n());\n\n\n\n\n\n\nThe object to be closed is the first argument and a closure to close it is the second argument. The argument passed to this closure is the object being closed. The closure must return a \nFuture\n that completes with the resource has finished closing. All registered resources are closed when an application is stopped.\n\n\nThe registry is per-isolate. This means that each isolate spawned for a \nRequestSink\n and the main isolate that runs \nRequestSink.initializeApplication()\n each have their own registry. This detail should not matter - you must only register each closable resource.\n\n\nThe return type of \nResourceRegistry.add\n is the object being registered. This makes registration syntax a bit more palatable:\n\n\nvar\n \nconnection\n \n=\n \nResourceRegistry\n.\nadd\nConnectionOfSomeKind\n(\n\n  \nnew\n \nConnectionOfSomeKind\n(),\n \n(\nc\n)\n \n=\n \nc\n.\nclose\n());\n\n\nawait\n \nconnection\n.\nopen\n();\n  \n\n\n\n\n\nConfiguring CORS\n\n\nAll request controllers have built-in behavior for handling CORS requests from a browser. When a preflight request is received from a browser (an OPTIONS request with Access-Control-Request-Method header and Origin headers), any request controller receiving this request will immediately pass it on to its \nnextController\n. The final controller listening to the stream will use its policy to validate and return a response to the HTTP client. This allows the final responding controller - typically a subclass of \nHTTPController\n - to determine CORS policy.\n\n\nEvery \nRequestController\n has a \npolicy\n property, of type \nCORSPolicy\n. The \npolicy\n has properties for configuring CORS options for that particular endpoint. By having a \npolicy\n, every \nRequestController\n automatically implements logic to respond to preflight requests without any additional code.\n\n\nPolicies can be set at the controller level or at the application level. The static property \nCORSPolicy.defaultPolicy\n can be modified at initialization time to set the CORS options for every controller.\n\n\nclass\n \nMyRequestSink\n \nextends\n \nRequestSink\n \n{\n\n  \nMyRequestSink\n(\nApplicationConfiguration\n \nconfig\n)\n \n:\n \nsuper\n(\nconfig\n)\n \n{\n\n    \nCORSPolicy\n.\ndefaultPolicy\n.\nallowedOrigins\n \n=\n \n[\nhttp://mywebsite.com/\n];\n\n  \n}\n\n\n}\n\n\n\n\n\n\nThe default policy is very permissive: POST, PUT, DELETE and GET are allowed methods. All origins are valid (*).\n\n\nEach individual controller can override or replace the default policy by modifying its own \npolicy\n in its constructor.\n\n\nclass\n \nMyHTTPController\n \nextends\n \nHTTPController\n \n{\n\n  \nMyHTTPController\n()\n \n{\n\n    \npolicy\n.\nallowedMethods\n \n=\n \n[\nPOST\n];\n\n  \n}\n\n\n}\n\n\n\n\n\n\nConfiguring HTTPS\n\n\nBy default, an Aqueduct application does not use HTTPS. In many cases, an Aqueduct application sits behind an SSL-enabled load balancer or some other proxy. The traffic from the load balancer is sent to the Aqueduct application unencrypted over HTTP.\n\n\nHowever, Aqueduct may be configured to manage HTTPS connections itself. By passing the value private key and SSL certificate paths as options to \n--ssl-key-path\n \nand\n \n--ssl-certificate-path\n in \naqueduct serve\n, an Aqueduct application will configure itself to only allow HTTPS connections.\n\n\naqueduct serve --ssl-key-path server.key.pem --ssl-certificate-path server.cert.pem\n\n\n\n\n\nBoth the key and certificate file must be unencrypted PEM files, and both must be provided to this command. These files are typically issued by a \"Certificate Authority\", such as \nletsencrypt.org\n.\n\n\nWhen an application is started with these options, the \ncertificateFilePath\n and \nkeyFilePath\n are set on the \nApplicationConfiguration\n your application is being run with. (If you are not using \naqueduct serve\n, you can set these values directly when instantiating \nApplicationConfiguration\n.)\n\n\nFor more granular control over setting up an HTTPS server, you may override \nsecurityContext\n in \nRequestSink\n. By default, this property will create a \nSecurityContext\n from the \ncertificateFilePath\n and \nkeyFilePath\n in the sink's \nconfiguration\n. A \nSecurityContext\n allows for password-encrypted credential files, configuring client certificates and other less used HTTPS schemes.\n\n\nclass\n \nMyRequestSink\n \nextends\n \nRequestSink\n \n{\n\n  \n@\noverride\n\n  \nSecurityContext\n \nget\n \nsecurityContext\n \n{\n\n    \nreturn\n \nnew\n \nSecurityContext\n()\n\n      \n..\nusePrivateKey\n(\nserver.key\n,\n \npassword:\n \n1234\n)\n\n      \n..\nuseCertificateChain\n(\nserver.crt\n,\n \npassword:\n \n1234\n);\n\n  \n}\n\n\n}", 
            "title": "CORS Configuration"
        }, 
        {
            "location": "/http/configure/#configuring-an-aqueduct-application", 
            "text": "This guide covers configuring an Aqueduct application.", 
            "title": "Configuring an Aqueduct Application"
        }, 
        {
            "location": "/http/configure/#configuration-files", 
            "text": "Aqueduct applications will likely use a YAML configuration file to provide environment-specific values like database connection information. Configuration is managed by the  aqueduct serve  command and your  RequestSink  subclass.  The path to a configuration file may be passed to  aqueduct serve  with the  --config  option. This value defaults to  config.yaml . When your application starts, the path to the configuration file is available in  ApplicationConfiguration.configurationFilePath .  The best practice for using a configuration file is to load its contents with  safe_config , which is automatically included as a dependency of Aqueduct applications. The documentation for this package is available at the link above, but the basic premise is to map a configuration file to a Dart object.  In  RequestSink.initializeApplication , the contents of the configuration file are read into an application-specific  ConfigurationItem .  class   MyRequestSink   extends   RequestSink   { \n   static   Future   initializeApplication ( ApplicationConfiguration   config )   async   {     \n     var   configFileValues   =   new   MyConfiguration ( config . configurationFilePath ); \n     config . options [ ConfigurationValuesKey ]   =   configFileValues ;     \n   }  }  class   MyConfiguration   extends   ConfigurationItem   { \n   MyConfiguration ( String   fileName )   :   super . fromFile ( fileName ); \n\n   String   username ; \n   String   password ; \n   String   host ; \n   String   name ;  }   Each property of a  ConfigurationItem  must be a key in the loaded YAML configuration file. Thus, the above requires a YAML file like so:  username :   abcdef  password :   foobar  host :   localhost  name :   appDB   In  initializeApplication , the configuration file is parsed and added to  ApplicationConfiguration.options . When each  RequestSink  isolate starts, the configuration item is available in the options passed to its constructor:  class   MyRequestSink   extends   RequestSink   { \n   static   Future   initializeApplication ( ApplicationConfiguration   config )   async   {     \n     var   configFileValues   =   new   MyConfiguration ( config . configurationFilePath ); \n     config . options [ appOptions ]   =   configFileValues ;     \n   } \n\n   MyRequestSink ( ApplicationConfiguration   config )   :   super ( config )   { \n     var   options   =   config [ appOptions ]; \n     var   store   =   new   PostgreSQLPersistentStore . fromConnectionInfo ( \n       options . username ,   options . password ,   options . host ,   5432 ,   options . name ); \n   }  }   The  safe_config  package has instructions for more complex configuration patterns and some built-in configuration types for things like database connections.", 
            "title": "Configuration Files"
        }, 
        {
            "location": "/http/configure/#preventing-resource-leaks", 
            "text": "When an Aqueduct application starts, the application and its  RequestSink s will likely open connections and streams that they use to respond to requests. In order for application tests to complete successfully, these connections and streams must be closed when the application stops. For built-in connections and streams, like  PostgreSQLPersistentStore , this happens automatically when  Application.stop()  is invoked.  Objects that need to be closed can be registered with  ResourceRegistry  to automatically be closed when the application is stopped. Registration looks like this:  var   connection   =   new   ConnectionOfSomeKind ();  await   connection . open ();  ResourceRegistry . add ConnectionOfSomeKind ( connection ,   ( c )   =   c . close ());   The object to be closed is the first argument and a closure to close it is the second argument. The argument passed to this closure is the object being closed. The closure must return a  Future  that completes with the resource has finished closing. All registered resources are closed when an application is stopped.  The registry is per-isolate. This means that each isolate spawned for a  RequestSink  and the main isolate that runs  RequestSink.initializeApplication()  each have their own registry. This detail should not matter - you must only register each closable resource.  The return type of  ResourceRegistry.add  is the object being registered. This makes registration syntax a bit more palatable:  var   connection   =   ResourceRegistry . add ConnectionOfSomeKind ( \n   new   ConnectionOfSomeKind (),   ( c )   =   c . close ());  await   connection . open ();", 
            "title": "Preventing Resource Leaks"
        }, 
        {
            "location": "/http/configure/#configuring-cors", 
            "text": "All request controllers have built-in behavior for handling CORS requests from a browser. When a preflight request is received from a browser (an OPTIONS request with Access-Control-Request-Method header and Origin headers), any request controller receiving this request will immediately pass it on to its  nextController . The final controller listening to the stream will use its policy to validate and return a response to the HTTP client. This allows the final responding controller - typically a subclass of  HTTPController  - to determine CORS policy.  Every  RequestController  has a  policy  property, of type  CORSPolicy . The  policy  has properties for configuring CORS options for that particular endpoint. By having a  policy , every  RequestController  automatically implements logic to respond to preflight requests without any additional code.  Policies can be set at the controller level or at the application level. The static property  CORSPolicy.defaultPolicy  can be modified at initialization time to set the CORS options for every controller.  class   MyRequestSink   extends   RequestSink   { \n   MyRequestSink ( ApplicationConfiguration   config )   :   super ( config )   { \n     CORSPolicy . defaultPolicy . allowedOrigins   =   [ http://mywebsite.com/ ]; \n   }  }   The default policy is very permissive: POST, PUT, DELETE and GET are allowed methods. All origins are valid (*).  Each individual controller can override or replace the default policy by modifying its own  policy  in its constructor.  class   MyHTTPController   extends   HTTPController   { \n   MyHTTPController ()   { \n     policy . allowedMethods   =   [ POST ]; \n   }  }", 
            "title": "Configuring CORS"
        }, 
        {
            "location": "/http/configure/#configuring-https", 
            "text": "By default, an Aqueduct application does not use HTTPS. In many cases, an Aqueduct application sits behind an SSL-enabled load balancer or some other proxy. The traffic from the load balancer is sent to the Aqueduct application unencrypted over HTTP.  However, Aqueduct may be configured to manage HTTPS connections itself. By passing the value private key and SSL certificate paths as options to  --ssl-key-path   and   --ssl-certificate-path  in  aqueduct serve , an Aqueduct application will configure itself to only allow HTTPS connections.  aqueduct serve --ssl-key-path server.key.pem --ssl-certificate-path server.cert.pem  Both the key and certificate file must be unencrypted PEM files, and both must be provided to this command. These files are typically issued by a \"Certificate Authority\", such as  letsencrypt.org .  When an application is started with these options, the  certificateFilePath  and  keyFilePath  are set on the  ApplicationConfiguration  your application is being run with. (If you are not using  aqueduct serve , you can set these values directly when instantiating  ApplicationConfiguration .)  For more granular control over setting up an HTTPS server, you may override  securityContext  in  RequestSink . By default, this property will create a  SecurityContext  from the  certificateFilePath  and  keyFilePath  in the sink's  configuration . A  SecurityContext  allows for password-encrypted credential files, configuring client certificates and other less used HTTPS schemes.  class   MyRequestSink   extends   RequestSink   { \n   @ override \n   SecurityContext   get   securityContext   { \n     return   new   SecurityContext () \n       .. usePrivateKey ( server.key ,   password:   1234 ) \n       .. useCertificateChain ( server.crt ,   password:   1234 ); \n   }  }", 
            "title": "Configuring HTTPS"
        }, 
        {
            "location": "/db/overview/", 
            "text": "Tasks\n\n\nAqueduct has an ORM to store data in a database and map database data to Dart objects.\n\n\n\n\nDefining a data model by declaring \nManagedObject\nT\n subclasses\n\n\nInserting, updating, reading and deleting data from a database with \nQuery\nT\n.\n\n\nCreating \nManagedObject\nT\ns from HTTP request body data like JSON\n\n\nEncoding \nManagedObject\nT\ns into an HTTP response body\n\n\nGenerating and upgrading database schemas with the \naqueduct db\n tool.\n\n\n\n\nGuides\n\n\n\n\nModeling Data\n\n\nStorage, Serialization and Deserialization\n\n\nExecuting Queries\n\n\nJoins, Filtering and Paging\n\n\nAdding Validations and Callbacks to ManagedObject\n\n\nAqueduct Database Tool\n\n\nInside the Machinery", 
            "title": "Overview"
        }, 
        {
            "location": "/db/overview/#tasks", 
            "text": "Aqueduct has an ORM to store data in a database and map database data to Dart objects.   Defining a data model by declaring  ManagedObject T  subclasses  Inserting, updating, reading and deleting data from a database with  Query T .  Creating  ManagedObject T s from HTTP request body data like JSON  Encoding  ManagedObject T s into an HTTP response body  Generating and upgrading database schemas with the  aqueduct db  tool.", 
            "title": "Tasks"
        }, 
        {
            "location": "/db/overview/#guides", 
            "text": "Modeling Data  Storage, Serialization and Deserialization  Executing Queries  Joins, Filtering and Paging  Adding Validations and Callbacks to ManagedObject  Aqueduct Database Tool  Inside the Machinery", 
            "title": "Guides"
        }, 
        {
            "location": "/db/modeling_data/", 
            "text": "Modeling Data\n\n\nIn Aqueduct, data from a database is represented by \nmanaged objects\n. A managed object is an instance of some subclass of \nManagedObject\nT\n. Each instance represents a row in the database. Managed objects are declared like so:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{\n  \n\n}\n\n\n\nclass\n \n_User\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n\n}\n\n\n\n\n\n\nHere, we have declared that there is a \nUser\n type. An instance of \nUser\n is an object that represents a row in a \n_User\n table. The \n_User\n table has two columns: a primary key integer named \nid\n and a string named \nname\n. This deserves an explanation.\n\n\nThe first class - \nUser\n - is the type you will use in your application code - you will get instances of \nUser\n from the database, you will create instances of \nUser\n to insert them in the database, you will decode JSON from an HTTP request body into \nUser\n instances and you will encode \nUser\n instances into JSON in an HTTP response body. This class - referred to as an \ninstance type\n - must extend \nManagedObject\nT\n. The class \nManagedObject\nT\n has behavior to make these tasks easier on the developer.\n\n\nThe second class - \n_User\n - declares the mapping to a database table. That is, it declares that there is a table named \n_User\n in the database with two columns, \nid\n and \nname\n. This class is referred to as a \npersistent type\n. A persistent type, by convention, is prefixed with an underscore. This is for two reasons. First, the underscore makes it can't be used in other files - because it shouldn't be. Second, some databases have predefined tables and you may want to have similarly named tables in your application. For example, there is a \nuser\n table in PostgreSQL. The prefix makes it so you don't have a name collision with a predefined table. (Later in the guide, we'll go over how to name tables differently than the persistent type name, but this is rarely useful.)\n\n\nA persistent type and instance type are always declared in pairs. The persistent type is used twice in the declaration of the instance type: as the type argument to \nManagedObject\nT\n and as an interface the instance type implements. In the above example, \nUser\n implements \n_User\n, therefore \nUser\n has two properties: \nid\n and \nname\n. Let's say we create a new \nUser\n instance and set its \nname\n:\n\n\nvar\n \nuser\n \n=\n \nnew\n \nUser\n();\n\n\nuser\n.\nname\n \n=\n \nBob\n;\n\n\n\n\n\n\nThis is where \nManagedObject\nT\n starts doing its job. Each \nManagedObject\nT\n stores its values in an internal \nMap\n. The keys in this map are the names of the properties from the persistent type. When an accessor method on \nUser\n is invoked, the values are fetched from or stored in that internal \nMap\n. The code in \nManagedObject\nT\n \nmanages\n the storage and validation of those values by ensuring they meet the definition in the persistent type.\n\n\nThe distinction between persistent type and instance type allows for many of the powerful features of Aqueduct, which are covered by other guides in this documentation.  For now, the key takeaway is that the persistent type must map directly to a database table - every property must correspond to a database column, and vice versa. Aqueduct has tools to generate database tables based on the declaration of persistent types in an application (see \nAqueduct Database Tool\n).\n\n\nMore on Persistent Types\n\n\nPersistent types define the mapping between your managed objects and a database table. As each property in a persistent type represents a database column, the type of the property must be storable in a database. The following types are available as scalar properties on a persistent type:\n\n\n\n\nint\n\n\ndouble\n\n\nString\n\n\nDateTime\n\n\nbool\n\n\n\n\nProperties that are one of these types are more referred to as the \nattributes\n of an entity. Properties that are references to other model objects - which we will see later - are called \nrelationships\n. Collectively, attributes and relationships are called \nproperties\n.\n\n\nIn addition to a type and name, each property can also have \nManagedColumnAttributes\n that adds some details to the associated column. \nManagedColumnAttributes\n are added as metadata to a property. For example, the following change to the \n_User\n persistent type adds a \nString\n \nemail\n property which must be unique across all users:\n\n\nclass\n \n_User\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n\n  \n@\nManagedColumnAttributes\n(\nunique:\n \ntrue\n)\n\n  \nString\n \nemail\n;\n\n\n}\n\n\n\n\n\n\nThere are eight configurable items available in the \nManagedColumnAttributes\n class.\n\n\n\n\nprimaryKey\n - Indicates that property is the primary key of the table represented by this persistent type. Must be one per persistent type.\n\n\ndatabaseType\n - Uses a more specific type for the database column than can be derived from the Dart type of the property. For example, you may wish to specify that an integer property is stored in a database column that holds an 8-byte integer, instead of the default 4-byte integer.\n\n\nnullable\n - Toggles whether or not this property can contain the null value.\n\n\ndefaultValue\n - A default value for this property when inserted into a database without an explicit value.\n\n\nunique\n - Toggles whether or not this property must be unique across all instances of this type.\n\n\nindexed\n - Toggles whether or not this property's database column should be indexed for faster searching.\n\n\nomitByDefault\n - Toggles whether or not this property should be fetched from the database by default. Useful for properties like hashed passwords, where you don't want to return that information when fetching an account unless you explicitly want to check the password.\n\n\nautoincrement\n - Toggles whether or not the underlying database should generate a new value from a serial generator each time a new instance is inserted into the database.\n\n\n\n\nBy not specifying \nManagedColumnAttributes\n, the default values for each of these possible configurations is used and the database type is inferred from the type of the property. This also means that all properties declared in a persistent type represent a column in a database table - even without \nManagedColumnAttributes\n metadata.\n\n\nEvery persistent type must have at least one property with \nManagedColumnAttributes\n where \nprimaryKey\n is true. There is a convenience instance of \nManagedColumnAttributes\n for this purpose, \n@managedPrimaryKey\n, which is equivalent to the following:\n\n\n@\nManagedColumnAttributes\n(\nprimaryKey:\n \ntrue\n,\n \ndatabaseType:\n \nPropertyType\n.\nbigInteger\n,\n \nautoincrement:\n \ntrue\n)\n\n\n\n\n\n\nAlso in the persistent type - and only the persistent type - you may override the name of the table by implementing a static method named \ntableName\n that returns the name of the table in a persistent type:\n\n\nclass\n \n_User\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n\n  \nstatic\n \nString\n \ntableName\n()\n \n=\n \nUserTable\n;\n\n\n}\n\n\n\n\n\n\nNote that the specific database driver determines whether or not the table name is case-sensitive or not. The included database driver for PostgreSQL automatically lowercases table names and is case-insensitive.\n\n\nManagedObject\n\n\nWhere persistent types simply declare a mapping to a database table, \nManagedObject\nT\ns do the actual work of lugging data between HTTP clients, Aqueduct applications and databases.\n\n\nManaged objects can be inserted into a database and fetched back from that database. They can be used to configure an update to a database row. They can read their values from a \nMap\n and write them into a \nMap\n - this \nMap\n can safely be encoded to or decoded from JSON or another transmission format. This allows \nManagedObject\nT\ns to be exactly represented in an HTTP request or response. Managed objects also lay the foundation for building queries. Here's an example of a common lifecycle of a \nManagedObject\nT\n subclass, \nUser\n:\n\n\n@\nhttpPost\n \ncreateThing\n()\n \nasync\n \n{\n\n  \n// Construct User from HTTP request body JSON\n\n  \nvar\n \nuserFromRequestBody\n \n=\n \nnew\n \nUser\n()\n\n    \n..\nreadMap\n(\nrequestBody\n);\n\n\n  \n// Construct Query for inserting the user, using values from the request body.\n\n  \nvar\n \ninsertQuery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n    \n..\nvalues\n \n=\n \nuserFromRequestBody\n;\n\n\n  \n// Execute insert, get User back from database\n\n  \nvar\n \ninsertedUser\n \n=\n \nawait\n \ninsertQuery\n.\ninsert\n();\n\n\n  \n// Return response with inserted User serialized as JSON HTTP response body.\n\n  \nreturn\n \nnew\n \nResponse\n.\nok\n(\ninsertedUser\n);\n\n\n}\n\n\n\n\n\n\nWhen getting managed objects from a database, each instance will represent one row. For example, consider the following table, and the previous example of \n_User\n and \nUser\n types:\n\n\n\n\n\n\n\n\nid\n\n\nname\n\n\n\n\n\n\n\n\n\n\n1\n\n\nBob\n\n\n\n\n\n\n2\n\n\nFred\n\n\n\n\n\n\n\n\nIf this entire table were fetched, you'd get a \nList\nUser\n as though you had written the following code:\n\n\nvar\n \nusers\n \n=\n \n[\n\n  \nnew\n \nUser\n()\n\n    \n..\nid\n \n=\n \n1\n\n    \n..\nname\n \n=\n \nBob\n,\n\n\n  \nnew\n \nUser\n()\n\n    \n..\nid\n \n=\n \n2\n\n    \n..\nname\n \n=\n \nFred\n\n\n];\n\n\n\n\n\n\nManaged objects may also declare additional properties and methods beyond those in its persistent type. Because these properties and methods are not part of the persistent type, they are \ntransient\n - that is, their values are not stored in the database. Any method or property defined in a subclass of \nManagedObject\nT\n is ignored when sending data to a database. This is different than properties in a persistent type, where every property explicitly maps to a database column. Here's an example:\n\n\nclass\n \nVideo\n \nextends\n \nManagedObject\n_Video\n \nimplements\n \n_Video\n \n{\n\n  \nbool\n \nget\n \nisRecent\n \n=\n \nreturn\n \nnew\n \nDateTime\n.\nnow\n().\ndifference\n(\nuploadDate\n).\ninDays\n \n \n7\n;\n\n\n}\n\n\n\nclass\n \n_Video\n \n{\n\n  \n@\nmanagedPrimaryKey\n \nint\n \nid\n;\n\n  \nDateTime\n \nuploadDate\n;\n\n\n  \n/* more properties */\n\n  \n...\n\n\n}\n\n\n\n\n\n\nEach video has a persistent property that indicates when the video was uploaded. As a convenience, you'd like to be able to determine if a video is \"recent\" - that is, it has been uploaded in the last week. Adding an \nisRecent\n property to the persistent type doesn't make any sense, because that information can be derived from the existing upload date property. This is a good place to use a transient property.\n\n\nBy default, transient properties are not included when a \nManagedObject\nT\n is written into or read from a \nMap\n. So when a \nVideo\n is returned as JSON in an HTTP response - \nisRecent\n won't be in the HTTP body. However, this is just the default behavior and can easily be changed, though - see \nStorage, Serialization and Deserialization\n for more details.\n\n\nYou may also override a \nManagedObject\nT\ns \nasMap()\n method to get to similar behavior:\n\n\nclass\n \nVideo\n \nextends\n \nManagedObject\n_Video\n \nimplements\n \n_Video\n \n{\n\n  \nMap\nString\n,\n \ndynamic\n \nasMap\n()\n \n{\n\n    \nvar\n \nm\n \n=\n \nsuper\n.\nasMap\n();\n\n    \nm\n[\nisRecent\n]\n \n=\n \nnew\n \nDateTime\n.\nnow\n().\ndifference\n(\nuploadDate\n).\ninDays\n \n \n7\n;\n\n    \nreturn\n \nm\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nModeling Managed Object Relationships\n\n\nIn addition to attributes, managed objects may also have properties that are other managed objects or collections of managed objects. These types of properties are called \nrelationships\n. For example, in a social network application, a user may have many posts that they have created. A user, then, should have a property that is a list of posts. This is called a 'has-many' relationship, because a user can have many posts.\n\n\nA user might also have a job, so the user type should also have a property that references their job. This is called a 'has-one' relationship, because a user can only ever have one job at a time (... work with me here).\n\n\nThese relationships are also properties declared in a persistent type. In the above examples, a user would look like this:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{}\n\n\nclass\n \n_User\n \n{\n  \n  \n@\nprimaryKey\n \nint\n \nid\n;\n\n  \nString\n \nname\n;\n\n\n  \nJob\n \njob\n;\n\n  \nManagedSet\nPost\n \nposts\n;\n\n\n}\n\n\n\n\n\n\nThe type \nManagedSet\n is what indicates that the relationship is has-many. A \nManagedSet\n is a glorified \nList\n - it can do everything a \nList\n can do - but has some additional behavior to help manage relationships and build queries. The type argument - here, \nPost\n - must be another \nManagedObject\nT\n subclass. That means there is also a \n_Post\n table. If the type of a property is a just a \nManagedObject\nT\n subclass - like \nJob\n - the relationship is has-one. One thing to note here is that all things 'database related' are declared inside the persistent type. The persistent type declares the database table, attribute properties declare the columns the table has, and relationship properties declare relationships to other database tables.\n\n\nThe relationship properties in \n_User\n do not represent columns in a database - they represent \nentire rows\n in a database table. Relationships in the database are maintained by foreign key reference columns. Therefore, the types \nJob\n and \nPost\n must have a column that stores the foreign key to \n_User\n. These properties are declared like so:\n\n\nclass\n \nPost\n \nextends\n \nManagedObject\n_Post\n \nimplements\n \n_Post\n \n{}\n\n\nclass\n \n_Post\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nid\n;\n\n  \nString\n \ntext\n;\n\n\n  \n@\nManagedRelationship\n(\n#\nposts\n)\n\n  \nUser\n \nuser\n;\n\n\n}\n\n\n\nclass\n \nJob\n \nextends\n \nManagedObject\n_Job\n \nimplements\n \n_Job\n \n{}\n\n\nclass\n \n_Job\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nid\n;\n\n  \nString\n \ntitle\n;\n\n\n  \n@\nManagedRelationship\n(\n#\njob\n)\n\n  \nUser\n \nuser\n;\n\n\n}\n\n\n\n\n\n\nThe properties \nuser\n on both \n_Post\n and \n_Job\n have \nManagedRelationship\n metadata and are the \ninverses\n of the \n_User\n's \nposts\n and \njob\n properties. All relationships must have an inverse. In other words, if a \nUser\n has \nposts\n, then a \nPost\n has a \nuser\n. The first argument to \nManagedRelationship\n is what links relationships together. For example, the value \n#job\n for a \nJob\n's \nuser\n indicates that the name of the property for a \nUser\n's job is \njob\n. Because tables can have multiple references to the same table, it's important that a distinction is made and therefore this value is required.\n\n\nBecause \nuser\n has \nManagedRelationship\n metadata in both \n_Post\n and \n_Job\n, it is said that \n_Post\ns and \n_Job\ns \nbelong to\n \n_User\n. \n_User\n, on the other hand, \nhas one\n \n_Job\n and \nhas many\n \n_Post\ns. Relationships may not belong to each other, so only one side of a relationship property may have the \nManagedRelationship\n metadata and that property cannot be a \nManagedSet\nT\n.\n\n\nIn the underlying database, properties with \nManagedRelationship\n metadata are actually a foreign key column. Therefore, \n_Post\n has three columns: \nid\n, \ntitle\n and \nuser_id\n. Whereas \nUser\n still only has two columns, \nname\n and \nid\n, even though it declares properties for \nJob\n and \nPost\n.\n\n\nThe types of relationship properties must always be the instance type, not the persistent type. In other words, \nUser\n's \njob\n is of type \nJob\n, not \n_Job\n.\n\n\nWhen an application starts up, relationships are checked for integrity. This check ensures that relationships are two-sided and only one property has the \nManagedRelationship\n metadata. If they do not, an exception will be thrown.\n\n\nManagedRelationship\n properties are always indexed; although this may change in the future to be configurable, but it will always be the default. Additionally, \nManagedRelationship\n properties specify that the column is unique if the other side is a 'has-one' relationship. Because the \nManagedRelationship\n property is actually a foreign key column, it may also define some extra configuration parameters: a delete rule and whether or not it is required.\n\n\nBy making \nPost.user\n required, we will require that every \nPost\n must have a user in order to be inserted into the database. This means that a \nPost\n cannot exist without a user (i.e., the foreign key may not be null),\n\n\nclass\n \n_Post\n \n{\n\n  \n...\n\n  \n@\nManagedRelationship\n(\n#\nposts\n,\n \nrequired:\n \ntrue\n)\n\n  \nUser\n \nuser\n;\n\n\n}\n\n\n\n\n\n\nBy changing the \nProfile.user\n delete rule to \nRelationshipDeleteRule.cascade\n, deleting a \nUser\n will also delete its \nProfile\n:\n\n\nclass\n \n_Profile\n \n{\n\n  \n...\n\n  \n@\nManagedRelationship\n(\n#\nprofile\n,\n \nonDelete:\n \nManagedRelationshipDeleteRule\n.\ncascade\n)\n\n  \nUser\n \nuser\n;\n\n\n}\n\n\n\n\n\n\nBy default, the delete rule is \nManagedRelationshipDeleteRule.nullify\n (it is the least destructive action) and required is \nfalse\n. If you try and set up a relationship where the \nManagedRelationship\n is both \nManagedRelationshipDeleteRule.nullify\n and \nisRequired\n, you will get an exception during startup: if the foreign key column can't be null and deleting the related object would nullify the foreign key column... well, that wouldn't work.\n\n\nWhen fetching managed objects from a database, there are rules on which relationship properties are fetched. By default, any 'has-one' or 'has-many' relationships are \nnot\n fetched from the database:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n();\n\n\nvar\n \nuser\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\n\nvar\n \nuserMap\n \n=\n \nuser\n.\nasMap\n();\n\n\nuserMap\n \n==\n \n{\n\n  \nid\n \n:\n \n1\n,\n\n  \nname\n \n:\n \nBob\n\n\n};\n \n// does not contain \nprofile\n or \nposts\n\n\n\n\n\n\nIn order to fetch these types of relationships, you must explicitly configure a \nQuery\nT\n to include them, which executes a SQL join. This is covered in the \nExecuting Queries\n.\n\n\nThe \nManagedRelationship\n property, however, will be fetched by default. But, the entire object is not fetched - only its primary key value:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nJob\n();\n\n\nvar\n \njob\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\n\nvar\n \njobMap\n \n=\n \njob\n.\nasMap\n();\n\n\njobMap\n \n==\n \n{\n\n  \nid\n \n:\n \n1\n,\n\n  \ntitle\n \n:\n \nProgrammer\n,\n\n  \nuser\n \n:\n \n{\n\n    \nid\n \n:\n \n1\n\n  \n}\n\n\n};\n\n\n\n\n\n\nIt is possible to configure a \nQuery\nT\n that will fetch the full object in this case, too.", 
            "title": "Modeling Data"
        }, 
        {
            "location": "/db/modeling_data/#modeling-data", 
            "text": "In Aqueduct, data from a database is represented by  managed objects . A managed object is an instance of some subclass of  ManagedObject T . Each instance represents a row in the database. Managed objects are declared like so:  class   User   extends   ManagedObject _User   implements   _User   {    }  class   _User   { \n   @ managedPrimaryKey \n   int   id ; \n\n   String   name ;  }   Here, we have declared that there is a  User  type. An instance of  User  is an object that represents a row in a  _User  table. The  _User  table has two columns: a primary key integer named  id  and a string named  name . This deserves an explanation.  The first class -  User  - is the type you will use in your application code - you will get instances of  User  from the database, you will create instances of  User  to insert them in the database, you will decode JSON from an HTTP request body into  User  instances and you will encode  User  instances into JSON in an HTTP response body. This class - referred to as an  instance type  - must extend  ManagedObject T . The class  ManagedObject T  has behavior to make these tasks easier on the developer.  The second class -  _User  - declares the mapping to a database table. That is, it declares that there is a table named  _User  in the database with two columns,  id  and  name . This class is referred to as a  persistent type . A persistent type, by convention, is prefixed with an underscore. This is for two reasons. First, the underscore makes it can't be used in other files - because it shouldn't be. Second, some databases have predefined tables and you may want to have similarly named tables in your application. For example, there is a  user  table in PostgreSQL. The prefix makes it so you don't have a name collision with a predefined table. (Later in the guide, we'll go over how to name tables differently than the persistent type name, but this is rarely useful.)  A persistent type and instance type are always declared in pairs. The persistent type is used twice in the declaration of the instance type: as the type argument to  ManagedObject T  and as an interface the instance type implements. In the above example,  User  implements  _User , therefore  User  has two properties:  id  and  name . Let's say we create a new  User  instance and set its  name :  var   user   =   new   User ();  user . name   =   Bob ;   This is where  ManagedObject T  starts doing its job. Each  ManagedObject T  stores its values in an internal  Map . The keys in this map are the names of the properties from the persistent type. When an accessor method on  User  is invoked, the values are fetched from or stored in that internal  Map . The code in  ManagedObject T   manages  the storage and validation of those values by ensuring they meet the definition in the persistent type.  The distinction between persistent type and instance type allows for many of the powerful features of Aqueduct, which are covered by other guides in this documentation.  For now, the key takeaway is that the persistent type must map directly to a database table - every property must correspond to a database column, and vice versa. Aqueduct has tools to generate database tables based on the declaration of persistent types in an application (see  Aqueduct Database Tool ).", 
            "title": "Modeling Data"
        }, 
        {
            "location": "/db/modeling_data/#more-on-persistent-types", 
            "text": "Persistent types define the mapping between your managed objects and a database table. As each property in a persistent type represents a database column, the type of the property must be storable in a database. The following types are available as scalar properties on a persistent type:   int  double  String  DateTime  bool   Properties that are one of these types are more referred to as the  attributes  of an entity. Properties that are references to other model objects - which we will see later - are called  relationships . Collectively, attributes and relationships are called  properties .  In addition to a type and name, each property can also have  ManagedColumnAttributes  that adds some details to the associated column.  ManagedColumnAttributes  are added as metadata to a property. For example, the following change to the  _User  persistent type adds a  String   email  property which must be unique across all users:  class   _User   { \n   @ managedPrimaryKey \n   int   id ; \n\n   String   name ; \n\n   @ ManagedColumnAttributes ( unique:   true ) \n   String   email ;  }   There are eight configurable items available in the  ManagedColumnAttributes  class.   primaryKey  - Indicates that property is the primary key of the table represented by this persistent type. Must be one per persistent type.  databaseType  - Uses a more specific type for the database column than can be derived from the Dart type of the property. For example, you may wish to specify that an integer property is stored in a database column that holds an 8-byte integer, instead of the default 4-byte integer.  nullable  - Toggles whether or not this property can contain the null value.  defaultValue  - A default value for this property when inserted into a database without an explicit value.  unique  - Toggles whether or not this property must be unique across all instances of this type.  indexed  - Toggles whether or not this property's database column should be indexed for faster searching.  omitByDefault  - Toggles whether or not this property should be fetched from the database by default. Useful for properties like hashed passwords, where you don't want to return that information when fetching an account unless you explicitly want to check the password.  autoincrement  - Toggles whether or not the underlying database should generate a new value from a serial generator each time a new instance is inserted into the database.   By not specifying  ManagedColumnAttributes , the default values for each of these possible configurations is used and the database type is inferred from the type of the property. This also means that all properties declared in a persistent type represent a column in a database table - even without  ManagedColumnAttributes  metadata.  Every persistent type must have at least one property with  ManagedColumnAttributes  where  primaryKey  is true. There is a convenience instance of  ManagedColumnAttributes  for this purpose,  @managedPrimaryKey , which is equivalent to the following:  @ ManagedColumnAttributes ( primaryKey:   true ,   databaseType:   PropertyType . bigInteger ,   autoincrement:   true )   Also in the persistent type - and only the persistent type - you may override the name of the table by implementing a static method named  tableName  that returns the name of the table in a persistent type:  class   _User   { \n   @ managedPrimaryKey \n   int   id ; \n\n   String   name ; \n\n   static   String   tableName ()   =   UserTable ;  }   Note that the specific database driver determines whether or not the table name is case-sensitive or not. The included database driver for PostgreSQL automatically lowercases table names and is case-insensitive.", 
            "title": "More on Persistent Types"
        }, 
        {
            "location": "/db/modeling_data/#managedobject", 
            "text": "Where persistent types simply declare a mapping to a database table,  ManagedObject T s do the actual work of lugging data between HTTP clients, Aqueduct applications and databases.  Managed objects can be inserted into a database and fetched back from that database. They can be used to configure an update to a database row. They can read their values from a  Map  and write them into a  Map  - this  Map  can safely be encoded to or decoded from JSON or another transmission format. This allows  ManagedObject T s to be exactly represented in an HTTP request or response. Managed objects also lay the foundation for building queries. Here's an example of a common lifecycle of a  ManagedObject T  subclass,  User :  @ httpPost   createThing ()   async   { \n   // Construct User from HTTP request body JSON \n   var   userFromRequestBody   =   new   User () \n     .. readMap ( requestBody ); \n\n   // Construct Query for inserting the user, using values from the request body. \n   var   insertQuery   =   new   Query User () \n     .. values   =   userFromRequestBody ; \n\n   // Execute insert, get User back from database \n   var   insertedUser   =   await   insertQuery . insert (); \n\n   // Return response with inserted User serialized as JSON HTTP response body. \n   return   new   Response . ok ( insertedUser );  }   When getting managed objects from a database, each instance will represent one row. For example, consider the following table, and the previous example of  _User  and  User  types:     id  name      1  Bob    2  Fred     If this entire table were fetched, you'd get a  List User  as though you had written the following code:  var   users   =   [ \n   new   User () \n     .. id   =   1 \n     .. name   =   Bob , \n\n   new   User () \n     .. id   =   2 \n     .. name   =   Fred  ];   Managed objects may also declare additional properties and methods beyond those in its persistent type. Because these properties and methods are not part of the persistent type, they are  transient  - that is, their values are not stored in the database. Any method or property defined in a subclass of  ManagedObject T  is ignored when sending data to a database. This is different than properties in a persistent type, where every property explicitly maps to a database column. Here's an example:  class   Video   extends   ManagedObject _Video   implements   _Video   { \n   bool   get   isRecent   =   return   new   DateTime . now (). difference ( uploadDate ). inDays     7 ;  }  class   _Video   { \n   @ managedPrimaryKey   int   id ; \n   DateTime   uploadDate ; \n\n   /* more properties */ \n   ...  }   Each video has a persistent property that indicates when the video was uploaded. As a convenience, you'd like to be able to determine if a video is \"recent\" - that is, it has been uploaded in the last week. Adding an  isRecent  property to the persistent type doesn't make any sense, because that information can be derived from the existing upload date property. This is a good place to use a transient property.  By default, transient properties are not included when a  ManagedObject T  is written into or read from a  Map . So when a  Video  is returned as JSON in an HTTP response -  isRecent  won't be in the HTTP body. However, this is just the default behavior and can easily be changed, though - see  Storage, Serialization and Deserialization  for more details.  You may also override a  ManagedObject T s  asMap()  method to get to similar behavior:  class   Video   extends   ManagedObject _Video   implements   _Video   { \n   Map String ,   dynamic   asMap ()   { \n     var   m   =   super . asMap (); \n     m [ isRecent ]   =   new   DateTime . now (). difference ( uploadDate ). inDays     7 ; \n     return   m ; \n   }  }", 
            "title": "ManagedObject"
        }, 
        {
            "location": "/db/modeling_data/#modeling-managed-object-relationships", 
            "text": "In addition to attributes, managed objects may also have properties that are other managed objects or collections of managed objects. These types of properties are called  relationships . For example, in a social network application, a user may have many posts that they have created. A user, then, should have a property that is a list of posts. This is called a 'has-many' relationship, because a user can have many posts.  A user might also have a job, so the user type should also have a property that references their job. This is called a 'has-one' relationship, because a user can only ever have one job at a time (... work with me here).  These relationships are also properties declared in a persistent type. In the above examples, a user would look like this:  class   User   extends   ManagedObject _User   implements   _User   {}  class   _User   {   \n   @ primaryKey   int   id ; \n   String   name ; \n\n   Job   job ; \n   ManagedSet Post   posts ;  }   The type  ManagedSet  is what indicates that the relationship is has-many. A  ManagedSet  is a glorified  List  - it can do everything a  List  can do - but has some additional behavior to help manage relationships and build queries. The type argument - here,  Post  - must be another  ManagedObject T  subclass. That means there is also a  _Post  table. If the type of a property is a just a  ManagedObject T  subclass - like  Job  - the relationship is has-one. One thing to note here is that all things 'database related' are declared inside the persistent type. The persistent type declares the database table, attribute properties declare the columns the table has, and relationship properties declare relationships to other database tables.  The relationship properties in  _User  do not represent columns in a database - they represent  entire rows  in a database table. Relationships in the database are maintained by foreign key reference columns. Therefore, the types  Job  and  Post  must have a column that stores the foreign key to  _User . These properties are declared like so:  class   Post   extends   ManagedObject _Post   implements   _Post   {}  class   _Post   { \n   @ managedPrimaryKey \n   int   id ; \n   String   text ; \n\n   @ ManagedRelationship ( # posts ) \n   User   user ;  }  class   Job   extends   ManagedObject _Job   implements   _Job   {}  class   _Job   { \n   @ managedPrimaryKey \n   int   id ; \n   String   title ; \n\n   @ ManagedRelationship ( # job ) \n   User   user ;  }   The properties  user  on both  _Post  and  _Job  have  ManagedRelationship  metadata and are the  inverses  of the  _User 's  posts  and  job  properties. All relationships must have an inverse. In other words, if a  User  has  posts , then a  Post  has a  user . The first argument to  ManagedRelationship  is what links relationships together. For example, the value  #job  for a  Job 's  user  indicates that the name of the property for a  User 's job is  job . Because tables can have multiple references to the same table, it's important that a distinction is made and therefore this value is required.  Because  user  has  ManagedRelationship  metadata in both  _Post  and  _Job , it is said that  _Post s and  _Job s  belong to   _User .  _User , on the other hand,  has one   _Job  and  has many   _Post s. Relationships may not belong to each other, so only one side of a relationship property may have the  ManagedRelationship  metadata and that property cannot be a  ManagedSet T .  In the underlying database, properties with  ManagedRelationship  metadata are actually a foreign key column. Therefore,  _Post  has three columns:  id ,  title  and  user_id . Whereas  User  still only has two columns,  name  and  id , even though it declares properties for  Job  and  Post .  The types of relationship properties must always be the instance type, not the persistent type. In other words,  User 's  job  is of type  Job , not  _Job .  When an application starts up, relationships are checked for integrity. This check ensures that relationships are two-sided and only one property has the  ManagedRelationship  metadata. If they do not, an exception will be thrown.  ManagedRelationship  properties are always indexed; although this may change in the future to be configurable, but it will always be the default. Additionally,  ManagedRelationship  properties specify that the column is unique if the other side is a 'has-one' relationship. Because the  ManagedRelationship  property is actually a foreign key column, it may also define some extra configuration parameters: a delete rule and whether or not it is required.  By making  Post.user  required, we will require that every  Post  must have a user in order to be inserted into the database. This means that a  Post  cannot exist without a user (i.e., the foreign key may not be null),  class   _Post   { \n   ... \n   @ ManagedRelationship ( # posts ,   required:   true ) \n   User   user ;  }   By changing the  Profile.user  delete rule to  RelationshipDeleteRule.cascade , deleting a  User  will also delete its  Profile :  class   _Profile   { \n   ... \n   @ ManagedRelationship ( # profile ,   onDelete:   ManagedRelationshipDeleteRule . cascade ) \n   User   user ;  }   By default, the delete rule is  ManagedRelationshipDeleteRule.nullify  (it is the least destructive action) and required is  false . If you try and set up a relationship where the  ManagedRelationship  is both  ManagedRelationshipDeleteRule.nullify  and  isRequired , you will get an exception during startup: if the foreign key column can't be null and deleting the related object would nullify the foreign key column... well, that wouldn't work.  When fetching managed objects from a database, there are rules on which relationship properties are fetched. By default, any 'has-one' or 'has-many' relationships are  not  fetched from the database:  var   query   =   new   Query User ();  var   user   =   await   query . fetchOne ();  var   userMap   =   user . asMap ();  userMap   ==   { \n   id   :   1 , \n   name   :   Bob  };   // does not contain  profile  or  posts   In order to fetch these types of relationships, you must explicitly configure a  Query T  to include them, which executes a SQL join. This is covered in the  Executing Queries .  The  ManagedRelationship  property, however, will be fetched by default. But, the entire object is not fetched - only its primary key value:  var   query   =   new   Query Job ();  var   job   =   await   query . fetchOne ();  var   jobMap   =   job . asMap ();  jobMap   ==   { \n   id   :   1 , \n   title   :   Programmer , \n   user   :   { \n     id   :   1 \n   }  };   It is possible to configure a  Query T  that will fetch the full object in this case, too.", 
            "title": "Modeling Managed Object Relationships"
        }, 
        {
            "location": "/db/serialization/", 
            "text": "Storage, Serialization and Deserialization\n\n\nIn the previous chapter, you have seen that \nManagedObject\nT\ns subclasses are responsible for representing database rows and can be encoded to or decoded from transmission formats like JSON or XML. This chapter explains the behavior of those transformations.\n\n\nManagedObject\nT\ns are created by reading JSON from a HTTP request body. Their values are often written to JSON in an HTTP response body. For these tasks, every \nManagedObject\nT\n has the methods \nreadMap\n and \nasMap\n. You'll likely invoke \nreadMap\n often - you rarely have to invoke \nasMap\n, as some other mechanisms do this for you when returning and HTTP response. Here's an example of those two methods:\n\n\nvar\n \nuserMap\n \n=\n \n{\n\n    \nid\n \n:\n \n1\n,\n\n    \nname\n \n:\n \nBob\n\n\n};\n\n\n\nvar\n \nuser\n \n=\n \nnew\n \nUser\n()..\nreadMap\n(\nuserMap\n);\n\n\n\nvar\n \noutUserMap\n \n=\n \nuser\n.\nasMap\n();\n\n\n\nuserMap\n \n==\n \noutUserMap\n;\n \n// yup\n\n\n\n\n\n\nNote that \nManagedObject\nT\ns don't have anything to do with JSON, XML or some other format here. Other parts of Aqueduct manage moving data back and forth between JSON and \nMap\ns - \nManagedObject\nT\n doesn't care about the actual format as long as it can work with \nMap\ns.\n\n\nIt's important to understand how \nnull\n works when reading from or writing to a \nMap\n with a \nManagedObject\nT\n. \nUser\n has two properties, \nid\n and \nname\n, and in the previous code block, both of those properties were in the both the input and output \nMap\n. But what happens if \nid\n is not in the input map:\n\n\nvar\n \nuserMap\n \n=\n \n{\n\n  \nname\n \n:\n \nBob\n\n\n};\n\n\n\nvar\n \nuser\n \n=\n \nnew\n \nUser\n()..\nreadMap\n(\nuserMap\n);\n\n\n\nuser\n.\nid\n \n==\n \nnull\n;\n \n// yup\n\n\nuser\n.\nname\n \n==\n \nBob\n;\n \n// yup\n\n\n\nvar\n \noutUserMap\n \n=\n \nuser\n.\nAsMap\n();\n\n\noutUserMap\n \n==\n \n{\n\n  \nname\n \n:\n \nBob\n\n\n};\n\n\n\n\n\n\nOK, so the \nUser\n reads in the map without \nid\n, says the \nid\n is \nnull\n, and when it transformed the \nUser\n back to \nMap\n, remembered that \nid\n wasn't in there. But what about this, where \nid\n is in the input map, but its explicitly \nnull\n:\n\n\nvar\n \nuserMap\n \n=\n \n{\n\n  \nid\n \n:\n \nnull\n\n  \nname\n \n:\n \nBob\n\n\n};\n\n\n\nvar\n \nuser\n \n=\n \nnew\n \nUser\n()..\nreadMap\n(\nuserMap\n);\n\n\n\nuser\n.\nid\n \n==\n \nnull\n;\n \n// yup\n\n\nuser\n.\nname\n \n==\n \nBob\n;\n \n// yup\n\n\n\nvar\n \noutUserMap\n \n=\n \nuser\n.\nasMap\n();\n\n\noutUserMap\n \n==\n \n{\n\n  \nid\n \n:\n \nnull\n\n  \nname\n \n:\n \nBob\n\n\n};\n\n\n\n\n\n\nHere, because the value in the input map was explicitly \nnull\n when read, \nUser\n includes it in its output map. A \nManagedObject\nT\n - like \nUser\n here - makes the distinction between a value that is \nnull\n and a value that it \ndoesn't have enough information about\n. A property of a \nManagedObject\nT\n can get set in three ways: its read from a map, its through an accessor method or its read from the database. In all three of these situations, not every property is available. For example, a database query may only fetch a subset of columns.\n\n\nThis is no more obvious than when just creating a brand new instance:\n\n\nvar\n \nuser\n \n=\n \nnew\n \nUser\n();\n\n\nuser\n.\nid\n \n==\n \nnull\n;\n \n// yup\n\n\nuser\n.\nname\n \n==\n \nnull\n;\n \n// yup\n\n\n\nuser\n.\nasMap\n()\n \n==\n \n{};\n \n// yup\n\n\n\n\n\n\nA \nManagedObject\nT\n will not include keys in its \nasMap()\n if it doesn't have a value for them. The value may exist somewhere else - like in the database - but if it doesn't have it, it won't include it. This distinction is useful information for clients of Aqueduct applications.\n\n\nSo what about values that are actually \nnull\n? A property with the value \nnull\n will be included in \nasMap()\n if its been read from the database, read using \nreadMap()\n or explicitly assigned to a property. The following three user objects will all have \n{\"name\": null}\n:\n\n\nvar\n \nuser1\n \n=\n \nnew\n \nUser\n()\n\n  \n..\nid\n \n=\n \n1\n\n  \n..\nname\n \n=\n \nnull\n;\n\n\n\nvar\n \nuser2\n \n=\n \nnew\n \nUser\n()..\nreadMap\n({\n\n  \nid\n:\n \n2\n\n  \nname\n:\n \nnull\n\n\n});\n\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nwhere\n.\nid\n \n=\n \nwhereEqualTo\n(\n3\n)\n\n  \n..\nwhere\n.\nname\n \n=\n \nwhereNull\n;\n\n\nvar\n \nuser3\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\n\n\n\n\nNote that any value that is returned from an accessor method that hasn't been populated in a \nManagedObject\nT\n will be \nnull\n. If using an object's values to perform some calculation, it's your job to know if the value has been fetched or not. (See \nManagedObject\nT\n.hasValueForProperty()\n for how to check this at runtime.)\n\n\nOne last thing to note: if you wish to remove a value from a \nManagedObject\nT\ns storage (and likewise, its \nasMap()\n), you may not simply set the property to \nnull\n. This can only be accomplished with \nManagedObject\nT\n.removePropertyFromBackingMap()\n.\n\n\nIt is helpful to think of a \nManagedObject\nT\n as a proxy to a database row that may or may not exist yet, and may have less data than actually exists in the database row.\n\n\nTransient Properties and Serialization/Deserialization\n\n\nBy default, transient properties and getters - those declared in the subclass of \nManagedObject\nT\n - are \nnot\n included in the \nasMap()\n. (Setters are obviously not included, as you can't get a value from them.) To include a transient property or getter in \nasMap()\n, you may mark it with \n@managedTransientOutputAttribute\n metadata. Properties marked with this metadata will be included in the serialized \nMap\n if and only if they are not null. A good reason to use this feature is when you want to provide a value to the consumer of the API that is derived from one or more values in persistent type of the managed object:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{\n\n  \n@\nmanagedTransientOutputAttribute\n\n  \nString\n \nget\n \nfullName\n \n=\n \n$\nfirstName\n \n$\nlastName\n;\n\n\n}\n\n\n\nclass\n \n_User\n \n{\n\n  \nString\n \nfirstName\n;\n\n  \nString\n \nlastName\n;\n\n\n  \n...\n\n\n}\n\n\n\nvar\n \nuser\n \n=\n \nnew\n \nUser\n()\n\n  \n..\nfirstName\n \n=\n \nBob\n\n  \n..\nlastName\n \n=\n \nBoberson\n;\n\n\n\nvar\n \nmap\n \n=\n \nuser\n.\nasMap\n();\n\n\nmap\n \n==\n \n{\n\n  \nfirstName\n \n:\n \nBob\n,\n\n  \nlastName\n \n:\n \nBoberson\n,\n\n  \nfullName\n \n:\n \nBob Boberson\n\n\n};\n\n\n\n\n\n\nTransient properties may also be used as inputs when reading with \nreadMap()\n by marking a property with \n@managedTransientInputAttribute\n. For example, consider how to handle user passwords. The persistent type - a direct mapping to the database - does not have a password property for security purposes. Instead, it has a password hash and a salt. An instance type could then define a password property, which automatically set the salt and hash of the password in the underlying persistent type:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{\n\n  \n@\nmanagedTransientInputAttribute\n\n  \nvoid\n \nset\n \npassword\n(\nString\n \npw\n)\n \n{\n\n    \nsalt\n \n=\n \ngenerateSalt\n();\n\n    \nhashedPassword\n \n=\n \nhash\n(\npw\n,\n \nsalt\n);\n\n  \n}\n\n\n}\n\n\nclass\n \n_User\n \n{\n\n  \nString\n \nsalt\n;\n\n  \nString\n \nhashedPassword\n;\n\n  \n...\n\n\n}\n\n\n\nvar\n \nmap\n \n=\n \n{\n\n  \npassword\n \n:\n \nmypassword\n\n\n};\n\n\nvar\n \nuser\n \n=\n \nnew\n \nUser\n()..\nreadMap\n(\nmap\n);\n\n\nvar\n \nsalt\n \n=\n \nuser\n.\nsalt\n;\n \n// \nsomerandomstring\n\n\nvar\n \nhashedPassword\n \n=\n \nuser\n.\nhashedPassword\n;\n \n// \nsomehashedstring\n\n\n\nvar\n \npassword\n \n=\n \nuser\n.\npassword\n;\n \n// Analyzer error - user.password doesn\nt exist!\n\n\n\n\n\n\nOn a related note, persistent properties are always included in \nasMap()\n by default, but can be omitted by adding \nManagedColumnAttributes\n metadata with the \nomitByDefault\n option:\n\n\nclass\n \n_User\n \n{\n\n  \n@\nManagedColumnAttributes\n(\nomitByDefault:\n \ntrue\n)\n\n  \nString\n \nsalt\n;\n\n\n  \n@\nManagedColumnAttributes\n(\nomitByDefault:\n \ntrue\n)\n\n  \nString\n \nhashedPassword\n;\n\n  \n...\n\n\n}\n\n\n\n\n\n\nA transient input attribute must be a setter or a property, just like an transient output attribute must be a getter or a property. For properties that are both inputs and outputs, you may use the metadata \n@managedTransientAttribute\n.\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{\n\n  \n@\nmanagedTransientAttribute\n\n  \nString\n \nnickname\n;\n \n// shows up in asMap() and can be read from readMap()\n\n\n}\n\n\n\n\n\n\nAlso, a separate getter and setter may exist for the same name to allow both input and output:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{\n\n  \n@\nmanagedTransientInputAttribute\n\n  \nvoid\n \nset\n \ntransientValue\n(\nString\n \ns\n)\n \n{\n\n    \n...\n\n  \n}\n\n\n  \n@\nmanagedTransientOutputAttribute\n\n  \nString\n \nget\n \ntransientValue\n \n=\n \n...;\n\n\n}\n\n\n\n\n\n\nTransient properties marked with these metadata \nare\n \nattributes\n in \nManagedEntity\n (like scalar properties on the persistent type, but unlike other properties on an instance type).\n\n\nSerialization and Deserialization of Relationship Properties\n\n\nRelationship properties - references to other \nManagedObject\nT\n subclasses - can also be included in \nasMap()\n and read from \nreadMap()\n, so long as the instance knows their value. Relationship properties are typically populated when executing a \nQuery\nT\n with \njoinOne()\n or \njoinMany()\n - aka, a SQL JOIN.\n\n\nIf an object has a \"has-one\" or \"belongs to\" relationship property, its \nasMap\n will contain a nested \nMap\n representing the related object. For example, recall the \nUser\n with a \njob\n:\n\n\nvar\n \njob\n \n=\n \nnew\n \nJob\n()\n\n  \n..\ntitle\n \n=\n \nProgrammer\n;\n\n\nvar\n \nuser\n \n=\n \nnew\n \nUser\n()\n\n  \n..\nname\n \n=\n \nBob\n\n  \n..\njob\n \n=\n \njob\n;\n\n\n\nvar\n \nuserMap\n \n=\n \nuser\n.\nasMap\n();\n\n\nuserMap\n \n==\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \nname\n:\n \nBob\n,\n\n  \njob\n:\n \n{\n\n    \nid\n:\n \n1\n\n    \ntitle\n:\n \nProgrammer\n\n  \n}\n\n\n};\n \n// yup\n\n\n\n\n\n\nNotice that the names of the keys - including relationship properties and properties of the related object - all match the names of their declared properties.\n\n\nIt's important to note that \"belongs to\" relationships - those with \nManagedRelationship\n metadata that represent foreign key columns - are always represented by \nMap\ns. When fetching an object with a from a database, the underlying foreign key column value is fetched by default. When that object's \nasMap()\n is invoked, the foreign key value is wrapped in a \nMap\n. The key to this \nMap\n is the primary key of the related object. For example:\n\n\nvar\n \njobQuery\n \n=\n \nnew\n \nQuery\nJob\n();\n\n\nvar\n \njob\n \n=\n \nawait\n \njobQuery\n.\nfetchOne\n();\n\n\n\njob\n.\nasMap\n()\n \n==\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \ntitle\n:\n \nProgrammer\n,\n\n  \nuser\n:\n \n{\n\n    \nid\n:\n \n1\n\n  \n}\n\n\n};\n \n// yup\n\n\n\n\n\n\nThis behavior might be different than some ORMs, which would include a key that matches the name of the underlying database column where the value is simply the integer foreign key. That would look like this:\n\n\njob\n.\nasMap\n()\n \n==\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \ntitle\n:\n \nProgrammer\n,\n\n  \nuser_id\n:\n \n1\n\n\n};\n \n// nope\n\n\n\n\n\n\nAqueduct treats relationships consistently and chooses not to expose any of the underlying database details to the API consumer. An iOS app, for example, shouldn't care - a relationship could be maintained by foreign key references or by witchcraft. The interesting piece to the API consumer is that job's have a user, and user's have a job.\n\n\n\"Has-many\" relationships, which are represented as \nManagedSet\nT\ns, are written as \nList\nMap\ns in \nasMap()\n.\n\n\nvar\n \nuser\n \n=\n \nnew\n \nUser\n()\n\n  \n..\nid\n \n=\n \n1\n;\n\n  \n..\nposts\n \n=\n \nnew\n \nManagedSet\n.\nfrom\n([\n\n      \nnew\n \nPost\n()..\nid\n \n=\n \n2\n,\n\n      \nnew\n \nPost\n()..\nid\n \n=\n \n3\n\n  \n]);\n\n\n\nvar\n \nuserMap\n \n=\n \nuser\n.\nasMap\n();\n\n\nuserMap\n \n==\n \n{\n\n  \nid\n \n:\n \n1\n,\n\n  \nposts\n \n:\n \n[\n\n    \n{\n\n      \nid\n \n:\n \n2\n\n    \n},\n\n    \n{\n\n      \nid\n \n:\n \n3\n\n    \n}\n\n  \n]\n\n\n};\n\n\n\n\n\n\nIt is important to note the potential for cyclic object graphs. Since all relationship properties are two-sided, the two properties in that relationship are references to one another. That is, you could do something like this:\n\n\nidentical\n(\nuser\n.\nprofile\n.\nuser\n,\n \nuser\n);\n\n\nidentical\n(\nuser\n.\nposts\n.\nfirst\n.\nuser\n,\n \nuser\n);\n\n\n\n\n\n\nWhen fetching objects from a database, this won't happen - Aqueduct will create multiple instances of the same row when necessary to avoid this. Therefore, the previous code snippet would not be true, but the following two statements that check the values inside those objects would be:\n\n\nuser.profile.user.id == user.id;\n\nuser.posts.first.user.id == user.id\n\n\n\n\n\nWhile managed objects from a database will not have cyclic references, managed objects you instantiate yourself can if you mistakenly do so. When you invoke \nasMap()\n on a cyclic graph, you'll get a stack overflow error. It's best to avoid creating cyclic graphs altogether. For example:\n\n\n// do:\n\n\nvar\n \nuser\n \n=\n \nnew\n \nUser\n();\n\n\nposts\n.\nforEach\n((\np\n)\n \n{\n\n  \np\n.\nuser\n \n=\n \nnew\n \nUser\n()..\nid\n \n=\n \nuser\n.\nid\n;\n\n\n});\n\n\n\n// do not:\n\n\nvar\n \nuser\n \n=\n \nnew\n \nUser\n();\n\n\nposts\n.\nforEach\n((\np\n)\n \n{\n\n  \np\n.\nuser\n \n=\n \nuser\n;\n\n\n});\n\n\n\n\n\n\nWhen reading the values of a \nManagedObject\nT\n with \nreadMap()\n, relationship properties must also be represented as nested \nMap\ns. Thus:\n\n\nvar\n \nuserMap\n \n=\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \nname\n:\n \nBob\n,\n\n  \nposts\n:\n \n[\n\n    \n{\nid\n:\n \n1\n,\n \ntext\n:\n \nhello\n}\n\n  \n]\n\n\n};\n\n\n\nvar\n \nuser\n \n=\n \nnew\n \nUser\n()..\nreadMap\n(\nuserMap\n);\n\n\nuser\n.\nposts\n \n==\n \nnew\n \nManagedSet\nPost\n[\n\n  \nnew\n \nPost\n()\n\n    \n..\nid\n \n=\n \n1\n\n    \n..\ntext\n \n=\n \nhello\n\n\n];\n \n// yup, other Post doesn\nt implement == to check property equality", 
            "title": "Storage, Serialization and Deserialization"
        }, 
        {
            "location": "/db/serialization/#storage-serialization-and-deserialization", 
            "text": "In the previous chapter, you have seen that  ManagedObject T s subclasses are responsible for representing database rows and can be encoded to or decoded from transmission formats like JSON or XML. This chapter explains the behavior of those transformations.  ManagedObject T s are created by reading JSON from a HTTP request body. Their values are often written to JSON in an HTTP response body. For these tasks, every  ManagedObject T  has the methods  readMap  and  asMap . You'll likely invoke  readMap  often - you rarely have to invoke  asMap , as some other mechanisms do this for you when returning and HTTP response. Here's an example of those two methods:  var   userMap   =   { \n     id   :   1 , \n     name   :   Bob  };  var   user   =   new   User ().. readMap ( userMap );  var   outUserMap   =   user . asMap ();  userMap   ==   outUserMap ;   // yup   Note that  ManagedObject T s don't have anything to do with JSON, XML or some other format here. Other parts of Aqueduct manage moving data back and forth between JSON and  Map s -  ManagedObject T  doesn't care about the actual format as long as it can work with  Map s.  It's important to understand how  null  works when reading from or writing to a  Map  with a  ManagedObject T .  User  has two properties,  id  and  name , and in the previous code block, both of those properties were in the both the input and output  Map . But what happens if  id  is not in the input map:  var   userMap   =   { \n   name   :   Bob  };  var   user   =   new   User ().. readMap ( userMap );  user . id   ==   null ;   // yup  user . name   ==   Bob ;   // yup  var   outUserMap   =   user . AsMap ();  outUserMap   ==   { \n   name   :   Bob  };   OK, so the  User  reads in the map without  id , says the  id  is  null , and when it transformed the  User  back to  Map , remembered that  id  wasn't in there. But what about this, where  id  is in the input map, but its explicitly  null :  var   userMap   =   { \n   id   :   null \n   name   :   Bob  };  var   user   =   new   User ().. readMap ( userMap );  user . id   ==   null ;   // yup  user . name   ==   Bob ;   // yup  var   outUserMap   =   user . asMap ();  outUserMap   ==   { \n   id   :   null \n   name   :   Bob  };   Here, because the value in the input map was explicitly  null  when read,  User  includes it in its output map. A  ManagedObject T  - like  User  here - makes the distinction between a value that is  null  and a value that it  doesn't have enough information about . A property of a  ManagedObject T  can get set in three ways: its read from a map, its through an accessor method or its read from the database. In all three of these situations, not every property is available. For example, a database query may only fetch a subset of columns.  This is no more obvious than when just creating a brand new instance:  var   user   =   new   User ();  user . id   ==   null ;   // yup  user . name   ==   null ;   // yup  user . asMap ()   ==   {};   // yup   A  ManagedObject T  will not include keys in its  asMap()  if it doesn't have a value for them. The value may exist somewhere else - like in the database - but if it doesn't have it, it won't include it. This distinction is useful information for clients of Aqueduct applications.  So what about values that are actually  null ? A property with the value  null  will be included in  asMap()  if its been read from the database, read using  readMap()  or explicitly assigned to a property. The following three user objects will all have  {\"name\": null} :  var   user1   =   new   User () \n   .. id   =   1 \n   .. name   =   null ;  var   user2   =   new   User ().. readMap ({ \n   id :   2 \n   name :   null  });  var   query   =   new   Query User () \n   .. where . id   =   whereEqualTo ( 3 ) \n   .. where . name   =   whereNull ;  var   user3   =   await   query . fetchOne ();   Note that any value that is returned from an accessor method that hasn't been populated in a  ManagedObject T  will be  null . If using an object's values to perform some calculation, it's your job to know if the value has been fetched or not. (See  ManagedObject T .hasValueForProperty()  for how to check this at runtime.)  One last thing to note: if you wish to remove a value from a  ManagedObject T s storage (and likewise, its  asMap() ), you may not simply set the property to  null . This can only be accomplished with  ManagedObject T .removePropertyFromBackingMap() .  It is helpful to think of a  ManagedObject T  as a proxy to a database row that may or may not exist yet, and may have less data than actually exists in the database row.", 
            "title": "Storage, Serialization and Deserialization"
        }, 
        {
            "location": "/db/serialization/#transient-properties-and-serializationdeserialization", 
            "text": "By default, transient properties and getters - those declared in the subclass of  ManagedObject T  - are  not  included in the  asMap() . (Setters are obviously not included, as you can't get a value from them.) To include a transient property or getter in  asMap() , you may mark it with  @managedTransientOutputAttribute  metadata. Properties marked with this metadata will be included in the serialized  Map  if and only if they are not null. A good reason to use this feature is when you want to provide a value to the consumer of the API that is derived from one or more values in persistent type of the managed object:  class   User   extends   ManagedObject _User   implements   _User   { \n   @ managedTransientOutputAttribute \n   String   get   fullName   =   $ firstName   $ lastName ;  }  class   _User   { \n   String   firstName ; \n   String   lastName ; \n\n   ...  }  var   user   =   new   User () \n   .. firstName   =   Bob \n   .. lastName   =   Boberson ;  var   map   =   user . asMap ();  map   ==   { \n   firstName   :   Bob , \n   lastName   :   Boberson , \n   fullName   :   Bob Boberson  };   Transient properties may also be used as inputs when reading with  readMap()  by marking a property with  @managedTransientInputAttribute . For example, consider how to handle user passwords. The persistent type - a direct mapping to the database - does not have a password property for security purposes. Instead, it has a password hash and a salt. An instance type could then define a password property, which automatically set the salt and hash of the password in the underlying persistent type:  class   User   extends   ManagedObject _User   implements   _User   { \n   @ managedTransientInputAttribute \n   void   set   password ( String   pw )   { \n     salt   =   generateSalt (); \n     hashedPassword   =   hash ( pw ,   salt ); \n   }  }  class   _User   { \n   String   salt ; \n   String   hashedPassword ; \n   ...  }  var   map   =   { \n   password   :   mypassword  };  var   user   =   new   User ().. readMap ( map );  var   salt   =   user . salt ;   //  somerandomstring  var   hashedPassword   =   user . hashedPassword ;   //  somehashedstring  var   password   =   user . password ;   // Analyzer error - user.password doesn t exist!   On a related note, persistent properties are always included in  asMap()  by default, but can be omitted by adding  ManagedColumnAttributes  metadata with the  omitByDefault  option:  class   _User   { \n   @ ManagedColumnAttributes ( omitByDefault:   true ) \n   String   salt ; \n\n   @ ManagedColumnAttributes ( omitByDefault:   true ) \n   String   hashedPassword ; \n   ...  }   A transient input attribute must be a setter or a property, just like an transient output attribute must be a getter or a property. For properties that are both inputs and outputs, you may use the metadata  @managedTransientAttribute .  class   User   extends   ManagedObject _User   implements   _User   { \n   @ managedTransientAttribute \n   String   nickname ;   // shows up in asMap() and can be read from readMap()  }   Also, a separate getter and setter may exist for the same name to allow both input and output:  class   User   extends   ManagedObject _User   implements   _User   { \n   @ managedTransientInputAttribute \n   void   set   transientValue ( String   s )   { \n     ... \n   } \n\n   @ managedTransientOutputAttribute \n   String   get   transientValue   =   ...;  }   Transient properties marked with these metadata  are   attributes  in  ManagedEntity  (like scalar properties on the persistent type, but unlike other properties on an instance type).", 
            "title": "Transient Properties and Serialization/Deserialization"
        }, 
        {
            "location": "/db/serialization/#serialization-and-deserialization-of-relationship-properties", 
            "text": "Relationship properties - references to other  ManagedObject T  subclasses - can also be included in  asMap()  and read from  readMap() , so long as the instance knows their value. Relationship properties are typically populated when executing a  Query T  with  joinOne()  or  joinMany()  - aka, a SQL JOIN.  If an object has a \"has-one\" or \"belongs to\" relationship property, its  asMap  will contain a nested  Map  representing the related object. For example, recall the  User  with a  job :  var   job   =   new   Job () \n   .. title   =   Programmer ;  var   user   =   new   User () \n   .. name   =   Bob \n   .. job   =   job ;  var   userMap   =   user . asMap ();  userMap   ==   { \n   id :   1 , \n   name :   Bob , \n   job :   { \n     id :   1 \n     title :   Programmer \n   }  };   // yup   Notice that the names of the keys - including relationship properties and properties of the related object - all match the names of their declared properties.  It's important to note that \"belongs to\" relationships - those with  ManagedRelationship  metadata that represent foreign key columns - are always represented by  Map s. When fetching an object with a from a database, the underlying foreign key column value is fetched by default. When that object's  asMap()  is invoked, the foreign key value is wrapped in a  Map . The key to this  Map  is the primary key of the related object. For example:  var   jobQuery   =   new   Query Job ();  var   job   =   await   jobQuery . fetchOne ();  job . asMap ()   ==   { \n   id :   1 , \n   title :   Programmer , \n   user :   { \n     id :   1 \n   }  };   // yup   This behavior might be different than some ORMs, which would include a key that matches the name of the underlying database column where the value is simply the integer foreign key. That would look like this:  job . asMap ()   ==   { \n   id :   1 , \n   title :   Programmer , \n   user_id :   1  };   // nope   Aqueduct treats relationships consistently and chooses not to expose any of the underlying database details to the API consumer. An iOS app, for example, shouldn't care - a relationship could be maintained by foreign key references or by witchcraft. The interesting piece to the API consumer is that job's have a user, and user's have a job.  \"Has-many\" relationships, which are represented as  ManagedSet T s, are written as  List Map s in  asMap() .  var   user   =   new   User () \n   .. id   =   1 ; \n   .. posts   =   new   ManagedSet . from ([ \n       new   Post ().. id   =   2 , \n       new   Post ().. id   =   3 \n   ]);  var   userMap   =   user . asMap ();  userMap   ==   { \n   id   :   1 , \n   posts   :   [ \n     { \n       id   :   2 \n     }, \n     { \n       id   :   3 \n     } \n   ]  };   It is important to note the potential for cyclic object graphs. Since all relationship properties are two-sided, the two properties in that relationship are references to one another. That is, you could do something like this:  identical ( user . profile . user ,   user );  identical ( user . posts . first . user ,   user );   When fetching objects from a database, this won't happen - Aqueduct will create multiple instances of the same row when necessary to avoid this. Therefore, the previous code snippet would not be true, but the following two statements that check the values inside those objects would be:  user.profile.user.id == user.id;\n\nuser.posts.first.user.id == user.id  While managed objects from a database will not have cyclic references, managed objects you instantiate yourself can if you mistakenly do so. When you invoke  asMap()  on a cyclic graph, you'll get a stack overflow error. It's best to avoid creating cyclic graphs altogether. For example:  // do:  var   user   =   new   User ();  posts . forEach (( p )   { \n   p . user   =   new   User ().. id   =   user . id ;  });  // do not:  var   user   =   new   User ();  posts . forEach (( p )   { \n   p . user   =   user ;  });   When reading the values of a  ManagedObject T  with  readMap() , relationship properties must also be represented as nested  Map s. Thus:  var   userMap   =   { \n   id :   1 , \n   name :   Bob , \n   posts :   [ \n     { id :   1 ,   text :   hello } \n   ]  };  var   user   =   new   User ().. readMap ( userMap );  user . posts   ==   new   ManagedSet Post [ \n   new   Post () \n     .. id   =   1 \n     .. text   =   hello  ];   // yup, other Post doesn t implement == to check property equality", 
            "title": "Serialization and Deserialization of Relationship Properties"
        }, 
        {
            "location": "/db/executing_queries/", 
            "text": "Inserting, Updating, Deleting and Fetching Objects\n\n\nTo send commands to a database - whether to fetch, insert, delete or update objects - you will create, configure and execute instances of \nQuery\nT\n. The type argument must be a subclass of \nManagedObject\nT\n. This tells the \nQuery\nT\n which table it will operate on. Here's an example of a \nQuery\nT\n that fetches all instances of \nUser\n:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n();\n\n\nvar\n \nallUsers\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nA \nQuery\nT\n has four basic execution methods: \nfetch\n, \nupdate\n, \ninsert\n, \ndelete\n.\n\n\n\n\nfetch\n will retrieve data from a database (it is equivalent to the SQL operation \nSELECT\n).\n\n\nupdate\n will modify existing data in a database (it is equivalent to the SQL operation \nUPDATE\n).\n\n\ninsert\n will add new data to a database (it is equivalent to the SQL operation \nINSERT\n).\n\n\ndelete\n will remove data from a database (it is equivalent to the SQL operation \nDELETE\n).\n\n\n\n\nA \nQuery\nT\n has many configurable properties. These properties will impact which objects get fetched, the data that gets sent to the database, the order that data is returned in, and so on.\n\n\nInserting Data with a Query\n\n\nLet's assume there exists a managed object type declared like this:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{}\n\n\nclass\n \n_User\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nManagedColumnAttributes\n(\nindexed:\n \ntrue\n)\n\n  \nString\n \nemail\n;\n\n\n  \nString\n \nname\n;\n\n\n}\n\n\n\n\n\n\nTo insert a new row into the \n_User\n table, a \nQuery\nT\n is constructed and executed like so:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nvalues\n.\nname\n \n=\n \nBob\n\n  \n..\nvalues\n.\nemail\n \n=\n \nbob@stablekernel.com\n;\n  \n\n\nvar\n \nuser\n \n=\n \nawait\n \nquery\n.\ninsert\n();\n  \n\nuser\n.\nasMap\n()\n \n==\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \nname\n:\n \nBob\n,\n\n  \nemail\n:\n \nbob@stablekernel.com\n\n\n};\n\n\n\n\n\n\nEvery \nQuery\nT\n has a \nvalues\n property that is the type of managed object being inserted. Here, \nvalues\n is an instance of \nUser\n. When a \nQuery\nT\n is executed with insert, a new row is created in the database with every property that has been set for \nvalues\n. In this case, both \nname\n and \nemail\n have been set. The generated SQL looks like this:\n\n\nINSERT\n \nINTO\n \n_user\n \n(\nname\n,\n \nemail\n)\n \nVALUES\n \n(\nBob\n,\n \nbob@stablekernel.com\n)\n\n\n\n\n\n\nNote there is no value provided for the \nid\n property in this query. Recall that \nmanagedPrimaryKey\n metadata is a convenience for \nManagedColumnAttributes\n with autoincrementing behavior. Therefore, the database will assign a value for \nid\n during insertion. The object returned from \ninsert()\n will be an instance of \nUser\n that represents the inserted row. Thus, the returned \nUser\n will have all of the values that were set in \nQuery\nT\n.values\n as well as the auto-generated \nid\n value.\n\n\nProperties that are not set in the \nvalues\n property will not be sent to the database. Values that are explicitly set to \nnull\n will be sent as \nNULL\n. For example, consider the following \nQuery\nT\n:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nvalues\n.\nname\n \n=\n \nnull\n;\n\n\nawait\n \nquery\n.\ninsert\n();\n\n\n\n\n\n\nThe generated SQL for this query does not send \nemail\n - because it isn't included - and sends \nNULL\n for \nname\n:\n\n\nINSERT\n \nINTO\n \n_user\n \n(\nname\n)\n \nVALUES\n \n(\nNULL\n);\n\n\n\n\n\n\nIf a property is not nullable (its \nManagedColumnAttributes\n has \nnullable: false\n) and its value is not set in a query prior to inserting it, the query will fail and throw an exception.\n\n\nYou may also set \nvalues\n with an instance of a managed object. This is valuable when reading an object from a JSON HTTP request body:\n\n\nvar\n \nuser\n \n=\n \nnew\n \nUser\n()\n\n  \n..\nreadMap\n(\nrequestBody\n);\n\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nvalues\n \n=\n \nuser\n;\n\n\n\n\n\n\nBy default, the returned object from an \ninsert()\n will have all of its properties set. See a later section on configuring which properties are returned from a \nQuery\nT\n.\n\n\nIf an insert query fails because of a conflict - a unique constraint is violated - the \nQuery\nT\n will throw a \nQueryException\n.  See a later section on how \nQueryException\ns are gracefully handled by \nRequestController\ns. In short, it is unlikely that you have to handle \nQueryException\n directly - \nRequestController\ns know how to turn them into the appropriate HTTP response.\n\n\nUpdating Data with a Query\n\n\nUpdating rows with a \nQuery\nT\n is similar to inserting data, in that you set the \nvalues\n of a \nQuery\nT\n for data you want to change. The type parameter for the \nQuery\nT\n indicates which entity - and therefore which database table - will get updated when the query is executed.\n\n\nAn update query can - and likely should - be restricted to a single row or subset of rows. This is done by configuring the \nwhere\n property of a \nQuery\nT\n - which gets translated into the \nwhere clause\n of the SQL command. Here's an example:\n\n\n// A Query that will change any user\ns whose name is \nBob\n to \nFred\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nvalues\n.\nname\n \n=\n \nFred\n\n  \n..\nwhere\n.\nname\n \n=\n \nwhereEqualTo\n(\nBob\n);\n\n\n\nList\nUser\n \nbobsThatAreNowFreds\n \n=\n \nawait\n \nquery\n.\nupdate\n();\n\n\n\n\n\n\nLike \nvalues\n, \nwhere\n is also the same managed object type the query is being executed on. In the above example, then, both \nvalues\n and \nwhere\n and instances of \nUser\n. This query executes the following SQL:\n\n\nUPDATE\n \n_user\n \nSET\n \nname\n=\nFred\n \nWHERE\n \nname\n=\nBob\n;\n\n\n\n\n\n\nThe \nwhere\n property is a very powerful and flexible, and so there is an entire section dedicated to it later in this guide. For now, we'll stick to some of the things specific to \nupdate()\n.\n\n\nLike \ninsert()\n, only the values set in the \nvalues\n property of a query get updated when executing \nupdate()\n. Values that are omitted are not included. Values that need to be set to \nnull\n must explicitly be set to \nnull\n in the query:\n\n\n// A Query that will remove names from anyone currently named Bob.\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nvalues\n.\nname\n \n=\n \nnull\n\n  \n..\nwhere\n.\nname\n \n=\n \nwhereEqualTo\n(\nBob\n);\n\n\n\n\n\n\nAn update query returns every modified row as a result. If no rows are updated, the return value is an empty list.  \n\n\nThere is a variant to \nQuery\nT\n.update\n named \nupdateOne\n. The \nupdateOne\n method will build and execute a SQL query in the same way a normal \nupdate\n does, however, it will only return the single instance that was updated instead of a list. This is convenience method for the caller to get back a single instance instead of a list:\n\n\n// Update user with id = 1 to have the name \nFred\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nvalues\n.\nname\n \n=\n \nFred\n\n  \n..\nwhere\n.\nid\n \n=\n \nwhereEqualTo\n(\n1\n);\n\n\n\nvar\n \nupdatedUser\n \n=\n \nawait\n \nquery\n.\nupdateOne\n();\n\n\n\n\n\n\nThe \nupdateOne\n method will return \nnull\n if no rows were updated. It is important to note that if \nupdateOne\n is used and more than one row is updated, \nupdateOne\n will throw an exception and the changes to the data \nare not reversible\n. Because this is likely a mistake, this is considered an error, hence the exception is thrown. It is up to the programmer to recognize whether or not a particular \nupdateOne\n query would impact multiple rows.\n\n\nUpdate queries have a safety feature that prevents you from accidentally updating every row. If you try to execute a \nQuery\nT\n to do an update and no values in \nwhere\n have been set, the default behavior of \nQuery\nT\n will throw an exception prior to carrying out the request. If you actually want to update every instance of some entity (that is, every row of a table), you must set the \nQuery\nT\n's \ncanModifyAllInstances\n to \ntrue\n prior to execution. (This property defaults to \nfalse\n.)\n\n\nDeleting Data with a Query\n\n\nA \nQuery\nT\n will delete rows from a database when using \ndelete()\n. Like update queries, you should specify a row or rows using \nwhere\n properties of the \nQuery\nT\n. The result of a delete operation will be a \nFuture\nint\n with the number of rows deleted.\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nwhere\n.\nid\n \n=\n \nwhereEqualTo\n(\n1\n);\n\n\n\nint\n \nusersDeleted\n \n=\n \nawait\n \nquery\n.\ndelete\n();\n\n\n\n\n\n\nAlso like update queries, delete queries have a safety feature that prevents you from accidentally deleting every row in a table with \ncanModifyAllInstances\n.\n\n\nAny properties set in the query's \nvalues\n are ignored when executing a delete.\n\n\nFetching Data with a Query\n\n\nOf the four basic operations of a \nQuery\nT\n, fetching data is the most configurable. A simple \nQuery\nT\n that would fetch every instance of some entity looks like this:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n();\n\n\n\nList\nUser\n \nallUsers\n \n=\n \nawait\n \nquery\n.\nfetch\n();\n\n\n\n\n\n\nA fetch \nQuery\nT\n uses its \nwhere\n property to filter the result set, just like delete and update queries. Any properties set in the query's \nvalues\n are ignored when executing a fetch, since there is no need for them. In addition to fetching a list of instances from a database, you may also fetch a single instance with \nfetchOne\n. If no instance is found, \nnull\n is returned. (If more than one instance is found, an exception is thrown.)\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nwhere\n.\nid\n \n=\n \nwhereEqualTo\n(\n1\n);\n\n\n\nUser\n \noneUser\n \n=\n \nawait\n \nquery\n.\nfetchOne\n();\n\n\n\n\n\n\nFetch queries can be limited to a number of instances with the \nfetchLimit\n property. You may also set the \noffset\n of a \nQuery\nT\n to skip the first \noffset\n number of rows. Between \nfetchLimit\n and \noffset\n, you can implement naive paging. However, this type of paging suffers from a number of problems and so there is another paging mechanism covered in later sections.\n\n\nMany of the other fantastic things you can do with fetch queries - like joins, sorting and complex predicates - all deserve their own section and are covered later.\n\n\nSpecifying Result Properties\n\n\nWhen executing queries that return managed objects (i.e., \ninsert()\n, \nupdate()\n and \nfetch()\n), the default properties for each object are fetched. The default properties of a managed object are properties that correspond to a database column - attributes declared in the persistent type. A managed object's default properties can be modified when declaring its persistent type:\n\n\nclass\n \n_User\n \n{\n\n  \n@\nManagedColumnAttributes\n(\nomitByDefault:\n \ntrue\n)\n\n  \nString\n \nhashedPassword\n;\n\n\n}\n\n\n\n\n\n\nAny property with \nomitByDefault\n set to true will not be fetched by default.\n\n\nA property that is \nomitByDefault\n can still be fetched. Likewise, a property that is in the defaults can still be omitted. Each \nQuery\nT\n has a \nreturningProperties\n method to adjust which properties do get returned from the query. Its usage looks like this:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nreturningProperties\n((\nuser\n)\n \n=\n \n[\nuser\n.\nid\n,\n \nuser\n.\nname\n]);\n\n\n\n\n\n\nThe method \nreturningProperties\n takes a closure with one argument - an instance of the type being queried. The closure must return a \nList\n of properties to be fetched. Here, both \nuser.id\n and \nuser.name\n are returned and this \nQuery\nT\n will fetch a user's \nid\n and \nname\n properties only. (The SQL would be something like \nSELECT id, name FROM _User\n.) Note that the properties returned from this closure \nare not\n added to the list of default properties - the list is an exact set of properties to be returned.\n\n\nThe way \nreturningProperties\n is constructed is a little interesting. You may look at this code and expect the closure's return value to be something like \n[1, \"Bob\"]\n - a \nList\n with an \nid\n and a \nname\n. Instead, \nManagedObject\nT\n and \nQuery\nT\n work together to interpret the return value differently. The benefit of this approach is best explained by comparing it to another approach:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nreturningProperties\n \n=\n \n[\nid\n,\n \nname\n];\n \n// This code is not valid!\n\n\n\n\n\n\nIn the above approach - which is not valid code - the names of the properties are \nString\ns. The drawback here is that there is no way for the analyzer to tell us if \nid\n and \nname\n are actually properties of a \nUser\n or if we misspelled one of the properties. We'd only find out at runtime. Additionally, we get the benefit of code completion and refactoring tools when using the closure approach. Many other features of \nQuery\nT\n like joins, paging and sorting use a similar construct to identify which properties are being used in the query.\n\n\nIf you specify a property that doesn't exist for a managed object in \nreturningProperties\n, you will get an exception when the \nQuery\nT\n is executed.\n\n\nYou may not add a 'has-many' or 'has-one' relationship to \nreturningProperties\n, as this mechanism is achieved by the methods \njoinOne\n and \njoinMany\n. If you do add a 'has-one' or 'has-many' relationship property name to the list of \nreturningProperties\n, an exception will be thrown when the query is executed.\n\n\nNote that if you omit the primary key of a managed object from \nreturningProperties\n, it will automatically be added. The primary key is necessary to transform the rows into instances of their \nManagedObject\nT\n subclass.\n\n\nSorting\n\n\nResults of a fetch can be sorted using the \nsortBy\n method of a \nQuery\nT\n. Here's an example:\n\n\nvar\n \nq\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nsortBy\n((\nu\n)\n \n=\n \nu\n.\ndateCreated\n,\n \nQuerySortOrder\n.\nascending\n);\n\n\n\n\n\n\nsortBy\n takes two arguments: a closure that returns which property to sort by and the order of the sort.\n\n\nA \nQuery\nT\n results can be sorted by multiple properties. When multiple \nsortBy\ns are invoked on a \nQuery\nT\n, later \nsortBy\ns are used to break ties in previous \nsortBy\ns. For example, the following query will sort by last name, then by first name:\n\n\nvar\n \nq\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nsortBy\n((\nu\n)\n \n=\n \nu\n.\nlastName\n,\n \nQuerySortOrder\n.\nascending\n)\n\n  \n..\nsortBy\n((\nu\n)\n \n=\n \nu\n.\nfirstName\n,\n \nQuerySortOrder\n.\nascending\n);\n\n\n\n\n\n\nThus, the following three names would be ordered like so: 'Sally Smith', 'John Wu', 'Sally Wu'.\n\n\nExceptions and Errors\n\n\nAn error encountered in preparing or executing a query will throw a \nQueryException\n. \nRequestController\ns, by default, will interpret the event of a \nQueryException\n to return a \nResponse\n to an HTTP client. For common scenarios - like a unique violation generating an exception with suggested status code of \n409\n - Aqueduct will return a reasonable status code to the requesting HTTP client. Therefore, you do not have to catch query exceptions unless you wish to override the suggested status code.\n\n\nStatement Reuse\n\n\nAqueduct will parameterize and reuse queries when possible. This allows for significant speed and security improvements. Note that you do not have to do anything special to take advantage of this feature. However, currently at this time, you may not disable this feature.", 
            "title": "Executing Queries"
        }, 
        {
            "location": "/db/executing_queries/#inserting-updating-deleting-and-fetching-objects", 
            "text": "To send commands to a database - whether to fetch, insert, delete or update objects - you will create, configure and execute instances of  Query T . The type argument must be a subclass of  ManagedObject T . This tells the  Query T  which table it will operate on. Here's an example of a  Query T  that fetches all instances of  User :  var   query   =   new   Query User ();  var   allUsers   =   await   query . fetch ();   A  Query T  has four basic execution methods:  fetch ,  update ,  insert ,  delete .   fetch  will retrieve data from a database (it is equivalent to the SQL operation  SELECT ).  update  will modify existing data in a database (it is equivalent to the SQL operation  UPDATE ).  insert  will add new data to a database (it is equivalent to the SQL operation  INSERT ).  delete  will remove data from a database (it is equivalent to the SQL operation  DELETE ).   A  Query T  has many configurable properties. These properties will impact which objects get fetched, the data that gets sent to the database, the order that data is returned in, and so on.", 
            "title": "Inserting, Updating, Deleting and Fetching Objects"
        }, 
        {
            "location": "/db/executing_queries/#inserting-data-with-a-query", 
            "text": "Let's assume there exists a managed object type declared like this:  class   User   extends   ManagedObject _User   implements   _User   {}  class   _User   { \n   @ managedPrimaryKey \n   int   id ; \n\n   @ ManagedColumnAttributes ( indexed:   true ) \n   String   email ; \n\n   String   name ;  }   To insert a new row into the  _User  table, a  Query T  is constructed and executed like so:  var   query   =   new   Query User () \n   .. values . name   =   Bob \n   .. values . email   =   bob@stablekernel.com ;    var   user   =   await   query . insert ();    user . asMap ()   ==   { \n   id :   1 , \n   name :   Bob , \n   email :   bob@stablekernel.com  };   Every  Query T  has a  values  property that is the type of managed object being inserted. Here,  values  is an instance of  User . When a  Query T  is executed with insert, a new row is created in the database with every property that has been set for  values . In this case, both  name  and  email  have been set. The generated SQL looks like this:  INSERT   INTO   _user   ( name ,   email )   VALUES   ( Bob ,   bob@stablekernel.com )   Note there is no value provided for the  id  property in this query. Recall that  managedPrimaryKey  metadata is a convenience for  ManagedColumnAttributes  with autoincrementing behavior. Therefore, the database will assign a value for  id  during insertion. The object returned from  insert()  will be an instance of  User  that represents the inserted row. Thus, the returned  User  will have all of the values that were set in  Query T .values  as well as the auto-generated  id  value.  Properties that are not set in the  values  property will not be sent to the database. Values that are explicitly set to  null  will be sent as  NULL . For example, consider the following  Query T :  var   query   =   new   Query User () \n   .. values . name   =   null ;  await   query . insert ();   The generated SQL for this query does not send  email  - because it isn't included - and sends  NULL  for  name :  INSERT   INTO   _user   ( name )   VALUES   ( NULL );   If a property is not nullable (its  ManagedColumnAttributes  has  nullable: false ) and its value is not set in a query prior to inserting it, the query will fail and throw an exception.  You may also set  values  with an instance of a managed object. This is valuable when reading an object from a JSON HTTP request body:  var   user   =   new   User () \n   .. readMap ( requestBody );  var   query   =   new   Query User () \n   .. values   =   user ;   By default, the returned object from an  insert()  will have all of its properties set. See a later section on configuring which properties are returned from a  Query T .  If an insert query fails because of a conflict - a unique constraint is violated - the  Query T  will throw a  QueryException .  See a later section on how  QueryException s are gracefully handled by  RequestController s. In short, it is unlikely that you have to handle  QueryException  directly -  RequestController s know how to turn them into the appropriate HTTP response.", 
            "title": "Inserting Data with a Query"
        }, 
        {
            "location": "/db/executing_queries/#updating-data-with-a-query", 
            "text": "Updating rows with a  Query T  is similar to inserting data, in that you set the  values  of a  Query T  for data you want to change. The type parameter for the  Query T  indicates which entity - and therefore which database table - will get updated when the query is executed.  An update query can - and likely should - be restricted to a single row or subset of rows. This is done by configuring the  where  property of a  Query T  - which gets translated into the  where clause  of the SQL command. Here's an example:  // A Query that will change any user s whose name is  Bob  to  Fred  var   query   =   new   Query User () \n   .. values . name   =   Fred \n   .. where . name   =   whereEqualTo ( Bob );  List User   bobsThatAreNowFreds   =   await   query . update ();   Like  values ,  where  is also the same managed object type the query is being executed on. In the above example, then, both  values  and  where  and instances of  User . This query executes the following SQL:  UPDATE   _user   SET   name = Fred   WHERE   name = Bob ;   The  where  property is a very powerful and flexible, and so there is an entire section dedicated to it later in this guide. For now, we'll stick to some of the things specific to  update() .  Like  insert() , only the values set in the  values  property of a query get updated when executing  update() . Values that are omitted are not included. Values that need to be set to  null  must explicitly be set to  null  in the query:  // A Query that will remove names from anyone currently named Bob.  var   query   =   new   Query User () \n   .. values . name   =   null \n   .. where . name   =   whereEqualTo ( Bob );   An update query returns every modified row as a result. If no rows are updated, the return value is an empty list.    There is a variant to  Query T .update  named  updateOne . The  updateOne  method will build and execute a SQL query in the same way a normal  update  does, however, it will only return the single instance that was updated instead of a list. This is convenience method for the caller to get back a single instance instead of a list:  // Update user with id = 1 to have the name  Fred  var   query   =   new   Query User () \n   .. values . name   =   Fred \n   .. where . id   =   whereEqualTo ( 1 );  var   updatedUser   =   await   query . updateOne ();   The  updateOne  method will return  null  if no rows were updated. It is important to note that if  updateOne  is used and more than one row is updated,  updateOne  will throw an exception and the changes to the data  are not reversible . Because this is likely a mistake, this is considered an error, hence the exception is thrown. It is up to the programmer to recognize whether or not a particular  updateOne  query would impact multiple rows.  Update queries have a safety feature that prevents you from accidentally updating every row. If you try to execute a  Query T  to do an update and no values in  where  have been set, the default behavior of  Query T  will throw an exception prior to carrying out the request. If you actually want to update every instance of some entity (that is, every row of a table), you must set the  Query T 's  canModifyAllInstances  to  true  prior to execution. (This property defaults to  false .)", 
            "title": "Updating Data with a Query"
        }, 
        {
            "location": "/db/executing_queries/#deleting-data-with-a-query", 
            "text": "A  Query T  will delete rows from a database when using  delete() . Like update queries, you should specify a row or rows using  where  properties of the  Query T . The result of a delete operation will be a  Future int  with the number of rows deleted.  var   query   =   new   Query User () \n   .. where . id   =   whereEqualTo ( 1 );  int   usersDeleted   =   await   query . delete ();   Also like update queries, delete queries have a safety feature that prevents you from accidentally deleting every row in a table with  canModifyAllInstances .  Any properties set in the query's  values  are ignored when executing a delete.", 
            "title": "Deleting Data with a Query"
        }, 
        {
            "location": "/db/executing_queries/#fetching-data-with-a-query", 
            "text": "Of the four basic operations of a  Query T , fetching data is the most configurable. A simple  Query T  that would fetch every instance of some entity looks like this:  var   query   =   new   Query User ();  List User   allUsers   =   await   query . fetch ();   A fetch  Query T  uses its  where  property to filter the result set, just like delete and update queries. Any properties set in the query's  values  are ignored when executing a fetch, since there is no need for them. In addition to fetching a list of instances from a database, you may also fetch a single instance with  fetchOne . If no instance is found,  null  is returned. (If more than one instance is found, an exception is thrown.)  var   query   =   new   Query User () \n   .. where . id   =   whereEqualTo ( 1 );  User   oneUser   =   await   query . fetchOne ();   Fetch queries can be limited to a number of instances with the  fetchLimit  property. You may also set the  offset  of a  Query T  to skip the first  offset  number of rows. Between  fetchLimit  and  offset , you can implement naive paging. However, this type of paging suffers from a number of problems and so there is another paging mechanism covered in later sections.  Many of the other fantastic things you can do with fetch queries - like joins, sorting and complex predicates - all deserve their own section and are covered later.", 
            "title": "Fetching Data with a Query"
        }, 
        {
            "location": "/db/executing_queries/#specifying-result-properties", 
            "text": "When executing queries that return managed objects (i.e.,  insert() ,  update()  and  fetch() ), the default properties for each object are fetched. The default properties of a managed object are properties that correspond to a database column - attributes declared in the persistent type. A managed object's default properties can be modified when declaring its persistent type:  class   _User   { \n   @ ManagedColumnAttributes ( omitByDefault:   true ) \n   String   hashedPassword ;  }   Any property with  omitByDefault  set to true will not be fetched by default.  A property that is  omitByDefault  can still be fetched. Likewise, a property that is in the defaults can still be omitted. Each  Query T  has a  returningProperties  method to adjust which properties do get returned from the query. Its usage looks like this:  var   query   =   new   Query User () \n   .. returningProperties (( user )   =   [ user . id ,   user . name ]);   The method  returningProperties  takes a closure with one argument - an instance of the type being queried. The closure must return a  List  of properties to be fetched. Here, both  user.id  and  user.name  are returned and this  Query T  will fetch a user's  id  and  name  properties only. (The SQL would be something like  SELECT id, name FROM _User .) Note that the properties returned from this closure  are not  added to the list of default properties - the list is an exact set of properties to be returned.  The way  returningProperties  is constructed is a little interesting. You may look at this code and expect the closure's return value to be something like  [1, \"Bob\"]  - a  List  with an  id  and a  name . Instead,  ManagedObject T  and  Query T  work together to interpret the return value differently. The benefit of this approach is best explained by comparing it to another approach:  var   query   =   new   Query User () \n   .. returningProperties   =   [ id ,   name ];   // This code is not valid!   In the above approach - which is not valid code - the names of the properties are  String s. The drawback here is that there is no way for the analyzer to tell us if  id  and  name  are actually properties of a  User  or if we misspelled one of the properties. We'd only find out at runtime. Additionally, we get the benefit of code completion and refactoring tools when using the closure approach. Many other features of  Query T  like joins, paging and sorting use a similar construct to identify which properties are being used in the query.  If you specify a property that doesn't exist for a managed object in  returningProperties , you will get an exception when the  Query T  is executed.  You may not add a 'has-many' or 'has-one' relationship to  returningProperties , as this mechanism is achieved by the methods  joinOne  and  joinMany . If you do add a 'has-one' or 'has-many' relationship property name to the list of  returningProperties , an exception will be thrown when the query is executed.  Note that if you omit the primary key of a managed object from  returningProperties , it will automatically be added. The primary key is necessary to transform the rows into instances of their  ManagedObject T  subclass.", 
            "title": "Specifying Result Properties"
        }, 
        {
            "location": "/db/executing_queries/#sorting", 
            "text": "Results of a fetch can be sorted using the  sortBy  method of a  Query T . Here's an example:  var   q   =   new   Query User () \n   .. sortBy (( u )   =   u . dateCreated ,   QuerySortOrder . ascending );   sortBy  takes two arguments: a closure that returns which property to sort by and the order of the sort.  A  Query T  results can be sorted by multiple properties. When multiple  sortBy s are invoked on a  Query T , later  sortBy s are used to break ties in previous  sortBy s. For example, the following query will sort by last name, then by first name:  var   q   =   new   Query User () \n   .. sortBy (( u )   =   u . lastName ,   QuerySortOrder . ascending ) \n   .. sortBy (( u )   =   u . firstName ,   QuerySortOrder . ascending );   Thus, the following three names would be ordered like so: 'Sally Smith', 'John Wu', 'Sally Wu'.", 
            "title": "Sorting"
        }, 
        {
            "location": "/db/executing_queries/#exceptions-and-errors", 
            "text": "An error encountered in preparing or executing a query will throw a  QueryException .  RequestController s, by default, will interpret the event of a  QueryException  to return a  Response  to an HTTP client. For common scenarios - like a unique violation generating an exception with suggested status code of  409  - Aqueduct will return a reasonable status code to the requesting HTTP client. Therefore, you do not have to catch query exceptions unless you wish to override the suggested status code.", 
            "title": "Exceptions and Errors"
        }, 
        {
            "location": "/db/executing_queries/#statement-reuse", 
            "text": "Aqueduct will parameterize and reuse queries when possible. This allows for significant speed and security improvements. Note that you do not have to do anything special to take advantage of this feature. However, currently at this time, you may not disable this feature.", 
            "title": "Statement Reuse"
        }, 
        {
            "location": "/db/advanced_queries/", 
            "text": "Advanced Queries: Filtering, Joins and Paging\n\n\nPaging Fetched Result Sets\n\n\nIn larger data sets, it may make sense to only return a portion of rows from a database. For example, in a social media application, a user could have thousands of pieces of content they had created over many years. The likely use case for fetching their content would be to grab only the most recent content, and only grab earlier content as necessary. Aqueduct has two mechanisms in \nQuery\nT\n for building queries that can fetch a subset of rows within a certain range.\n\n\nNaive paging can be accomplished using the \nfetchLimit\n and \noffset\n properties of a \nQuery\nT\n. For example, if a table contains 100 rows, and you would like to grab 10 at a time, each query would have a value of 10 for its \nfetchLimit\n. The first query would have an \noffset\n of 0, then 10, then 20, and so on. Especially when using \nsortBy\n, this type of paging can be effective. One of the drawbacks to this type of paging is that it can skip or duplicate rows if rows are being added or deleted between fetches.\n\n\nFor example, a table contains 100 rows and you're fetching ten at a time. After two queries, you've fetched 20 total. The next query will fetch rows 21-30 - but before that, a new row is inserted at row 10. That means the old row 10 moves to row 11, row 11 moves to row 12 and so on. Most importantly, row 20 moves to row 21; and the next query will fetch row 21. This row was already fetched in the previous query, so it shows up as a duplicate. (Yes, this needs a diagram.)\n\n\nA similar issue occurs if a row is deleted from within the first 20 rows after they have been fetched. Row 21 slides down to row 20, so the next query won't fetch that row.\n\n\nA \nQuery\nT\n has a method named \npageBy\n to better handle paging and avoid the problem of sliding rows. The usage of \npageBy\n is similar to \nsortBy\n. Here's an example:\n\n\nvar\n \nfirstQuery\n \n=\n \nnew\n \nQuery\nPost\n()\n\n  \n..\npageBy\n((\np\n)\n \n=\n \np\n.\ndateCreated\n,\n \nQuerySortOrder\n.\ndescending\n)\n\n  \n..\nfetchLimit\n \n=\n \n10\n;\n\n\n\nvar\n \nfirstQueryResults\n \n=\n \nawait\n \nfirstQuery\n.\nfetch\n();\n\n\n\nvar\n \noldestPostWeGot\n \n=\n \nfirstQueryResults\n.\nlast\n.\ndateCreated\n;\n\n\nvar\n \nnextQuery\n \n=\n \nnew\n \nQuery\nPost\n()\n\n  \n..\npageBy\n((\np\n)\n \n=\n \np\n.\ndateCreated\n,\n \nQuerySortOrder\n.\ndescending\n,\n \nboundingValue:\n \noldestPostWeGot\n)\n\n  \n..\nfetchLimit\n \n=\n \n10\n;\n\n\n\n\n\n\nThis query would fetch the newest 10 posts. Then, it fetches the next 10 after skipping past all of the ones newer than the oldest post it got in the first result set.\n\n\nConceptually, this works by sorting the rows in descending order - larger times are later times and come first, smaller times are earlier times and come later - and then grabs the first 10 from that ordered list. The next query sorts the rows again, but removes any newer than the oldest one in the last query. It takes the first 10 from that shortened list. If you were to search from oldest to newest, you'd reverse the sort order.\n\n\nWhen paging, the query must have a \nfetchLimit\n - otherwise you're just sorting and returning every row. The \npageBy\n method takes a closure to identify which property is being used to sort the rows. This closure will be passed an instance of \nPost\n and it must return one of its properties. This pattern of using a closure to identify a property like this is common to all of the advanced querying methods. The reason it is done this way is to let the analyzer help you catch errors in query building and the code completion to kick in and write faster code.\n\n\nThe next argument to \npageBy\n defines the order the rows will be sorted in. Without a bounding value, \npageBy\n returns rows starting from the beginning of the sorted list of rows. Therefore, when no bounding value is passed, the \"first page\" of rows is returned. With a bounding value, the query returns rows starting from the first row past the bounding value. The bounding value is not inclusive. For example, consider the following table and a \nfetchLimit\n of 2.\n\n\n\n\n\n\n\n\nid\n\n\ndateCreated\n\n\n\n\n\n\n\n\n\n\n1\n\n\nJan 1 -- First Query Starts here\n\n\n\n\n\n\n2\n\n\nJan 2\n\n\n\n\n\n\n3\n\n\nJan 3\n\n\n\n\n\n\n4\n\n\nJan 4\n\n\n\n\n\n\n\n\nThe first query would return \nJan 1\n and \nJan 2\n. In the next query, bounding value is set to \nJan 2\n. The query would start grabbing rows from after Jan 2:\n\n\n\n\n\n\n\n\nid\n\n\ndateCreated\n\n\n\n\n\n\n\n\n\n\n1\n\n\nJan 1\n\n\n\n\n\n\n2\n\n\nJan 2\n\n\n\n\n\n\n3\n\n\nJan 3 -- Next Query Starts here\n\n\n\n\n\n\n4\n\n\nJan 4\n\n\n\n\n\n\n\n\nIn practice, this means passing the property value for the last object in the previous set. This is often accomplished by adding a query parameter to an endpoint that takes in a bounding value. (See \nManagedObjectController\nT\n as an example.)\n\n\nA \npageBy\n query will return an empty list of objects when no more values are left. If the number of objects remaining in the last page are less than the \nfetchLimit\n, only those objects will be returned. For example, if there four more objects left and the \nfetchLimit\n is 10, the number of objects returned will be four.\n\n\nYou should index properties that will be paged by:\n\n\n@\nManagedColumnAttributes\n(\nindexed:\n \ntrue\n)\n\n\nint\n \npageableProperty\n;\n\n\n\n\n\n\nFiltering Results of a Fetch Operation\n\n\nMore often than not, fetching every row of a table doesn't make sense. Instead, the desired result is a specific object or set of objects matching some condition. Aqueduct offers two ways to perform this filtering, both of which translate to a SQL \nwhere clause\n.\n\n\nThe first option is the least prohibitive, the most prone to error and the most difficult to maintain: a \nQuery\nT\n.predicate\n. A \nQueryPredicate\n is a \nString\n that is added to the underlying query's where clause. A \nQueryPredicate\n has two properties, a format string and a \nMap\nString, dynamic\n of parameter values. The \nformat\n string can (and should) parameterize any input values. Parameters are indicated in the format string using the \n@\n token:\n\n\n// Creates a predicate that would only include instances where some column \nid\n is less than 2\n\n\nvar\n \npredicate\n \n=\n \nnew\n \nPredicate\n(\nid \n @idVariable\n,\n \n{\nidVariable\n \n:\n \n2\n});\n\n\n\n\n\n\nThe text following the \n@\n token may contain \n[A-Za-z0-9_]\n. The resulting where clause will be formed by replacing each token with the matching key in the parameters map. The value is not transformed in any way, so it must be the appropriate type for the property it is filtering by. If a key is not present in the \nMap\n, an exception will be thrown. Extra keys will be ignored.\n\n\nA raw \nQueryPredicate\n like this one suffers from a few issues. First, predicates are \ndatabase specific\n that is, after the values from the \nparameters\n are added to the \nformat\n string, the resulting \nString\n is evaluated as-is by the underlying database. Perhaps more importantly, there is nothing to verify that the \nQueryPredicate\n refers to the appropriate column names or that the data in the \nparameters\n is the right type. This can cause chaos when refactoring code, where a simple name change to a property would break a query. This option is primarily intended to be used as a fallback if \nQuery\nT\n.where\n is incapable of expressing the desired SQL.\n\n\nThe \nwhere\n property of a \nQuery\nT\n is a much safer and more elegant way to build a query. The \nwhere\n property allows you to assign \nmatchers\n to the properties of a \nManagedObject\nT\n. A matcher applies a condition - like equal to or less than - to the property it is assigned to. (This follows the same Hamcrest matcher style that the Dart test framework uses.)\n\n\nThe \nwhere\n property of a \nQuery\nT\n has the same properties as the managed object being fetched. For each property of \nwhere\n that is assigned a matcher will be added to the SQL where clause. Here's an example of a query that finds a \nUser\n with an \nid\n equal to 1:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nwhere\n.\nid\n \n=\n \nwhereEqualTo\n(\n1\n);\n\n\n\n\n\n\n(The generated SQL here would be 'SELECT _user.id, _user.name, ... FROM _user WHERE _user.id = 1'.)\n\n\nAll matchers are created using one of the \nwhere\n top-level methods in Aqueduct. Other examples are \nwhereGreaterThan\n, \nwhereBetween\n, and \nwhereIn\n. Every matcher set on a \nwhere\n is combined using logical 'and'. In other words, the following query will find all users whose \nname\n is \"Bob\" \nand\n \nemail\n is not null:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nwhere\n.\nid\n \n=\n \nwhereEqualTo\n(\nBob\n)\n\n  \n..\nwhere\n.\nemail\n \n=\n \nwhereNotNull\n;\n\n\n\n\n\n\nThere are a number of \nwhere\n methods for different logic and string comparisons, see the API reference for more.\n\n\nRelationship properties can be have matchers, too. For example, the following query will fetch all parents who have children that are less than 10 years old:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nParent\n()\n\n  \n..\nwhere\n.\nchildren\n.\nhaveAtLeastOneWhere\n.\nage\n \n=\n \nwhereLessThan\n(\n10\n);\n\n\n\n\n\n\nWhen building \nwhere\n with relationship properties, there are some important things to understand. First, the values for any relationship properties are not returned in the results. In the previous query, that means that a list of \nParent\ns would be returned - but their \nchildren\n property wouldn't be populated. (To actually include relationship values, the next section talks about \njoinOne\n and \njoinMany\n.)\n\n\nMost \nwhere\ns that match on relationship properties will trigger a SQL join. This is a more expensive query than fetching from a single row. The only time a relationship matcher doesn't incur a SQL join is when matching the value of a foreign key column. That is, a belongs-to relationship property where we're only checking the primary key of the related object. There are two ways of doing this:\n\n\nvar\n \npreferredQuery\n \n=\n \nnew\n \nQuery\nChild\n()\n\n  \n..\nwhere\n.\nparent\n \n=\n \nwhereRelatedByValue\n(\n23\n);\n\n\n\nvar\n \nsameQuery\n \n=\n \nnew\n \nQuery\nChild\n()\n\n  \n..\nwhere\n.\nparent\n.\nid\n \n=\n \nwhereEqualTo\n(\n23\n);\n\n\n\n\n\n\nThe first query is preferred because it's clear to the reader what's happening. A query can be filtered by whether or not it has a value for its relationships. For example, the following queries return people with and without children:\n\n\nvar\n \npeopleWithoutChildren\n \n=\n \nnew\n \nQuery\nPerson\n()\n\n  \n..\nwhere\n.\nchildren\n \n=\n \nwhereNull\n;\n\n\n\nvar\n \npeopleWithChildren\n \n=\n \nnew\n \nQuery\nPerson\n()\n\n  \n..\nwhere\n.\nchildren\n \n=\n \nwhereNotNull\n;\n\n\n\n\n\n\nThe only matchers that can be applied directly to a relationship property are the three shown in these examples: \nwhereRelatedByValue\n, \nwhereNull\n and \nwhereNotNull\n. Properties of a relationship property, i.e. \nwhere.parent.age = whereGreaterThan(40)\n, don't have these restrictions.\n\n\nYou can access relationship properties of relationships, too:\n\n\nvar\n \nchildrenWithDoctorParents\n \n=\n \nnew\n \nQuery\nChild\n()\n\n  \n..\nwhere\n.\nparent\n.\njob\n.\ntitle\n \n=\n \nwhereEqualTo\n(\nDoctor\n);\n\n\n\n\n\n\nYou can match belongs to or has one relationships by just assigning matchers to their properties. A has-many relationship, however, is a \nManagedSet\nT\n. When matching on properties of a has-many relationship, you have to access their \nhaveAtLeastOneWhere\n property. The type of this property is the type of object in the \nManagedSet\nT\n, so it will have the properties of that type. To repeat the example above:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nParent\n()\n\n  \n..\nwhere\n.\nchildren\n.\nhaveAtLeastOneWhere\n.\nage\n \n=\n \nwhereLessThan\n(\n10\n);\n\n\n\n\n\n\nThe name here is important. The filter is applied to the returned \nParent\ns - if a parent doesn't have a child that is younger than 10, it will be removed from the result set. If just one of a parent's children is less than 10, it will be included. There is currently no support for checking the number of objects in the relationship.\n\n\nIncluding Relationships in a Fetch (aka, Joins)\n\n\nA \nQuery\nT\n can also fetch relationship properties. This allows queries to fetch entire model graphs and reduces the number of round-trips to a database. (This type of fetch will execute a SQL LEFT OUTER JOIN.)\n\n\nBy default, relationship properties are not fetched in a query and therefore aren't included in an object's \nasMap()\n. For example, consider the following two \nManagedObject\nT\ns, where a \nUser\n has-many \nTask\ns:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n \nimplements\n \n_User\n \n{}\n\n\nclass\n \n_User\n \n{\n\n  \n@\nmanagedPrimaryKey\n \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n  \nManagedSet\nTask\n \ntasks\n;\n  \n\n}\n\n\n\nclass\n \nTask\n \nextends\n \nManagedObject\n_Task\n \nimplements\n \n_Task\n \n{}\n\n\nclass\n \n_Task\n \n{\n\n  \n@\nmanagedPrimaryKey\n \nint\n \nid\n;\n\n\n  \n@\nManagedColumnAttributes\n(\n#\ntasks\n)\n\n  \nUser\n \nuser\n;\n\n\n  \nString\n \ncontents\n;\n\n\n}\n\n\n\n\n\n\nA \nQuery\nUser\n will fetch the \nname\n and \nid\n of each \nUser\n. A \nUser\n's \ntasks\n are not fetched, so the data returned looks like this:\n\n\nvar\n \nq\n \n=\n \nnew\n \nQuery\nUser\n();\n\n\nvar\n \nusers\n \n=\n \nawait\n \nq\n.\nfetch\n();\n\n\n\nusers\n.\nfirst\n.\nasMap\n()\n \n==\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \nname\n:\n \nBob\n\n\n};\n \n// yup\n\n\n\n\n\n\nThe method \njoinMany()\n will tell a \nQuery\nT\n to also include a particular has-many relationship, here, a user's \ntasks\n:\n\n\nvar\n \nq\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\njoinMany\n((\nu\n)\n \n=\n \nu\n.\ntasks\n);\n\n\nvar\n \nusers\n \n=\n \nawait\n \nq\n.\nfetch\n();\n\n\n\nusers\n.\nfirst\n.\nasMap\n()\n \n==\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \nname\n:\n \nBob\n,\n\n  \ntasks\n:\n \n[\n\n      \n{\nid\n:\n \n1\n,\n \ncontents\n:\n \nTake out trash\n,\n \nuser\n \n:\n \n{\nid\n:\n \n1\n}},\n\n      \n...\n\n  \n]\n\n\n};\n \n// yup\n\n\n\n\n\n\nNotice that the \ntasks\n are in fact included in this query. The argument to \njoinMany\n is a closure that must return a \nManagedSet\nT\n property of the object being queried. The values for each task is the default set of properties as though a \nQuery\nTask\n was executed. However, this can be modified.\n\n\nThe method \njoinMany()\n actually returns a new \nQuery\nT\n, where \nT\n is the type of object in the relationship property. That is, the above code could also be written as such:\n\n\nvar\n \nq\n \n=\n \nnew\n \nQuery\nUser\n();\n\n\n\n// type annotation added for clarity\n\n\nQuery\nTask\n \ntaskSubQuery\n \n=\n \nq\n.\njoinMany\n((\nu\n)\n \n=\n \nu\n.\ntasks\n);\n\n\n\n\n\n\nJust like any other \nQuery\nT\n, the set of returning properties can be modified through \nreturningProperties\n:\n\n\nvar\n \nq\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nreturningProperties\n((\nu\n)\n \n=\n \n[\nu\n.\nid\n,\n \nu\n.\nname\n]);\n\n\n\nq\n.\njoinMany\n((\nu\n)\n \n=\n \nu\n.\ntasks\n)\n  \n  \n..\nreturningProperties\n((\nt\n)\n \n=\n \n[\nt\n.\nid\n,\n \nt\n.\ncontents\n]);\n\n\n\n\n\n\nWhen joining on a has-one or a belongs-to relationship, use \njoinOne()\n instead of \njoinMany()\n:\n\n\nvar\n \nq\n \n=\n \nnew\n \nQuery\nTask\n()\n\n  \n..\njoinOne\n((\nt\n)\n \n=\n \nt\n.\nuser\n);\n\n\nvar\n \nresults\n \n=\n \nawait\n \nq\n.\nfetch\n();\n\n\n\nresults\n.\nfirst\n.\nasMap\n()\n \n==\n \n{\n\n  \nid\n:\n \n1\n,\n\n  \ncontents\n:\n \nTake out trash\n,\n\n  \nuser\n:\n \n{\n\n    \nid\n:\n \n1\n,\n\n    \nname\n:\n \nBob\n\n  \n}\n\n\n};\n \n// yup\n\n\n\n\n\n\nNotice that the results of this query include all of the details for a \nTask\n's \nuser\n - not just its \nid\n.\n\n\nA subquery created through \njoinOne\n or \njoinMany\n can also be filtered through its \nwhere\n. For example, the following query would return user's named 'Bob' and their overdue tasks only:\n\n\nvar\n \nq\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nwhere\n.\nname\n \n=\n \nwhereEquals\n(\nBob\n);\n\n\n\nq\n.\njoinMany\n((\nu\n)\n \n=\n \nu\n.\ntasks\n)\n  \n  \n..\nwhere\n.\noverdue\n \n=\n \nwhereEqualTo\n(\ntrue\n);\n\n\n\n\n\n\nNote that the \nwhere\n property on the subquery is an instance of \nTask\n, whereas \nwhere\n on the \nUser\n query is \nUser\n.\n\n\nMore than one join can be applied to a query, and subqueries can be nested. So, this is all valid, assuming the relationship properties exist:\n\n\nvar\n \nq\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\njoinOne\n((\nu\n)\n \n=\n \nu\n.\naddress\n);\n\n\n\nq\n.\njoinMany\n((\nu\n)\n \n=\n \nu\n.\ntasks\n)\n\n  \n..\njoinOne\n((\nu\n)\n \n=\n \nu\n.\nlocation\n);\n\n\n\n\n\n\nThis would fetch all users, their addresses, all of their tasks, and the location for each of their tasks. You'd get a nice sized tree of objects here.\n\n\nIt's important to understand how objects are filtered when using \nwhere\n and subqueries. Matchers applied to the top-level query will filter out those types of objects. A \nwhere\n on a subquery has no impact on the number of objects returned at the top-level. Let's say there were 10 total users, each with 10 total tasks. The following query would always return 10 user objects, but each user's \ntasks\n wouldn't necessarily contain all 10:\n\n\nvar\n \nq\n \n=\n \nnew\n \nQuery\nUser\n();\n\n\n\nq\n.\njoinMany\n((\nu\n)\n \n=\n \nu\n.\ntasks\n)\n\n  \n..\nwhere\n.\noverdue\n \n=\n \nwhereEqualTo\n(\ntrue\n);\n\n\n\n\n\n\nHowever, the following query would return less than 10 users, but for each user returned, they would have all 10 of their tasks:\n\n\nvar\n \nq\n \n=\n \nnew\n \nQuery\nUser\n()\n\n  \n..\nwhere\n.\nname\n \n=\n \nwhereEqualTo\n(\nBob\n)\n\n  \n..\njoinMany\n((\nu\n)\n \n=\n \nu\n.\ntasks\n);\n\n\n\n\n\n\nNote that a query will always fetch the primary key of all objects, even if it is omitted in \nreturningProperties\n.", 
            "title": "Advanced Queries"
        }, 
        {
            "location": "/db/advanced_queries/#advanced-queries-filtering-joins-and-paging", 
            "text": "", 
            "title": "Advanced Queries: Filtering, Joins and Paging"
        }, 
        {
            "location": "/db/advanced_queries/#paging-fetched-result-sets", 
            "text": "In larger data sets, it may make sense to only return a portion of rows from a database. For example, in a social media application, a user could have thousands of pieces of content they had created over many years. The likely use case for fetching their content would be to grab only the most recent content, and only grab earlier content as necessary. Aqueduct has two mechanisms in  Query T  for building queries that can fetch a subset of rows within a certain range.  Naive paging can be accomplished using the  fetchLimit  and  offset  properties of a  Query T . For example, if a table contains 100 rows, and you would like to grab 10 at a time, each query would have a value of 10 for its  fetchLimit . The first query would have an  offset  of 0, then 10, then 20, and so on. Especially when using  sortBy , this type of paging can be effective. One of the drawbacks to this type of paging is that it can skip or duplicate rows if rows are being added or deleted between fetches.  For example, a table contains 100 rows and you're fetching ten at a time. After two queries, you've fetched 20 total. The next query will fetch rows 21-30 - but before that, a new row is inserted at row 10. That means the old row 10 moves to row 11, row 11 moves to row 12 and so on. Most importantly, row 20 moves to row 21; and the next query will fetch row 21. This row was already fetched in the previous query, so it shows up as a duplicate. (Yes, this needs a diagram.)  A similar issue occurs if a row is deleted from within the first 20 rows after they have been fetched. Row 21 slides down to row 20, so the next query won't fetch that row.  A  Query T  has a method named  pageBy  to better handle paging and avoid the problem of sliding rows. The usage of  pageBy  is similar to  sortBy . Here's an example:  var   firstQuery   =   new   Query Post () \n   .. pageBy (( p )   =   p . dateCreated ,   QuerySortOrder . descending ) \n   .. fetchLimit   =   10 ;  var   firstQueryResults   =   await   firstQuery . fetch ();  var   oldestPostWeGot   =   firstQueryResults . last . dateCreated ;  var   nextQuery   =   new   Query Post () \n   .. pageBy (( p )   =   p . dateCreated ,   QuerySortOrder . descending ,   boundingValue:   oldestPostWeGot ) \n   .. fetchLimit   =   10 ;   This query would fetch the newest 10 posts. Then, it fetches the next 10 after skipping past all of the ones newer than the oldest post it got in the first result set.  Conceptually, this works by sorting the rows in descending order - larger times are later times and come first, smaller times are earlier times and come later - and then grabs the first 10 from that ordered list. The next query sorts the rows again, but removes any newer than the oldest one in the last query. It takes the first 10 from that shortened list. If you were to search from oldest to newest, you'd reverse the sort order.  When paging, the query must have a  fetchLimit  - otherwise you're just sorting and returning every row. The  pageBy  method takes a closure to identify which property is being used to sort the rows. This closure will be passed an instance of  Post  and it must return one of its properties. This pattern of using a closure to identify a property like this is common to all of the advanced querying methods. The reason it is done this way is to let the analyzer help you catch errors in query building and the code completion to kick in and write faster code.  The next argument to  pageBy  defines the order the rows will be sorted in. Without a bounding value,  pageBy  returns rows starting from the beginning of the sorted list of rows. Therefore, when no bounding value is passed, the \"first page\" of rows is returned. With a bounding value, the query returns rows starting from the first row past the bounding value. The bounding value is not inclusive. For example, consider the following table and a  fetchLimit  of 2.     id  dateCreated      1  Jan 1 -- First Query Starts here    2  Jan 2    3  Jan 3    4  Jan 4     The first query would return  Jan 1  and  Jan 2 . In the next query, bounding value is set to  Jan 2 . The query would start grabbing rows from after Jan 2:     id  dateCreated      1  Jan 1    2  Jan 2    3  Jan 3 -- Next Query Starts here    4  Jan 4     In practice, this means passing the property value for the last object in the previous set. This is often accomplished by adding a query parameter to an endpoint that takes in a bounding value. (See  ManagedObjectController T  as an example.)  A  pageBy  query will return an empty list of objects when no more values are left. If the number of objects remaining in the last page are less than the  fetchLimit , only those objects will be returned. For example, if there four more objects left and the  fetchLimit  is 10, the number of objects returned will be four.  You should index properties that will be paged by:  @ ManagedColumnAttributes ( indexed:   true )  int   pageableProperty ;", 
            "title": "Paging Fetched Result Sets"
        }, 
        {
            "location": "/db/advanced_queries/#filtering-results-of-a-fetch-operation", 
            "text": "More often than not, fetching every row of a table doesn't make sense. Instead, the desired result is a specific object or set of objects matching some condition. Aqueduct offers two ways to perform this filtering, both of which translate to a SQL  where clause .  The first option is the least prohibitive, the most prone to error and the most difficult to maintain: a  Query T .predicate . A  QueryPredicate  is a  String  that is added to the underlying query's where clause. A  QueryPredicate  has two properties, a format string and a  Map String, dynamic  of parameter values. The  format  string can (and should) parameterize any input values. Parameters are indicated in the format string using the  @  token:  // Creates a predicate that would only include instances where some column  id  is less than 2  var   predicate   =   new   Predicate ( id   @idVariable ,   { idVariable   :   2 });   The text following the  @  token may contain  [A-Za-z0-9_] . The resulting where clause will be formed by replacing each token with the matching key in the parameters map. The value is not transformed in any way, so it must be the appropriate type for the property it is filtering by. If a key is not present in the  Map , an exception will be thrown. Extra keys will be ignored.  A raw  QueryPredicate  like this one suffers from a few issues. First, predicates are  database specific  that is, after the values from the  parameters  are added to the  format  string, the resulting  String  is evaluated as-is by the underlying database. Perhaps more importantly, there is nothing to verify that the  QueryPredicate  refers to the appropriate column names or that the data in the  parameters  is the right type. This can cause chaos when refactoring code, where a simple name change to a property would break a query. This option is primarily intended to be used as a fallback if  Query T .where  is incapable of expressing the desired SQL.  The  where  property of a  Query T  is a much safer and more elegant way to build a query. The  where  property allows you to assign  matchers  to the properties of a  ManagedObject T . A matcher applies a condition - like equal to or less than - to the property it is assigned to. (This follows the same Hamcrest matcher style that the Dart test framework uses.)  The  where  property of a  Query T  has the same properties as the managed object being fetched. For each property of  where  that is assigned a matcher will be added to the SQL where clause. Here's an example of a query that finds a  User  with an  id  equal to 1:  var   query   =   new   Query User () \n   .. where . id   =   whereEqualTo ( 1 );   (The generated SQL here would be 'SELECT _user.id, _user.name, ... FROM _user WHERE _user.id = 1'.)  All matchers are created using one of the  where  top-level methods in Aqueduct. Other examples are  whereGreaterThan ,  whereBetween , and  whereIn . Every matcher set on a  where  is combined using logical 'and'. In other words, the following query will find all users whose  name  is \"Bob\"  and   email  is not null:  var   query   =   new   Query User () \n   .. where . id   =   whereEqualTo ( Bob ) \n   .. where . email   =   whereNotNull ;   There are a number of  where  methods for different logic and string comparisons, see the API reference for more.  Relationship properties can be have matchers, too. For example, the following query will fetch all parents who have children that are less than 10 years old:  var   query   =   new   Query Parent () \n   .. where . children . haveAtLeastOneWhere . age   =   whereLessThan ( 10 );   When building  where  with relationship properties, there are some important things to understand. First, the values for any relationship properties are not returned in the results. In the previous query, that means that a list of  Parent s would be returned - but their  children  property wouldn't be populated. (To actually include relationship values, the next section talks about  joinOne  and  joinMany .)  Most  where s that match on relationship properties will trigger a SQL join. This is a more expensive query than fetching from a single row. The only time a relationship matcher doesn't incur a SQL join is when matching the value of a foreign key column. That is, a belongs-to relationship property where we're only checking the primary key of the related object. There are two ways of doing this:  var   preferredQuery   =   new   Query Child () \n   .. where . parent   =   whereRelatedByValue ( 23 );  var   sameQuery   =   new   Query Child () \n   .. where . parent . id   =   whereEqualTo ( 23 );   The first query is preferred because it's clear to the reader what's happening. A query can be filtered by whether or not it has a value for its relationships. For example, the following queries return people with and without children:  var   peopleWithoutChildren   =   new   Query Person () \n   .. where . children   =   whereNull ;  var   peopleWithChildren   =   new   Query Person () \n   .. where . children   =   whereNotNull ;   The only matchers that can be applied directly to a relationship property are the three shown in these examples:  whereRelatedByValue ,  whereNull  and  whereNotNull . Properties of a relationship property, i.e.  where.parent.age = whereGreaterThan(40) , don't have these restrictions.  You can access relationship properties of relationships, too:  var   childrenWithDoctorParents   =   new   Query Child () \n   .. where . parent . job . title   =   whereEqualTo ( Doctor );   You can match belongs to or has one relationships by just assigning matchers to their properties. A has-many relationship, however, is a  ManagedSet T . When matching on properties of a has-many relationship, you have to access their  haveAtLeastOneWhere  property. The type of this property is the type of object in the  ManagedSet T , so it will have the properties of that type. To repeat the example above:  var   query   =   new   Query Parent () \n   .. where . children . haveAtLeastOneWhere . age   =   whereLessThan ( 10 );   The name here is important. The filter is applied to the returned  Parent s - if a parent doesn't have a child that is younger than 10, it will be removed from the result set. If just one of a parent's children is less than 10, it will be included. There is currently no support for checking the number of objects in the relationship.", 
            "title": "Filtering Results of a Fetch Operation"
        }, 
        {
            "location": "/db/advanced_queries/#including-relationships-in-a-fetch-aka-joins", 
            "text": "A  Query T  can also fetch relationship properties. This allows queries to fetch entire model graphs and reduces the number of round-trips to a database. (This type of fetch will execute a SQL LEFT OUTER JOIN.)  By default, relationship properties are not fetched in a query and therefore aren't included in an object's  asMap() . For example, consider the following two  ManagedObject T s, where a  User  has-many  Task s:  class   User   extends   ManagedObject _User   implements   _User   {}  class   _User   { \n   @ managedPrimaryKey   int   id ; \n\n   String   name ; \n   ManagedSet Task   tasks ;    }  class   Task   extends   ManagedObject _Task   implements   _Task   {}  class   _Task   { \n   @ managedPrimaryKey   int   id ; \n\n   @ ManagedColumnAttributes ( # tasks ) \n   User   user ; \n\n   String   contents ;  }   A  Query User  will fetch the  name  and  id  of each  User . A  User 's  tasks  are not fetched, so the data returned looks like this:  var   q   =   new   Query User ();  var   users   =   await   q . fetch ();  users . first . asMap ()   ==   { \n   id :   1 , \n   name :   Bob  };   // yup   The method  joinMany()  will tell a  Query T  to also include a particular has-many relationship, here, a user's  tasks :  var   q   =   new   Query User () \n   .. joinMany (( u )   =   u . tasks );  var   users   =   await   q . fetch ();  users . first . asMap ()   ==   { \n   id :   1 , \n   name :   Bob , \n   tasks :   [ \n       { id :   1 ,   contents :   Take out trash ,   user   :   { id :   1 }}, \n       ... \n   ]  };   // yup   Notice that the  tasks  are in fact included in this query. The argument to  joinMany  is a closure that must return a  ManagedSet T  property of the object being queried. The values for each task is the default set of properties as though a  Query Task  was executed. However, this can be modified.  The method  joinMany()  actually returns a new  Query T , where  T  is the type of object in the relationship property. That is, the above code could also be written as such:  var   q   =   new   Query User ();  // type annotation added for clarity  Query Task   taskSubQuery   =   q . joinMany (( u )   =   u . tasks );   Just like any other  Query T , the set of returning properties can be modified through  returningProperties :  var   q   =   new   Query User () \n   .. returningProperties (( u )   =   [ u . id ,   u . name ]);  q . joinMany (( u )   =   u . tasks )   \n   .. returningProperties (( t )   =   [ t . id ,   t . contents ]);   When joining on a has-one or a belongs-to relationship, use  joinOne()  instead of  joinMany() :  var   q   =   new   Query Task () \n   .. joinOne (( t )   =   t . user );  var   results   =   await   q . fetch ();  results . first . asMap ()   ==   { \n   id :   1 , \n   contents :   Take out trash , \n   user :   { \n     id :   1 , \n     name :   Bob \n   }  };   // yup   Notice that the results of this query include all of the details for a  Task 's  user  - not just its  id .  A subquery created through  joinOne  or  joinMany  can also be filtered through its  where . For example, the following query would return user's named 'Bob' and their overdue tasks only:  var   q   =   new   Query User () \n   .. where . name   =   whereEquals ( Bob );  q . joinMany (( u )   =   u . tasks )   \n   .. where . overdue   =   whereEqualTo ( true );   Note that the  where  property on the subquery is an instance of  Task , whereas  where  on the  User  query is  User .  More than one join can be applied to a query, and subqueries can be nested. So, this is all valid, assuming the relationship properties exist:  var   q   =   new   Query User () \n   .. joinOne (( u )   =   u . address );  q . joinMany (( u )   =   u . tasks ) \n   .. joinOne (( u )   =   u . location );   This would fetch all users, their addresses, all of their tasks, and the location for each of their tasks. You'd get a nice sized tree of objects here.  It's important to understand how objects are filtered when using  where  and subqueries. Matchers applied to the top-level query will filter out those types of objects. A  where  on a subquery has no impact on the number of objects returned at the top-level. Let's say there were 10 total users, each with 10 total tasks. The following query would always return 10 user objects, but each user's  tasks  wouldn't necessarily contain all 10:  var   q   =   new   Query User ();  q . joinMany (( u )   =   u . tasks ) \n   .. where . overdue   =   whereEqualTo ( true );   However, the following query would return less than 10 users, but for each user returned, they would have all 10 of their tasks:  var   q   =   new   Query User () \n   .. where . name   =   whereEqualTo ( Bob ) \n   .. joinMany (( u )   =   u . tasks );   Note that a query will always fetch the primary key of all objects, even if it is omitted in  returningProperties .", 
            "title": "Including Relationships in a Fetch (aka, Joins)"
        }, 
        {
            "location": "/db/validations/", 
            "text": "Validating Data\n\n\nData is added to a database through \nupdate\n and \ninsert\n queries. As part of these two operations, a \nManagedObject\nT\n will ensure that its properties have valid values. For example, a \nPerson\n object might ensure that its name starts with a capital letter and that its phone number has only numeric values.  If one or more validation fails, the update or insert operation will fail and the data is not sent to the database. A validation failure will throw a \nQueryException\n, which automatically sends an HTTP response with error messaging to help the client correct their request.\n\n\nThe preferred way of setting a validation is to add \nValidate\n metadata to properties of a persistent type of a \nManagedObject\nT\n. Here's an example of a validation that ensures a tweet is less than 140 characters:\n\n\nclass\n \nTweet\n \nextends\n \nManagedObject\n_Tweet\n \nimplements\n \n_Tweet\n \n{}\n\n\nclass\n \n_Tweet\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nValidate\n.\nlength\n(\nlessThan:\n \n140\n)\n\n  \nString\n \nmessage\n;\n\n\n}\n\n\n\n\n\n\nBuilt-in Validators\n\n\nThere are a handful of built-in validations for common operations. For example, it is common to apply a regular expression to a value to ensure it formatted correctly or restrict the possible values to a list of available options. Common validators are available as named constructors on the \nValidate\n class. Here is an example:\n\n\nclass\n \n_Story\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nValidate\n.\noneOf\n(\nconst\n \n[\nstarted\n,\n \naccepted\n,\n \nrejected\n,\n \ndelivered\n])\n\n  \nString\n \nstate\n;\n\n\n}\n\n\n\n\n\n\nA built-in validator is useful because it automatically generates an error message that is returned in an HTTP response. For example, the previous code snippet indicates that the \nstate\n property must be one of the four listed strings. If a value other than one of those four strings is used, the error message returned to the HTTP client would be:\n\n\nThe value `invalidValue` is not valid for \na\n \nhref=\nhttps://www.dartdocs.org/documentation/aqueduct/latest/aqueduct/AuthCodeController/state.html\nstate\n/a\n. Valid values are: \nstarted\n, \naccepted\n, \nrejected\n, \ndelivered\n.\n.\n\n\n\n\n\nSee the API reference for \nValidate\n and its named constructors for possible options.\n\n\nValidate\n metadata on transient properties have no effect. This metadata is only valid for database-backed properties declared in a persistent type.\n\n\nCustom Validators\n\n\nThere will be times where the built-in validators are not sufficient for your application's use case. You may create subclasses of \nValidate\n to provide custom validation behavior.For example, a \nValidate\n subclass you have declared named \nValidatePhoneNumber\n would be used like so:\n\n\nclass\n \n_Person\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nid\n;\n\n\n  \n@\nValidatePhoneNumber\n()\n\n  \nString\n \nphoneNumber\n;\n\n\n}\n\n\n\n\n\n\nA subclass of \nValidate\n must override \nValidate.validate()\n and call the superclass' primary constructor when instantiated. Here's an example of that phone number validator:\n\n\nclass\n \nValidatePhoneNumber\n \nextends\n \nValidate\nString\n \n{\n\n  \nValidatePhoneNumber\n({\nbool\n \nonUpdate:\n \ntrue\n,\n \nbool\n \nonInsert:\n \ntrue\n})\n \n:\n\n    \nsuper\n(\nonUpdate:\n \nonUpdate\n,\n \nonInsert:\n \nonInsert\n);\n\n\n  \n@\noverride\n\n  \nbool\n \nvalidate\n(\n\n      \nValidateOperation\n \noperation\n,\n\n      \nManagedAttributeDescription\n \nproperty\n,\n\n      \nString\n \nvalue\n,\n\n      \nList\nString\n \nerrors\n)\n \n{\n  \n    \nif\n \n(\nvalue\n.\nlength\n \n!=\n \n15\n)\n \n{\n\n      \nerrors\n.\nadd\n(\n\n        \n${\nproperty\n.\nname\n}\n has invalid length of \n${\nvalue\n.\nlength\n}\n, must be 15 digits.\n);\n\n      \nreturn\n \nfalse\n;\n\n    \n}\n\n\n    \nif\n \n(\ncontainsNonNumericValues\n(\nvalue\n))\n \n{\n\n      \nerrors\n.\nadd\n(\n\n        \n${\nproperty\n.\nname\n}\n has invalid format, must contain characters 0-9 only.\n);\n\n      \nreturn\n \nfalse\n;\n\n    \n}\n\n\n    \nreturn\n \ntrue\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nNote that \nValidate\n is generic - you may provide a type argument which must match the type of the \nvalue\n argument to \nValidate.validate()\n. Omitting the type argument defaults to \ndynamic\n and therefore \nvalue\n must be \ndynamic\n.\n\n\nThe \nvalidate\n method must return \nfalse\n if validation failed, otherwise it should return \ntrue\n. It should add error messages for any failed validations. These error messages are returned in the HTTP response.\n\n\nValidation Behavior\n\n\nA property may have more than one \nValidate\n metadata. In this case, all of the validations for a property must pass. The order in which multiple validations are performed is undefined and subject to change. Here's an example of validations that ensure a property's value is 10 characters long and only contains 10 alphabetic capital letters:\n\n\n@\nValidate\n.\nlength\n(\nequalTo:\n \n10\n)\n\n\n@\nValidate\n.\nmatches\n(\nr\n$[A-Z]+^\n)\n\n\nString\n \ntenCapitalLetters\n;\n\n\n\n\n\n\nBy default, validations are executed when a \nQuery\nT\n's \ninsert\n or \nupdate\n method is invoked. A validator can be restricted to only run on \ninsert\n or \nupdate\n by passing values for its optional constructor arguments \nonUpdate\n and \nonInsert\n:\n\n\n@\nValidate\n.\nmatches\n(\nr\n^[A-Z]+$\n,\n \nonInsert:\n \ntrue\n,\n \nonUpdate:\n \nfalse\n)\n\n\nString\n \nvalidateOnInsertOnly\n;\n\n\n\n\n\n\nIt is important to understand how validations work when a value for a property is \nnot\n specified in an insert or update query. For example, consider a \nPerson\n with a \nname\n and \nemail\n property and then inserted in a query that omits \nemail\n:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nPerson\n()\n\n  \n..\nvalues\n.\nname\n \n=\n \nBob\n;\n\n\n\nawait\n \nquery\n.\ninsert\n();\n\n\n\n\n\n\nBecause \nemail\n was not set on \nQuery.values\n, validations will not be run on that property.\n\n\nThere are two special validators that can require a property to be set, or require that a property \nnot\n be set. \nValidate.present()\n requires that the associated property must have a value. A property with this validator must be provided each time the object is inserted or updated. Like all validators, \nValidate.present()\n can be adjusted to be invoked on only inserts or only updates. For example, the following declaration requires that \nemail\n is set on insertion, but doesn't have to be for updates:\n\n\n@\nValidate\n.\npresent\n(\nonUpdate:\n \nfalse\n,\n \nonInsert:\n \ntrue\n)\n\n\nString\n \nemail\n;\n\n\n\n\n\n\nThe inverse of \nValidate.present()\n is \nValidate.absent()\n. This validation prevents a property from being set. This is useful when a value should be included during insertion, but can't be updated. Here's an example:\n\n\n@\nValidate\n.\nabsent\n(\nonUpdate:\n \ntrue\n,\n \nonInsert:\n \nfalse\n)\n\n\nString\n \ncanOnlyBeSetOnce\n;\n\n\n\n\n\n\nIn the above declaration, the validator is only run on update operations and ensures that the property \ncanOnlyBeSetOnce\n does not have a value. Because this validator is not run on insert operations, there is no restriction when the object is first inserted.\n\n\nValidators are not run when a value is null. For example, the following insertion explicitly inserts \nnull\n for the property \nemail\n:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nPerson\n()\n\n  \n..\nvalues\n.\nemail\n \n=\n \nnull\n\n  \n..\nvalues\n.\nname\n \n=\n \nBob\n;\n\n\n\nawait\n \nquery\n.\ninsert\n();\n\n\n\n\n\n\nNullability is enforced by \nManagedColumnAttributes.isNullable\n property. Consider the following declaration:\n\n\n@\nManagedColumnAttributes\n(\nnullable:\n \nfalse\n)\n\n\n@\nValidate\n.\nlength\n(\ngreaterThan:\n \n10\n)\n\n\nString\n \nname\n;\n\n\n\n\n\n\nHere, the property \nname\n must not be null and must be greater than 10 characters long. The behavior of inserting or updating this property is shown in the following table.\n\n\n\n\n\n\n\n\nInput Value for Name\n\n\nValidation Runs?\n\n\nOutcome\n\n\n\n\n\n\n\n\n\n\nInsert value longer than 10 characters\n\n\nYes\n\n\nSuccessful database insert\n\n\n\n\n\n\nInsert value shorter than 10 characters\n\n\nYes\n\n\nDatabase insert not executed, exception thrown\n\n\n\n\n\n\nInsert value not specified\n\n\nNo\n\n\nDatabase insert fails with non-null violation, exception thrown\n\n\n\n\n\n\nInsert value is null\n\n\nNo\n\n\nDatabase insert fails with non-null violation, exception thrown\n\n\n\n\n\n\nUpdate value longer than 10 characters\n\n\nYes\n\n\nSuccessful database update\n\n\n\n\n\n\nUpdate value shorter than 10 characters\n\n\nYes\n\n\nDatabase update not executed, exception thrown\n\n\n\n\n\n\nUpdate value not specified\n\n\nNo\n\n\nSuccessful database update\n\n\n\n\n\n\nUpdate value is explicit null\n\n\nNo\n\n\nSuccessful database update\n\n\n\n\n\n\n\n\nThis behavior allows \nManagedObject\nT\n instances to be partially updated, which also allows for partial PUTs. Partial PUTs can be prevented by adding \nValidate.present()\n metadata to all properties. While partial PUTs are not idiomatic REST, they are pragmatic software development.\n\n\nThis also means that any custom validator can safely assume that a value passed to \nValidate.validate()\n is non-null.\n\n\nOther Validator Behavior\n\n\nFor validators that can't be built by subclassing \nValidate\n, you may override \nManagedObject\nT\n.validate()\n. This method is useful when a validation involves more than one property.\n\n\nThis method is passed the type of operation triggering the validation - either an insert or update. Here's an example:\n\n\nclass\n \nPerson\n \nextends\n \nManagedObject\n_Person\n \nimplements\n \n_Person\n \n{\n\n  \n@\noverride\n\n  \nbool\n \nvalidate\n(\n\n      \n{\nValidateOperation\n \nforOperation:\n \nValidateOperation\n.\ninsert\n,\n\n      \nList\nString\n \ncollectErrorsIn\n})\n \n{\n\n   \nvar\n \nvalid\n \n=\n \nsuper\n(\n\n     \nforOperation:\n \nforOperation\n,\n \ncollectErrorsIn:\n \ncollectErrorsIn\n);\n\n\n    \nif\n \n(\na\n \n+\n \nb\n \n \n10\n)\n \n{\n\n      \nvalid\n \n=\n \nfalse\n;\n\n      \ncollectErrorsIn\n.\nadd\n(\na + b must be greater than 10\n);\n\n    \n}\n\n\n    \nreturn\n \nvalid\n;\n\n  \n}\n\n\n}\n\n\n\n\n\n\nWhen overriding this method, the \nsuper\n implementation must be invoked and if it returns \nfalse\n, the overridden method must return \nfalse\n.\n\n\nSkipping Validations\n\n\nValidations are only run when values are set via \nQuery\nT\n.values\n. Values set via \nQuery\nT\n.valueMap\n are not validated. Therefore, objects should typically be inserted and updated using \nQuery\nT\n.values\n unless validation must be ignored. Here's an example of skipping validation:\n\n\nvar\n \nquery\n \n=\n \nnew\n \nQuery\nPerson\n()\n\n  \n..\nvalueMap\n \n=\n \n{\n\n    \nname\n \n:\n \nxyz\n,\n\n    \nemail\n \n:\n \nwhatever\n\n  \n};\n\n\n\n\n\n\nSkipping validation should be rare.\n\n\nUpdate and Insert Callbacks\n\n\nManagedObject\nT\n subclasses may override \nwillUpdate\n and \nwillInsert\n to modify its properties prior to being updated or inserted by a \nQuery\nT\n. For example, a managed object may have updated and created dates that can be guaranteed to be set when inserted or updated:\n\n\nclass\n \nPerson\n \nextends\n \nManagedObject\n_Person\n \nimplements\n \n_Person\n \n{\n\n  \n@\noverride\n\n  \nvoid\n \nwillUpdate\n()\n \n{\n\n    \nupdatedAt\n \n=\n \nnew\n \nDateTime\n.\nnow\n().\ntoUtc\n();\n\n  \n}\n\n\n  \n@\noverride\n\n  \nvoid\n \nwillInsert\n()\n \n{\n\n    \ncreatedAt\n \n=\n \nnew\n \nDateTime\n.\nnow\n().\ntoUtc\n();\n\n  \n}\n\n\n}\n\n\nclass\n \n_Person\n \n{\n\n  \n@\nmanagedPrimaryKey\n\n  \nint\n \nid\n;\n\n\n  \nString\n \nname\n;\n\n  \nDateTime\n \ncreatedAt\n;\n\n  \nDateTime\n \nupdatedAt\n;\n\n\n}\n\n\n\n\n\n\nNote that all operations must be synchronous in these methods.\n\n\nBoth \nwillUpdate\n and \nwillInsert\n are invoked prior the validation phase. Thus, any values set in these methods will be subject to the declared validations of the instance.\n\n\nLike validations, \nwillUpdate\n and \nwillInsert\n  are skipped when using \nQuery.valueMap\n.", 
            "title": "Validations"
        }, 
        {
            "location": "/db/validations/#validating-data", 
            "text": "Data is added to a database through  update  and  insert  queries. As part of these two operations, a  ManagedObject T  will ensure that its properties have valid values. For example, a  Person  object might ensure that its name starts with a capital letter and that its phone number has only numeric values.  If one or more validation fails, the update or insert operation will fail and the data is not sent to the database. A validation failure will throw a  QueryException , which automatically sends an HTTP response with error messaging to help the client correct their request.  The preferred way of setting a validation is to add  Validate  metadata to properties of a persistent type of a  ManagedObject T . Here's an example of a validation that ensures a tweet is less than 140 characters:  class   Tweet   extends   ManagedObject _Tweet   implements   _Tweet   {}  class   _Tweet   { \n   @ managedPrimaryKey \n   int   id ; \n\n   @ Validate . length ( lessThan:   140 ) \n   String   message ;  }", 
            "title": "Validating Data"
        }, 
        {
            "location": "/db/validations/#built-in-validators", 
            "text": "There are a handful of built-in validations for common operations. For example, it is common to apply a regular expression to a value to ensure it formatted correctly or restrict the possible values to a list of available options. Common validators are available as named constructors on the  Validate  class. Here is an example:  class   _Story   { \n   @ managedPrimaryKey \n   int   id ; \n\n   @ Validate . oneOf ( const   [ started ,   accepted ,   rejected ,   delivered ]) \n   String   state ;  }   A built-in validator is useful because it automatically generates an error message that is returned in an HTTP response. For example, the previous code snippet indicates that the  state  property must be one of the four listed strings. If a value other than one of those four strings is used, the error message returned to the HTTP client would be:  The value `invalidValue` is not valid for  a   href= https://www.dartdocs.org/documentation/aqueduct/latest/aqueduct/AuthCodeController/state.html state /a . Valid values are:  started ,  accepted ,  rejected ,  delivered . .  See the API reference for  Validate  and its named constructors for possible options.  Validate  metadata on transient properties have no effect. This metadata is only valid for database-backed properties declared in a persistent type.", 
            "title": "Built-in Validators"
        }, 
        {
            "location": "/db/validations/#custom-validators", 
            "text": "There will be times where the built-in validators are not sufficient for your application's use case. You may create subclasses of  Validate  to provide custom validation behavior.For example, a  Validate  subclass you have declared named  ValidatePhoneNumber  would be used like so:  class   _Person   { \n   @ managedPrimaryKey \n   int   id ; \n\n   @ ValidatePhoneNumber () \n   String   phoneNumber ;  }   A subclass of  Validate  must override  Validate.validate()  and call the superclass' primary constructor when instantiated. Here's an example of that phone number validator:  class   ValidatePhoneNumber   extends   Validate String   { \n   ValidatePhoneNumber ({ bool   onUpdate:   true ,   bool   onInsert:   true })   : \n     super ( onUpdate:   onUpdate ,   onInsert:   onInsert ); \n\n   @ override \n   bool   validate ( \n       ValidateOperation   operation , \n       ManagedAttributeDescription   property , \n       String   value , \n       List String   errors )   {   \n     if   ( value . length   !=   15 )   { \n       errors . add ( \n         ${ property . name }  has invalid length of  ${ value . length } , must be 15 digits. ); \n       return   false ; \n     } \n\n     if   ( containsNonNumericValues ( value ))   { \n       errors . add ( \n         ${ property . name }  has invalid format, must contain characters 0-9 only. ); \n       return   false ; \n     } \n\n     return   true ; \n   }  }   Note that  Validate  is generic - you may provide a type argument which must match the type of the  value  argument to  Validate.validate() . Omitting the type argument defaults to  dynamic  and therefore  value  must be  dynamic .  The  validate  method must return  false  if validation failed, otherwise it should return  true . It should add error messages for any failed validations. These error messages are returned in the HTTP response.", 
            "title": "Custom Validators"
        }, 
        {
            "location": "/db/validations/#validation-behavior", 
            "text": "A property may have more than one  Validate  metadata. In this case, all of the validations for a property must pass. The order in which multiple validations are performed is undefined and subject to change. Here's an example of validations that ensure a property's value is 10 characters long and only contains 10 alphabetic capital letters:  @ Validate . length ( equalTo:   10 )  @ Validate . matches ( r $[A-Z]+^ )  String   tenCapitalLetters ;   By default, validations are executed when a  Query T 's  insert  or  update  method is invoked. A validator can be restricted to only run on  insert  or  update  by passing values for its optional constructor arguments  onUpdate  and  onInsert :  @ Validate . matches ( r ^[A-Z]+$ ,   onInsert:   true ,   onUpdate:   false )  String   validateOnInsertOnly ;   It is important to understand how validations work when a value for a property is  not  specified in an insert or update query. For example, consider a  Person  with a  name  and  email  property and then inserted in a query that omits  email :  var   query   =   new   Query Person () \n   .. values . name   =   Bob ;  await   query . insert ();   Because  email  was not set on  Query.values , validations will not be run on that property.  There are two special validators that can require a property to be set, or require that a property  not  be set.  Validate.present()  requires that the associated property must have a value. A property with this validator must be provided each time the object is inserted or updated. Like all validators,  Validate.present()  can be adjusted to be invoked on only inserts or only updates. For example, the following declaration requires that  email  is set on insertion, but doesn't have to be for updates:  @ Validate . present ( onUpdate:   false ,   onInsert:   true )  String   email ;   The inverse of  Validate.present()  is  Validate.absent() . This validation prevents a property from being set. This is useful when a value should be included during insertion, but can't be updated. Here's an example:  @ Validate . absent ( onUpdate:   true ,   onInsert:   false )  String   canOnlyBeSetOnce ;   In the above declaration, the validator is only run on update operations and ensures that the property  canOnlyBeSetOnce  does not have a value. Because this validator is not run on insert operations, there is no restriction when the object is first inserted.  Validators are not run when a value is null. For example, the following insertion explicitly inserts  null  for the property  email :  var   query   =   new   Query Person () \n   .. values . email   =   null \n   .. values . name   =   Bob ;  await   query . insert ();   Nullability is enforced by  ManagedColumnAttributes.isNullable  property. Consider the following declaration:  @ ManagedColumnAttributes ( nullable:   false )  @ Validate . length ( greaterThan:   10 )  String   name ;   Here, the property  name  must not be null and must be greater than 10 characters long. The behavior of inserting or updating this property is shown in the following table.     Input Value for Name  Validation Runs?  Outcome      Insert value longer than 10 characters  Yes  Successful database insert    Insert value shorter than 10 characters  Yes  Database insert not executed, exception thrown    Insert value not specified  No  Database insert fails with non-null violation, exception thrown    Insert value is null  No  Database insert fails with non-null violation, exception thrown    Update value longer than 10 characters  Yes  Successful database update    Update value shorter than 10 characters  Yes  Database update not executed, exception thrown    Update value not specified  No  Successful database update    Update value is explicit null  No  Successful database update     This behavior allows  ManagedObject T  instances to be partially updated, which also allows for partial PUTs. Partial PUTs can be prevented by adding  Validate.present()  metadata to all properties. While partial PUTs are not idiomatic REST, they are pragmatic software development.  This also means that any custom validator can safely assume that a value passed to  Validate.validate()  is non-null.", 
            "title": "Validation Behavior"
        }, 
        {
            "location": "/db/validations/#other-validator-behavior", 
            "text": "For validators that can't be built by subclassing  Validate , you may override  ManagedObject T .validate() . This method is useful when a validation involves more than one property.  This method is passed the type of operation triggering the validation - either an insert or update. Here's an example:  class   Person   extends   ManagedObject _Person   implements   _Person   { \n   @ override \n   bool   validate ( \n       { ValidateOperation   forOperation:   ValidateOperation . insert , \n       List String   collectErrorsIn })   { \n    var   valid   =   super ( \n      forOperation:   forOperation ,   collectErrorsIn:   collectErrorsIn ); \n\n     if   ( a   +   b     10 )   { \n       valid   =   false ; \n       collectErrorsIn . add ( a + b must be greater than 10 ); \n     } \n\n     return   valid ; \n   }  }   When overriding this method, the  super  implementation must be invoked and if it returns  false , the overridden method must return  false .", 
            "title": "Other Validator Behavior"
        }, 
        {
            "location": "/db/validations/#skipping-validations", 
            "text": "Validations are only run when values are set via  Query T .values . Values set via  Query T .valueMap  are not validated. Therefore, objects should typically be inserted and updated using  Query T .values  unless validation must be ignored. Here's an example of skipping validation:  var   query   =   new   Query Person () \n   .. valueMap   =   { \n     name   :   xyz , \n     email   :   whatever \n   };   Skipping validation should be rare.", 
            "title": "Skipping Validations"
        }, 
        {
            "location": "/db/validations/#update-and-insert-callbacks", 
            "text": "ManagedObject T  subclasses may override  willUpdate  and  willInsert  to modify its properties prior to being updated or inserted by a  Query T . For example, a managed object may have updated and created dates that can be guaranteed to be set when inserted or updated:  class   Person   extends   ManagedObject _Person   implements   _Person   { \n   @ override \n   void   willUpdate ()   { \n     updatedAt   =   new   DateTime . now (). toUtc (); \n   } \n\n   @ override \n   void   willInsert ()   { \n     createdAt   =   new   DateTime . now (). toUtc (); \n   }  }  class   _Person   { \n   @ managedPrimaryKey \n   int   id ; \n\n   String   name ; \n   DateTime   createdAt ; \n   DateTime   updatedAt ;  }   Note that all operations must be synchronous in these methods.  Both  willUpdate  and  willInsert  are invoked prior the validation phase. Thus, any values set in these methods will be subject to the declared validations of the instance.  Like validations,  willUpdate  and  willInsert   are skipped when using  Query.valueMap .", 
            "title": "Update and Insert Callbacks"
        }, 
        {
            "location": "/db/db_tools/", 
            "text": "Database Migration and Tooling\n\n\nThe \naqueduct db\n command line tool creates and executes \nmigration files\n. A migration file contains SQL commands that create and modify database tables to match your application's data model.\n\n\nMigration Files\n\n\nDatabase tables are described by \nManagedObject\nT\n subclasses and their persistent type. Migration files describe a series of database commands that will create or modify a database schema to match an application's \nManagedObject\nT\n declarations. Migration files are executed on a database when an application is first deployed and when changes to the data model occur - like adding new \nManagedObject\nT\n subclasses or changing the name of a \nManagedObject\nT\n property.\n\n\nEach migration file contains only the changes made since the last migration file was generated. For example, let's say that version 1 of your application has two \nManagedObject\nT\n subclasses, \nUser\n and \nPost\n. Before you launch, you create a migration file that creates two tables, one for \nUser\n and one for \nPost\n. A month later, you have developed version 1.1 of your application and now you have a third \nManagedObject\nT\n named \nLocation\n. Prior to deploying version 1.1, you generate a new migration file and execute it. This migration file only contains instructions to create a table for \nLocation\n. The 'final product' of your database is the sum of both migration files.\n\n\nFor this reason, migrations files should be stored in source control.\n\n\nGenerating Migration Files\n\n\nMigration files are automatically generated by running \naqueduct db generate\n in an Aqueduct project directory. This tool finds every \nManagedObject\nT\n subclass and adds commands to the migration file to create a database table that matches its declaration. When subsequent migration files are generated, the difference between the schema created by existing migration files is compared to the current schema declared in an application's code. The commands to rectify those differences are added to the new migration file.\n\n\nThis tool will find all \nManagedObject\nT\n subclasses that are visible from an application's library file. (In an application named \nfoo\n, the library file is \nlib/foo.dart\n.) As a convention, every \nManagedObject\nT\n subclass is declared in its own file in \nlib/model/\n. For example, a \nUser\n class is defined in \nlib/model/user.dart\n.\n\n\nWhen creating a project through \naqueduct create\n, there is a file and directory structure set up like so:\n\n\nwildfire/\n  lib/\n    wildfire.dart\n    wildfire_model.dart\n    model/\n      user.dart\n      account.dart\n    ...\n\n\n\n\n\nAfter adding a new file to \nlib/model/\n, that file should be exported from \nwildfire_model.dart\n, where \nwildfire\n is the name of your application. This allows your application and the \ngenerate\n tool to see the declaration.\n\n\nMigration files are stored in an application's \nmigrations\n directory. Migration files are prefixed with a version number, a \"0\" padded eight digit number, ad suffixed with \n.migration.dart\n. For example, \n00000001_Initial.migration.dart\n is a migration filename. The version number portion of the filename is required, as is the \n.migration.dart\n suffix. The underscore and remainder of the filename are optional and have no effect, they are just a way to name the file. Here is an example of two migration file names:\n\n\n00000001_initial.migration.dart\n00000002_add_user_nickname.migration.dart\n\n\n\n\n\nThe version number of migration files indicate the order in which they are applied. Leading zeros are stripped from the filenames before their version numbers are compared. Version numbers do not necessarily have to be continuous, but doing otherwise is not recommended.\n\n\nMigration files may be created manually or altered after they are generated by \naqueduct db generate\n. A migration file's \nMigration.upgrade\n method makes calls to \nMigration.database\n (an instance of \nSchemaBuilder\n) property to add, remove, and modify tables and columns. Each method invocation creates one or more SQL commands. When a migration file is executed, its \nupgrade\n method is invoked and each command is collected and run within a transaction. The commands are executed in order, and it's important to note that the order often matters.\n\n\nThere are scenarios where there are more than one operation can rectify a change in the data model. It is important to review migration files after they have been generated to ensure the expected behavior.\n\n\nValidating Migration Files\n\n\nMigration files may be altered after they have been generated. This is often the case if \naqueduct db generate\n can't say for certain how a database should change. For example, is renaming a property just renaming a column, or is it deleting a column and creating a new column? The \naqueduct db validate\n tool ensures that the database schema after running all migration files matches the database schema declared by an application's \nManagedObject\nT\ns. Any generated migration file will pass \naqueduct db validate\n. The validate tool will display differences found between the schema in code and the schema created by migration files.\n\n\nListing Migration Files\n\n\nUse \naqueduct db list\n to list all database migration files and their resolved version number.\n\n\nExecuting Migration Files\n\n\nThe tool \naqueduct db upgrade\n will apply migration files to a running database. This tool is run in an application's directory and finds migration files in the \nmigrations\n directory. The connection info for a the running database is provided with the \n--connect\n option. For example, the following would execute migration files on a PostgreSQL database:\n\n\naqueduct db upgrade --connect postgres://username:password@localhost:5432/my_application\n\n\n\n\n\nThe first time \naqueduct db upgrade\n is executed, it creates a version table that keeps the version number and dates of upgrades. When \naqueduct db upgrade\n is ran after the initial migration, the version number is fetched from the database. The tool only runs migration files after the version number stored in the database.\n\n\nConnection information can also be stored in a database configuration file named \ndatabase.yaml\n in the application directory. If this file exists with the following format, \n--connect\n can be omitted and connection information will be read from this file:\n\n\nusername: \nuser\n\npassword: \npassword\n\nhost: \nhost\n\nport: port\ndatabaseName: \ndatabase\n\n\n\n\n\n\nGetting a Database's Version\n\n\nYou can fetch a database's current version number with \naqueduct db get-version\n. This command takes \n--connect\n or a \ndatabase.yaml\n file as described in the previous section to get connection info for the database.\n\n\nWhen to Execute Migration Files\n\n\nDuring development, there is no need to create a migration file for each change. Execute migration files prior to deployment of a new version of an application.\n\n\nYou may delete migration files. When \naqueduct db generate\n is run again, will replay only the existing migration files before determining which commands to add to the new migration file. For example, if you have 10 migration files over time and delete them all - the next generated migration file will contain commands to recreate the entire database schema.", 
            "title": "Migration and Tooling"
        }, 
        {
            "location": "/db/db_tools/#database-migration-and-tooling", 
            "text": "The  aqueduct db  command line tool creates and executes  migration files . A migration file contains SQL commands that create and modify database tables to match your application's data model.", 
            "title": "Database Migration and Tooling"
        }, 
        {
            "location": "/db/db_tools/#migration-files", 
            "text": "Database tables are described by  ManagedObject T  subclasses and their persistent type. Migration files describe a series of database commands that will create or modify a database schema to match an application's  ManagedObject T  declarations. Migration files are executed on a database when an application is first deployed and when changes to the data model occur - like adding new  ManagedObject T  subclasses or changing the name of a  ManagedObject T  property.  Each migration file contains only the changes made since the last migration file was generated. For example, let's say that version 1 of your application has two  ManagedObject T  subclasses,  User  and  Post . Before you launch, you create a migration file that creates two tables, one for  User  and one for  Post . A month later, you have developed version 1.1 of your application and now you have a third  ManagedObject T  named  Location . Prior to deploying version 1.1, you generate a new migration file and execute it. This migration file only contains instructions to create a table for  Location . The 'final product' of your database is the sum of both migration files.  For this reason, migrations files should be stored in source control.", 
            "title": "Migration Files"
        }, 
        {
            "location": "/db/db_tools/#generating-migration-files", 
            "text": "Migration files are automatically generated by running  aqueduct db generate  in an Aqueduct project directory. This tool finds every  ManagedObject T  subclass and adds commands to the migration file to create a database table that matches its declaration. When subsequent migration files are generated, the difference between the schema created by existing migration files is compared to the current schema declared in an application's code. The commands to rectify those differences are added to the new migration file.  This tool will find all  ManagedObject T  subclasses that are visible from an application's library file. (In an application named  foo , the library file is  lib/foo.dart .) As a convention, every  ManagedObject T  subclass is declared in its own file in  lib/model/ . For example, a  User  class is defined in  lib/model/user.dart .  When creating a project through  aqueduct create , there is a file and directory structure set up like so:  wildfire/\n  lib/\n    wildfire.dart\n    wildfire_model.dart\n    model/\n      user.dart\n      account.dart\n    ...  After adding a new file to  lib/model/ , that file should be exported from  wildfire_model.dart , where  wildfire  is the name of your application. This allows your application and the  generate  tool to see the declaration.  Migration files are stored in an application's  migrations  directory. Migration files are prefixed with a version number, a \"0\" padded eight digit number, ad suffixed with  .migration.dart . For example,  00000001_Initial.migration.dart  is a migration filename. The version number portion of the filename is required, as is the  .migration.dart  suffix. The underscore and remainder of the filename are optional and have no effect, they are just a way to name the file. Here is an example of two migration file names:  00000001_initial.migration.dart\n00000002_add_user_nickname.migration.dart  The version number of migration files indicate the order in which they are applied. Leading zeros are stripped from the filenames before their version numbers are compared. Version numbers do not necessarily have to be continuous, but doing otherwise is not recommended.  Migration files may be created manually or altered after they are generated by  aqueduct db generate . A migration file's  Migration.upgrade  method makes calls to  Migration.database  (an instance of  SchemaBuilder ) property to add, remove, and modify tables and columns. Each method invocation creates one or more SQL commands. When a migration file is executed, its  upgrade  method is invoked and each command is collected and run within a transaction. The commands are executed in order, and it's important to note that the order often matters.  There are scenarios where there are more than one operation can rectify a change in the data model. It is important to review migration files after they have been generated to ensure the expected behavior.", 
            "title": "Generating Migration Files"
        }, 
        {
            "location": "/db/db_tools/#validating-migration-files", 
            "text": "Migration files may be altered after they have been generated. This is often the case if  aqueduct db generate  can't say for certain how a database should change. For example, is renaming a property just renaming a column, or is it deleting a column and creating a new column? The  aqueduct db validate  tool ensures that the database schema after running all migration files matches the database schema declared by an application's  ManagedObject T s. Any generated migration file will pass  aqueduct db validate . The validate tool will display differences found between the schema in code and the schema created by migration files.", 
            "title": "Validating Migration Files"
        }, 
        {
            "location": "/db/db_tools/#listing-migration-files", 
            "text": "Use  aqueduct db list  to list all database migration files and their resolved version number.", 
            "title": "Listing Migration Files"
        }, 
        {
            "location": "/db/db_tools/#executing-migration-files", 
            "text": "The tool  aqueduct db upgrade  will apply migration files to a running database. This tool is run in an application's directory and finds migration files in the  migrations  directory. The connection info for a the running database is provided with the  --connect  option. For example, the following would execute migration files on a PostgreSQL database:  aqueduct db upgrade --connect postgres://username:password@localhost:5432/my_application  The first time  aqueduct db upgrade  is executed, it creates a version table that keeps the version number and dates of upgrades. When  aqueduct db upgrade  is ran after the initial migration, the version number is fetched from the database. The tool only runs migration files after the version number stored in the database.  Connection information can also be stored in a database configuration file named  database.yaml  in the application directory. If this file exists with the following format,  --connect  can be omitted and connection information will be read from this file:  username:  user \npassword:  password \nhost:  host \nport: port\ndatabaseName:  database", 
            "title": "Executing Migration Files"
        }, 
        {
            "location": "/db/db_tools/#getting-a-databases-version", 
            "text": "You can fetch a database's current version number with  aqueduct db get-version . This command takes  --connect  or a  database.yaml  file as described in the previous section to get connection info for the database.", 
            "title": "Getting a Database's Version"
        }, 
        {
            "location": "/db/db_tools/#when-to-execute-migration-files", 
            "text": "During development, there is no need to create a migration file for each change. Execute migration files prior to deployment of a new version of an application.  You may delete migration files. When  aqueduct db generate  is run again, will replay only the existing migration files before determining which commands to add to the new migration file. For example, if you have 10 migration files over time and delete them all - the next generated migration file will contain commands to recreate the entire database schema.", 
            "title": "When to Execute Migration Files"
        }, 
        {
            "location": "/db/inside_the_db/", 
            "text": "Unsung Heroes of the ORM\n\n\nAqueduct applications use a number of objects to manage its relationship to a database. A \nQuery\nT\n is an interface to a concrete class that translates it into flavor-specific SQL. \nQuery\nT\ns are executed in a \nManagedContext\n, which has two important properties: a \nPersistentStore\n and a \nManagedDataModel\n. A \nPersistentStore\n is also an interface to a concrete class that manages flavor-specific SQL connections. A \nManagedDataModel\n keeps all of the information about the \nManagedObject\nT\ns in your application. This data model contains an instance of \nManagedEntity\n for each \nManagedObject\nT\n declared.\n\n\nAll of these objects work together to move data in and out of an Aqueduct application from where it came from and where it needs to go. They are all instantiated when an application starts up in the \nRequestSink\n's constructor:\n\n\nclass\n \nMyRequestSink\n \nextends\n \nRequestSink\n \n{\n\n\n  \nMyRequestSink\n(\nApplicationConfiguration\n \nconfig\n)\n \n:\n \nsuper\n(\nconfig\n)\n \n{\n\n    \nvar\n \ndataModel\n \n=\n \nnew\n \nManagedDataModel\n.\nfromCurrentMirrorSystem\n();\n\n    \nvar\n \npsc\n \n=\n \nnew\n \nPostgreSQLPersistentStore\n.\nfromConnectionInfo\n(\n\n        \nconfig\n.\nconnectionInfo\n.\nusername\n,\n\n        \nconfig\n.\nconnectionInfo\n.\npassword\n,\n\n        \nconfig\n.\nconnectionInfo\n.\nhost\n,\n\n        \nconfig\n.\nconnectionInfo\n.\nport\n,\n\n        \nconfig\n.\nconnectionInfo\n.\ndatabaseName\n);\n\n\n    \nManagedContext\n.\ndefaultContext\n \n=\n \nnew\n \nManagedContext\n(\ndataModel\n,\n \npsc\n);\n\n  \n}\n\n\n  \n...\n\n\n}\n\n\n\n\n\n\nThis code will create a data model by reflecting on the codebase and finding every \nManagedObject\nT\n subclass, creating and storing \nManagedEntity\n for each. Then, it creates a concrete subclass of \nPersistentStore\n, \nPostgreSQLPersistentStore\n, with all the information it needs to connect to a PostgreSQL database. Finally, the context itself is created and assigned as the \nManagedContext.defaultContext\n. (Even if you did not assign the new context to \ndefaultContext\n, the last instantiated \nManagedContext\n is always assigned as the default context.)\n\n\nModelContext is the Bridge from Aqueduct to a Database\n\n\nAn instance of a \nManagedContext\n is the container for all things related to a single database. It keeps a reference to its \nPersistentStore\n and \nManagedDataModel\n, which together allow for the translation and transmission to and from a database into an Aqueduct application.  Most applications will only have one \nManagedContext\n. Applications that talk to more than one database or different schemas within a database will have more.\n\n\nBecause most applications only have one \nManagedContext\n, there is a default context for every application. If you are only creating a single \nManagedContext\n in an application, that context is set to be the default context without any further action. The default context can be changed, but this is rarely done:\n\n\nManagedContext\n.\ndefaultContext\n \n=\n \nnew\n \nManagedContext\n(\ndataModel\n,\n \npersistentStore\n);\n\n\n\n\n\n\nObjects and methods that need a \nManagedContext\n will default to the \ndefaultContext\n, so its rare that you'd see \nManagedContext\n anywhere outside of where it is first instantiated.\n\n\nManagedDataModels Describe an Application's ManagedEntitys\n\n\nInstances of \nManagedDataModel\n are one of the two components of a \nManagedContext\n. A \nManagedDataModel\n has a definition for all of the managed objects in a context. In most applications, this means every \nManagedObject\nT\n subclass you declare in your application. The \nManagedDataModel\n will create instances of \nManagedEntity\n to describe each \nManagedObject\nT\n. In other words, a \nManagedDataModel\n compiles your data model into entities that contain information at runtime to map data back and forth between a database.\n\n\nManagedEntity\ns are the description of a database table in your application.  A \nManagedEntity\n contains references to the two types that make up a fully formed entity - the instance type (subclass of \nManagedObject\nT\n) and its persistent type. They also contain the information derived from these types - the attributes and relationships - in a quickly accessible format. (More specifically, the reflection on all \nManagedObject\nT\ns happens at startup only and all information is cached for use later.)\n\n\nManagedEntity\ns store relationship and attribute information in instances of \nManagedRelationshipDescription\n and \nManagedAttributeDescription\n, both of which extend \nManagedPropertyDescription\n. This information is used by the rest of Aqueduct to determine how database columns are mapped to properties and back. This information is derived from the class declarations, and \nManagedColumnAttributes\n and \nManagedRelationship\n metadata that is used when defining your persistent types.\n\n\nA \nManagedDataModel\n will also validate all entities and their relationships. If validation fails, an exception will be thrown. As \nManagedDataModel\ns are created at the beginning of the application's startup, this behavior will stop your application from running if there are data model errors.\n\n\nPersistent Stores Manage Database Connections and Versioning\n\n\nPersistentStore\n is an abstract class. To connect to and interact with a specific flavor of SQL - like PostgreSQL or MySQL - a flavor-specific implementation of \nPersistentStore\n must exist. By default, Aqueduct ships with a \nPostgreSQLPersistentStore\n. There is nothing that prevents a \nPersistentStore\n implementation from connecting to and working with a NoSQL database, but the interface is geared towards SQL databases.\n\n\nPersistentStore\ns are rarely used directly. Instead, a concrete implementation of \nQuery\nT\n will send SQL to a \nPersistentStore\n for it to execute. \nPersistentStore\ns may be used directly to issue direct SQL to its underlying database connection. This is often useful for scripts and tests that modify a database schema. For this purpose, \nPersistentStore\n has an \nexecute\n method to run raw SQL.\n\n\nThe tools to run database migrations invoke methods on a \nPersistentStore\n that must be implemented by a flavor-specific subclass.", 
            "title": "Inside the DB"
        }, 
        {
            "location": "/db/inside_the_db/#unsung-heroes-of-the-orm", 
            "text": "Aqueduct applications use a number of objects to manage its relationship to a database. A  Query T  is an interface to a concrete class that translates it into flavor-specific SQL.  Query T s are executed in a  ManagedContext , which has two important properties: a  PersistentStore  and a  ManagedDataModel . A  PersistentStore  is also an interface to a concrete class that manages flavor-specific SQL connections. A  ManagedDataModel  keeps all of the information about the  ManagedObject T s in your application. This data model contains an instance of  ManagedEntity  for each  ManagedObject T  declared.  All of these objects work together to move data in and out of an Aqueduct application from where it came from and where it needs to go. They are all instantiated when an application starts up in the  RequestSink 's constructor:  class   MyRequestSink   extends   RequestSink   { \n\n   MyRequestSink ( ApplicationConfiguration   config )   :   super ( config )   { \n     var   dataModel   =   new   ManagedDataModel . fromCurrentMirrorSystem (); \n     var   psc   =   new   PostgreSQLPersistentStore . fromConnectionInfo ( \n         config . connectionInfo . username , \n         config . connectionInfo . password , \n         config . connectionInfo . host , \n         config . connectionInfo . port , \n         config . connectionInfo . databaseName ); \n\n     ManagedContext . defaultContext   =   new   ManagedContext ( dataModel ,   psc ); \n   } \n\n   ...  }   This code will create a data model by reflecting on the codebase and finding every  ManagedObject T  subclass, creating and storing  ManagedEntity  for each. Then, it creates a concrete subclass of  PersistentStore ,  PostgreSQLPersistentStore , with all the information it needs to connect to a PostgreSQL database. Finally, the context itself is created and assigned as the  ManagedContext.defaultContext . (Even if you did not assign the new context to  defaultContext , the last instantiated  ManagedContext  is always assigned as the default context.)", 
            "title": "Unsung Heroes of the ORM"
        }, 
        {
            "location": "/db/inside_the_db/#modelcontext-is-the-bridge-from-aqueduct-to-a-database", 
            "text": "An instance of a  ManagedContext  is the container for all things related to a single database. It keeps a reference to its  PersistentStore  and  ManagedDataModel , which together allow for the translation and transmission to and from a database into an Aqueduct application.  Most applications will only have one  ManagedContext . Applications that talk to more than one database or different schemas within a database will have more.  Because most applications only have one  ManagedContext , there is a default context for every application. If you are only creating a single  ManagedContext  in an application, that context is set to be the default context without any further action. The default context can be changed, but this is rarely done:  ManagedContext . defaultContext   =   new   ManagedContext ( dataModel ,   persistentStore );   Objects and methods that need a  ManagedContext  will default to the  defaultContext , so its rare that you'd see  ManagedContext  anywhere outside of where it is first instantiated.", 
            "title": "ModelContext is the Bridge from Aqueduct to a Database"
        }, 
        {
            "location": "/db/inside_the_db/#manageddatamodels-describe-an-applications-managedentitys", 
            "text": "Instances of  ManagedDataModel  are one of the two components of a  ManagedContext . A  ManagedDataModel  has a definition for all of the managed objects in a context. In most applications, this means every  ManagedObject T  subclass you declare in your application. The  ManagedDataModel  will create instances of  ManagedEntity  to describe each  ManagedObject T . In other words, a  ManagedDataModel  compiles your data model into entities that contain information at runtime to map data back and forth between a database.  ManagedEntity s are the description of a database table in your application.  A  ManagedEntity  contains references to the two types that make up a fully formed entity - the instance type (subclass of  ManagedObject T ) and its persistent type. They also contain the information derived from these types - the attributes and relationships - in a quickly accessible format. (More specifically, the reflection on all  ManagedObject T s happens at startup only and all information is cached for use later.)  ManagedEntity s store relationship and attribute information in instances of  ManagedRelationshipDescription  and  ManagedAttributeDescription , both of which extend  ManagedPropertyDescription . This information is used by the rest of Aqueduct to determine how database columns are mapped to properties and back. This information is derived from the class declarations, and  ManagedColumnAttributes  and  ManagedRelationship  metadata that is used when defining your persistent types.  A  ManagedDataModel  will also validate all entities and their relationships. If validation fails, an exception will be thrown. As  ManagedDataModel s are created at the beginning of the application's startup, this behavior will stop your application from running if there are data model errors.", 
            "title": "ManagedDataModels Describe an Application's ManagedEntitys"
        }, 
        {
            "location": "/db/inside_the_db/#persistent-stores-manage-database-connections-and-versioning", 
            "text": "PersistentStore  is an abstract class. To connect to and interact with a specific flavor of SQL - like PostgreSQL or MySQL - a flavor-specific implementation of  PersistentStore  must exist. By default, Aqueduct ships with a  PostgreSQLPersistentStore . There is nothing that prevents a  PersistentStore  implementation from connecting to and working with a NoSQL database, but the interface is geared towards SQL databases.  PersistentStore s are rarely used directly. Instead, a concrete implementation of  Query T  will send SQL to a  PersistentStore  for it to execute.  PersistentStore s may be used directly to issue direct SQL to its underlying database connection. This is often useful for scripts and tests that modify a database schema. For this purpose,  PersistentStore  has an  execute  method to run raw SQL.  The tools to run database migrations invoke methods on a  PersistentStore  that must be implemented by a flavor-specific subclass.", 
            "title": "Persistent Stores Manage Database Connections and Versioning"
        }, 
        {
            "location": "/auth/overview/", 
            "text": "Tasks\n\n\nAqueduct has built-in classes to manage authentication and authorization according to the \nOAuth 2.0 specification\n.  To manage authentication and authorization, the following tasks are required/suggested:\n\n\n\n\nCreating \nAuthServer\n instances to enable OAuth 2.0 in an Aqueduct application\n\n\nUsing \naqueduct/managed_auth\n to manage storage of authorization objects, e.g. storing tokens in a database.\n\n\nUsing \nAuthCodeController\n and \nAuthController\n to expose endpoints for exchanging credentials for authorization tokens.\n\n\nAdding \nAuthorizer\ns to a series of \nRequestController\ns to allow only authorized requests.\n\n\nCreating OAuth 2.0 Client Identifiers through the \naqueduct auth\n tool\n\n\n\n\n\n\nGuides\n\n\n\n\nWhat is OAuth 2.0?\n\n\nCreating and Using AuthServers\n\n\nSecuring Routes with Authorizer\n\n\nAdding Auth Endpoints\n\n\nCreating OAuth 2.0 Client IDs", 
            "title": "Overview"
        }, 
        {
            "location": "/auth/overview/#tasks", 
            "text": "Aqueduct has built-in classes to manage authentication and authorization according to the  OAuth 2.0 specification .  To manage authentication and authorization, the following tasks are required/suggested:   Creating  AuthServer  instances to enable OAuth 2.0 in an Aqueduct application  Using  aqueduct/managed_auth  to manage storage of authorization objects, e.g. storing tokens in a database.  Using  AuthCodeController  and  AuthController  to expose endpoints for exchanging credentials for authorization tokens.  Adding  Authorizer s to a series of  RequestController s to allow only authorized requests.  Creating OAuth 2.0 Client Identifiers through the  aqueduct auth  tool", 
            "title": "Tasks"
        }, 
        {
            "location": "/auth/overview/#guides", 
            "text": "What is OAuth 2.0?  Creating and Using AuthServers  Securing Routes with Authorizer  Adding Auth Endpoints  Creating OAuth 2.0 Client IDs", 
            "title": "Guides"
        }, 
        {
            "location": "/auth/server/", 
            "text": "Creating AuthServers to Authenticate and Authorize\n\n\nAn instance of \nAuthServer\n handles creating, verifying and refreshing authorization tokens. An instance of \nAuthServer\n is created when an application starts up and is referenced by \nAuthorizer\ns, \nAuthCodeController\ns and \nAuthController\ns to manage authorization. \nAuthServer\n handles the logic of authorization, and when it needs to fetch or store persistent data, it invokes a callback on its \nAuthStorage\n. Therefore, an \nAuthServer\n must have \nAuthStorage\n to persist authorization objects like tokens, clients and resource owners.\n\n\nCreating Instances of AuthServer and AuthStorage\n\n\nOne instance of \nAuthServer\n is created in a \nRequestSink\n's constructor along with its instance of \nAuthStorage\n. \nAuthStorage\n is an interface and a concrete implementation of it - \nManagedAuthStorage\nT\n - exists in an optional library in Aqueduct, \naqueduct/managed_auth\n. It is strongly recommended to use an instance of \nManagedAuthStorage\nT\n because it has been thoroughly tested and handles cleaning up unused tokens.\n\n\nManagedAuthStorage\n declares and uses \nManagedObject\ns to represent authorization objects. Therefore, it must have a reference to \nManagedContext\n (see \nAqueduct ORM\n). Initialization looks like this:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\n\nclass\n \nMyRequestSink\n \nextends\n \nRequestSink\n \n{\n\n  \nMyRequestSink\n(\nApplicationConfiguration\n \nconfig\n)\n \n:\n \nsuper\n(\nconfig\n)\n \n{\n\n    \ncontext\n \n=\n \nnew\n \nManagedContext\n(...);\n\n    \nvar\n \nstorage\n \n=\n \nnew\n \nManagedAuthStorage\nUser\n(\ncontext\n);\n\n    \nauthServer\n \n=\n \nnew\n \nAuthServer\n(\nstorage\n);\n\n  \n}\n\n\n  \nAuthServer\n \nauthServer\n;\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \n...\n\n\n}\n\n\n\n\n\n\nNotice that the \naqueduct/managed_auth\n library is imported - this library is not part of \naqueduct/aqueduct\n by default and must be imported explicitly. Also notice that \nManagedAuthStorage\n has a type argument that will be covered in the next section.\n\n\nIt's important to keep a property reference to an instance of \nAuthServer\n so that later methods in the initialization process - specifically, \nsetupRouter\n - can use it to protect routes and add routes that grant authorization tokens.\n\n\nWhile \nAuthServer\n has methods for handling authorization tasks, it is rarely used directly. Instead, \nAuthCodeController\n and \nAuthController\n are hooked up to routes to grant authorization tokens via the API. Instances of \nAuthorizer\n secure routes when building processing pipelines in \nsetupRouter\n. All of these types have a reference to an \nAuthServer\n and invoke the appropriate methods to carry out their task.\n\n\nTherefore, a full authorization implementation rarely extends past a \nRequestSink\n. Here's an example \nRequestSink\n subclass that sets up and uses authorization:\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:aqueduct/managed_auth.dart\n;\n\n\n\nclass\n \nMyRequestSink\n \nextends\n \nRequestSink\n \n{\n\n  \nMyRequestSink\n(\nApplicationConfiguration\n \nconfig\n)\n \n:\n \nsuper\n(\nconfig\n)\n \n{\n\n    \ncontext\n \n=\n \nnew\n \nManagedContext\n(...);\n\n    \nvar\n \nstorage\n \n=\n \nnew\n \nManagedAuthStorage\nUser\n(\ncontext\n);\n\n    \nauthServer\n \n=\n \nnew\n \nAuthServer\n(\nstorage\n);\n\n  \n}\n\n\n  \nAuthServer\n \nauthServer\n;\n\n  \nManagedContext\n \ncontext\n;\n\n\n  \nvoid\n \nsetupRouter\n(\nRouter\n \nrouter\n)\n \n{\n\n    \n// Set up auth token route\n\n    \nrouter\n.\nroute\n(\n/auth/token\n).\ngenerate\n(()\n \n=\n \nnew\n \nAuthController\n(\nauthServer\n));\n\n\n    \n// Set up auth code route\n\n    \nrouter\n.\nroute\n(\n/auth/code\n).\ngenerate\n(()\n \n=\n \nnew\n \nAuthCodeController\n(\nauthServer\n));\n\n\n    \n// Set up protected route\n\n    \nrouter\n\n      \n.\nroute\n(\n/protected\n)\n\n      \n.\npipe\n(\nnew\n \nAuthorizer\n.\nbearer\n(\nauthServer\n))\n\n      \n.\ngenerate\n(()\n \n=\n \nnew\n \nProtectedController\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nFor more details on authorization controllers, see \nAuthorization Controllers\n. For more details on securing routes, see \nAuthorizers\n.\n\n\nUsing ManagedAuthStorage\n\n\nManagedAuthStorage\nT\n is a concrete implementation of \nAuthStorage\n, providing storage of authorization tokens and clients for \nAuthServer\n. Storage is accomplished by Aqueduct's ORM. \nManagedAuthStorage\nT\n, by default, is not part of the standard \naqueduct/aqueduct\n library. To use this class, an application must import \npackage:aqueduct/managed_auth.dart\n.\n\n\nThe type argument to \nManagedAuthStorage\nT\n represents the concept of a 'user' or 'account' in an application - OAuth 2.0 terminology would refer to this concept as a \nresource owner\n.\n\n\nThe type argument must be a \nManagedObject\nT\n subclass that is specific to your application. Its persistent type must \nextend\n \nManagedAuthenticatable\n and the subclass itself must implement \nManagedAuthResourceOwner\n. A basic definition may look like this:\n\n\nclass\n \nUser\n \nextends\n \nManagedObject\n_User\n\n    \nimplements\n \n_User\n,\n \nManagedAuthResourceOwner\n \n{\n\n  \n@\nmanagedTransientInputAttribute\n\n  \nvoid\n \nset\n \npassword\n(\nString\n \npassword\n)\n \n{\n\n    \nsalt\n \n=\n \nAuthUtility\n.\ngenerateRandomSalt\n();\n\n    \nhashedPassword\n \n=\n \nAuthUtility\n.\ngeneratePasswordHash\n(\npassword\n,\n \nsalt\n);\n\n  \n}\n\n\n}\n\n\n\nclass\n \n_User\n \nextends\n \nManagedAuthenticatable\n \n{\n\n  \n@\nManagedColumnAttributes\n(\nunique:\n \ntrue\n)\n\n  \nString\n \nemail\n;\n\n\n}\n\n\n\n\n\n\nBy extending \nManagedAuthenticatable\n, the persistent type has an integer primary key, a unique username, a hashed password (and its salt) and a \nManagedSet\nT\n of authorization tokens that have been granted by this user. These are the necessary attributes that the type argument to \nManagedAuthStorage\nT\n must have for an \nAuthServer\n to properly store and fetch resource owners. The interface \nManagedAuthResourceOwner\n is a requirement that ensures the type argument is both a \nManagedObject\nT\n and \nManagedAuthenticatable\n, and serves no other purpose than to restrict \nManagedAuthStorage\nT\n's type parameter to an appropriate type.\n\n\nThe purpose of this structure is to allow an application to declare its own resource owner type - with additional attributes and relationships - while still enforcing the needs of Aqueduct's OAuth 2.0 implementation.\n\n\nOnce a resource owner has been defined, instances of \nManagedAuthStorage\nT\n can be created and passed to an \nAuthServer\n:\n\n\nvar\n \ncontext\n \n=\n \nnew\n \nManagedContext\n(...);\n\n\nvar\n \nstorage\n \n=\n \nnew\n \nManagedAuthStorage\nUser\n(\ncontext\n);\n\n\nvar\n \nserver\n \n=\n \nnew\n \nAuthServer\n(\nstorage\n);\n\n\n\n\n\n\nThe \naqueduct/managed_auth\n library also declares two \nManagedObject\nT\n subclasses. \nManagedToken\n represents instances of authorization tokens and codes, and \nManagedClient\n represents instances of OAuth 2.0 clients. Both of these types must be visible to the \naqueduct db\n tool, and so the library must at least be imported in an application's library file. Since these types will at least be referenced by the definition of the resource owner, it makes sense to export \npackage:aqueduct/managed_auth.dart\n from an application's library file. It's rare that these types are referenced elsewhere in an application, since they exist to serve the behavior of \nAuthServer\n.\n\n\nManagedAuthStorage\nT\n will delete authorization tokens and codes when they are no longer in use. This is determined by how many tokens a resource owner has and the tokens expiration dates. Once a resource owner acquires more than 40 tokens/codes, the oldest tokens/codes (determined by expiration date) are deleted. Effectively, the resource owner is limited to 40 tokens. This number can be changed when instantiating \nManagedAuthStorage\nT\n:\n\n\nvar\n \nstorage\n \n=\n \nnew\n \nManagedAuthStorage\n(\ncontext\n,\n \ntokenLimit:\n \n20\n);", 
            "title": "Setting up Authorization"
        }, 
        {
            "location": "/auth/server/#creating-authservers-to-authenticate-and-authorize", 
            "text": "An instance of  AuthServer  handles creating, verifying and refreshing authorization tokens. An instance of  AuthServer  is created when an application starts up and is referenced by  Authorizer s,  AuthCodeController s and  AuthController s to manage authorization.  AuthServer  handles the logic of authorization, and when it needs to fetch or store persistent data, it invokes a callback on its  AuthStorage . Therefore, an  AuthServer  must have  AuthStorage  to persist authorization objects like tokens, clients and resource owners.", 
            "title": "Creating AuthServers to Authenticate and Authorize"
        }, 
        {
            "location": "/auth/server/#creating-instances-of-authserver-and-authstorage", 
            "text": "One instance of  AuthServer  is created in a  RequestSink 's constructor along with its instance of  AuthStorage .  AuthStorage  is an interface and a concrete implementation of it -  ManagedAuthStorage T  - exists in an optional library in Aqueduct,  aqueduct/managed_auth . It is strongly recommended to use an instance of  ManagedAuthStorage T  because it has been thoroughly tested and handles cleaning up unused tokens.  ManagedAuthStorage  declares and uses  ManagedObject s to represent authorization objects. Therefore, it must have a reference to  ManagedContext  (see  Aqueduct ORM ). Initialization looks like this:  import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  class   MyRequestSink   extends   RequestSink   { \n   MyRequestSink ( ApplicationConfiguration   config )   :   super ( config )   { \n     context   =   new   ManagedContext (...); \n     var   storage   =   new   ManagedAuthStorage User ( context ); \n     authServer   =   new   AuthServer ( storage ); \n   } \n\n   AuthServer   authServer ; \n   ManagedContext   context ; \n\n   ...  }   Notice that the  aqueduct/managed_auth  library is imported - this library is not part of  aqueduct/aqueduct  by default and must be imported explicitly. Also notice that  ManagedAuthStorage  has a type argument that will be covered in the next section.  It's important to keep a property reference to an instance of  AuthServer  so that later methods in the initialization process - specifically,  setupRouter  - can use it to protect routes and add routes that grant authorization tokens.  While  AuthServer  has methods for handling authorization tasks, it is rarely used directly. Instead,  AuthCodeController  and  AuthController  are hooked up to routes to grant authorization tokens via the API. Instances of  Authorizer  secure routes when building processing pipelines in  setupRouter . All of these types have a reference to an  AuthServer  and invoke the appropriate methods to carry out their task.  Therefore, a full authorization implementation rarely extends past a  RequestSink . Here's an example  RequestSink  subclass that sets up and uses authorization:  import   package:aqueduct/aqueduct.dart ;  import   package:aqueduct/managed_auth.dart ;  class   MyRequestSink   extends   RequestSink   { \n   MyRequestSink ( ApplicationConfiguration   config )   :   super ( config )   { \n     context   =   new   ManagedContext (...); \n     var   storage   =   new   ManagedAuthStorage User ( context ); \n     authServer   =   new   AuthServer ( storage ); \n   } \n\n   AuthServer   authServer ; \n   ManagedContext   context ; \n\n   void   setupRouter ( Router   router )   { \n     // Set up auth token route \n     router . route ( /auth/token ). generate (()   =   new   AuthController ( authServer )); \n\n     // Set up auth code route \n     router . route ( /auth/code ). generate (()   =   new   AuthCodeController ( authServer )); \n\n     // Set up protected route \n     router \n       . route ( /protected ) \n       . pipe ( new   Authorizer . bearer ( authServer )) \n       . generate (()   =   new   ProtectedController ()); \n   }  }   For more details on authorization controllers, see  Authorization Controllers . For more details on securing routes, see  Authorizers .", 
            "title": "Creating Instances of AuthServer and AuthStorage"
        }, 
        {
            "location": "/auth/server/#using-managedauthstorage", 
            "text": "ManagedAuthStorage T  is a concrete implementation of  AuthStorage , providing storage of authorization tokens and clients for  AuthServer . Storage is accomplished by Aqueduct's ORM.  ManagedAuthStorage T , by default, is not part of the standard  aqueduct/aqueduct  library. To use this class, an application must import  package:aqueduct/managed_auth.dart .  The type argument to  ManagedAuthStorage T  represents the concept of a 'user' or 'account' in an application - OAuth 2.0 terminology would refer to this concept as a  resource owner .  The type argument must be a  ManagedObject T  subclass that is specific to your application. Its persistent type must  extend   ManagedAuthenticatable  and the subclass itself must implement  ManagedAuthResourceOwner . A basic definition may look like this:  class   User   extends   ManagedObject _User \n     implements   _User ,   ManagedAuthResourceOwner   { \n   @ managedTransientInputAttribute \n   void   set   password ( String   password )   { \n     salt   =   AuthUtility . generateRandomSalt (); \n     hashedPassword   =   AuthUtility . generatePasswordHash ( password ,   salt ); \n   }  }  class   _User   extends   ManagedAuthenticatable   { \n   @ ManagedColumnAttributes ( unique:   true ) \n   String   email ;  }   By extending  ManagedAuthenticatable , the persistent type has an integer primary key, a unique username, a hashed password (and its salt) and a  ManagedSet T  of authorization tokens that have been granted by this user. These are the necessary attributes that the type argument to  ManagedAuthStorage T  must have for an  AuthServer  to properly store and fetch resource owners. The interface  ManagedAuthResourceOwner  is a requirement that ensures the type argument is both a  ManagedObject T  and  ManagedAuthenticatable , and serves no other purpose than to restrict  ManagedAuthStorage T 's type parameter to an appropriate type.  The purpose of this structure is to allow an application to declare its own resource owner type - with additional attributes and relationships - while still enforcing the needs of Aqueduct's OAuth 2.0 implementation.  Once a resource owner has been defined, instances of  ManagedAuthStorage T  can be created and passed to an  AuthServer :  var   context   =   new   ManagedContext (...);  var   storage   =   new   ManagedAuthStorage User ( context );  var   server   =   new   AuthServer ( storage );   The  aqueduct/managed_auth  library also declares two  ManagedObject T  subclasses.  ManagedToken  represents instances of authorization tokens and codes, and  ManagedClient  represents instances of OAuth 2.0 clients. Both of these types must be visible to the  aqueduct db  tool, and so the library must at least be imported in an application's library file. Since these types will at least be referenced by the definition of the resource owner, it makes sense to export  package:aqueduct/managed_auth.dart  from an application's library file. It's rare that these types are referenced elsewhere in an application, since they exist to serve the behavior of  AuthServer .  ManagedAuthStorage T  will delete authorization tokens and codes when they are no longer in use. This is determined by how many tokens a resource owner has and the tokens expiration dates. Once a resource owner acquires more than 40 tokens/codes, the oldest tokens/codes (determined by expiration date) are deleted. Effectively, the resource owner is limited to 40 tokens. This number can be changed when instantiating  ManagedAuthStorage T :  var   storage   =   new   ManagedAuthStorage ( context ,   tokenLimit:   20 );", 
            "title": "Using ManagedAuthStorage"
        }, 
        {
            "location": "/auth/authorizer/", 
            "text": "Securing Routes with Authorizer\n\n\nInstances of \nAuthorizer\n are \nRequestController\ns that verify an HTTP request's authorization information before passing the request on to their next controller. \nAuthorizer\ns are created in a \nRequestSink\n's \nsetupRouter\n method as part of a request pipeline. They protect access to their next controller and typically come right after \nroute\n. Here's an example:\n\n\n@\noverride\n\n\nvoid\n \nsetupRouter\n(\nRouter\n \nrouter\n)\n \n{\n\n  \nrouter\n\n    \n.\nroute\n(\n/protected\n)\n\n    \n.\npipe\n(\nnew\n \nAuthorizer\n.\nbearer\n(\nauthServer\n))\n\n    \n.\ngenerate\n(()\n \n=\n \nnew\n \nProtectedController\n());\n\n\n  \nrouter\n\n    \n.\nroute\n(\n/other\n)\n\n    \n.\npipe\n(\nnew\n \nAuthorizer\n.\nbasic\n(\nauthServer\n))\n\n    \n.\ngenerate\n(()\n \n=\n \nnew\n \nOtherController\n());\n\n\n}\n\n\n\n\n\n\nAn \nAuthorizer\n has no state itself, so it is added to a request pipeline via \npipe\n; i.e., it does not need to be \ngenerate\nd.\n\n\nAn \nAuthorizer\n parses the Authorization header of an HTTP request. The named constructors of \nAuthorizer\n indicate the required format of Authorization header. The \nAuthorization.bearer()\n constructor expects an OAuth 2.0 bearer token in the header, which has the following format:\n\n\nAuthorization\n:\n \nBearer\n \n768\niuzjkx82jkasjkd9z9\n\n\n\n\n\n\nAuthorizer.basic\n expects HTTP Basic Authentication, where the username and password are joined with the colon character (\n:\n) and Base 64 encoded:\n\n\n// \ndXNlcjpwYXNzd29yZA==\n is \nuser:password\n\nAuthorization: Basic dXNlcjpwYXNzd29yZA==\n\n\n\n\n\nIf the header can't be parsed, doesn't exist or is in the wrong format, an \nAuthorizer\n responds to the request with a 401 status code and prevents the next controller from receiving the request.\n\n\nOnce parsed, an \nAuthorizer\n sends the information - either the bearer token, or the username and password - to an \nAuthServer\n for verification. If the \nAuthServer\n rejects the authorization info, the \nAuthorizer\n responds to the request with a 401 status code and prevents the next controller from receiving the request. Otherwise, the request continues to the next controller.\n\n\nThe type of \nAuthorizer\n - \nAuthStrategy.bearer\n or \nAuthStrategy.basic\n - determines how the \nAuthServer\n verifies the information.\n\n\nFor \nAuthorizer.bearer\n authorizers, the value in a request's header must be a valid, unexpired access token. These types of authorizers are used when an endpoint requires a logged in user.\n\n\nFor \nAuthorizer.basic\n authorizers, credentials are verified by finding an OAuth 2.0 client identifier and ensuring its client secret matches. Routes with this type of authorizer are known as \nclient authenticated\n routes. These types of authorizers are used when an endpoint requires a valid client application, but not a logged in user.\n\n\nAuthorizer and OAuth 2.0 Scope\n\n\nAn \nAuthorizer\n may restrict access to controllers based on the scope of the request's bearer token. By default, an \nAuthorizer.bearer\n allows any valid bearer token to pass through it. If desired, an \nAuthorizer\n is initialized with a list of required scopes. A request may only pass the \nAuthorizer\n if it has access to \nall\n scopes listed in the \nAuthorizer\n. For example, the following requires at least \nuser:posts\n and \nlocation\n scope:\n\n\nrouter\n\n  \n.\nroute\n(\n/checkin\n)\n\n  \n.\npipe\n(\nnew\n \nAuthorizer\n.\nbearer\n(\nauthServer\n,\n \nscopes:\n \n[\nuser:posts\n,\n \nlocation\n]))\n\n  \n.\ngenerate\n(()\n \n=\n \nnew\n \nCheckInController\n());\n\n\n\n\n\n\nNote that you don't have to use an \nAuthorizer\n to restrict access based on scope. A controller has access to scope information after the request has passed through an \nAuthorizer\n, so it can use the scope to make more granular decisions about the result of an API call.\n\n\nAuthorization Objects\n\n\nA bearer token is a representation of granted authorization - at some point in the past, a user provided their credentials and the token is the proof of that. When a bearer token is sent back to an Aqueduct application as part of an HTTP request, the application can look up which user the token is for and the client application it was issued for. This information is stored in an instance of \nAuthorization\n. When a \nRequest\n successfully passes through an \nAuthorizer\n, an instance of \nAuthorization\n is assigned to its \nauthorization\n property.\n\n\nSubsequent controllers - those protected by an \nAuthorizer\n - can access this information to further determine their behavior. For example, a social networking application might have a \n/news_feed/[:id]\n endpoint protected by an \nAuthorizer\n. When an authenticated user makes a request for \n/news_feed\n, the controller will return that user's news feed. It can determine this by using the \nAuthorization\n:\n\n\nclass\n \nNewsFeedController\n \nextends\n \nHTTPController\n \n{\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetNewsFeed\n()\n \nasync\n \n{\n\n    \nvar\n \nforUserID\n \n=\n \nrequest\n.\nauthorization\n.\nresourceOwnerIdentifier\n;\n\n\n    \nvar\n \nquery\n \n=\n \nnew\n \nQuery\nPost\n()\n\n      \n..\nwhere\n.\nauthor\n \n=\n \nwhereRelatedByValue\n(\nforUserID\n);\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nawait\n \nquery\n.\nfetch\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nIn the above controller, it's impossible for a user to access another user's posts without having an access token granted by them.\n\n\nAuthorization\n objects also retain the scope of an access token so that a controller can make more granular decisions about the information/action in the endpoint. Checking whether an \nAuthorization\n has access to a particular scope is accomplished by either looking at the list of its \nscopes\n or using \nauthorizedForScope\n:\n\n\nclass\n \nNewsFeedController\n \nextends\n \nHTTPController\n \n{\n\n  \n@\nhttpGet\n\n  \nFuture\nResponse\n \ngetNewsFeed\n()\n \nasync\n \n{\n\n    \nif\n \n(\n!\nrequest\n.\nauthorization\n.\nauthorizedForScope\n(\nuser:feed\n))\n \n{\n\n      \nreturn\n \nnew\n \nResponse\n.\nunauthorized\n();\n\n    \n}\n\n\n    \nvar\n \nforUserID\n \n=\n \nrequest\n.\nauthorization\n.\nresourceOwnerIdentifier\n;\n\n\n    \nvar\n \nquery\n \n=\n \nnew\n \nQuery\nPost\n()\n\n      \n..\nwhere\n.\nauthor\n \n=\n \nwhereRelatedByValue\n(\nforUserID\n);\n\n\n    \nreturn\n \nnew\n \nResponse\n.\nok\n(\nawait\n \nquery\n.\nfetch\n());\n\n  \n}\n\n\n}\n\n\n\n\n\n\nUsing Authorizers Without AuthServer\n\n\nThroughout this guide, the argument to an instance of \nAuthorizer\n has been referred to as an \nAuthServer\n. This is true - but only because \nAuthServer\n implements \nAuthValidator\n, a simple interface for verifying bearer tokens and username/password combinations. You may use \nAuthorizer\n without using \nAuthServer\n. For example, an application that used simple Basic Auth credentials would have no need for \nAuthServer\n and its OAuth 2.0 behavior. See the API reference for \nAuthValidator\n for more details.", 
            "title": "Protected Routes"
        }, 
        {
            "location": "/auth/authorizer/#securing-routes-with-authorizer", 
            "text": "Instances of  Authorizer  are  RequestController s that verify an HTTP request's authorization information before passing the request on to their next controller.  Authorizer s are created in a  RequestSink 's  setupRouter  method as part of a request pipeline. They protect access to their next controller and typically come right after  route . Here's an example:  @ override  void   setupRouter ( Router   router )   { \n   router \n     . route ( /protected ) \n     . pipe ( new   Authorizer . bearer ( authServer )) \n     . generate (()   =   new   ProtectedController ()); \n\n   router \n     . route ( /other ) \n     . pipe ( new   Authorizer . basic ( authServer )) \n     . generate (()   =   new   OtherController ());  }   An  Authorizer  has no state itself, so it is added to a request pipeline via  pipe ; i.e., it does not need to be  generate d.  An  Authorizer  parses the Authorization header of an HTTP request. The named constructors of  Authorizer  indicate the required format of Authorization header. The  Authorization.bearer()  constructor expects an OAuth 2.0 bearer token in the header, which has the following format:  Authorization :   Bearer   768 iuzjkx82jkasjkd9z9   Authorizer.basic  expects HTTP Basic Authentication, where the username and password are joined with the colon character ( : ) and Base 64 encoded:  //  dXNlcjpwYXNzd29yZA==  is  user:password \nAuthorization: Basic dXNlcjpwYXNzd29yZA==  If the header can't be parsed, doesn't exist or is in the wrong format, an  Authorizer  responds to the request with a 401 status code and prevents the next controller from receiving the request.  Once parsed, an  Authorizer  sends the information - either the bearer token, or the username and password - to an  AuthServer  for verification. If the  AuthServer  rejects the authorization info, the  Authorizer  responds to the request with a 401 status code and prevents the next controller from receiving the request. Otherwise, the request continues to the next controller.  The type of  Authorizer  -  AuthStrategy.bearer  or  AuthStrategy.basic  - determines how the  AuthServer  verifies the information.  For  Authorizer.bearer  authorizers, the value in a request's header must be a valid, unexpired access token. These types of authorizers are used when an endpoint requires a logged in user.  For  Authorizer.basic  authorizers, credentials are verified by finding an OAuth 2.0 client identifier and ensuring its client secret matches. Routes with this type of authorizer are known as  client authenticated  routes. These types of authorizers are used when an endpoint requires a valid client application, but not a logged in user.", 
            "title": "Securing Routes with Authorizer"
        }, 
        {
            "location": "/auth/authorizer/#authorizer-and-oauth-20-scope", 
            "text": "An  Authorizer  may restrict access to controllers based on the scope of the request's bearer token. By default, an  Authorizer.bearer  allows any valid bearer token to pass through it. If desired, an  Authorizer  is initialized with a list of required scopes. A request may only pass the  Authorizer  if it has access to  all  scopes listed in the  Authorizer . For example, the following requires at least  user:posts  and  location  scope:  router \n   . route ( /checkin ) \n   . pipe ( new   Authorizer . bearer ( authServer ,   scopes:   [ user:posts ,   location ])) \n   . generate (()   =   new   CheckInController ());   Note that you don't have to use an  Authorizer  to restrict access based on scope. A controller has access to scope information after the request has passed through an  Authorizer , so it can use the scope to make more granular decisions about the result of an API call.", 
            "title": "Authorizer and OAuth 2.0 Scope"
        }, 
        {
            "location": "/auth/authorizer/#authorization-objects", 
            "text": "A bearer token is a representation of granted authorization - at some point in the past, a user provided their credentials and the token is the proof of that. When a bearer token is sent back to an Aqueduct application as part of an HTTP request, the application can look up which user the token is for and the client application it was issued for. This information is stored in an instance of  Authorization . When a  Request  successfully passes through an  Authorizer , an instance of  Authorization  is assigned to its  authorization  property.  Subsequent controllers - those protected by an  Authorizer  - can access this information to further determine their behavior. For example, a social networking application might have a  /news_feed/[:id]  endpoint protected by an  Authorizer . When an authenticated user makes a request for  /news_feed , the controller will return that user's news feed. It can determine this by using the  Authorization :  class   NewsFeedController   extends   HTTPController   { \n   @ httpGet \n   Future Response   getNewsFeed ()   async   { \n     var   forUserID   =   request . authorization . resourceOwnerIdentifier ; \n\n     var   query   =   new   Query Post () \n       .. where . author   =   whereRelatedByValue ( forUserID ); \n\n     return   new   Response . ok ( await   query . fetch ()); \n   }  }   In the above controller, it's impossible for a user to access another user's posts without having an access token granted by them.  Authorization  objects also retain the scope of an access token so that a controller can make more granular decisions about the information/action in the endpoint. Checking whether an  Authorization  has access to a particular scope is accomplished by either looking at the list of its  scopes  or using  authorizedForScope :  class   NewsFeedController   extends   HTTPController   { \n   @ httpGet \n   Future Response   getNewsFeed ()   async   { \n     if   ( ! request . authorization . authorizedForScope ( user:feed ))   { \n       return   new   Response . unauthorized (); \n     } \n\n     var   forUserID   =   request . authorization . resourceOwnerIdentifier ; \n\n     var   query   =   new   Query Post () \n       .. where . author   =   whereRelatedByValue ( forUserID ); \n\n     return   new   Response . ok ( await   query . fetch ()); \n   }  }", 
            "title": "Authorization Objects"
        }, 
        {
            "location": "/auth/authorizer/#using-authorizers-without-authserver", 
            "text": "Throughout this guide, the argument to an instance of  Authorizer  has been referred to as an  AuthServer . This is true - but only because  AuthServer  implements  AuthValidator , a simple interface for verifying bearer tokens and username/password combinations. You may use  Authorizer  without using  AuthServer . For example, an application that used simple Basic Auth credentials would have no need for  AuthServer  and its OAuth 2.0 behavior. See the API reference for  AuthValidator  for more details.", 
            "title": "Using Authorizers Without AuthServer"
        }, 
        {
            "location": "/auth/controllers/", 
            "text": "Issue Access Tokens with AuthController\n\n\nAn application using Aqueduct's Auth framework must have endpoints to exchange credentials for access tokens. While a developer could implement these endpoints themselves and talk directly to an \nAuthServer\n, the OAuth 2.0 specification is where happiness goes to die. Therefore, there exists a \nRequestController\ns in Aqueduct that handles granting and refreshing authorization tokens named \nAuthController\n (the resource owner grant flow). Another controller, \nAuthCodeController\n, handles the authorization code flow.\n\n\nIssue, Refresh and Exchange Tokens with AuthController\n\n\nUsing an \nAuthController\n in an application is straightforward - hook it up to a \nRouter\n and pass it an \nAuthServer\n.\n\n\n@\noverride\n\n\nvoid\n \nsetupRouter\n(\nRouter\n \nrouter\n)\n \n{\n\n  \nrouter\n\n    \n.\nroute\n(\n/auth/token\n)\n\n    \n.\ngenerate\n(()\n \n=\n \nnew\n \nAuthController\n(\nauthServer\n));\n\n\n}\n\n\n\n\n\n\nAn \nAuthController\n follows the OAuth 2.0 specification for granting and refreshing access tokens. To grant an access token, a client application sends a POST HTTP request to the controller. The request must contain two important components: an Authorization header with the Client ID and Client Secret, and a \nx-www-form-urlencoded\n body with the username and password of the authenticating user. The body must also contain the key-value pair \ngrant_type=password\n. For example, the following Dart code will initiate successful authentication:\n\n\nvar\n \nclientID\n \n=\n \n...;\n\n\nvar\n \nclientSecret\n \n=\n \n...;\n\n\n\nvar\n \nbody\n \n=\n \n{\n\n  \nusername\n:\n \nbob@stablekernel.com\n,\n\n  \npassword\n:\n \nfoobar\n,\n\n  \ngrant_type\n:\n \npassword\n\n\n};\n\n\n\n// this creates a URL encoded version of: \nusername=bob@stablekernel.com\npassword=foobar\ngrant_type=password\n\n\nvar\n \nbodyForm\n \n=\n \nbody\n.\nkeys\n\n  \n.\nmap\n((\nkey\n)\n \n=\n \n$\nkey\n=\n${\nUri\n.\nencodeQueryComponent\n(\nbody\n[\nkey\n])\n}\n)\n\n  \n.\njoin\n(\n);\n\n\n\nvar\n \nclientCredentials\n \n=\n \nnew\n \nBase64Encoder\n().\nconvert\n(\n$\nclientID\n:\n$\nclientSecret\n.\ncodeUnits\n);\n\n\n\nvar\n \nresponse\n \n=\n \nawait\n \nhttp\n.\npost\n(\n\n  \nhttps://stablekernel.com/auth/token\n,\n\n  \nheaders:\n \n{\n\n    \nContent-Type\n:\n \napplication/x-www-form-urlencoded\n,\n\n    \nAuthorization\n:\n \nBasic \n$\nclientCredentials\n\n  \n},\n\n  \nbody:\n \nbodyForm\n);\n\n\n\n\n\n\nThe response to a password token request is a JSON body that follows the OAuth 2.0 specification:\n\n\n{\n  \naccess_token\n: \n...\n\n  \nrefresh_token\n: \n...\n,\n  \nexpires_in\n: 3600,\n  \ntoken_type\n: \nbearer\n\n}\n\n\n\n\n\nTokens are refreshed through the same endpoint, but with a payload that contains the refresh token and \ngrant_type=refresh_token\n.\n\n\ngrant_type=refresh_token\nrefresh_token=kjasdiuz9u3namnsd\n\n\n\n\n\nSee \nAqueduct Auth CLI\n for more details on creating OAuth 2.0 client identifier and secrets.\n\n\nIf an Aqueduct application is using scope, an additional \nscope\n parameter can contain a space-delimited list of requested authorization scope. Only allowed scopes are returned and granted, and if no scopes are allowed then the request fails. If scope is provided, granted scope will be available in the response body.\n\n\nIt is important that an \nAuthorizer\n \ndoes not\n protect instances of \nAuthController\n. The Authorization header is parsed and verified by \nAuthController\n.\n\n\nOnce granted, an access token can be used to pass \nAuthorizer\ns in protected endpoints.\n\n\nIssue Authorization Codes with AuthCodeController\n\n\nAn \nAuthCodeController\n manages the OAuth 2.0 authorization code flow. The authorization code flow is used when an Aqueduct application allows third party applications access to authorized resources.\n\n\nLet's say you've built an Aqueduct application that allows people to store notes to themselves, and it has users that have created accounts. Now, a friend approaches you with their application that is a to-do list. Instead of building their own note-taking feature, your friend wants their users of their application to access the notes those users have stored in your application. While trustworthy, you don't want your friend to have access to the username and passwords of your subscribers.\n\n\nTo handle this, your friend builds a link into their application that takes the user to a web form hosted by your application. The user enters their credentials in this form and they are sent to your application. Your application responds by redirecting the user's browser back into your friend's application, but with an authorization code in the URL. Your friend's application parses the code from the URL and sends it to their server. Behind the scenes, their server exchanges this code with your server for an access token.\n\n\nAn \nAuthCodeController\n responds to both \nGET\n and \nPOST\n requests. When issued a \nGET\n, it serves up a webpage with a login form. This login form's action sends a \nPOST\n back to the same endpoint with the username and password of the user. Upon success, the response from the \nPOST\n is a 302 redirect with an authorization code.\n\n\nSetting up an \nAuthCodeController\n is nearly as simple as setting up an \nAuthController\n, but requires a function that renders the HTML login form. Here's an example:\n\n\n@\noverride\n\n\nvoid\n \nsetupRouter\n(\nRouter\n \nrouter\n)\n \n{\n\n  \nrouter\n\n    \n.\nroute\n(\n/auth/code\n)\n\n    \n.\ngenerate\n(()\n \n=\n \nnew\n \nAuthCodeController\n(\n\n      \nauthServer\n,\n \nrenderAuthorizationPageHTML:\n \nrenderLogin\n));\n\n\n}\n\n\n\nFuture\nString\n \nrenderLogin\n(\n\n    \nAuthCodeController\n \nrequestingController\n,\n\n    \nURI\n \nrequestURI\n,\n\n    \nMap\nString\n,\n \nString\n \nqueryParameters\n)\n \n{\n\n  \nvar\n \nhtml\n \n=\n \nHTMLRenderer\n.\ntemplateWithSubstitutions\n(\n\n    \nweb/login.html\n,\n \nrequestURI\n,\n \nqueryParameters\n);\n\n\n  \nreturn\n \nhtml\n;\n\n\n}\n\n\n\n\n\n\nIt is important that all values passed to HTML rendering function are sent in the form's query parameters - they contain necessary security components and scope information. (The default project created with \naqueduct create\n has an implementation with a simple login form that does this.)\n\n\nWhen your friend's application links to your login page - here, a \nGET /auth/code\n - they must include three query parameters: \nstate\n, \nclient_id\n, \nresponse_type\n. They may optionally include \nscope\n:\n\n\nGET https://stablekernel/auth/code?client_id=friend.app\nresponse_type=code\nstate=87uijn3rkja\n\n\n\n\n\nThe value of \nclient_id\n must be a previously created client identifier specifically made for your friend's application. (See more on generating client identifiers with \naqueduct auth\n in \nAqueduct Auth CLI\n.) The \nresponse_type\n must always be \ncode\n. The \nstate\n must be a value your friend's application creates.\n\n\nWhen your application redirects back to your friend's application, both the generated authorization code and the value for \nstate\n will be query parameters in the URL. It is your friend's job to ensure that the \nstate\n matches the state they provided to the initial \nGET\n. (They probably generated it from a session cookie.) That redirect URL will look like:\n\n\nhttps://friends.app/code_callback?code=abcd672kk\nstate=87uijn3rkja\n\n\n\n\n\nThe redirect URL is pre-determined when generating the client identifier with \naqueduct auth\n.\n\n\nOnce your friend's application has an authorization code, it is sent to their server. To exchange the code, a \nPOST\n to an \nAuthController\n - \nNOT\n the \nAuthCodeController\n - with the following body will return a token response:\n\n\ngrant_type=authorization_code\ncode=abcd672kk", 
            "title": "Issuing Access Tokens"
        }, 
        {
            "location": "/auth/controllers/#issue-access-tokens-with-authcontroller", 
            "text": "An application using Aqueduct's Auth framework must have endpoints to exchange credentials for access tokens. While a developer could implement these endpoints themselves and talk directly to an  AuthServer , the OAuth 2.0 specification is where happiness goes to die. Therefore, there exists a  RequestController s in Aqueduct that handles granting and refreshing authorization tokens named  AuthController  (the resource owner grant flow). Another controller,  AuthCodeController , handles the authorization code flow.", 
            "title": "Issue Access Tokens with AuthController"
        }, 
        {
            "location": "/auth/controllers/#issue-refresh-and-exchange-tokens-with-authcontroller", 
            "text": "Using an  AuthController  in an application is straightforward - hook it up to a  Router  and pass it an  AuthServer .  @ override  void   setupRouter ( Router   router )   { \n   router \n     . route ( /auth/token ) \n     . generate (()   =   new   AuthController ( authServer ));  }   An  AuthController  follows the OAuth 2.0 specification for granting and refreshing access tokens. To grant an access token, a client application sends a POST HTTP request to the controller. The request must contain two important components: an Authorization header with the Client ID and Client Secret, and a  x-www-form-urlencoded  body with the username and password of the authenticating user. The body must also contain the key-value pair  grant_type=password . For example, the following Dart code will initiate successful authentication:  var   clientID   =   ...;  var   clientSecret   =   ...;  var   body   =   { \n   username :   bob@stablekernel.com , \n   password :   foobar , \n   grant_type :   password  };  // this creates a URL encoded version of:  username=bob@stablekernel.com password=foobar grant_type=password  var   bodyForm   =   body . keys \n   . map (( key )   =   $ key = ${ Uri . encodeQueryComponent ( body [ key ]) } ) \n   . join ( );  var   clientCredentials   =   new   Base64Encoder (). convert ( $ clientID : $ clientSecret . codeUnits );  var   response   =   await   http . post ( \n   https://stablekernel.com/auth/token , \n   headers:   { \n     Content-Type :   application/x-www-form-urlencoded , \n     Authorization :   Basic  $ clientCredentials \n   }, \n   body:   bodyForm );   The response to a password token request is a JSON body that follows the OAuth 2.0 specification:  {\n   access_token :  ... \n   refresh_token :  ... ,\n   expires_in : 3600,\n   token_type :  bearer \n}  Tokens are refreshed through the same endpoint, but with a payload that contains the refresh token and  grant_type=refresh_token .  grant_type=refresh_token refresh_token=kjasdiuz9u3namnsd  See  Aqueduct Auth CLI  for more details on creating OAuth 2.0 client identifier and secrets.  If an Aqueduct application is using scope, an additional  scope  parameter can contain a space-delimited list of requested authorization scope. Only allowed scopes are returned and granted, and if no scopes are allowed then the request fails. If scope is provided, granted scope will be available in the response body.  It is important that an  Authorizer   does not  protect instances of  AuthController . The Authorization header is parsed and verified by  AuthController .  Once granted, an access token can be used to pass  Authorizer s in protected endpoints.", 
            "title": "Issue, Refresh and Exchange Tokens with AuthController"
        }, 
        {
            "location": "/auth/controllers/#issue-authorization-codes-with-authcodecontroller", 
            "text": "An  AuthCodeController  manages the OAuth 2.0 authorization code flow. The authorization code flow is used when an Aqueduct application allows third party applications access to authorized resources.  Let's say you've built an Aqueduct application that allows people to store notes to themselves, and it has users that have created accounts. Now, a friend approaches you with their application that is a to-do list. Instead of building their own note-taking feature, your friend wants their users of their application to access the notes those users have stored in your application. While trustworthy, you don't want your friend to have access to the username and passwords of your subscribers.  To handle this, your friend builds a link into their application that takes the user to a web form hosted by your application. The user enters their credentials in this form and they are sent to your application. Your application responds by redirecting the user's browser back into your friend's application, but with an authorization code in the URL. Your friend's application parses the code from the URL and sends it to their server. Behind the scenes, their server exchanges this code with your server for an access token.  An  AuthCodeController  responds to both  GET  and  POST  requests. When issued a  GET , it serves up a webpage with a login form. This login form's action sends a  POST  back to the same endpoint with the username and password of the user. Upon success, the response from the  POST  is a 302 redirect with an authorization code.  Setting up an  AuthCodeController  is nearly as simple as setting up an  AuthController , but requires a function that renders the HTML login form. Here's an example:  @ override  void   setupRouter ( Router   router )   { \n   router \n     . route ( /auth/code ) \n     . generate (()   =   new   AuthCodeController ( \n       authServer ,   renderAuthorizationPageHTML:   renderLogin ));  }  Future String   renderLogin ( \n     AuthCodeController   requestingController , \n     URI   requestURI , \n     Map String ,   String   queryParameters )   { \n   var   html   =   HTMLRenderer . templateWithSubstitutions ( \n     web/login.html ,   requestURI ,   queryParameters ); \n\n   return   html ;  }   It is important that all values passed to HTML rendering function are sent in the form's query parameters - they contain necessary security components and scope information. (The default project created with  aqueduct create  has an implementation with a simple login form that does this.)  When your friend's application links to your login page - here, a  GET /auth/code  - they must include three query parameters:  state ,  client_id ,  response_type . They may optionally include  scope :  GET https://stablekernel/auth/code?client_id=friend.app response_type=code state=87uijn3rkja  The value of  client_id  must be a previously created client identifier specifically made for your friend's application. (See more on generating client identifiers with  aqueduct auth  in  Aqueduct Auth CLI .) The  response_type  must always be  code . The  state  must be a value your friend's application creates.  When your application redirects back to your friend's application, both the generated authorization code and the value for  state  will be query parameters in the URL. It is your friend's job to ensure that the  state  matches the state they provided to the initial  GET . (They probably generated it from a session cookie.) That redirect URL will look like:  https://friends.app/code_callback?code=abcd672kk state=87uijn3rkja  The redirect URL is pre-determined when generating the client identifier with  aqueduct auth .  Once your friend's application has an authorization code, it is sent to their server. To exchange the code, a  POST  to an  AuthController  -  NOT  the  AuthCodeController  - with the following body will return a token response:  grant_type=authorization_code code=abcd672kk", 
            "title": "Issue Authorization Codes with AuthCodeController"
        }, 
        {
            "location": "/auth/cli/", 
            "text": "Manage OAuth 2.0 Clients\n\n\nThe \naqueduct auth\n command line tool creates OAuth 2.0 client application identifiers and inserts them into an application's database. To use this tool, you must use \nManagedAuthStorage\n for an \nAuthServer\n's \nstorage\n.\n\n\nExchanging credentials for an authorization token requires a registered client identifier. A token belongs to both the authenticating user and the client application. Clients are represented by instances of \nManagedClient\n from \naqueduct/managed_auth\n. Authenticating clients must provide their client ID (and client secret, if applicable) in the Authorization header when requesting access tokens.\n\n\nAn application's database must have already been provisioned such that the table that backs \nManagedClient\n exists. (See \nGenerating Databases\n.) An OAuth 2.0 client must have a string identifier that uniquely identifies the client. For example, \ncom.food_app.mobile\n may be a client identifier for the mobile applications for some 'Food App'.\n\n\nTo create a simple OAuth 2.0 client, the following command line utility can be run:\n\n\naqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --connect postgres://user:password@dbhost:5432/food_app\n\n\n\n\n\nThe \nconnect\n option identifies the database for the application, which this tool will connect to and insert a record into the \nManagedClient\n database table. The identifier is provided through the \nid\n option.\n\n\nAn OAuth 2.0 client created in this way is a \npublic\n client; there is no client secret. An OAuth 2.0 client that uses the resource owner grant flow, but cannot secure its client secret should use this type of client. An application can't secure its client secret if its source code is viewable - like any JavaScript application. It is suggested that native mobile applications also use public clients because their source code could potentially disassembled to reveal a client secret, but this in practice this isn't all that common.\n\n\nTo include a public client in an authorization header, the client secret is omitted. The string to base64 encode is \nClientID:\n, where the colon (\n:\n) is required. For example, to generate an authorization header in Dart for a public client:\n\n\nvar\n \nclientID\n \n=\n \ncom.foobar.xyz\n;\n\n\nvar\n \nclientCredentials\n \n=\n \nnew\n \nBase64Encoder\n()\n.\nconvert\n(\n$clientID:\n.\ncodeUnits\n);\n\n\nvar\n \nheader\n \n=\n \nBasic $clientCredentials\n;\n\n\n\n\n\n\nAn OAuth 2.0 client is \nconfidential\n if it has a client secret. Client secrets can be provided with the \nauth\n tool:\n\n\naqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --connect postgres://user:password@dbhost:5432/food_app\n\n\n\n\n\nClient secrets are hashed with a randomly generated salt before they are stored. Therefore, their actual value must be stored securely elsewhere. (We use LastPass, for example.)\n\n\nTo allow the authorization code flow (provided by \nAuthCodeController\n), a client must have a redirect URI. This is the URI that an authenticating user's browser will be redirected to after entering their username and password. A client must be a confidential client to have a redirect URI.\n\n\naqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --redirect-uri https://someapp.com/callback \\\n  --connect postgres://user:password@dbhost:5432/food_app\n\n\n\n\n\nIf an application is using OAuth 2.0 scopes, a client can have scopes that it allows tokens to have access to. This allows scopes to be restricted by the client they are authenticating with.\n\n\naqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --allowed-scopes \nscopeA scopeB scopeC.readonly\n \\\n  --connect postgres://user:password@dbhost:5432/food_app\n\n\n\n\n\nScopes are space-delimited and must be enclosed in quotes such that your shell will treat the entire string as one value.\n\n\nScope may be set after a client has already been created with \naqueduct auth set-scope\n:\n\n\naqueduct auth set-scope \\\n  --id com.food_app.mobile \\\n  --scopes \nscopeA scopeC\n \\\n  --connect postgres://user:password@dbhost:5432/food_app\n\n\n\n\n\nLike all \naqueduct\n commands that send commands to a database, the \nconnect\n option can be replaced by a \ndatabase.yaml\n file in the project directory with the following format:\n\n\nusername: \nuser\n\npassword: \npassword\n\nhost: \nhost\n\nport: 5432\ndatabaseName: \nmy_app", 
            "title": "Creating OAuth 2.0 Clients"
        }, 
        {
            "location": "/auth/cli/#manage-oauth-20-clients", 
            "text": "The  aqueduct auth  command line tool creates OAuth 2.0 client application identifiers and inserts them into an application's database. To use this tool, you must use  ManagedAuthStorage  for an  AuthServer 's  storage .  Exchanging credentials for an authorization token requires a registered client identifier. A token belongs to both the authenticating user and the client application. Clients are represented by instances of  ManagedClient  from  aqueduct/managed_auth . Authenticating clients must provide their client ID (and client secret, if applicable) in the Authorization header when requesting access tokens.  An application's database must have already been provisioned such that the table that backs  ManagedClient  exists. (See  Generating Databases .) An OAuth 2.0 client must have a string identifier that uniquely identifies the client. For example,  com.food_app.mobile  may be a client identifier for the mobile applications for some 'Food App'.  To create a simple OAuth 2.0 client, the following command line utility can be run:  aqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --connect postgres://user:password@dbhost:5432/food_app  The  connect  option identifies the database for the application, which this tool will connect to and insert a record into the  ManagedClient  database table. The identifier is provided through the  id  option.  An OAuth 2.0 client created in this way is a  public  client; there is no client secret. An OAuth 2.0 client that uses the resource owner grant flow, but cannot secure its client secret should use this type of client. An application can't secure its client secret if its source code is viewable - like any JavaScript application. It is suggested that native mobile applications also use public clients because their source code could potentially disassembled to reveal a client secret, but this in practice this isn't all that common.  To include a public client in an authorization header, the client secret is omitted. The string to base64 encode is  ClientID: , where the colon ( : ) is required. For example, to generate an authorization header in Dart for a public client:  var   clientID   =   com.foobar.xyz ;  var   clientCredentials   =   new   Base64Encoder () . convert ( $clientID: . codeUnits );  var   header   =   Basic $clientCredentials ;   An OAuth 2.0 client is  confidential  if it has a client secret. Client secrets can be provided with the  auth  tool:  aqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --connect postgres://user:password@dbhost:5432/food_app  Client secrets are hashed with a randomly generated salt before they are stored. Therefore, their actual value must be stored securely elsewhere. (We use LastPass, for example.)  To allow the authorization code flow (provided by  AuthCodeController ), a client must have a redirect URI. This is the URI that an authenticating user's browser will be redirected to after entering their username and password. A client must be a confidential client to have a redirect URI.  aqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --redirect-uri https://someapp.com/callback \\\n  --connect postgres://user:password@dbhost:5432/food_app  If an application is using OAuth 2.0 scopes, a client can have scopes that it allows tokens to have access to. This allows scopes to be restricted by the client they are authenticating with.  aqueduct auth add-client \\\n  --id com.food_app.mobile \\\n  --secret myspecialsecret \\\n  --allowed-scopes  scopeA scopeB scopeC.readonly  \\\n  --connect postgres://user:password@dbhost:5432/food_app  Scopes are space-delimited and must be enclosed in quotes such that your shell will treat the entire string as one value.  Scope may be set after a client has already been created with  aqueduct auth set-scope :  aqueduct auth set-scope \\\n  --id com.food_app.mobile \\\n  --scopes  scopeA scopeC  \\\n  --connect postgres://user:password@dbhost:5432/food_app  Like all  aqueduct  commands that send commands to a database, the  connect  option can be replaced by a  database.yaml  file in the project directory with the following format:  username:  user \npassword:  password \nhost:  host \nport: 5432\ndatabaseName:  my_app", 
            "title": "Manage OAuth 2.0 Clients"
        }, 
        {
            "location": "/auth/what_is_oauth/", 
            "text": "What is OAuth 2.0?\n\n\nMost applications have the concept of a user. To prevent just anyone from saying they are this user, the user has a password. When a user wants to use your application, they send their username and password to the server so it can ensure they are who they say they are.\n\n\nThe simple way to do this is to send the username and password in an Authorization header for every request. Two reasons this is bad: first, every time the user wants to do something, their password is sent in every request and that can be unsafe. Second, any application that wants to keep the user logged in has to store that password - and that is unsafe.\n\n\nIn OAuth 2.0, the user gives their username and password to a client application once. The application sends those credentials to a server, and the server gives the application back an access token. A access token is a long, random string that no one can guess. When the user wants to do more stuff, the application sends the token with every request, instead of the user's password. The server checks the token, makes sure its not expired, and then lets the application's request go through. This means the application doesn't store the password, but doesn't have to ask the user for their password again.\n\n\nThis credential-for-token exchange happens by sending a POST request to some endpoint, where the username and password are sent in the request body. Typically, an Aqueduct application's route for this is \n/auth/token\n and handled by an instance of \nAuthController\n.\n\n\nOAuth 2.0 makes a subtle distinction: a user and the application they are using are not the same thing. It's intuitive to think of a user as \"making a request to the server\", but in reality, the user makes a request to an application. The application makes the request to the server. The server \ngrants\n the application access on behalf of the user. In other words, when a user enters their credentials into an application, the application goes to the server and says \"Hey, this user said I can do stuff for them. Look, this is their secret password!\"\n\n\nThis is an important distinction, because an OAuth 2.0 server doesn't just verify users: it also verifies applications. An application has a identifier that has been registered with the server. So, for an ecosystem that has a web client, an Android and an iOS app there would likely be three identifiers - one for each. The application usually stores that identifier in its code or a configuration file that it ships with. This identifier is called a \nclient identifier\n. Client identifiers are added to Aqueduct applications with the \naqueduct auth\n tool (see \nAqueduct Auth CLI\n).\n\n\nWhen the user is logging in through an application, they submit their username and password. The user doesn't provide the client identifier - in fact, the user doesn't know it. The application creates a request with the username and password in the body and the client identifier in the Authorization header. All three have to check out for the server to give the application back a token. The full request in pseudo-code looks something like:\n\n\nvar\n \nrequest\n \n=\n \nnew\n \nHTTPRequest\n(\n/auth/token\n);\n\n\nrequest\n.\nmethod\n \n=\n \nPOST\n;\n\n\nrequest\n.\ncontentType\n \n=\n \napplication/x-www-form-urlencoded\n;\n\n\nrequest\n.\nauthorization\n \n=\n \nBase64\n.\nencode\n(\n$\nclientID\n:\n);\n\n\nrequest\n.\nbody\n \n=\n \n{\n\n  \nusername\n \n:\n \nUserName\n,\n\n  \npassword\n \n:\n \nPassword\n,\n\n  \ngrant_type\n \n:\n \npassword\n\n\n};\n\n\n\n\n\n\nAn access token can expire. How long it takes to expire is up to the server - Aqueduct defaults to 24 hours. At first glance, this means that the application would have to ask the user for a password again. But, tokens can also be refreshed. Refreshing a token grants a brand new access token, but without having to ask for the password. This is possible because an access token comes with a \nrefresh token\n. The refresh token is another long, random string. So, the JSON the server sends back when granting a token looks like this:\n\n\n{\n\n  \naccess_token\n \n:\n \nAbca09zzzza2o2kelmzlli3ijlka\n,\n\n  \ntoken_type\n \n:\n \nbearer\n,\n\n  \nrefresh_token\n \n:\n \nlkmLIAmooa898nm20jannnnnxaww\n,\n\n  \nexpire_in\n \n:\n \n3600\n\n\n}\n\n\n\n\n\n\nThe application hangs on to both an access token and a refresh token. When it decides that the token is expired, it will send the refresh token back to the server to get a replacement access token. This is done through the same route that the access token came from - \n/auth/token\n - except the parameters are a bit different:\n\n\nvar\n \nrequest\n \n=\n \nnew\n \nHTTPRequest\n(\n/auth/token\n);\n\n\nrequest\n.\nmethod\n \n=\n \nPOST\n;\n\n\nrequest\n.\ncontentType\n \n=\n \napplication/x-www-form-urlencoded\n;\n\n\nrequest\n.\nauthorization\n \n=\n \nBase64\n.\nencode\n(\n$\nclientID\n:\n);\n\n\nrequest\n.\nbody\n \n=\n \n{\n\n  \nrefresh_token\n \n:\n \nRefreshToken\n,\n\n  \ngrant_type\n \n:\n \nrefresh_token\n\n\n};\n\n\n\n\n\n\nExchanging a refresh token has the same response as the initial exchange for username and password - except a few values will have changed.\n\n\nThe verification and storage of authorization and authentication information is managed by an \nAuthServer\n.\n\n\nOther Methods for Obtaining Authorization\n\n\nThe method of getting a token above - sending a username and password to \n/auth/token\n - is just one of four possible methods OAuth 2.0 uses to authenticate a user. This particular one is called the \nresource owner password credentials grant\n. A resource owner is a fancy word for a 'user'. We can shorten it up to just the 'password flow'. It's probably the most common flow - mobiles applications and front-end web applications often use this flow. When you enter your credentials, the client application sends them directly to the server.\n\n\nThe other commonly used flow prevents the client application from ever seeing the user's credentials. For example, you might sign into Pivotal Tracker with your Google account. Your account on Pivotal Tracker doesn't have a password. Instead, it is linked to your Google account - which does. Pivotal Tracker never sees your Google password. When you login to Pivotal Tracker in this way, it takes you to Google's authentication page - owned and operated by Google. When you login successfully, Google gives Pivotal Tracker your token. Pivotal Tracker is now an application that can do things on your behalf.\n\n\nThis is called the \nauthorization code grant\n - or just 'auth code flow'. An instance of \nAuthCodeController\n handles granting authorization codes. Once a code is received, it can be exchanged via an \nAuthController\n.", 
            "title": "What is OAuth 2.0?"
        }, 
        {
            "location": "/auth/what_is_oauth/#what-is-oauth-20", 
            "text": "Most applications have the concept of a user. To prevent just anyone from saying they are this user, the user has a password. When a user wants to use your application, they send their username and password to the server so it can ensure they are who they say they are.  The simple way to do this is to send the username and password in an Authorization header for every request. Two reasons this is bad: first, every time the user wants to do something, their password is sent in every request and that can be unsafe. Second, any application that wants to keep the user logged in has to store that password - and that is unsafe.  In OAuth 2.0, the user gives their username and password to a client application once. The application sends those credentials to a server, and the server gives the application back an access token. A access token is a long, random string that no one can guess. When the user wants to do more stuff, the application sends the token with every request, instead of the user's password. The server checks the token, makes sure its not expired, and then lets the application's request go through. This means the application doesn't store the password, but doesn't have to ask the user for their password again.  This credential-for-token exchange happens by sending a POST request to some endpoint, where the username and password are sent in the request body. Typically, an Aqueduct application's route for this is  /auth/token  and handled by an instance of  AuthController .  OAuth 2.0 makes a subtle distinction: a user and the application they are using are not the same thing. It's intuitive to think of a user as \"making a request to the server\", but in reality, the user makes a request to an application. The application makes the request to the server. The server  grants  the application access on behalf of the user. In other words, when a user enters their credentials into an application, the application goes to the server and says \"Hey, this user said I can do stuff for them. Look, this is their secret password!\"  This is an important distinction, because an OAuth 2.0 server doesn't just verify users: it also verifies applications. An application has a identifier that has been registered with the server. So, for an ecosystem that has a web client, an Android and an iOS app there would likely be three identifiers - one for each. The application usually stores that identifier in its code or a configuration file that it ships with. This identifier is called a  client identifier . Client identifiers are added to Aqueduct applications with the  aqueduct auth  tool (see  Aqueduct Auth CLI ).  When the user is logging in through an application, they submit their username and password. The user doesn't provide the client identifier - in fact, the user doesn't know it. The application creates a request with the username and password in the body and the client identifier in the Authorization header. All three have to check out for the server to give the application back a token. The full request in pseudo-code looks something like:  var   request   =   new   HTTPRequest ( /auth/token );  request . method   =   POST ;  request . contentType   =   application/x-www-form-urlencoded ;  request . authorization   =   Base64 . encode ( $ clientID : );  request . body   =   { \n   username   :   UserName , \n   password   :   Password , \n   grant_type   :   password  };   An access token can expire. How long it takes to expire is up to the server - Aqueduct defaults to 24 hours. At first glance, this means that the application would have to ask the user for a password again. But, tokens can also be refreshed. Refreshing a token grants a brand new access token, but without having to ask for the password. This is possible because an access token comes with a  refresh token . The refresh token is another long, random string. So, the JSON the server sends back when granting a token looks like this:  { \n   access_token   :   Abca09zzzza2o2kelmzlli3ijlka , \n   token_type   :   bearer , \n   refresh_token   :   lkmLIAmooa898nm20jannnnnxaww , \n   expire_in   :   3600  }   The application hangs on to both an access token and a refresh token. When it decides that the token is expired, it will send the refresh token back to the server to get a replacement access token. This is done through the same route that the access token came from -  /auth/token  - except the parameters are a bit different:  var   request   =   new   HTTPRequest ( /auth/token );  request . method   =   POST ;  request . contentType   =   application/x-www-form-urlencoded ;  request . authorization   =   Base64 . encode ( $ clientID : );  request . body   =   { \n   refresh_token   :   RefreshToken , \n   grant_type   :   refresh_token  };   Exchanging a refresh token has the same response as the initial exchange for username and password - except a few values will have changed.  The verification and storage of authorization and authentication information is managed by an  AuthServer .", 
            "title": "What is OAuth 2.0?"
        }, 
        {
            "location": "/auth/what_is_oauth/#other-methods-for-obtaining-authorization", 
            "text": "The method of getting a token above - sending a username and password to  /auth/token  - is just one of four possible methods OAuth 2.0 uses to authenticate a user. This particular one is called the  resource owner password credentials grant . A resource owner is a fancy word for a 'user'. We can shorten it up to just the 'password flow'. It's probably the most common flow - mobiles applications and front-end web applications often use this flow. When you enter your credentials, the client application sends them directly to the server.  The other commonly used flow prevents the client application from ever seeing the user's credentials. For example, you might sign into Pivotal Tracker with your Google account. Your account on Pivotal Tracker doesn't have a password. Instead, it is linked to your Google account - which does. Pivotal Tracker never sees your Google password. When you login to Pivotal Tracker in this way, it takes you to Google's authentication page - owned and operated by Google. When you login successfully, Google gives Pivotal Tracker your token. Pivotal Tracker is now an application that can do things on your behalf.  This is called the  authorization code grant  - or just 'auth code flow'. An instance of  AuthCodeController  handles granting authorization codes. Once a code is received, it can be exchanged via an  AuthController .", 
            "title": "Other Methods for Obtaining Authorization"
        }, 
        {
            "location": "/testing/overview/", 
            "text": "Tasks\n\n\nAqueduct's aim is to make developers productive, and testing is an important part of being productive. Therefore, Aqueduct has helpful utilities for testing an application.\n\n\nAqueduct tests run the application locally, which connects to a temporary, local database. Requests are issued in tests with a \nTestClient\n that makes configuring requests simple. Specialized test matchers - in the Hamcrest matcher style - validate request responses and can be mix and matched with the official Dart test package matchers.\n\n\nGuides\n\n\n\n\nUsing a Test Harness\n\n\nExecuting Requests and Validating Responses", 
            "title": "Overview"
        }, 
        {
            "location": "/testing/overview/#tasks", 
            "text": "Aqueduct's aim is to make developers productive, and testing is an important part of being productive. Therefore, Aqueduct has helpful utilities for testing an application.  Aqueduct tests run the application locally, which connects to a temporary, local database. Requests are issued in tests with a  TestClient  that makes configuring requests simple. Specialized test matchers - in the Hamcrest matcher style - validate request responses and can be mix and matched with the official Dart test package matchers.", 
            "title": "Tasks"
        }, 
        {
            "location": "/testing/overview/#guides", 
            "text": "Using a Test Harness  Executing Requests and Validating Responses", 
            "title": "Guides"
        }, 
        {
            "location": "/testing/harness/", 
            "text": "Using the Test Harness\n\n\nWhen creating an application with \naqueduct create\n, a test harness class is available in \ntest/harness/app.dart\n. It is responsible for starting a temporary, local instance of an application before tests run and stopping it once tests have finished.\n\n\nIt is required that you run the \naqueduct setup\n command prior to running Aqueduct application tests. (See \nGetting Started\n.)\n\n\nA test file, then, only needs to import this harness and start and stop the application to enable testing. Here's an example of a test file:\n\n\nimport\n \nharness/app.dart\n;\n\n\n\nvoid\n \nmain\n()\n \n{\n\n  \nTestApplication\n \napp\n \n=\n \nnew\n \nTestApplication\n();\n\n\n  \nsetUp\n(()\n \nasync\n \n{\n\n    \nawait\n \napp\n.\nstart\n();\n  \n  \n});\n\n\n  \ntearDown\n(()\n \nasync\n \n{\n\n    \nawait\n \napp\n.\nstop\n();\n\n  \n});\n\n\n  \ntest\n(\n...\n,\n \n()\n \nasync\n \n{\n\n    \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n();\n\n    \nexpect\n(\nresponse\n,\n \nhasStatus\n(\n200\n));\n\n  \n});\n\n\n}\n\n\n\n\n\n\nNote that the app harness file exports the Dart test package and Aqueduct's test helper package.\n\n\nBefore each test is run, the \nTestApplication\n harness is started. This harness starts your application running locally. Tests can issue requests to the application through its \nclient\n, which is covered in more detail \nhere\n.\n\n\nThere are a few important details to understand about the \nTestApplication\n when it is started.\n\n\nAn Aqueduct application will likely read values from a configuration file. The convention for configuration files in Aqueduct applications is to have two files: a template file that is checked into version control (\nconfig.yaml.src\n) and a deployed file that exists on a machine running a deployed instance of the application (\nconfig.yaml\n).\n\n\nBy default, a project created with \naqueduct create\n follows this convention. The file \nconfig.yaml.src\n is created when the project is created. It is the 'template' for your application's configuration file. As your configuration needs change, your modify the \nconfig.yaml.src\n file to include all of the keys that a deployed \nconfig.yaml\n file should have.\n\n\nThe test harness uses the values from \nconfig.yaml.src\n to configure the test instance of the application. This is very valuable: it ensures that the application you are testing is being configured in the same way as the deployed application. It also allows you to choose appropriate test configuration values for your test application so that things that need to be mocked can be driven by the values in the template configuration file.\n\n\nOn startup, the \nTestApplication\n will add a temporary version of your application's database schema to a local database. The database connection information comes from \nconfig.yaml.src\n - which defaults to and should stay \npostgres://dart:dart@localhost:5432/dart_test\n. This database is set up by the \naqueduct setup\n command. Once your tests run, all of the created tables are deleted.\n\n\nBecause most applications will use Aqueduct's Auth framework, it is required that an application have valid client ID and client secrets during testing to issue authorization tokens. By default, a single client ID/secret pair is added when starting the application: \ncom.aqueduct.test\n/\nkilimanjaro\n. If your application uses scopes or has behavioral differences for client IDs, you'll need to add those client IDs with \nTestApplication.addClientRecord\n. This can be done by adding the code to the test harness's \nstart\n method.\n\n\nYou may modify the \nTestApplication\n to do any additional work that your application needs to do prior during startup.\n\n\nA \nTestApplication\n has a \nclient\n property that executes requests against the application. The client is configured such that making requests only requires the path. The following sends a request for \nGET /users\n to the application, regardless of the host or port the application is listening on.\n\n\nvar\n \napp\n \n=\n \nnew\n \nTestApplication\n();\n\n\nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/users\n).\nget\n;\n\n\n\n\n\n\nMore details about the \nclient\n are available in the next guide, \nTestClient\n.\n\n\nLastly, a \nTestApplication\n runs its \nRequestSink\n on the main isolate - the same isolate that is running your tests. This allows your tests to peek at values inside the \nRequestSink\n and ensures there is only one database connection, since that connection is the only one that has access to the database schema.", 
            "title": "Test Harness"
        }, 
        {
            "location": "/testing/harness/#using-the-test-harness", 
            "text": "When creating an application with  aqueduct create , a test harness class is available in  test/harness/app.dart . It is responsible for starting a temporary, local instance of an application before tests run and stopping it once tests have finished.  It is required that you run the  aqueduct setup  command prior to running Aqueduct application tests. (See  Getting Started .)  A test file, then, only needs to import this harness and start and stop the application to enable testing. Here's an example of a test file:  import   harness/app.dart ;  void   main ()   { \n   TestApplication   app   =   new   TestApplication (); \n\n   setUp (()   async   { \n     await   app . start ();   \n   }); \n\n   tearDown (()   async   { \n     await   app . stop (); \n   }); \n\n   test ( ... ,   ()   async   { \n     var   response   =   await   app . client . request ( /endpoint ). get (); \n     expect ( response ,   hasStatus ( 200 )); \n   });  }   Note that the app harness file exports the Dart test package and Aqueduct's test helper package.  Before each test is run, the  TestApplication  harness is started. This harness starts your application running locally. Tests can issue requests to the application through its  client , which is covered in more detail  here .  There are a few important details to understand about the  TestApplication  when it is started.  An Aqueduct application will likely read values from a configuration file. The convention for configuration files in Aqueduct applications is to have two files: a template file that is checked into version control ( config.yaml.src ) and a deployed file that exists on a machine running a deployed instance of the application ( config.yaml ).  By default, a project created with  aqueduct create  follows this convention. The file  config.yaml.src  is created when the project is created. It is the 'template' for your application's configuration file. As your configuration needs change, your modify the  config.yaml.src  file to include all of the keys that a deployed  config.yaml  file should have.  The test harness uses the values from  config.yaml.src  to configure the test instance of the application. This is very valuable: it ensures that the application you are testing is being configured in the same way as the deployed application. It also allows you to choose appropriate test configuration values for your test application so that things that need to be mocked can be driven by the values in the template configuration file.  On startup, the  TestApplication  will add a temporary version of your application's database schema to a local database. The database connection information comes from  config.yaml.src  - which defaults to and should stay  postgres://dart:dart@localhost:5432/dart_test . This database is set up by the  aqueduct setup  command. Once your tests run, all of the created tables are deleted.  Because most applications will use Aqueduct's Auth framework, it is required that an application have valid client ID and client secrets during testing to issue authorization tokens. By default, a single client ID/secret pair is added when starting the application:  com.aqueduct.test / kilimanjaro . If your application uses scopes or has behavioral differences for client IDs, you'll need to add those client IDs with  TestApplication.addClientRecord . This can be done by adding the code to the test harness's  start  method.  You may modify the  TestApplication  to do any additional work that your application needs to do prior during startup.  A  TestApplication  has a  client  property that executes requests against the application. The client is configured such that making requests only requires the path. The following sends a request for  GET /users  to the application, regardless of the host or port the application is listening on.  var   app   =   new   TestApplication ();  var   response   =   await   app . client . request ( /users ). get ;   More details about the  client  are available in the next guide,  TestClient .  Lastly, a  TestApplication  runs its  RequestSink  on the main isolate - the same isolate that is running your tests. This allows your tests to peek at values inside the  RequestSink  and ensures there is only one database connection, since that connection is the only one that has access to the database schema.", 
            "title": "Using the Test Harness"
        }, 
        {
            "location": "/testing/test_client/", 
            "text": "Verify Requests with TestClient\n\n\nSetting up a \nTest Harness\n is required for testing Aqueduct applications. Once a test harness is set up, tests are comprised of issuing HTTP requests to the application, verifying responses, and sometimes checking external data sources for desired changes.\n\n\nHTTP requests are issued through an instance of \nTestClient\n. A \nTestApplication\n harness has a \nclient\n property of this type. Starting a \nTestApplication\n configures the \nTestClient\n so that its requests go to your application. There are three execution methods on \nTestClient\n, the most basic being \nrequest\n:\n\n\ntest\n(\nTest that this endpoint returns 200\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasStatus\n(\n200\n));\n\n\n});\n\n\n\n\n\n\nThe \nrequest\n method creates a new instance of \nTestRequest\n. A \nTestRequest\n is an object that represents an HTTP request, and it has execution methods like \nget\n, \npost\n, etc. as well as properties for setting headers, query parameters and an HTTP body. Here's a configured \nTestRequest\n:\n\n\napp\n.\nclient\n.\nrequest\n(\n/endpoint\n)\n\n  \n..\nqueryParameters\n \n=\n \n{\nq\n:\n \n1\n},\n\n  \n..\nheaders\n \n=\n \n{\nHeader\n:\n \nvalue\n}\n\n  \n..\nbody\n \n=\n \n...\n;\n\n\n\n\n\n\nQuery parameter values are URL string encoded.\n\n\nThere are conveniences for adding authorization info:\n\n\napp\n.\nclient\n.\nrequest\n(\n/endpoint\n)\n\n  \n..\nsetBasicAuthorization\n(\nusername\n,\n \npassword\n);\n\n\n\napp\n.\nclient\n.\nrequest\n(\n/endpoint\n)\n\n  \n..\nbearerAuthorization\n(\nbearerToken\n);\n\n\n\n\n\n\nThere are also conveniences for setting the body of the request. The following code both encodes the body argument as JSON and sets the content-type header to \napplication/json\n:\n\n\napp\n.\nclient\n.\nrequest\n(\n/endpoint\n)\n\n  \n..\njson\n \n=\n \n{\nkey\n:\n \nvalue\n};\n\n\n\n\n\n\nA similar property named \nformData\n exists for \nx-www-form-urlencoded\n bodies.\n\n\nThe other two variants of \nrequest\n are \nclientAuthenticatedRequest\n and \nauthenticatedRequest\n. A \nclientAuthenticatedRequest\n includes a Basic Authorization header, while an \nauthenticatedRequest\n includes a Bearer Authorization header.\n\n\nA \nTestClient\n has default values for both bearer and basic authorization headers. For example, the test harness sets the default credentials for a \nclientAuthenticatedRequest\n to the testing client ID. When creating a \nclientAuthenticatedRequest\n and not specifying the client ID and secret, those values are used:\n\n\nvar\n \nrequest\n \n=\n \napp\n.\nclient\n.\nclientAuthenticatedRequest\n(\n/endpoint\n);\n\n\n// request\ns authorization header is: Basic base64(com.aqueduct.test:kilimanjaro)\n\n\n\n\n\n\nThe default can be replaced with optional arguments:\n\n\nvar\n \nrequest\n \n=\n \napp\n.\nclient\n.\nclientAuthenticatedRequest\n(\n\n  \n/endpoint\n,\n \nclientID:\n \nfoo\n,\n \nclientSecret:\n \nbar\n);\n\n\n\n\n\n\nThe same goes for \nauthenticatedRequest\n, except that there is no default value to begin with. It often makes sense to create a 'user' during the setup of tests and then set the default bearer token to that user's granted token:\n\n\nsetUp\n(()\n \nasync\n \n{\n\n  \nawait\n \napp\n.\nstart\n();\n\n\n  \nvar\n \nregisterRequest\n \n=\n \napp\n.\nclient\n.\nclientAuthenticatedRequest\n(\n/register\n)\n\n    \n..\njson\n \n=\n \n{\nemail\n:\n \nfred@fred.com\n,\n \npassword\n:\n \nbob\n};\n\n  \nvar\n \nregisterResponse\n \n=\n \nawait\n \nregisterRequest\n.\npost\n();\n\n  \napp\n.\nclient\n.\ndefaultAccessToken\n \n=\n \nregisterResponse\n.\nasMap\n[\naccess_token\n];\n\n\n});\n\n\n\ntest\n(\nWith default bearer token\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nauthenticatedRequest\n(\n/endpoint\n).\nget\n();\n\n  \n...\n\n\n});\n\n\n\ntest\n(\nWith another bearer token\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n\n    \n.\nauthenticatedRequest\n(\n/endpoint\n,\n \naccessToken:\n \nsomeOtherToken\n).\nget\n();\n\n  \n...\n\n\n});\n\n\n\n\n\n\nIt's often useful to move this code into a method in the \nTestApplication\n itself.\n\n\nMatching Responses\n\n\nTests for an Aqueduct application usually involve sending a request and verifying the response is what you expected. When a \nTestRequest\n is executed with a method like \nget\n, a \nTestResponse\n is returned. A \nTestResponse\n can be cherry-picked for information to validate, but there are also special test matchers in the \naqueduct/test\n library. (This library is exported from the test harness file that ships with applications created by \naqueduct create\n.)\n\n\nAn example of a test that verifies a 200 status code response looks like this:\n\n\ntest\n(\nGet 200\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasStatus\n(\n200\n));\n\n\n});\n\n\n\n\n\n\nhasStatus\n is an Aqueduct matcher. It verifies that a \nTestResponse\n's status code is 200. It's more likely that you are interested in verifying the body of a response using the \nhasResponse\n matcher. This matcher checks everything about a response.\n\n\ntest\n(\nGet 200 with key value pair\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \n{\n\n      \nkey\n:\n \nvalue\n\n  \n}));\n\n\n});\n\n\n\n\n\n\nThis will validate that not only does the response have a 200 status code, but its body - after decoding - is a \nMap\n that contains \nkey: value\n. A \nTestResponse\n automatically decodes its HTTP body according to the Content-Type response header.\n\n\nMatchers from the official Dart test package can be mixed and matched into \nhasResponse\n:\n\n\ntest\n(\nGet 200 with key value pair\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \n{\n\n      \ncount\n:\n \ngreaterThan\n(\n1\n)\n\n  \n}));\n\n\n});\n\n\n\n\n\n\nThis ensures that the response's body is a map, for which the key \ncount\n has a value greater than 1. We can get even cuter - this test ensures that the body is a list of objects where every one is a map with the same property:\n\n\ntest\n(\nGet 200 with a lot of key value pairs\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \neveryElement\n({\n\n      \ncount\n:\n \ngreaterThan\n(\n1\n)\n\n  \n})));\n\n\n});\n\n\n\n\n\n\nThe body of a \nTestResponse\n can also be accessed via \nbody\n, \nasMap\n, and \nasList\n.\n\n\ntest\n(\nGet 200 with more than five key value pairs\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \neveryElement\n({\n\n      \ncount\n:\n \ngreaterThan\n(\n1\n)\n\n  \n})));\n\n\n  \nexpect\n(\nresponse\n.\nasList\n,\n \nhasLength\n(\ngreaterThan\n(\n5\n)));\n\n\n});\n\n\n\n\n\n\nAnother valuable matcher is \npartial\n. Sometimes it doesn't make sense to validate every single key-value pair in a response. The \npartial\n matcher only checks that the body has the specified keys - extra keys don't create a mismatch.\n\n\ntest\n(\nGet 200 that at least have these keys\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \npartial\n({\n\n    \nkey1\n:\n \nisInteger\n,\n\n    \nkey2\n:\n \nisString\n,\n\n    \nkey3\n:\n \nisTimestamp\n\n  \n})));\n\n\n});\n\n\n\n\n\n\nEven if the response has keys 4, 5 and 6, as long as the values for keys 1, 2 and 3 match, this test will pass.\n\n\nWhen using \npartial\n, you can also ensure that a map doesn't have a key with the \nisNotPresent\n matcher.\n\n\ntest\n(\nGet 200 that at least have these keys\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/endpoint\n).\nget\n();\n\n  \nexpect\n(\nresponse\n,\n \nhasResponse\n(\n200\n,\n \npartial\n({\n\n    \nkey3\n:\n \nisNotPresent\n\n  \n})));\n\n\n});\n\n\n\n\n\n\nThis ensures that \nkey3\n is not in the map. This is different than verifying \nkey3: null\n, which would be true if \nkey3\n's value was actually the null value. See the API reference for more matchers.\n\n\nVerifying Other Information\n\n\nSometimes, the response to a request doesn't have all of the information that needs to be verified. For example, a request that triggers the Aqueduct application to send a request to some other server can't always be verified through the response. The \nMockHTTPServer\n makes it easy to check if the request triggered another request.\n\n\nsetUp\n(()\n \nasync\n \n{\n\n  \n...\n\n  \nmockServer\n \n=\n \nnew\n \nMockHTTPServer\n(\n4000\n);\n\n  \nawait\n \nmockServer\n.\nopen\n();\n\n\n});\n\n\n\ntearDown\n(()\n \nasync\n \n{\n\n  \nawait\n \nmockServer\n.\nclose\n();\n\n\n});\n\n\n\ntest\n(\nSends message to Google\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \napp\n.\nclient\n.\nrequest\n(\n/do_google_stuff\n).\nget\n();\n\n\n  \nvar\n \noutRequest\n \n=\n \nawait\n \nmockServer\n.\nnext\n();\n\n  \nexpect\n(\noutRequest\n.\nmethod\n,\n \nPOST\n);\n\n  \nexpect\n(\noutRequest\n.\npath\n,\n \n/search\n);\n\n\n});\n\n\n\n\n\n\nA \nMockHTTPServer\n always listens on localhost. You can specify the port. In practice, you will configure remote services like these through a configuration file. If in production, this outgoing request should go to \nhttps://google.com\n, the \nconfig.yaml\n file would have that value:\n\n\ngoogle\n:\n\n  \nurl\n:\n \nhttps\n://\ngoogle\n.\ncom\n\n\n\n\n\n\nBut in the \nconfig.yaml.src\n file that drives the tests, this configuration value would point back locally to a port of your choosing:\n\n\ngoogle\n:\n\n  \nurl\n:\n \nhttp\n://\nlocalhost\n\n  \nport\n:\n \n4000\n\n\n\n\n\n\nYou may also want to query the database a test application is working with. You can access any property of the application's \nRequestSink\n - including its \nManagedContext\n - through the \nTestApplication\n.\n\n\ntest\n(\nensure we hashed the password\n,\n \n()\n \nasync\n \n{\n\n  \nvar\n \nresponse\n \n=\n \nawait\n \n(\napp\n.\nclient\n.\nrequest\n(\n/register\n)\n\n    \n..\njson\n \n=\n \n{\nemail\n:\n \na@b.com\n,\n \npassword\n:\n \nfoo\n}).\nget\n();\n\n\n  \nvar\n \npasswordQuery\n \n=\n \nnew\n \nQuery\nUser\n(\napp\n.\nmainIsolateSink\n.\ncontext\n)\n\n    \n..\nwhere\n.\nemail\n \n=\n \nwhereEqualTo\n(\na@b.com\n);\n\n  \nvar\n \nuser\n \n=\n \nawait\n \npasswordQuery\n.\nfetchOne\n();\n\n  \nexpect\n(\nAuthUtility\n.\ngeneratePasswordHash\n(\nfoo\n,\n \nuser\n.\nsalt\n),\n \nuser\n.\npassword\n);\n\n\n});", 
            "title": "Writing Tests and the TestClient"
        }, 
        {
            "location": "/testing/test_client/#verify-requests-with-testclient", 
            "text": "Setting up a  Test Harness  is required for testing Aqueduct applications. Once a test harness is set up, tests are comprised of issuing HTTP requests to the application, verifying responses, and sometimes checking external data sources for desired changes.  HTTP requests are issued through an instance of  TestClient . A  TestApplication  harness has a  client  property of this type. Starting a  TestApplication  configures the  TestClient  so that its requests go to your application. There are three execution methods on  TestClient , the most basic being  request :  test ( Test that this endpoint returns 200 ,   ()   async   { \n   var   response   =   app . client . request ( /endpoint ). get (); \n   expect ( response ,   hasStatus ( 200 ));  });   The  request  method creates a new instance of  TestRequest . A  TestRequest  is an object that represents an HTTP request, and it has execution methods like  get ,  post , etc. as well as properties for setting headers, query parameters and an HTTP body. Here's a configured  TestRequest :  app . client . request ( /endpoint ) \n   .. queryParameters   =   { q :   1 }, \n   .. headers   =   { Header :   value } \n   .. body   =   ... ;   Query parameter values are URL string encoded.  There are conveniences for adding authorization info:  app . client . request ( /endpoint ) \n   .. setBasicAuthorization ( username ,   password );  app . client . request ( /endpoint ) \n   .. bearerAuthorization ( bearerToken );   There are also conveniences for setting the body of the request. The following code both encodes the body argument as JSON and sets the content-type header to  application/json :  app . client . request ( /endpoint ) \n   .. json   =   { key :   value };   A similar property named  formData  exists for  x-www-form-urlencoded  bodies.  The other two variants of  request  are  clientAuthenticatedRequest  and  authenticatedRequest . A  clientAuthenticatedRequest  includes a Basic Authorization header, while an  authenticatedRequest  includes a Bearer Authorization header.  A  TestClient  has default values for both bearer and basic authorization headers. For example, the test harness sets the default credentials for a  clientAuthenticatedRequest  to the testing client ID. When creating a  clientAuthenticatedRequest  and not specifying the client ID and secret, those values are used:  var   request   =   app . client . clientAuthenticatedRequest ( /endpoint );  // request s authorization header is: Basic base64(com.aqueduct.test:kilimanjaro)   The default can be replaced with optional arguments:  var   request   =   app . client . clientAuthenticatedRequest ( \n   /endpoint ,   clientID:   foo ,   clientSecret:   bar );   The same goes for  authenticatedRequest , except that there is no default value to begin with. It often makes sense to create a 'user' during the setup of tests and then set the default bearer token to that user's granted token:  setUp (()   async   { \n   await   app . start (); \n\n   var   registerRequest   =   app . client . clientAuthenticatedRequest ( /register ) \n     .. json   =   { email :   fred@fred.com ,   password :   bob }; \n   var   registerResponse   =   await   registerRequest . post (); \n   app . client . defaultAccessToken   =   registerResponse . asMap [ access_token ];  });  test ( With default bearer token ,   ()   async   { \n   var   response   =   await   app . client . authenticatedRequest ( /endpoint ). get (); \n   ...  });  test ( With another bearer token ,   ()   async   { \n   var   response   =   await   app . client \n     . authenticatedRequest ( /endpoint ,   accessToken:   someOtherToken ). get (); \n   ...  });   It's often useful to move this code into a method in the  TestApplication  itself.", 
            "title": "Verify Requests with TestClient"
        }, 
        {
            "location": "/testing/test_client/#matching-responses", 
            "text": "Tests for an Aqueduct application usually involve sending a request and verifying the response is what you expected. When a  TestRequest  is executed with a method like  get , a  TestResponse  is returned. A  TestResponse  can be cherry-picked for information to validate, but there are also special test matchers in the  aqueduct/test  library. (This library is exported from the test harness file that ships with applications created by  aqueduct create .)  An example of a test that verifies a 200 status code response looks like this:  test ( Get 200 ,   ()   async   { \n   var   response   =   await   app . client . request ( /endpoint ). get (); \n   expect ( response ,   hasStatus ( 200 ));  });   hasStatus  is an Aqueduct matcher. It verifies that a  TestResponse 's status code is 200. It's more likely that you are interested in verifying the body of a response using the  hasResponse  matcher. This matcher checks everything about a response.  test ( Get 200 with key value pair ,   ()   async   { \n   var   response   =   await   app . client . request ( /endpoint ). get (); \n   expect ( response ,   hasResponse ( 200 ,   { \n       key :   value \n   }));  });   This will validate that not only does the response have a 200 status code, but its body - after decoding - is a  Map  that contains  key: value . A  TestResponse  automatically decodes its HTTP body according to the Content-Type response header.  Matchers from the official Dart test package can be mixed and matched into  hasResponse :  test ( Get 200 with key value pair ,   ()   async   { \n   var   response   =   await   app . client . request ( /endpoint ). get (); \n   expect ( response ,   hasResponse ( 200 ,   { \n       count :   greaterThan ( 1 ) \n   }));  });   This ensures that the response's body is a map, for which the key  count  has a value greater than 1. We can get even cuter - this test ensures that the body is a list of objects where every one is a map with the same property:  test ( Get 200 with a lot of key value pairs ,   ()   async   { \n   var   response   =   await   app . client . request ( /endpoint ). get (); \n   expect ( response ,   hasResponse ( 200 ,   everyElement ({ \n       count :   greaterThan ( 1 ) \n   })));  });   The body of a  TestResponse  can also be accessed via  body ,  asMap , and  asList .  test ( Get 200 with more than five key value pairs ,   ()   async   { \n   var   response   =   await   app . client . request ( /endpoint ). get (); \n   expect ( response ,   hasResponse ( 200 ,   everyElement ({ \n       count :   greaterThan ( 1 ) \n   }))); \n\n   expect ( response . asList ,   hasLength ( greaterThan ( 5 )));  });   Another valuable matcher is  partial . Sometimes it doesn't make sense to validate every single key-value pair in a response. The  partial  matcher only checks that the body has the specified keys - extra keys don't create a mismatch.  test ( Get 200 that at least have these keys ,   ()   async   { \n   var   response   =   await   app . client . request ( /endpoint ). get (); \n   expect ( response ,   hasResponse ( 200 ,   partial ({ \n     key1 :   isInteger , \n     key2 :   isString , \n     key3 :   isTimestamp \n   })));  });   Even if the response has keys 4, 5 and 6, as long as the values for keys 1, 2 and 3 match, this test will pass.  When using  partial , you can also ensure that a map doesn't have a key with the  isNotPresent  matcher.  test ( Get 200 that at least have these keys ,   ()   async   { \n   var   response   =   await   app . client . request ( /endpoint ). get (); \n   expect ( response ,   hasResponse ( 200 ,   partial ({ \n     key3 :   isNotPresent \n   })));  });   This ensures that  key3  is not in the map. This is different than verifying  key3: null , which would be true if  key3 's value was actually the null value. See the API reference for more matchers.", 
            "title": "Matching Responses"
        }, 
        {
            "location": "/testing/test_client/#verifying-other-information", 
            "text": "Sometimes, the response to a request doesn't have all of the information that needs to be verified. For example, a request that triggers the Aqueduct application to send a request to some other server can't always be verified through the response. The  MockHTTPServer  makes it easy to check if the request triggered another request.  setUp (()   async   { \n   ... \n   mockServer   =   new   MockHTTPServer ( 4000 ); \n   await   mockServer . open ();  });  tearDown (()   async   { \n   await   mockServer . close ();  });  test ( Sends message to Google ,   ()   async   { \n   var   response   =   await   app . client . request ( /do_google_stuff ). get (); \n\n   var   outRequest   =   await   mockServer . next (); \n   expect ( outRequest . method ,   POST ); \n   expect ( outRequest . path ,   /search );  });   A  MockHTTPServer  always listens on localhost. You can specify the port. In practice, you will configure remote services like these through a configuration file. If in production, this outgoing request should go to  https://google.com , the  config.yaml  file would have that value:  google : \n   url :   https :// google . com   But in the  config.yaml.src  file that drives the tests, this configuration value would point back locally to a port of your choosing:  google : \n   url :   http :// localhost \n   port :   4000   You may also want to query the database a test application is working with. You can access any property of the application's  RequestSink  - including its  ManagedContext  - through the  TestApplication .  test ( ensure we hashed the password ,   ()   async   { \n   var   response   =   await   ( app . client . request ( /register ) \n     .. json   =   { email :   a@b.com ,   password :   foo }). get (); \n\n   var   passwordQuery   =   new   Query User ( app . mainIsolateSink . context ) \n     .. where . email   =   whereEqualTo ( a@b.com ); \n   var   user   =   await   passwordQuery . fetchOne (); \n   expect ( AuthUtility . generatePasswordHash ( foo ,   user . salt ),   user . password );  });", 
            "title": "Verifying Other Information"
        }, 
        {
            "location": "/deploy/overview/", 
            "text": "Tasks\n\n\nAqueduct has a built in tool, \naqueduct\n, for deploying Aqueduct applications, managing database schemas, OAuth 2.0 clients and creating projects. See \nGetting Started\n for installation instructions. Many of the tasks for deployment rely on using this tool.\n\n\nAqueduct applications can be run anywhere that Dart can be installed. This topic covers deployment tasks on common hosting services. If you are just getting started or a hobbyist, you should consider using \nHeroku\n to host your applications.\n\n\nGuides\n\n\n\n\nRunning an Aqueduct Application Locally\n\n\nRunning an Aqueduct Application on Heroku\n\n\nRunning an Aqueduct Application on Amazon Web Services (AWS)\n\n\nRunning an Aqueduct Application without aqueduct serve", 
            "title": "Overview"
        }, 
        {
            "location": "/deploy/overview/#tasks", 
            "text": "Aqueduct has a built in tool,  aqueduct , for deploying Aqueduct applications, managing database schemas, OAuth 2.0 clients and creating projects. See  Getting Started  for installation instructions. Many of the tasks for deployment rely on using this tool.  Aqueduct applications can be run anywhere that Dart can be installed. This topic covers deployment tasks on common hosting services. If you are just getting started or a hobbyist, you should consider using  Heroku  to host your applications.", 
            "title": "Tasks"
        }, 
        {
            "location": "/deploy/overview/#guides", 
            "text": "Running an Aqueduct Application Locally  Running an Aqueduct Application on Heroku  Running an Aqueduct Application on Amazon Web Services (AWS)  Running an Aqueduct Application without aqueduct serve", 
            "title": "Guides"
        }, 
        {
            "location": "/deploy/deploy_local/", 
            "text": "Deploying an Aqueduct Application on a Local Machine\n\n\nFor other deployment options, see \nDeploying Aqueduct Applications\n.\n\n\nPurpose\n\n\nTo run a local development version of an Aqueduct application with persistent storage. This is useful in developing client applications against an Aqueduct application. Make sure to also read \nTesting Aqueduct Applications\n.\n\n\nPrerequisites\n\n\n\n\nDart has been installed.\n\n\nPostgreSQL has been installed locally.\n\n\nAqueduct has been activated globally.\n\n\nAn application has been created with \naqueduct create\n.\n\n\n\n\nIf one or more of these is not true, see \nGetting Started\n.\n\n\nOverview\n\n\n\n\nCreate a local database.\n\n\nUpload the application schema to the local database.\n\n\nAdd an OAuth 2.0 client.\n\n\nModify the configuration file.\n\n\nRun the application.\n\n\n\n\nEstimated Time: \n5 minutes.\n\n\nStep 1: Create a Local Database\n\n\nCreate a database with the same name as your application and a user that can access that database. Do not use the name 'dart_test' for the database; this database is used by Aqueduct to run tests by default.\n\n\nRun the following SQL locally with a user that has privileges to create databases. (If using \nPostgres.app\n, open the \npsql\n terminal from the \nPostgres.app\n status menu item \nOpen psql\n).\n\n\nCREATE\n \nDATABASE\n \napp_name\n;\n\n\nCREATE\n \nUSER\n \napp_name_user\n \nWITH\n \nCREATEDB\n;\n\n\nALTER\n \nUSER\n \napp_name_user\n \nWITH\n \nPASSWORD\n \nyourpassword\n;\n\n\nGRANT\n \nALL\n \nON\n \nDATABASE\n \napp_name\n \nTO\n \napp_name_user\n;\n\n\n\n\n\n\nStep 2: Upload the Application Schema\n\n\nRun the database schema generation tool from the project directory:\n\n\naqueduct db generate\n\n\n\n\n\nThis command creates the file \nmigrations/00000001_Initial.migration.dart\n. Now, run the database migration tool to execute the migration file against the local database. Ensure that the values for the option \n--connect\n match those of the database created in the last step.\n\n\naqueduct db upgrade --connect postgres://app_name_user:yourpassword@localhost:5432/app_name\n\n\n\n\n\n(Note that you may provide database credentials in a file named \ndatabase.yaml\n instead of using \n--connect\n. See \naqueduct db --help\n for details.)\n\n\nStep 3: Add an OAuth 2.0 client.\n\n\nFrom the command line, run the following, ensuring that the values for the option \n--connect\n match the recently created database.\n\n\naqueduct auth add-client --id com.app_name.standard --secret abcdefghi --connect postgres://app_name_user:yourpassword@localhost:5432/app_name\n\n\n\n\n\nStep 4: Modify the Configuration File\n\n\nIf \nconfig.yaml\n doesn't exist, create it by copying the configuration file template \nconfig.yaml.src\n.\n\n\nIn \nconfig.yaml\n, update the database credentials to the local database.\n\n\ndatabase\n:\n\n \nusername\n:\n \napp_name_user\n\n \npassword\n:\n \nyourpassword\n\n \nhost\n:\n \nlocalhost\n\n \nport\n:\n \n5432\n\n \ndatabaseName\n:\n \napp_name\n\n\n\n\n\n\nStep 5: Run the Application\n\n\nFrom the project directory, run:\n\n\naqueduct serve\n\n\n\n\n\nYour application is now running.\n\n\nNote: You can add the \n--observe\n flag to \naqueduct serve\n to run Observatory. Observatory will automatically open in a browser if the platform supports it.", 
            "title": "Deploy Locally"
        }, 
        {
            "location": "/deploy/deploy_local/#deploying-an-aqueduct-application-on-a-local-machine", 
            "text": "For other deployment options, see  Deploying Aqueduct Applications .", 
            "title": "Deploying an Aqueduct Application on a Local Machine"
        }, 
        {
            "location": "/deploy/deploy_local/#purpose", 
            "text": "To run a local development version of an Aqueduct application with persistent storage. This is useful in developing client applications against an Aqueduct application. Make sure to also read  Testing Aqueduct Applications .", 
            "title": "Purpose"
        }, 
        {
            "location": "/deploy/deploy_local/#prerequisites", 
            "text": "Dart has been installed.  PostgreSQL has been installed locally.  Aqueduct has been activated globally.  An application has been created with  aqueduct create .   If one or more of these is not true, see  Getting Started .", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/deploy/deploy_local/#overview", 
            "text": "Create a local database.  Upload the application schema to the local database.  Add an OAuth 2.0 client.  Modify the configuration file.  Run the application.   Estimated Time:  5 minutes.", 
            "title": "Overview"
        }, 
        {
            "location": "/deploy/deploy_local/#step-1-create-a-local-database", 
            "text": "Create a database with the same name as your application and a user that can access that database. Do not use the name 'dart_test' for the database; this database is used by Aqueduct to run tests by default.  Run the following SQL locally with a user that has privileges to create databases. (If using  Postgres.app , open the  psql  terminal from the  Postgres.app  status menu item  Open psql ).  CREATE   DATABASE   app_name ;  CREATE   USER   app_name_user   WITH   CREATEDB ;  ALTER   USER   app_name_user   WITH   PASSWORD   yourpassword ;  GRANT   ALL   ON   DATABASE   app_name   TO   app_name_user ;", 
            "title": "Step 1: Create a Local Database"
        }, 
        {
            "location": "/deploy/deploy_local/#step-2-upload-the-application-schema", 
            "text": "Run the database schema generation tool from the project directory:  aqueduct db generate  This command creates the file  migrations/00000001_Initial.migration.dart . Now, run the database migration tool to execute the migration file against the local database. Ensure that the values for the option  --connect  match those of the database created in the last step.  aqueduct db upgrade --connect postgres://app_name_user:yourpassword@localhost:5432/app_name  (Note that you may provide database credentials in a file named  database.yaml  instead of using  --connect . See  aqueduct db --help  for details.)", 
            "title": "Step 2: Upload the Application Schema"
        }, 
        {
            "location": "/deploy/deploy_local/#step-3-add-an-oauth-20-client", 
            "text": "From the command line, run the following, ensuring that the values for the option  --connect  match the recently created database.  aqueduct auth add-client --id com.app_name.standard --secret abcdefghi --connect postgres://app_name_user:yourpassword@localhost:5432/app_name", 
            "title": "Step 3: Add an OAuth 2.0 client."
        }, 
        {
            "location": "/deploy/deploy_local/#step-4-modify-the-configuration-file", 
            "text": "If  config.yaml  doesn't exist, create it by copying the configuration file template  config.yaml.src .  In  config.yaml , update the database credentials to the local database.  database : \n  username :   app_name_user \n  password :   yourpassword \n  host :   localhost \n  port :   5432 \n  databaseName :   app_name", 
            "title": "Step 4: Modify the Configuration File"
        }, 
        {
            "location": "/deploy/deploy_local/#step-5-run-the-application", 
            "text": "From the project directory, run:  aqueduct serve  Your application is now running.  Note: You can add the  --observe  flag to  aqueduct serve  to run Observatory. Observatory will automatically open in a browser if the platform supports it.", 
            "title": "Step 5: Run the Application"
        }, 
        {
            "location": "/deploy/deploy_heroku/", 
            "text": "Deploying an Aqueduct Application on Heroku\n\n\nFor other deployment options, see \nDeploying Aqueduct Applications\n.\n\n\nPurpose\n\n\nTo run a production Aqueduct application on Heroku. Make sure to also read \nTesting Aqueduct Applications\n.\n\n\nPrerequisites\n\n\n\n\nDart has been installed.\n\n\nA Heroku account.\n\n\ngit\n has been installed.\n\n\nheroku\n has been installed.\n\n\nAqueduct has been activated.\n\n\n\n\nOverview\n\n\n\n\nSetting up a Heroku application\n\n\nSetting up an Aqueduct application to run on Heroku\n\n\nConfiguring application values\n\n\nRunning the Aqueduct application\n\n\n\n\nEstimated Time: \n5 minutes.\n\n\nStep 1: Setting up a Heroku Application\n\n\nCreate a new application in Heroku. Add the 'Heroku Postgres' add-on.\n\n\nNavigate to the Settings tab in the Heroku web interface and click 'Reveal Config Vars'. Note the DATABASE_URL, it'll get used later.\n\n\nStep 2: Setting up an Aqueduct Application to Run on Heroku\n\n\nIf you have not yet, create a new Aqueduct application on your local machine, go into that directory, and initialize it as a git repository:\n\n\naqueduct create app_name\n\ncd\n app_name\ngit init\n\n\n\n\n\nLogin to Heroku and run the Aqueduct tool to configure a project for Heroku. The value for \n--heroku\n \nmust\n be the name of the Heroku application (not the Aqueduct application, unless they are the same, obvi).\n\n\nheroku login\naqueduct setup --heroku\n=\napp_name\n\n\n\n\n\nThis command will create the files Heroku needs to run the application, remove \nconfig.yaml\n from \n.gitignore\n (you'll see why in a moment) and runs some \nheroku\n commands to set up the Heroku application's environment.\n\n\nStep 3: Configuring Application Values\n\n\nHeroku provides configuration values through environment variables, where Aqueduct normally provides them in \nconfig.yaml\n file. Because Aqueduct uses \nsafe_config\n, configuration files can map keys to environment variables with a simple syntax. The \nconfig.yaml\n file's values get replaced with their environment variable names and it gets checked into source control. To map configuration values to an environment variable, the value for a configuration key is prefixed with a dollar sign (\n$\n) followed by the case-sensitive name of the environment variable.\n\n\nModify \nconfig.yaml\n to appear as follows:\n\n\ndatabase: $DATABASE_URL\nlogging:\n type: console\n\n\n\n\n\nRecall that \naqueduct setup\n with the \n--heroku\n option removes \nconfig.yaml\n from \n.gitignore\n.\n\n\nStep 4: Running the Aqueduct Application\n\n\nFirst, create a database migration. The \nProcfile\n declared that Heroku will automatically run any migration files prior to running the application as long as they are checked into source control.\n\n\naqueduct db generate\n\n\n\n\n\nNow, add all of the files to \ngit\n and push it to heroku:\n\n\ngit add .\ngit commit -m \ninitial commit\n\ngit push heroku master\n\n\n\n\n\nNext, set up an OAuth 2.0 client id:\n\n\nheroku run /app/dart-sdk/bin/pub global run aqueduct:aqueduct auth add-client --id com.app.standard --secret secret --connect \n\\$\nDATABASE_URL\n\n\n\n\n\nFinally, spin up a dyno and the application will start receiving requests:\n\n\nheroku ps:scale \nweb\n=\n1", 
            "title": "Deploy on Heroku"
        }, 
        {
            "location": "/deploy/deploy_heroku/#deploying-an-aqueduct-application-on-heroku", 
            "text": "For other deployment options, see  Deploying Aqueduct Applications .", 
            "title": "Deploying an Aqueduct Application on Heroku"
        }, 
        {
            "location": "/deploy/deploy_heroku/#purpose", 
            "text": "To run a production Aqueduct application on Heroku. Make sure to also read  Testing Aqueduct Applications .", 
            "title": "Purpose"
        }, 
        {
            "location": "/deploy/deploy_heroku/#prerequisites", 
            "text": "Dart has been installed.  A Heroku account.  git  has been installed.  heroku  has been installed.  Aqueduct has been activated.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/deploy/deploy_heroku/#overview", 
            "text": "Setting up a Heroku application  Setting up an Aqueduct application to run on Heroku  Configuring application values  Running the Aqueduct application   Estimated Time:  5 minutes.", 
            "title": "Overview"
        }, 
        {
            "location": "/deploy/deploy_heroku/#step-1-setting-up-a-heroku-application", 
            "text": "Create a new application in Heroku. Add the 'Heroku Postgres' add-on.  Navigate to the Settings tab in the Heroku web interface and click 'Reveal Config Vars'. Note the DATABASE_URL, it'll get used later.", 
            "title": "Step 1: Setting up a Heroku Application"
        }, 
        {
            "location": "/deploy/deploy_heroku/#step-2-setting-up-an-aqueduct-application-to-run-on-heroku", 
            "text": "If you have not yet, create a new Aqueduct application on your local machine, go into that directory, and initialize it as a git repository:  aqueduct create app_name cd  app_name\ngit init  Login to Heroku and run the Aqueduct tool to configure a project for Heroku. The value for  --heroku   must  be the name of the Heroku application (not the Aqueduct application, unless they are the same, obvi).  heroku login\naqueduct setup --heroku = app_name  This command will create the files Heroku needs to run the application, remove  config.yaml  from  .gitignore  (you'll see why in a moment) and runs some  heroku  commands to set up the Heroku application's environment.", 
            "title": "Step 2: Setting up an Aqueduct Application to Run on Heroku"
        }, 
        {
            "location": "/deploy/deploy_heroku/#step-3-configuring-application-values", 
            "text": "Heroku provides configuration values through environment variables, where Aqueduct normally provides them in  config.yaml  file. Because Aqueduct uses  safe_config , configuration files can map keys to environment variables with a simple syntax. The  config.yaml  file's values get replaced with their environment variable names and it gets checked into source control. To map configuration values to an environment variable, the value for a configuration key is prefixed with a dollar sign ( $ ) followed by the case-sensitive name of the environment variable.  Modify  config.yaml  to appear as follows:  database: $DATABASE_URL\nlogging:\n type: console  Recall that  aqueduct setup  with the  --heroku  option removes  config.yaml  from  .gitignore .", 
            "title": "Step 3: Configuring Application Values"
        }, 
        {
            "location": "/deploy/deploy_heroku/#step-4-running-the-aqueduct-application", 
            "text": "First, create a database migration. The  Procfile  declared that Heroku will automatically run any migration files prior to running the application as long as they are checked into source control.  aqueduct db generate  Now, add all of the files to  git  and push it to heroku:  git add .\ngit commit -m  initial commit \ngit push heroku master  Next, set up an OAuth 2.0 client id:  heroku run /app/dart-sdk/bin/pub global run aqueduct:aqueduct auth add-client --id com.app.standard --secret secret --connect  \\$ DATABASE_URL  Finally, spin up a dyno and the application will start receiving requests:  heroku ps:scale  web = 1", 
            "title": "Step 4: Running the Aqueduct Application"
        }, 
        {
            "location": "/deploy/deploy_aws/", 
            "text": "Deploying an Aqueduct Application on Amazon Web Services (AWS)\n\n\nFor other deployment options, see \nDeploying Aqueduct Applications\n.\n\n\nPurpose\n\n\nTo run a production Aqueduct application on Amazon Web Services. Make sure to also read \nTesting Aqueduct Applications\n.\n\n\nPrerequisites\n\n\n\n\nDart has been installed on your local machine.\n\n\nAn AWS Account\n\n\nA GitHub Account*\n\n\ngit\n has been installed\n on your local machine.\n\n\nAqueduct has been activated on your local machine.\n\n\n\n\n* GitHub will be used for transferring code to the remote machine. You could use \nftp\n, \nscp\n, \nrsync\n, another Git provider, another VCS system, AWS's CodeDeploy, etc.\n\n\nEstimated Time: \n15 minutes.\n\n\nOverview\n\n\n\n\nSetting up the Aqueduct application and GitHub\n\n\nSetting up an EC2 Instance\n\n\nSetting up a Database\n\n\nConfiguring application values\n\n\nRunning the Aqueduct application\n\n\n\n\nStep 1: Setting up the Aqueduct Application\n\n\nSet up a new GitHub repository with the name of your application. The purpose of GitHub here is to transfer the application code to the AWS instance. There are other ways of accomplishing this, so as long as you can get the source code to the machine, you're in good shape.\n\n\nIf you have not yet, create a new Aqueduct application on your local machine, go into that directory, and initialize it as a git repository:\n\n\naqueduct create app_name\n\ncd\n app_name\ngit init\n\n\n\n\n\nThen, setup your local git repository with your remote git repository for the application by executing one of the following commands in the project's directory:\n\n\n# If your machine is set up to use git over SSH ...\n\ngit remote add origin git@github.com:organization/app_name.git\n\n\n# If your machine is set up to use git over HTTPS\n\ngit remote add origin https://github.com/organization/app_name.git\n\n\n# If you are unsure or haven\nt set up GitHub before,\n\n\n# see https://help.github.com/articles/set-up-git/\n\n\n\n\n\n\nThen, grab the repository contents:\n\n\ngit pull\n\n\n\n\n\nKeep the GitHub web interface open, as you'll have to come back to it one more time.\n\n\nStep 2: Setting up an EC2 Instance\n\n\nIn the AWS EC2 control panel, create a new Ubuntu instance. Make sure your VPC has DNS resolution (the default VPC configuration does). Choose or create a security group that allows both HTTP and SSH access for this instance. The rest of the default configuration values are fine.\n\n\nLaunch that instance. When prompted, make sure you either create a new key pair or have access to an existing key pair.\n\n\nAfter creating the EC2 instance, select it in the AWS console and click 'Connect' for instructions on how to SSH into the instance.  \n\n\nIt's useful to add the \nssh\n command that connects to this instance as an alias in your shell and the key file into more permanent storage. The command is something like \nssh -i key.pem ubuntu@host\n. Move the key file \nkey.pem\n into \n~/.ssh\n (it may be named differently):\n\n\ncp key.pem ~/.ssh/key.pem\n\n\n\n\n\nThen add the following line to the file \n~/.bash_profile\n and then reload your profle:\n\n\nalias app_name=\nssh -i ~/.ssh/key.pem ubuntu@host\n\nsource ~/.bash_profile\n\n\n\n\n\nNext, SSH into the EC2 instance by executing the alias locally:\n\n\napp_name\n\n\n\n\n\nOnce the shell for the instance is opened, install Dart (these instructions are located at https://www.dartlang.org/install/linux):\n\n\nsudo apt-get update\nsudo apt-get install apt-transport-https\nsudo sh -c \ncurl https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add -\n\nsudo sh -c \ncurl https://storage.googleapis.com/download.dartlang.org/linux/debian/dart_stable.list \n /etc/apt/sources.list.d/dart_stable.list\n\nsudo apt-get update\nsudo apt-get install dart\n\n\n\n\n\nWhen these steps are completed correctly, the following command will yield \n/usr/bin/dart\n:\n\n\nwhich dart\n\n\n\n\n\nAdd the Dart executable directories to your path by adding the following line to the end of the file \n~/.profile\n:\n\n\nexport PATH=$PATH:\n/usr/lib/dart/bin\n:\n~/.pub-cache/bin\n\n\n\n\n\n\nThen reload the profile:\n\n\nsource\n ~/.profile\n\n\n\n\n\nNow, we'll give this instance permission to clone the application repository from GitHub. In the instance's shell, install \ngit\n and create a new SSH key:\n\n\nsudo apt-get install git\nssh-keygen -t rsa -b \n4096\n -C \nyouremail\n\n\n\n\n\n\nThis command will prompt you three times (for a file name, password and password confirm). Simply hit the Enter key each time.\nThen, add the following to the file \n/etc/ssh/ssh_config\n (requires \nsudo\n):\n\n\nHost github.com\n    Hostname github.com\n    IdentityFile ~/.ssh/id_rsa\n    User git\n\n\n\n\n\nPrint out the contents of the public key and copy them:\n\n\ncat ~/.ssh/id_rsa.pub\n\n\n\n\n\nThe contents will start with the phrase \nssh-rsa\n and end with your email, and you must copy all of it.\n\n\nIn the GitHub repository web interface, select the \nSettings\n tab then select \nDeploy keys\n. Click \nAdd deploy key\n. Enter \"AWS\" for the title and paste the contents of the public key into the \nKey\n area. Then click \nAdd key\n.\n\n\nTo ensure this all works, clone the repository onto the AWS instance:\n\n\ngit clone git@github.com:organization/app_name.git\n\n\n\n\n\nAt this point, the repository should mostly be empty, but as long as it clones correctly you're in good shape.\n\n\nStep 3: Setting up a Database\n\n\nIn the AWS control panel, select the RDS service. Choose the \nInstances\n item from the left hand panel and select \nLaunch DB Instance\n. Choose PostgreSQL and configure the database details. Make sure to store the username and password as you'll need them shortly.\n\n\nIn the \nConfigure Advanced Settings\n, make sure the database is Publicly Accessible. Set \nDatabase Name\n to the name of your application, this will make it easy to remember.\n\n\nAdd a new Inbound entry to the security group for the database. The type must be \nPostgreSQL\n (which automatically configures the protocol to \nTCP\n and the port range to \n5432\n). Choose a custom Source and enter the name of the security group that the EC2 instance is in. (You can start by typing \"sg-\", and it give you a drop-down list so that you can select the appropriate one.)\n\n\nThen, launch the database.\n\n\nOnce the database has finished launching, we must upload the application's schema. From the project directory on your local machine, run the following:\n\n\naqueduct db generate\n\n\n\n\n\nNext, run the newly generated migration file on the database, substituting the values in the \n--connect\n option with values from the recently configured database:\n\n\naqueduct db upgrade --connect postgres://username:password@host:5432/app_name\n\n\n\n\n\nStep 4: Configuring the Application\n\n\nConfiguring an Aqueduct application on AWS means having a configuration file that lives on the instance, but is not checked into source control. There are tools for managing configurations across instances, but those are up to you.\n\n\nIn the project directory on your local machine, add all of the project files to the git repository:\n\n\ngit add .\ngit commit -am \nInitial commit\n\ngit push -u origin master\n\n\n\n\n\nOn the EC2 instance, grab these files from the repository (this assumes you ran \ngit clone\n earlier).\n\n\ncd\n app_name\ngit pull\n\n\n\n\n\nCreate a new configuration file just for this instance by cloning the configuration template file that is checked into the repository:\n\n\ncp config.yaml.src config.yaml\n\n\n\n\n\nModify \nconfig.yaml\n by replacing the database credentials with the credentials of the RDS database and change \nlogging:type\n to \nfile\n:\n\n\ndatabase\n:\n\n \nusername\n:\n \nusername\n\n \npassword\n:\n \npassword\n\n \nhost\n:\n \nhost\n\n \nport\n:\n \n5432\n\n \ndatabaseName\n:\n \napp_name\n\n\nlogging\n:\n\n \ntype\n:\n \nfile\n\n \nfilename\n:\n \napi\n.\nlog\n\n\n\n\n\n\nStep 5: Running the Application\n\n\nThen, activate the Aqueduct package:\n\n\npub global activate aqueduct\n\n\n\n\n\nFetch the application's dependencies:\n\n\npub get\n\n\n\n\n\nNow, run the application in \n--detached\n mode:\n\n\naqueduct serve --detached\n\n\n\n\n\nBy default, an Aqueduct application will listen on port 8081. HTTP requests will come in on port 80. You can't bind to port 80 without using sudo. Instead, reroute HTTP requests on port 80 to port 8081 by entering the following on the EC2 instance:\n\n\nsudo iptables -t nat -A PREROUTING -p tcp --dport \n80\n -j REDIRECT --to \n8081\n\nsudo iptables-save\n\n\n\n\n\nThen - either locally or remotely - add a new OAuth 2.0 client:\n\n\n  aqueduct auth add-client --id com.app.standard --secret secret --connect postgres://user:password@deploy-aws.hexthing.us-east-1.rds.amazonaws.com:5432/deploy_aws\n\n\n\n\n\nYour Aqueduct application is now up and running.", 
            "title": "Deploy on AWS"
        }, 
        {
            "location": "/deploy/deploy_aws/#deploying-an-aqueduct-application-on-amazon-web-services-aws", 
            "text": "For other deployment options, see  Deploying Aqueduct Applications .", 
            "title": "Deploying an Aqueduct Application on Amazon Web Services (AWS)"
        }, 
        {
            "location": "/deploy/deploy_aws/#purpose", 
            "text": "To run a production Aqueduct application on Amazon Web Services. Make sure to also read  Testing Aqueduct Applications .", 
            "title": "Purpose"
        }, 
        {
            "location": "/deploy/deploy_aws/#prerequisites", 
            "text": "Dart has been installed on your local machine.  An AWS Account  A GitHub Account*  git  has been installed  on your local machine.  Aqueduct has been activated on your local machine.   * GitHub will be used for transferring code to the remote machine. You could use  ftp ,  scp ,  rsync , another Git provider, another VCS system, AWS's CodeDeploy, etc.  Estimated Time:  15 minutes.", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/deploy/deploy_aws/#overview", 
            "text": "Setting up the Aqueduct application and GitHub  Setting up an EC2 Instance  Setting up a Database  Configuring application values  Running the Aqueduct application", 
            "title": "Overview"
        }, 
        {
            "location": "/deploy/deploy_aws/#step-1-setting-up-the-aqueduct-application", 
            "text": "Set up a new GitHub repository with the name of your application. The purpose of GitHub here is to transfer the application code to the AWS instance. There are other ways of accomplishing this, so as long as you can get the source code to the machine, you're in good shape.  If you have not yet, create a new Aqueduct application on your local machine, go into that directory, and initialize it as a git repository:  aqueduct create app_name cd  app_name\ngit init  Then, setup your local git repository with your remote git repository for the application by executing one of the following commands in the project's directory:  # If your machine is set up to use git over SSH ... \ngit remote add origin git@github.com:organization/app_name.git # If your machine is set up to use git over HTTPS \ngit remote add origin https://github.com/organization/app_name.git # If you are unsure or haven t set up GitHub before,  # see https://help.github.com/articles/set-up-git/   Then, grab the repository contents:  git pull  Keep the GitHub web interface open, as you'll have to come back to it one more time.", 
            "title": "Step 1: Setting up the Aqueduct Application"
        }, 
        {
            "location": "/deploy/deploy_aws/#step-2-setting-up-an-ec2-instance", 
            "text": "In the AWS EC2 control panel, create a new Ubuntu instance. Make sure your VPC has DNS resolution (the default VPC configuration does). Choose or create a security group that allows both HTTP and SSH access for this instance. The rest of the default configuration values are fine.  Launch that instance. When prompted, make sure you either create a new key pair or have access to an existing key pair.  After creating the EC2 instance, select it in the AWS console and click 'Connect' for instructions on how to SSH into the instance.    It's useful to add the  ssh  command that connects to this instance as an alias in your shell and the key file into more permanent storage. The command is something like  ssh -i key.pem ubuntu@host . Move the key file  key.pem  into  ~/.ssh  (it may be named differently):  cp key.pem ~/.ssh/key.pem  Then add the following line to the file  ~/.bash_profile  and then reload your profle:  alias app_name= ssh -i ~/.ssh/key.pem ubuntu@host \nsource ~/.bash_profile  Next, SSH into the EC2 instance by executing the alias locally:  app_name  Once the shell for the instance is opened, install Dart (these instructions are located at https://www.dartlang.org/install/linux):  sudo apt-get update\nsudo apt-get install apt-transport-https\nsudo sh -c  curl https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add - \nsudo sh -c  curl https://storage.googleapis.com/download.dartlang.org/linux/debian/dart_stable.list   /etc/apt/sources.list.d/dart_stable.list \nsudo apt-get update\nsudo apt-get install dart  When these steps are completed correctly, the following command will yield  /usr/bin/dart :  which dart  Add the Dart executable directories to your path by adding the following line to the end of the file  ~/.profile :  export PATH=$PATH: /usr/lib/dart/bin : ~/.pub-cache/bin   Then reload the profile:  source  ~/.profile  Now, we'll give this instance permission to clone the application repository from GitHub. In the instance's shell, install  git  and create a new SSH key:  sudo apt-get install git\nssh-keygen -t rsa -b  4096  -C  youremail   This command will prompt you three times (for a file name, password and password confirm). Simply hit the Enter key each time.\nThen, add the following to the file  /etc/ssh/ssh_config  (requires  sudo ):  Host github.com\n    Hostname github.com\n    IdentityFile ~/.ssh/id_rsa\n    User git  Print out the contents of the public key and copy them:  cat ~/.ssh/id_rsa.pub  The contents will start with the phrase  ssh-rsa  and end with your email, and you must copy all of it.  In the GitHub repository web interface, select the  Settings  tab then select  Deploy keys . Click  Add deploy key . Enter \"AWS\" for the title and paste the contents of the public key into the  Key  area. Then click  Add key .  To ensure this all works, clone the repository onto the AWS instance:  git clone git@github.com:organization/app_name.git  At this point, the repository should mostly be empty, but as long as it clones correctly you're in good shape.", 
            "title": "Step 2: Setting up an EC2 Instance"
        }, 
        {
            "location": "/deploy/deploy_aws/#step-3-setting-up-a-database", 
            "text": "In the AWS control panel, select the RDS service. Choose the  Instances  item from the left hand panel and select  Launch DB Instance . Choose PostgreSQL and configure the database details. Make sure to store the username and password as you'll need them shortly.  In the  Configure Advanced Settings , make sure the database is Publicly Accessible. Set  Database Name  to the name of your application, this will make it easy to remember.  Add a new Inbound entry to the security group for the database. The type must be  PostgreSQL  (which automatically configures the protocol to  TCP  and the port range to  5432 ). Choose a custom Source and enter the name of the security group that the EC2 instance is in. (You can start by typing \"sg-\", and it give you a drop-down list so that you can select the appropriate one.)  Then, launch the database.  Once the database has finished launching, we must upload the application's schema. From the project directory on your local machine, run the following:  aqueduct db generate  Next, run the newly generated migration file on the database, substituting the values in the  --connect  option with values from the recently configured database:  aqueduct db upgrade --connect postgres://username:password@host:5432/app_name", 
            "title": "Step 3: Setting up a Database"
        }, 
        {
            "location": "/deploy/deploy_aws/#step-4-configuring-the-application", 
            "text": "Configuring an Aqueduct application on AWS means having a configuration file that lives on the instance, but is not checked into source control. There are tools for managing configurations across instances, but those are up to you.  In the project directory on your local machine, add all of the project files to the git repository:  git add .\ngit commit -am  Initial commit \ngit push -u origin master  On the EC2 instance, grab these files from the repository (this assumes you ran  git clone  earlier).  cd  app_name\ngit pull  Create a new configuration file just for this instance by cloning the configuration template file that is checked into the repository:  cp config.yaml.src config.yaml  Modify  config.yaml  by replacing the database credentials with the credentials of the RDS database and change  logging:type  to  file :  database : \n  username :   username \n  password :   password \n  host :   host \n  port :   5432 \n  databaseName :   app_name  logging : \n  type :   file \n  filename :   api . log", 
            "title": "Step 4: Configuring the Application"
        }, 
        {
            "location": "/deploy/deploy_aws/#step-5-running-the-application", 
            "text": "Then, activate the Aqueduct package:  pub global activate aqueduct  Fetch the application's dependencies:  pub get  Now, run the application in  --detached  mode:  aqueduct serve --detached  By default, an Aqueduct application will listen on port 8081. HTTP requests will come in on port 80. You can't bind to port 80 without using sudo. Instead, reroute HTTP requests on port 80 to port 8081 by entering the following on the EC2 instance:  sudo iptables -t nat -A PREROUTING -p tcp --dport  80  -j REDIRECT --to  8081 \nsudo iptables-save  Then - either locally or remotely - add a new OAuth 2.0 client:    aqueduct auth add-client --id com.app.standard --secret secret --connect postgres://user:password@deploy-aws.hexthing.us-east-1.rds.amazonaws.com:5432/deploy_aws  Your Aqueduct application is now up and running.", 
            "title": "Step 5: Running the Application"
        }, 
        {
            "location": "/deploy/script/", 
            "text": "You may also run Aqueduct applications with a standalone script, instead of \naqueduct serve\n. In fact, \naqueduct serve\n creates a temporary Dart script to run the application. That script looks something like this:\n\n\nimport\n \ndart:async\n;\n\n\nimport\n \ndart:io\n;\n\n\n\nimport\n \npackage:aqueduct/aqueduct.dart\n;\n\n\nimport\n \npackage:my_application/my_application.dart\n;\n\n\n\nmain\n()\n \nasync\n \n{\n\n  \ntry\n \n{\n\n    \nvar\n \napp\n \n=\n \nnew\n \nApplication\nMyRequestSink\n();\n\n    \nvar\n \nconfig\n \n=\n \nnew\n \nApplicationConfiguration\n()\n\n      \n..\nport\n \n=\n \n8081\n\n      \n..\nconfigurationFilePath\n \n=\n \nconfig.yaml\n;\n\n\n    \napp\n.\nconfiguration\n \n=\n \nconfig\n;\n\n\n    \nawait\n \napp\n.\nstart\n(\nnumberOfInstances:\n \n3\n);\n    \n  \n}\n \ncatch\n \n(\ne\n,\n \nst\n)\n \n{\n\n    \nawait\n \nwriteError\n(\n$\ne\n\\n\n \n$\nst\n);\n\n  \n}\n\n\n}\n\n\n\nFuture\n \nwriteError\n(\nString\n \nerror\n)\n \nasync\n \n{\n\n  \nprint\n(\n$\nerror\n);\n\n\n}\n\n\n\n\n\n\nThe \naqueduct serve\n command properly exits and reports the error if the application fails to start.\n\n\nApplications that aren't use \naqueduct serve\n must be sure to take appropriate action when the application fails to start such that the runner of the script is aware of the failure. A standalone start script should be placed in the \nbin\n directory of a project.", 
            "title": "Deploying without aqueduct serve"
        }
    ]
}